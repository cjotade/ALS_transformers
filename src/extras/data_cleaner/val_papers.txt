Significant work been devoted to the study of the of the control system in Fig . , when arbitrarily complex are employed see , e .., , . However , the study of simple and efficient received much less attention . This is indeed one of the main for the present work . 
 . SCHEME 
 We seek simple , though effective , and . We propose to use the scheme shown in Fig . . In that figure , F is an filter , and , are for the moment abstract that are to exploit the history of their to generate their corresponding . More precisely , for every N , 
 s , , , 
 where and are possibly stochastic that may depend explicitly upon time , and where the range of is a collection of prefix free binary see , e .., . Note that the resulting control loop is well if F . 
 The scheme defined above is a restricted instance of much more general . Indeed , it is a special case of a scheme that the history of the plant output and of the received in an arbitrary causal fashion see , e .., , . 
 We will assume that the following : 
 Assumption scheme : The scheme in Fig . is such that , N , 
 a knowing and does not provide more knowledge about than just knowing , 
 the sequence of i ,, is known at the and is such that can be exactly from and vice . Also , 
 F and the corresponding initial state is an independent second order random variable . At each time the symbol a word of length measured in . We will be interested in the average rate and , accordingly , we define the average data rate as 
 , 
 provided the limit . is the average rate at which the are sent trough the channel and , as such , is a measure of the information flow at the physical level . 
 A key question that when considering any scheme is how to characterize lower on the achievable average data . To that end we define the following : Definition : Consider two . We define if the limit the average directed mutual information see also 
 . 
 N 
 We can now characterize lower on the average data rate for the scheme : 
 Theorem Lower on data : Consider the control architecture in Fig . and the specific scheme in Fig . , where and are as above . If a hold , then I . 
 Proof : See . 
 Theorem a physical quantity , namely average data rate , to an information theoretic quantity , namely average directed mutual information . It is important to note that a different bound on the average data rate would have arisen if we had considered and with different information available . 
 Theorem is a key one . However , it is not straightforward to characterize I unless one suitable on and or , equivalently , on the signal 
 q ,. 
 In the next section we will make some . Later , in Section , we will consider a simple instance of and and we will exploit the for the I is sometimes directed mutual information rate . 
  
 Fig . . Model of the control system under study . 
 case to provide upper on the associated to that specific scheme , without the . 
 V . THE CASE 
 As at the end of Section , we will assume in this section that the following : 
 Assumption : The noise see is an independent second order zero mean i . i .. sequence . The initial of all in Fig . plant and controller are independent second order random , jointly . 
 N 
 Consistent with the fact that the the way in which and are chosen , we will consider the variance of , say , as design parameter . Assumption , when combined with the control system in Fig . and the scheme in Fig . , the linear model in Fig . . 
 We will associate to every pair F , a vector defined via 
 . 
 As long as and hold variance , the control system in Fig . is if and only if is such that the feedback loop in Fig . is well internally stable in the standard deterministic sense see , e .., , . Thus , if we define 
 S , : the loop in Fig . is 
 internally stable and well , 
 then is equivalent to provided and hold ; see . It is easy to see that if and only if F is stable , and is an admissible controller for see , e .., . 
 Theorem we can now characterize average directed mutual information in the situation under study : 
 Corollary I under : 
 Consider the feedback loop in Fig . and assume that , and hold . If and , 
 then 
 I 
 a 
 , , , 
 where is the stationary of , is the stationary variance of , and is the stationary scheme signal to noise ratio . Equality in a if and only if is constant for every . 
 Proof : See . 
 Corollary an explicit expression for the average directed mutual information across the scheme in the considered situation . Also , it a relationship between the average directed mutual information across the scheme and the corresponding signal to noise ratio . In particular , it from that provided , and hold the scheme signal ratio to an upper bound on the average directed mutual information across it . Moreover , if is a constant , then we have equality in . Hence , under the constraint of constant , the scheme signal to noise ratio also the average directed mutual information across it . We will show below that , in our setting , one can restrict to be constant without loss of generality . Towards that goal , we start with the following theorem : 
 Theorem Directed mutual information for : Suppose that , and . Then : 
 There such that the feedback loop in Fig . is if and only if 
  
 I , pi . 
 i 
 Any I can be in a loop if one a stable and strictly proper F such that F is minimum phase , is any stable admissible controller for , and is made sufficiently large but finite . 
 Proof : See . 
 Theorem a bound on the directed mutual information across the considered whose satisfaction is necessary and sufficient to achieve . It also a characterization of the controller , the filter F , and the noise variance , that allow one to achieve any average directed mutual information arbitrarily close to the bound established . 
 We can use Theorem to immediately infer that , provided the in Theorem hold , 
  
 R pi 
 i 
 is a necessary condition that average data need to satisfy in order to guarantee when the scheme . We note that we have , for the class of considered plant , the bound on average data for derived in . However , we have not provided a proof of the of this bound . This issue will be in Section . 
 We next explore the minimal stationary scheme signal to noise ratio compatible with . This will enable us to state the main result of this section . 
 Theorem Signal to noise ratio for : Suppose that , and hold . 
 There such that the feedback loop in Fig . is if and only if the stationary scheme signal to noise ratio 
 . 
 Any can be in a loop if one as any stable admissible controller for , F is chosen as 
 F , where , , and is made sufficiently large but finite . 
 Proof : See . 
 From and we have the following corollary : 
 Corollary : Consider the feedback loop in Fig . and suppose that , and hold . A solution to the problem of finding the minimal stationary scheme signal to noise ratio that a solution to the problem of finding the minimal average directed mutual information across the scheme that . 
 Proof : See . 
 Corollary is one of the main in this paper . Indeed , by virtue of Theorem , Corollary one to conclude that the minimal signal to noise ratio for an immediate lower bound on the average data that allow one to achieve . The key to these in that we consider a architecture with sufficient of freedom . This one to make constant in the limit as , without constraining the minimum achievable directed mutual information across the scheme , or the corresponding minimal achievable signal to noise ratio a simple calculation based on the of Theorem this . We feel that the provided by these are of fundamental importance and , to the best of our knowledge , new . 
 Remark : The work also minimal signal ratio for stability . However , the of constrain themselves to the particular case F , which does not , in general , allow one to achieve the absolute minimal scheme signal to noise ratio in Theorem . Hence , it is not surprising that the in do not always suggest on average data that are consistent with the in , where that exploit the history used . N 
  
 Fig . . Entropy . 
 . UPPER ON ACHIEVABLE DATA 
 a necessary lower bound on the average data rate that one to guarantee . We have , however , provided no proof of the of this bound . It is well known see , that there exist that allow one to achieve with average data arbitrarily close to the bound in Section . However , since we have chosen a specific scheme that is much simpler than those in , , there no guarantee that we will be able to actually achieve the bound . This the study of upper on the average data rate for applicable to the scheme . In particular , we will use the in study achievable , when a memoryless entropy is used to generate the binary that are sent over the channel . 
 Fig . the architecture of an and its relationship to and in Fig . see , e .., . The is such that , 
 where is the dither signal which is known at both of the channel , a uniform defined via , i for , i , where is the quantization step . At each time instant , is memory and loss by the entropy coder explicit information about and the corresponding binary word is sent over the channel . Upon reception , the , which , the received symbol . Accordingly , the output becomes equal to . 
 Key of are the following : 
 Lemma see : Consider an as above . If is an independent sequence of i . i .. random , uniformly distributed on , then the in is distributed according to the distribution of , and the scalar mutual information between and I ; . 
  
 Remark : The proof in no feedback around the . If there is strictly causal feedback around it as in our case , then the same result see detailed proof in . N 
 The in Lemma state that , if one an appropriately , then the difference between the input and output of the , namely , becomes just an i . i .. source , uniformly distributed on each quantization interval as in the classical additive white noise model for quantization ; see , e .., , . This that the use of an one to achieve a the noise source considered in Section except for a different distribution . Therefore , it is sensible to expect that use of an appropriately designed average data close to the in Section . We will show below that this is indeed true . We note that , given the fact that the dither signal is known at both of the channel , choosing as in Lemma that the a i . e ., an is a valid instance of and in Fig . . 
 We are now ready to prove the main result of this paper : 
 Theorem Achievable : Consider the control system in Fig . with the scheme in Fig . , where and form an as above . Suppose that the memoryless entropy coder pair inside the see that , and hold , that the controller initial state is an independent second order random variable , and that the dither signal is an independent sequence of i . i .. random , uniformly distributed on . Then , if one as in Theorem Part ; see and 
 , with , then the resulting control system will be and the corresponding average data rate will be upper bounded as 
 , 
 where is a continuous and decreasing function of such that lim , lim . 
 Proof : See . 
 Remark are conservative : The upper bound for the average data rate in Theorem is conservative . Indeed , the by are usually closer to the entropy of the source than to the entropy of the source plus see , e .., .. As a consequence , the actual data will be usually close to the expression in 
 Theorem with the term . N 
 Theorem is the main result in this paper . It upper on the average data that guarantee and that are achievable with the scheme in Fig . , when and form a memoryless and when the plant model is strongly . If one as in Part of Theorem , and is chosen sufficiently large but finite , then one will be able to achieve a rate that is no more than per sample i . e ., . per sample away from the absolute bound in , . This additional rate is composed by two : the first one is due to the divergence of the distribution of quantization noise from , and the second one in the inefficiency of the loss less scheme employed to generate the binary . We feel that this extra rate is a fair price to be if one constrain oneself to the conceptually simple considered in this paper . 
 Remark : Note that the in Theorem rely on the in Section . In other , the when lower on the average data for stabilization were key when an actual scheme that a close to that bound . It is also worth that the quantization scheme considered in this paper a well studied building block in the Information Theory literature see , e .., , , . All the above in stark contrast to the approach in , e .., . N 
 . 
 In this paper , we have studied the mean square stabilization of strongly plant over bit rate limited . We have a simple scheme which only and an entropy . Within this setup , we have shown that the excess data , which derive from this reduced complexity scheme instead of an arbitrarily complex one , are no than . per sample . to more general and to performance related can be found in . 
  
  
 ﻿We present several novel identities and inequalities relating the mutual information and the directed information in systems with feedback. The internal blocks within such systems are restricted only to be causal mappings, but are allowed to be non-linear, stochastic and time varying. Moreover, the involved signals can be arbitrarily distributed. We bound the directed information between signals inside the feedback loop by the mutual information between signals inside and outside the feedback loop. This fundamental result has an interesting interpretation as a law of conservation of information flow. Building upon it, we derive several novel identities and inequalities, which allow us to prove some existing 
 information inequalities under less restrictive assumptions. Finally, we establish new relationships between nested directed informations inside a feedback loop. This yields a new and general data-processing 
 The notion of directed information introduced by Massey in [1] assesses the amount of information that causally “flows” from a given random and ordered sequence to another. For this reason, it has increasingly found use in diverse applications, from characterizing the capacity of channels with feedback [1]–[4], the rate distortion function under causality constraints [5], establishing some of the fundamental limitations in 
 networked control [6]–[11], determining causal relationships in neural networks [12], to portfolio theory and hypothesis testing [13], to name a few. 
 The directed information from a random  sequence xk to a random sequence yk is defined as 
 where the notation xi represents the sequence x(1),x(2),...,x(i). The causality inherent in this definition becomes evident when comparing it with the mutual information between xk and yk, given by 
 sequence xk present in y(i), given the past values yi-1. By contrast, in the conditional mutual informations in the sum of (1), only the past and current values of xk are considered, that is, xi. Thus, I(xk ? yk) represents the amount of information causally conveyed from xk to yk. 
 There exist several results characterizing the relationship between I(xk ? yk) and I(xk;yk). First, it is well known that I(xk ? yk) = I(xk;yk), with equality if and only if yk is causally related to xk [1]. A conservation law of mutual and directed information has been found in [14], which asserts that I(xk ? yk)+I(0*yk-1 ? xk) = I(xk;yk), where 0*yk-1 denotes the concatenation 0,y(1),... ,yk-1. 
 Given its prominence in settings involving feedback, it is perhaps in these scenarios where the directed information becomes most important. For instance, the directed information has been instrumental in characterizing the capacity of channels with feedback (see, e.g., [3], [4], [15] and the references therein), as well as the rate-distortion function in setups involving feedback [5], [9]–[11], [16]. 
 In this paper, our focus is on the relationships (inequalities and identities) involving directed and mutual informations within feedback systems, as well as between directed informations involving different signals within the corresponding feedback loop. In order to discuss some of the existing results related to this problem, it is convenient to consider the general feedback system shown in Fig. 1-(a). In this diagram, the blocks S1,...,S4 represent possibly non-linear and time-varying causal systems such that the total delay of the loop is at least one sample. In the same figure, r,p,s,q are exogenous random signals (scalars, vectors or sequences), which could represent, for example, any combination of disturbances, noises, random initial states or side informations. We note that any of these exogenous signals, in combination with its corresponding deterministic mapping Si, can also yield any desired stochastic causal mapping. 
 For the simple case in which all the systems {Si}4i=1 are linear time invariant (LTI) and stable, and assuming p,x,q = 0 (deterministically), it was shown in [17] that I(rk ? ek) does not depend on whether there is feedback from e to u or not. Inequalities between mutual and directed informations in a less restricted setup, shown in Fig. 1-(b), have been found in [7], [8]. In that setting (a networkedcontrol system), G is a strictly causal LTI dynamic system having (vector) state sequence, with x0 ,x(0) being the random initial state in its state-space representation. The external signal r (which could correspond to a disturbance) is statistically independent of s, the latter corresponding to, for example, side information or channel noise. Both are also statistically independent of x0. The blocks labeled E, 
 Figure 1. (a): The general system considered in this work. (b): A special case, corresponding to the closed-loop system studied in [7]. 
 D and f correspond to an encoder, a decoder and a channel, respectively, all of which are causal. The channel f maps sk and xk to y(k) in a possibly time-varying manner, i.e., y(k) = f(k,xk,sk). Similarly, the concatenation of the encoder, the channel and the decoder, maps sk and wk to u(k) as a possibly time-dependent function u(k) = ?(k,wk,sk). Under these assumptions, the following fundamental result was shown in [8, Lemma 5.1]: 
 By further assuming in [8] that the decoder D in Fig. 1-(b) is deterministic, the following Markov chain naturally holds, 
 which is found in the proof of [8, Corollary 5.3]. The deterministic nature of the decoder D played a crucial role in the proof of this result, since otherwise the Markov chain (3) does not hold, in general, due to the feedback from u to y. 
 Notice that both (2) and (4) provide lower bounds to the difference between two mutual informations, each of them relating a signal external to the loop (such as x0,rk) to a signal internal to the loop (such 
 which holds for the system in Fig. 1-(a) and appears in [1, Theorem 3] (and rediscovered later in [6, Lemma 4.8.1]), involves the directed information between two internal signals and the mutual information between the second of these and an external sequence. A related bound, similar to (4) but involving information rates and with the leftmost mutual information replaced by the directed information from xk to yk (which are two signals internal to the loop), has been obtained in [7, Lemma 4.1]: 
 8. This result relies on three assumptions: a) that the channel f is memory-less and satisfies a “conditional invertibility” property, b) a finite-memory condition, and c) a fading-memory condition, these two related to the decoder D (see Fig. 1). It is worth noting that, as defined in [7], these assumptions upon D exclude the use of side information by the decoder and/or the possibility of D being affected by random noise or having a random internal state which is non-observable (please see [7] for a detailed description of these assumptions). 
 The inequality (5) has recently been extended in [4, Theorem 1], for the case of discrete-valued random variables and assuming s ?? (r,p,q), as the following identity (written in terms of the signals and setup shown in Fig. 1-(a)): 
 Letting q = s in Fig. 1-(a) and with the additional assumption that (p,s) ?? q, it was also shown in [4, Theorem 1] that 
 for the cases in which u(i) = y(i) + q(i) (i.e., when the concatenation of S4 and S1 corresponds to a summing node). In [4], (7) and (8) play important roles in characterizing the capacity of channels with noisy feedback. 
 To the best of our knowledge, (2), (4), (5) (6), (7) and (8) are the only results available in the literature which lower bound the difference between an internal-to-internal directed information and an external-tointernal mutual information. There exist even fewer published results in relation to inequalities between two directed informations involving only signals internal to the loop. To the best of our knowledge, the only inequality of this type in the literature is the one found in the proof of Theorem 4.1 of [9]. The latter takes the form of a (quasi) data-processing inequality for directed informations in closed-loop systems, and states that 
 provided  q ?? (r,p) and if S4 is such that yi is a function of  (i.e., if S4 is conditionally invertible) ?i. In (9), 
 corresponds to the causally conditioned directed information defined in [2]. Inequality (9) plays a crucial role [9], since it allowed lower bounding the average data rate across a digital error-free channel by a directed information. (In [9], q corresponded to a random dither signal in an entropy-coded dithered 
 In this paper, we derive a set of information identities and inequalities involving pairs of sequences (internal or external to the loop) in feedback systems. The first of these is an identity which, under an independence condition, can be interpreted as a law of conservation of information flows. The latter identity is the starting point for most of the results which follow it. Among other things, we extend (4) and (6) to the general setup depicted in Fig. 1-(a), where none of the assumptions made in [7]–[9] (except causality) needs to hold. Moreover, we will prove the validity of (9) without assuming the conditional invertibility of S4 nor that q ?? (r,p). The latter result is one of four novel data-processing inequalities derived in Section III-B, each involving two nested directed informations valid for the system depicted in Fig. 1-(a). The last of these is a complete closed-loop counterpart of the traditional open-loop dataprocessing inequality. 
 The remainder of this paper begins with a description of the systems under study and the extension of Massey’s directed information to the case in which each of the blocks in the loop may introduce an arbitrary, non-negative delay (i.e., we do not allow for anticipation). The information identities and inequalities are presented in Section III. For clarity of the exposition, all the proofs are deferred to Section IV. A brief discussion of potential applications of our results is presented in Section V, which is followed by the conclusions in Section VI. 
 We begin by providing a formal description of the systems labeled S1 ...S4 in Fig. 1-(a). Their inputoutput relationships are given by the possibly-varying deterministic mappings 
 e(i) = S1(ui-d1(i),ri),	(11a) x(i) = S2(ei-d2(i),pi),	(11b) y(i) = S3(xi-d3(i),si),	(11c) u(i) = S4(yi-d4(i),qi),	(11d) 
 where r,p,s,q are exogenous random signals and the (possibly time-varying) delays d1,d2,d3,d4 ? {0,1,...} are such that 
 That is, the concatenation of S1,...,S4 has a delay of at least one sample. For every i ? {1,...,k}, r(i) ? Rnr(i), i.e., r(i) is a real random vector whose dimension is given by some function nr : {1,... ,k} ? N. 
 As stated in [1], the directed information (as defined in (1)) is a more meaningful measure of 
 the flow of information between xk and yk than the conventional mutual information I(xk;yk) = 
 discrete-valued sequences, input and output, respectively, of a forward channel, and if there exists strictly causal, perfect feedback, so that x(i) = y(i - 1) (a scenario utilized in [1] as part of an argument in favor of the directed information), then the mutual information becomes 
 I(xk;yk) = H(yk) - H(yk |xk) = H(yk) - H(yk |yk-1) = H(yk) - H(y(k)|yk-1) = H(yk-1). 
 Thus, when strictly causal feedback is present, I(xk;yk) fails to account for how much information about xk has been conveyed to yk through the forward channel that lies between them. 
 It is important to note that, in [1] (as well as in many works concerned with communications), the forward channel is instantaneous, i.e., it has no delay. Therefore, if a feedback channel is utilized, then this feedback channel must have a delay of at least one sample, as in the example above. However, when studying the system in Fig. 1-(a), we may need to evaluate the directed information between signals xk and yk which are, respectively, input and output of a strictly casual forward channel (i.e., with a delay of at least one sample), whose output is instantaneously fed back to its input. In such case, if one further assumes perfect feedback and sets x(i) = y(i), then, in the same spirit as before, 
 As one can see, Massey’s definition of directed information ceases to be meaningful if instantaneous feedback is utilized. 
 It is natural to solve this problem by recalling that, in the latter example, the forward channel had a delay, say d, greater than one sample. Therefore, if we are interested in measuring how much of the information in y(k), not present in yi-1, was conveyed from xi through the forward channel, we should look at the mutual information I(y(i);xi-d |yi-1), because only the input samples xi-d can have an influence on y(i). For this reason, we introduce the following, modified notion of directed information 
 Definition 1 (Directed Information with Forward Delay): In this paper, the directed information from 
 xk to yk through a forward channel with a non-negative time varying delay of d(i) samples is defined as 
 For a zero-delay forward channel, the latter definition coincides with Massey’s. 
 Likewise, we adapt the definition of causally-conditioned directed information to the definition 
 Before finishing this section, it is convenient to recall the following identity (a particular case of the chain rule of conditional mutual information [18]), which will be extensively utilized in the proofs of our results: 
 We begin by stating a fundamental result, which relates the directed information between two signals within a feedback loop, say x and y, to the mutual information between an external set of signals and y: 
 This fundamental result, which for the cases in which s ?? (p,q,r) can be understood as a law of conservation of information flow, is illustrated in Fig. 2. For such cases, the information causally conveyed from x to y equals the information flow from (q,r,p) to y. When (p,q,r) are not independent of s, part of the mutual information between (p,q,r) and y (corresponding to the term can be thought of as being “leaked” through s, thus bypassing the forward link from x to y. This provides an intuitive interpretation for (14). 
 Figure 2. The flow of information between exogenous signals (p,q,r) and the internal signal y equals the directed information from xk to yk when s ?? (p,q,r). 
 Remark 1: Theorem 1 implies that I(xk ? yk) is only a part of (or at most equal to) the information “flow” between all the exogenous signals entering the loop outside the link x ? y (namely (q,r,p)), and 
 y. In particular, if (p,q,r) were deterministic, then I(xk ? yk) = 0, regardless of the blocks S1,...,S4 
 Remark 2: By using (13),. Then, applying Theorem 1, we recover (5), whenever s ?? (q,r,p). Thus, [1, Theorem 3] and [6, Lemma 4.8.1]) can be obtained as 
 The following result provides an inequality relating I(xk ? yk) with the separate flows of information 
 Theorem 2 shows that, provided (p,q,r) ?? s, I(xk ? yk) is lower bounded by the sum of the individual flows from all the subsets in any given partition of , to yk, provided these subsets are mutually independent. Indeed, both theorems 1 and 2 can be generalized for any appropriate choice of external and internal signals. More precisely, let T be the set of all external signals in a feedback system. Let a and ß be two internal signals in the loop. Define Ta,ß ? T as the set of exogenous signals which are introduced to the loop at every subsystem Si that lies in the path going from a to ß. Thus, for any ? ? T \ Ta,ß, if Ta,ß ?? T \ Ta,ß, we have that (14) and (15) become 
 To finish this section, we present a stronger, non-asymptotic version of inequality (6): 
 Theorem 3: In the system shown in Fig. 1-(a), if (r,p,q,s) are mutually independent, then	(17) 
 As anticipated, Theorem 3 can be seen as an extension of (6) to the more general setup shown in Fig. 1- 
 (a), where the assumptions made in [7, Lemma 4.1] do not need to hold. In particular, letting the decoder D and x0 in Fig. 1-(b) correspond to S4 and pk in Fig. 1-(a), respectively, we see that inequality (15) holds even if D and E have dependent initial states, or if the internal state of D is not observable [19]. 
 Theorem 3 also admits an interpretation in terms of information flows. This can be appreciated in the diagram shown in Fig. 3, which depicts the individual full-turn flows (around the entire feedback loop) stemming from q, r and p. Theorem 3 states that the sum of these individual flows is a lower bound for the directed information from x to y, provided q,r,p,s are independent. 
 Figure 3.	A representation of the three first information flows on the right-hand-side of (18). 
 This section presents three closed-loop versions of the data processing inequality relating two directed informations, both between pairs of signals internal to the loop. As already mentioned in Section I, to the best of our knowledge, the first inequality of this type to appear in the literature is the one in Theorem 4.1 in [9] (see (9)). Recall that the latter result stated that I(xk ? yk k qk) = I(xk ? uk), requiring S4 to be such that yi is a deterministic function of  and that q ?? (r,p). The following result presents another inequality which also relates two nested directed informations, namely, I(xk ? yk) and I(ek ? yk), but requiring only that s ?? (q,r,p). 
 Notice that Theorem 4 does not require p to be independent of r or q. This may seem counter-intuitive upon noting that p enters the loop between the link from e to x. 
 The following theorem is an identity between two directed informations involving only internal signals. It can also be seen as a complement to Theorem 4, since it can be directly applied to establish the relationship between I(ek ? yk) and I(ek ? uk). 
 Notice that, by requiring additional independence conditions upon the exogenous signals (specifically, q ?? s), Theorem 5 (and, in particular, (21)) yields 
 which strengthens the inequality in [9, Theorem 4.1] (stated above in (9)). More precisely, (22) does not require conditioning one of the directed informations and holds irrespective of the invertibility of the mappings in the loop. 
 A closer counterpart of (9) (i.e., of [9, Theorem 4.1]), involving I(xk ? yk k qk), is presented next. 
 Thus, provided (q,s) ?? (r,p), (23) yields that (9) holds regardless of the invertibility of S4, requiring instead that, for all i ? {1,...,k}, any statistical dependence between qk and si resides only in qi (i.e., that Markov chain (24) holds). 
 The results derived so far relate directed informations having either the same “starting” sequence or the same “destination” sequence. We finish this section with the following corollary, which follows directly by combining theorems 4 and 5 and relates directed informations involving four different sequences internal to the loop. 
 Corollary 1 (Full Closed-Loop Directed Data Processing Inequality): For the system shown in Fig. 1- 
 Equality holds in (a) if, in addition, r ?? p (i.e., if (q,r,p,s) are mutually independent).	N 
 To the best of our knowledge, Corollary 1 is the first result available in the literature providing a lower bound to the gap between two nested directed informations, involving four different signals inside the feedback loop. This result can be seen as the first full extension of the open-loop (traditional) dataprocessing inequality, to arbitrary closed-loop scenarios. (Notice that there is no need to consider systems with more than four mappings, since all external signals entering the loop between a given pair of internal signals can be regarded as exogenous inputs to a single equivalent deterministic mapping.) 
 Proof of Theorem 1: It is clear from Fig. 1-(a) and from (11) that the relationship between r, p, q, s, x and y can be represented by the diagram shown in Fig. 4. From this diagram and Lemma 1 (in the appendix) it follows that if s is independent of (r,p,q), then the following Markov chain holds: 
 Figure 4. Representation of the system of Fig. 1-(b) highlighting the dependency between p, q, r, s, x and y. The dependency on i of the delays d1(i),...,d4(i) is omitted for clarity. 
 In the above, (a) follows from the fact that, if yi-1 is known, then xi-d3(i) is a deterministic function of ?i. The resulting sums on the right-hand side of (28a) correspond to I(qk,rk,pk ? yk)-I(qk,rk,pk ? yk k xk), and thereby proving the first part of the theorem, i.e., the equality in (14). In turn, (b) stems from the non-negativity of mutual informations, turning into equality if s ?? (r,p,q), as a direct consequence of the Markov chain in (26). Finally, equality holds in (c) if s ?? (q,r,p), since y depends causally upon 
 ?. This shows that equality in (14) is achieved if s ?? (q,r,p), completing the proof. 
 Proof of Theorem 2: Apply the chain-rule identity (13) to the RHS of (14) to obtain 
 where the second equality follows since . The result then follows directly by combining (30) with (29) and (14). 
 where (a) is due to Theorem 5, (b) follows from Theorem 1 and the fact that (s,q) ?? (r,p) and (c) from the chain rule of mutual information. For the second term on the RHS of the last equation, we have 
 where (a) holds since r ?? p, (b), (d) and (e) stem from the chain rule of mutual information (13), 
 and (c) is a consequence of the Markov chain e which is due to the fact that ek = S1(uk-d1(k),rk). Finally, (f) is due to the Markov chain r, which holds because r ?? (p,s,q) as a consequence of Lemma 1 in the appendix (see also Fig. 1-(a)). Substitution of (39) into (33) yields (18), thereby completing the proof. 
 Proof of Theorem 4: Since (p,q,r) ?? s, we can apply (5) (where now (q,r) plays the role of r), and obtain 
 where (a) follows from Theorem 1, which also states that equality is reached if and only if (r,p,q) ?? s. In turn, (b) is due to the fact that uk is a deterministic function of q. Equality (c) holds if and only if (r,p) ?? q. Finally, from Lemma 1 (in the appendix), (d) turns into equality if q ?? (r,p,s). Substitution of (42) into (45) yields (21), completing the proof. 
 Proof of Theorem 6: We begin with the second part of the theorem, proving the validity of the equality (†) in (23). We have the following: 
 where equality holds in (a) if and only if the Markov chain si ? qi ? (ri,pi) holds for all i ? {1,... ,k} (as a straightforward extension of Lemma 1). In our case, the latter Markov chain holds since we are assuming (qk,sk) ?? (rk,pk). In turn, (b) stems from the fact that, for all i ? {1,... ,k}, xi-d3(i) is a function of yi-1,qi,ri,pi. To prove (c), we resort to (13) and write 
 From the definitions of the blocks (in (11)), it can be seen that, given qi, the triad of random sequences 
 is a deterministic function of (at most) . Recalling that  and that q (see (24)), it readily follows that , and thus each of the mutual 
 informations on the right-hand-side of (55) is zero. To verify the validity of (d), we use (13) and obtain 
 last term in this chain of inequalities was shown to be zero in the proof of (d). Equality holds in (e) if 
 and only if , a Markov chain which is satisfied in our case from the fact that (q,s) ?? (r,p) and from Lemma 1. 
 Finally, since (rk,pk) ?? (qk,sk), we have that the chain of equalities from (43) to (44) holds, from which we conclude that 
 Inserting this result into (54) and invoking Theorem 1 we arrive at equality (†) in (23). 
 To prove the first equality the (23), it suffices to notice that I(xk ? yk |qk) corresponds to the sum on the right-hand-side of (53), from where we proceed as with the first part. This completes the proof of the theorem. 
 Information inequalities and, in particular, the data-processing inequality, have played a fundamental role in Information Theory and its applications [20]–[27]. It is perhaps the lack of a similar body of results associated with the directed information (and with non-asymptotic, causal information transmission) which has limited the extension of many important information-theoretic ideas and insights to situations involving feedback or causality constraints [5], [28]. Two such areas, already mentioned in this paper, are the understanding of the fundamental limitations arising in networked control systems over noiseless digital channels, and causal rate distortion problems. In those contexts, causality is of paramount relevance an thus the directed information appears, naturally, as the appropriate measure of information flow (see, for example, [5], [9], [11], [29], [30] and [7]). We believe that our results might help gaining insights into the fundamental trade-offs underpinning those problems, and might also allow for the solution of open problems such as, for instance, characterizing the minimal average data-rate that guarantees a given performance level [10] (an improved version of the latter paper, which extensively uses the results derived here, is currently under preparation by the authors). On a different vein, directed mutual information plays a role akin to that of (standard) mutual information when characterizing channel feedback capacity (see, e.g., [3], [4] and the references therein). Our results may also play a role in expanding the understanding of communication problems over channels used with feedback, particularly when including in the analysis additional exogenous signals such as a random channel state, interference and, in general, any form of side information. Thus, we hope that the inequalities and identities presented in Section III may help in extending results such as dirty-paper coding [31], watermarking [32], distributed source coding [25], [26], [33], [34], multi-terminal coding [35], [36], and data encryption [37], to scenarios involving causal feedback. 
 In this paper, we have derived fundamental relations between mutual and directed informations in general discrete-time systems with feedback. The first of these is an inequality between the directed information between to signals inside the feedback loop and the mutual information involving a subset of all the exogenous incoming signals. The latter result can be interpreted as a law of conservation of information flows for closed-loop systems. Crucial to establishing these bounds was the repeated use of chain rules for conditional mutual information as well as the development of new Markov chains. The proof techniques do not rely upon properties of entropies or distributions, and the results hold in very general cases including non-linear, time-varying and stochastic systems with arbitrarily distributed signals. Indeed, the only restriction is that all blocks within the system must be causal mappings, and that their combined delay must be at least one sample. A new generalized data processing inequality was also proved, which is valid for nested directed informations within the loop. A key insight to be gained from this inequality was that the further apart the signals are in the loop, the lower is the directed information between them. This closely resembles the behavior of mutual information in open loop systems, where it is well known that any independent processing of the signals can only reduce their mutual information. 
 Lemma 1: In the system shown in Fig. 5, the exogenous signals r,q are mutually independent and 
 Figure 5.	Two arbitrary causal systems S1,S2 interconnected in a feedback loop. The exogenous signals r,q are mutually 
 for every possible pair of sequences yk,uk, the sets ?yk,uk , {rk : yk = S1(rk,uk)} and fyk,uk , 
 ﻿In this paper we review the previously proposed methods for successive compute-and-forward and discuss about their incompleteness through some examples. Then we present a comprehensive formulation for multi-step successive interference cancellation problem through the asymmetric successive computeand-forward strategy. It is shown that the generalized formulation includes the previous approaches. 
 Interference management in relay networks is one of the most important topics in wireless communications. Among the various methods proposed for relay networks named decodeand forward, compress-and-forward, amplify-and-forward, and compute-and-forward (see [1]-[2] and references therein), the later one has attracted interesting attention for the problem of interference harnessing in noisy relay networks, especially when it is more helpful to decode linear combinations of codewords rather than individually decoding them. In [2][10], several approaches have been presented for decoding integer/non-integer linear combinations of codewords in the networks with equal/unequal power constraints, and with symmetric/asymmetric channel gains conditions. 
 In [2], a compute-and-forward strategy (CAF) has been proposed for Gaussian relay networks with equal power constraints and asymmetric channel gains based on nested lattice codes [3]. The receiver given sufficiently many linear combinations, can decode integer-linear combinations of transmitted codewords and solve for its desired messages. To obtain higher rates, receivers can recover those linear equations which are closer to the channel fading coefficients. This strategy simultaneously provides protection against noise and the opportunity to exploit interference for cooperative gains [2]. On the other hand, in [4], a scheme has been proposed for Gaussian relay networks with unequal power constraints and symmetric channel gains based on nested lattice codes and compute an achievable multi-cast rate within a constant gap to the capacity. There is one point here: in [2], the authors assumed equal power constraints and stated that unequal power constraints can be incorporated by scaling the channel coefficients appropriately. Here with an example we show that, when one does this, the results of [2] yields a smaller rate region than that found in [4]. 
 In [5] successive CAF strategy (SCAF) has been presented for the Gaussian relay network with the same assumption as in [2]. In this method after decoding a linear combination of transmitted codewords, the receiver can combine it with its channel observation to obtain a new effective channel which is better for decoding the next targeted linear combination. 
 In [6] an asymmetric CAF has been proposed for MIMO networks with unequal power constraints and asymmetric channel gains based on nested lattice codes. In [7], Gaussian relay networks with unequal power constraints and asymmetric channel gains has been considered as a special case of the model presented in [?]. They also consider successful recovery of the individual messages at the final destination in addition to the relay recovery. 
 In [8] and [9] a modified asymmetric CAF has been presented. This method utilizes scaling factors to decode integer linear combinations of transmitted codewords. The use of scaling factors in fact is equivalent to decoding non-integer linear combinations of lattice codewords and it allows different users to have different coding rates, so by appropriately adjusting those factors, different points on the boundary of the rate region can be achieved. Also, in [10] the idea of decoding non-integer linear combinations of lattice codewords has been presented. Their method can be considered as a special case of the methods of [8] and [9] as well. 
 In this correspondence we first give a brief review of the previous works about SCAF. Moreover we discuss about their incompleteness of some methods through some examples. Then we present our generalized formulation for the successive interference cancellation problem in asymmetric Gaussian relay networks through the asymmetric successive computeand-forward strategy. More specifically, we extend the method of [7] to N-step SCAF and also we take advantage of scaling factors to reach to a comprehensive formulation for the asymmetric SCAF strategy. It is shown that the generalized formulation includes the previous approaches. 
 The paper is organized as follows: In Section II the system model is defined. In Section III the strategies of [2][10] are reviewed and discussed. In Section IV our main results, the extended asymmetric successive compute-andforward approach for general Gaussian relay networks is introduced. Some concluding remarks are provided in Section 
 set of integers   denotes the real-valued x rounded up to the nearest integer value. Vectors are shown with boldface letters. 
 In this paper we consider a real Gaussian relay network with L transmitters and M relays. It is the same network as has been used in [2], but here we consider the assumption of unequal power constraints and asymmetric channel gains. Each relay in the network, indexed by m = [1;M], observes a noisy linear combination of the transmitted signals through 
 where hml ? R are the channel gains and zm is i.i.d. Gaussian noise, zm ~ N(0,In×n). Let hm = [hm1,··· ,hmL]T denote the vector of channel gains from the L users to the relay m. For all , each channel input x -length sequence subject to the average power constraint P, i.e.,  . 
 The channel gains are assumed to be known and constant. In this document we only consider communication between the transmitter and the relays. 
 In this section we review and compare the works of [2], [4]-[10] and discuss about their performances. 
 In [2] and [5], achievable rate regions have been proposed for real-valued AWGN networks based on the successive compute-and-forward strategy. The combination of those results is rewritten in the following theorem. 
 Theorem 1. For the defined system model with equal power constraints P and equation gain vectors am,bm ? ZL, where non-zero am = [am1,··· ,amL]T, bm = [bm1,··· ,bmL]T, with m ? [1;M], the following computation rates are achievable 
 As mentioned in [5], the interpretation of (4) is that the relay can first target a linear combination, am, that is easy to decode and then use it to create a better effective channel for decoding the second linear combination, bm. 
 In [4], a class of real Gaussian networks with one receiver and L users having unequal power constraints P1,··· ,PL and symmetric channel gains has been considered. Channel gains have been assumed to be one. An achievable rate region has been proposed based on the compute-and-forward strategy. It is rewritten in the following theorem, 
 is achievable for user  , with bounded error probability which goes to zero as n tends to infinity. 
 In [2] equal power constraints have been allocated to the users in the network. It has been declared in [2] that in the case of unequal power constraints, channel gains can be scaled in order to get equal power constraints. Next by the aid of two examples, we show that the rates that can be achieved by the method of [2] with the scaling of channel gains are smaller than those obtained by the method of [4]. 
 Example 1: Consider a network with M = 1, L = 2, unequal power constraint P1 = P2, and channel gains h1 = h2 = 1. Theorem 2 yields the following achievable rate for users : 
 If we do channel gain scaling as , we get to equal power constraint P1 for both users. Substituting these values along with a = [1 1] (which maximizes 
 (6) is larger than (7), e.g., assume i = 1 in (6), then from the assumption P1 = P2, it is concluded that  . 
 With another example, we show that the rate region of [5] with equal power constraints and asymmetric channel gains, is smaller than the one obtained from [4] by scaling the power constraints accordingly while leaving unit channel gains. 
 Example 2: Consider a network with M = 1, L = 2, P1 = P2 = 1, and h1 = h2. Substituting them in Theorem 1 along with a = [1 1] results, 
 If we do scaling in order to obtain symmetric channel gains equal to 1, the scaled power constraints will be P1 = h21 and P2 = h22. With this, Theorem 2 yields the following rate for user i = 1, 
 since (h22 + h21)/h21 < 2 subject to h1 = h2. So as before, it is seen that (9) results in a higher rate R1 in comparison with 
 Thus, the method of [5], scaling channel gains with power constraints, achieves smaller rate region than that obtained in [4] in the case of unequal power constraints. 
 In [?] and [7], an asymmetric compute-and-forward is presented which solves the mentioned problem by appropriately defining fine and course lattices for each user. Also in [8], by the aid of scaling factors, the modified equation has been presented which can reach to the rate of [4] for the case of unequal power constraints. 
 In [?] a Gaussian MIMO network has been considered which consists of L transmitters and a receiver with Nr antennas which observes an Nr×n dimensional channel output Y   Z, where h  is the channel gain between th transmitter and the receiver, Z is componentwise i.i.d. white noise with distribution N(0,1), and x  subject to the power constraint P. Let H = [h1,··· ,hL] and P = diag[P1,··· ,PL]. The theorem is as follows, 
 Theorem 3. For the defined system model and equation coefficient vectors am ? ZL, with m ? [1;M] where am = [am1,··· ,amL]T, the following computation rate is 
 and P denotes the vector of power constraints of the users as P = [P1,P2,··· ,PL]. 
 In Section IV we state the extension of (12) to N-step asymmetric successive compute-and-forward by the same method as used in [5] and also we consider scaling factors as done in [8] and [9]. 
 In [8] and [9] by introducing real scaling factors ßi and decoding the resulting non-integer linear combination of codewords, one obtains additional flexibility for controlling the individual message rates of different users. Corresponding results of interest from [8] and [9] can be summed up in the following theorem, 
 Theorem 4. Let ß1,··· ,ßL be L nonzero real numbers. For the defined system model in Section II with equal power constraint P and equation coefficient vectors am ? ZL, where am = [am1,··· ,amL]T, the computation rate tuple   is achievable if 
 The main idea behind this result relies on the observation that the transmitted lattice codewords do not have to lie in the lattice which is used for encoding at the transmitters. 
 As an example in [8], the Gaussian two-way relay channel (GTRC) has been considered where two users have unequal power constraints P1 and P2 and the channel gain vector to the relay is unity. The relay has power constraint PR. All noises are Gaussian with unit variance. They obtain the following achievable rate region for the GTRC, where the relay is assumed to decode a linear combination of user codewords tk of the form   where  , 
 [vP1,vP2]/vP, and   for all  in (13). As it is seen, the previously mentioned problem for unequal power constraints is solved here by the aid of ß’s, but it is not obviously a straightforward substitution of channel vector and ß’s in the equation of the rate region. In the next section we propose a straightforward formulation which solves this problem. 
 In [9], the multi-step successive interference cancellation strategy has been introduced for decoding more than one linear combination of codewords in multiple access networks. The method is based on the matrix algebra consider general equation gain vectors which is different from the method of [5] which is based on successive interference cancellation and consider orthogonal equation gain vectors. 
 In [10] a network with M = 1 relay and L = 2 users has been considered. They’ve used the idea decoding the non-integer linear combination of codewords instead of using scaling factors and they have obtained critical points on the rate region where the rate of one user coincides the cut-set bound. For GTRC the method of [10] is actually a special case of [8] and [9] by considering  . 
 In this section we propose a straightforward and comprehensive equation for multi-step asymmetric successive compute-and-forward strategy. We assume unequal power constraints and asymmetric channel gains.Our main result for N-step asymmetric successive compute-and-forward strategy is presented in the following theorem: 
 Theorem 5. For the system model with unequal power constraint P1,··· ,PL, consider non-zero equation coefficient vectors ami ? ZL, where ami = [ami,1,··· ,ami,L]T and i ? [1;N], and let ß1,··· ,ßL be L nonzero real numbers. The computation rate tuple (R1,··· ,RL) is achievable where 
 Corollary 1. For N = 1, i.e., single step decoding of integer linear combination of transmitted codewords, the rate of (16)- 
 Remark 2: One can see that by scaling channel gains with power constraints, i.e., substituting hm with hpm, and also substituting ß with   in (13), (22) is obtained. But in spite of the formal equivalence of (22) and (13) in the case of unequal power constraints, there is a difference between the conceptual basis of these equations. As explained in the proof of Theorem 5 in Appendix B, in the strategy of (13), the transmitted codewords of different users have equal powers independent of what the values of ß’s are, but in the strategy of (22), the users transmit their own real power values. 
 Corollary 2. For N = 2, i.e., 2-step interference cancelation, the rate of (16)-(17) reduces to 
 Remark 1: (Equal power constraints and asymmetric channel coefficients) By considering equal power constraints P1 = P2 = ··· = PL = P, (24) reduces to (13), and also by considering  for all , and ˜am2 = bm, 
 Remark 2: (Unequal power constraints and symmetric channel coefficients) Assume  for all , and h = a = I1×L, then  . 
 As it is seen from the above remarks, our proposed formulation is capable of manipulating both unequal power constraints and asymmetric channel coefficients conditions without the aid of scaling factors. 
 In the following corollary we obtain a more reduced form for (24) and (25) when L = 2 and M = 1, e.g., the network with one relay and less than three transmitters. 
 Corollary 3. For the network with L = 2, M = 1, the rate of Theorem 5 for 2-step successive interference cancelation, i.e. 
 Remark: For L = 2, P1 = P2 = P, i.e., equal power constraints, a1 = [a1,a2] and a2 = [b1,b2], (26) and (27) reduces to [9, (11)-(13)]. 
 In this paper we studied the asymmetric multi-step successive compute-and-forward scheme for interference management in Gaussian relay networks with unequal power constraints and asymmetric channel gains. We first reviewed the previous proposed methods for this scheme and discussed about their inefficiencies through some examples. Then we presented a comprehensive formulation for asymmetric multistep successive compute-and-forward scheme by taking advantage of all the benefits of the previous works together. It is shown that the proposed approach includes the previously proposed schemes. 
 Proof:   Let ?1,...,?M be M nested lattice codes which are simultaneously good and ?cm denotes the coarsest lattice among them. The equivalent noise variance at the relays, which will be defined later in the proof, determine the order of this lattice chain. Larger noise variance corresponds to a coarser lattice. Additionally, L nested lattices are constructed such that   which are simultaneously “good” with second moments , where ß is a positive number. At each transmitter , the codebook  is constructed, where denotes the Voronoi region of  , and   denotes the number of the relay which results in lower achievable rates among the relays which should decode the message of transmitter . The transmitter , sends 
 where is a random vector uniformly distributed in  which is called as a dither. x is independent of t and uniformly distributed in , so it has average power P for all 
 The receiver tries to retrieve Tm1 from ˜ym1 instead of recovering  , for all . Note that there is a one to one mapping between , so decoding 
 is equivalent to decoding  . For decoding, the receiver consider Euclidean lattice decoding which finds the closest lattice point ˜ym1 in   in which Tm1 lies, i.e., 
 so the lattice decoding of transmitter , is successful if R satisfies the following relation, 
 for all , where   denotes the variance of the effective noise z˜m1 and it is obtained as follows: 
 In the following, we obtain the rates for the successive decoding of other possible integer combinations of transmitted codewords. To decode the ith integer sum with coefficient vector ami, where i = [2;N], the relay removes the projection of  onto ym1 from ym1 as follows: 
 At last the relay decodes the linear combination with coefficient vector ˜ami by estimating 
 By repeating the same steps as shown in (28) and substituting  with with  , and am1 with ami, it can be shown that the following rate is achievable for all 
 First we introduce the following lemma which will be used in the proof of Corollary 3. 
 Lemma 1. The following identity is satisfied for arbitrary n-dimensional real vectors a = [a1,a2,··· ,an], b = [b1,b2,··· ,bn] and c = [c1,c2,··· ,cn], with n = 2. 
 By substituting the elements of the vectors a, b, and c in the right-hand side of (42), we have 
 . So the total number of terms in the first and second line of (43) are (3n2(n-1)-2n3 +2n) which is equal to n(n - 1)(n - 2) and is zero for n = 2. 
 is n2(n - 1), the number of terms in 2  i=1 j=1 k=1 i i j j k k is 2n3 - 2n when i = j = k is not satisfied, so the number of remaining terms in (43) is (3n2(n - 1) - 2n3 + 2n) which is equal to zero for n = 2. 
 Proof: We must show that (24) and (25) reduces to (26). It is easy to see that (24) is exactly the same as the first term of (26). Now we simplify (25) to obtain the second term of 
 ﻿ Fundamental in control have been for the last with many stability , from channel transmission minimal rate based on information theory , to minimal signal to noise . For the latter , it been confirmed early on that the usual increase the minimal for stability , such as unstable plant , non minimum phase , time delay , together with new such as communication channel and colored transmission noise . In this work we specifically propose two to completely avoid the effect of on the minimal for time . The first approach from the observation that the controller that the minimal for a minimum phase plant in , all its outside the unit circle . Such observation allow then to characterize this set of as candidate of alternative plant with the same unstable , which in turn will not increase the minimal for stability above the expression only by the plant unstable . Our second approach the set of possible that do not increase the limitation to any location , by the synthesis of a two degree of freedom linear time invariant controller solution that the minimal for stability only by the plant unstable . 
 Index Control over , Linear , control , Optimal control . 
 Introduction 
 N 
 control have been a subject of research for at least the last two , with review available in , . on fundamental on stability in this framework were for example in , . performance have also been extended information theory to include disturbance rejection , reference and , as in , . 
 A different approach for is , on the other hand , in where an framework for stability of feedback , both in continuous time and discrete time , is based on the channel model signal to noise ratio . The fundamental limitation in is as an lower bound on the channel 
 M . is with the de ´ ´ ,´ Mar ´ , Chile . 
 A .. is with the de ´ El ´ , de ´, Chile . : 
 The thankfully acknowledge the support from , through Basal Project . 
 for the stabilization of an unstable plant model by of output feedback over a memoryless additive white noise communication channel , such as the case in Figure . More so , in 
 r 
 Fig . . One degree of freedom , general configuration . 
 recent it been shown that for second order statistics , control over a power constrained erasure channel are equivalent to control subject to an constraint , . Furthermore , the equivalence , in a second order sense , been extended to include fading in . As a result , the approach been able to capture the most important communication and characterize their impact on fundamental , as well as performance , see also for example , . More so , the approach also a reinterpretation of the classic control feedback loop by of the reference to disturbance ratio , , , which performance as the trade off between reference and closed loop input disturbance rejection . 
 A common observation , in particular in , is that the limitation for output feedback stabilization of an unstable plant model with , is strictly greater than the one for state feedback emphasis added by the present . As an alternative the of propose a linear time alternative control scheme to eliminate the effect of the on the for . 
 Our first contribution in this work is to explicitly characterize the one degree of freedom , see Figure , optimal controller that the minimal in . Furthermore we will characterize the of such controller and prove that these are all outside the unit circle . To the best of our knowledge such a characterization is novel . The controller outside the unit circle are then by definition . As a result , if the of an alternative plant model with the same unstable belong to this specific set of , then both , output feedback and state feedback , will coincide thus the effect of over the limitation . 
 Our second contribution the set of potential to an arbitrary set , by and a specific two degree of freedom controller solution . The use of a two degree of freedom controller been before in order to eliminate the effect of in different the approach , see for example , . The contribution here instead is the explicit definition of a two degree of freedom controller to avoid the deleterious effect of arbitrary many , the minimal for stability only by the plant unstable . A preliminary result for first order plant was in . 
 As a result of our we update the common observation about minimal and as : the for stabilization of an unstable plant model with , via output feedback , is greater or equal than the for state feedback , in an setting . 
 This paper is organized as : Section the behind the minimal in . Section characterize the structure for the optimal controller that the minimal for an unstable plant model and the zero for this optimal controller . Section the synthesis of the two controller that the effect of any arbitrary plant zero . We conclude the exposition in final and possible future research . 
  
 In this section we present the general plant model , and summarize the discrete time for solution . 
 A . 
 Plant model : the plant model is defined as 
 , 
 where i , i are and distinct plant model . The term is the stable , minimum phase , part of . The relative degree the choice of is to avoid a plant time delay that would further increase the later minimal for stability . Channel model : we consider here the memoryless channel model , see for example Figure . This type of channel is by the channel input power and its channel additive noise process . Channel additive noise process : The channel additive noise a zero mean i . i .. white noise process with variance s . 
 : The assumed to be zero , that is we consider here only a regulation problem , not a problem . 
 B . Minimal for Stability 
 Consider the feedback loop in Figure where the problem is to stabilize an unstable plant subject to a channel power constraint . From Figure we observe that the closed loop between the channel input u and the exogenous given by u , with the closed loop complementary sensitivity function . The channel input is to satisfy the power , for some input power level . We assume that the closed loop feedback system is stable , in the sense that for any distribution of initial , the distribution of all closed loop in Figure to a stationary distribution . Without loss of generality , we therefore consider the of the stationary distribution of the relevant . The power of the channel input signal then 
 . The channel input power constraint can be from this , as a constraint on the channel We thus observe that for the setting in Figure , the limitation is uniquely defined by the H norm of . 
 We now present a novel lemma which a lower bound to the channel in discrete time that when the closed loop system is stable . This lemma also sufficient and necessary , stated in of the transfer function so that the channel is equal to this lower bound . The latter is given only by the unstable is universal in the sense that it for any choice of Figure . 
 Before proceeding , it is convenient to note that , i . i .., it that , for every , u , and s . This that the channel is given by 
 . 
 Lemma . If the closed loop system shown in Figure is stable , then 
 , 
 with equality if and only if the following three are satisfied : 
 There are no external in Figure is zero . 
 The non minimum phase of are exactly the unstable of . 
 is an all pass transfer function . and are equivalent to 
 m 
 i , ,. 
 i 
 Proof . Since the are independent of the channel noise , we have that 
 , 
 with equality in a zero mean , and equality in is the only exogenous signal in the system in which mean . The external disturbance case is for example in , for performance , however here we are interested in , thus the no external disturbance stated in condition i . The channel output power is thus , condition i . 
 If the closed loop system is stable , then the sensitivity function is stable and there can be no unstable . Thus 
  
 where is due to inequality and the fact that log is a concave function , with equality if and only if does not depend on . On the other hand , is due to Bode integral theorem and the fact that the unstable of , which cannot be , appear as of , with equality if and only if the of are exactly the unstable of , Theorem . . . Combining this with and , it that i , and in the statement are necessary and sufficient for equality in , and that the latter two are equivalent to , the proof . 
 It is worth that Lemma is valid regardless of whether there are in the plant model or its relative degree . It is well known , see , that the minimal for a state feedback strategy and an output feedback strategy , as in Figure , if the plant unstable , minimum phase with no time delay . As stated in the presence of the to a value o such that o . We will show in the next section that , for a one degree of freedom controller solution , this is not always true , and on we can still have o , even if the plant model . 
 Optimal Controller Characterization 
 We next present a theorem which characterize the unique controller which the lower bound . 
 Theorem . For the system shown in Figure , unstable , minimum phase with relative degree , it that . Furthermore , the 
 is by a unique controller the set of , given by 
  
 Proof . We will show that , in this case , there a and of Lemma and that such controller is unique . For this purpose , let us define the and , respectively , as the numerator and denominator of 
 , i . e ., 
 . 
 Notice that is a stable all pass transfer function if and only if all the of are outside the unit circle . On the other hand , from , the controller can be expressed as 
 . 
 phase leaves no unstable cancel . In order to ensure not cancel the unstable that those become the only of , one must choose i . Since must have an all pass frequency response , the denominator of must be , automatically yielding a stable . 
 In summary , we have found that there a which and of Lemma , and that it is unique . This and that the corresponding minimal controller is the one defined in . 
 Theorem how the unstable of the plant a fundamental role in the minimum of the communication channel . It is also easy to see that , for a stable plant , the minimal is zero . 
 Remark Without , is a minimum .. Theorem that , in this case one degree of freedom , minimum phase , and without , one can reach an equal to and obtain a stable closed loop system . Thus , the for stability is actually a minimum . However , it shall be noted that the sensitivity function , and thus it is all pass . This that the channel noise the only exogenous signal in the system is not being at any particular frequency . 
 Notice also that the stability of the minimum system that if one the controller and then are added , closed loop stability is not . However , any additional external disturbance will increase the variance of u as well as that of the other in the system , increasing the above . 
 After the in the previous it is natural to ask ourselves the following question : Can the lower bound given by be if the plant We next show that if , the answer is yes , for very special . In doing so , we will also provide some insight into the why in general the answer is no . 
 the reasoning in the proof of Theorem , let and be as in , so that . In order to reach the lower bound in , condition must hold , which that 
 , 
 for some complex such that , and a set of complex , with a correspondence between each root outside the unit circle and one of the unstable of from condition in Lemma . The stability of that can only have stable and thus , in view of , only i . e ., and ai i , ,...,. 
 This and , 
 yielding 
 , 
 and , from , do not cancel the unstable of a requirement for . 
 We now lift the assumption and propose an unstable plant model that also 
 , and to stress the difference with , such an unstable plant model is . The term is the stable , minimum phase , part of . As relative degree of is also one . From , the only way in not cancel these is that the latter are also of . Clearly , this is not possible in general , since , as we have seen , satisfying and in Lemma that the specific form given by . 
 This that , in general , if the closed loop system is stable and if indeed , then the cannot reach the lower bound in . At the same time , the above analysis the following question : Are there special in which the plant model and yet the lower bound is compatible with closed loop stability The following theorem an answer to this question . 
 Theorem . Let be such that 
  
 Then : 
 In the shown in Figure , an equal to the lower bound in is reachable , while yielding a stable closed loop system , if and only if and the i of constitute a subset of . 
 For all i ,..., , it that i . 
 If the in i are met , then the unique controller , which when in Figure an equal to , is given by 
 , 
 where . 
 Proof . i As above , the lower bound in to take the form given in , which if and only if given by as . A construction of the optimal controller is also for example in , Theorem . the approach , but such approach the characterization of the zero obscure . Since that relative degree equal to , it that when relative degree , which is not realizable causally . If , this controller is , the stable given by thus satisfying and in Lemma and does not cancel the unstable of . The only condition be a controller is that it does not cancel the unstable of either , which is equivalent to being a subset of the of . This claim i . 
 When , the set the of . These can be studied standard root locus analysis , which the of the expression , as the varied , for any given rational transfer function . , we will show that when , all the of lie outside the unit circle . 
 Since is as in , it its outside the unit circle and all its inside the unit circle . Recall that the of continuously migrate from the of at to the of toward . Hence , close to zero , lie outside the unit circle . 
 Suppose that for some when , for some and some ,. 
 Then is real and positive . that see , we conclude that . Thus , from , all the which start outside and end inside the unit circle lie exactly on the unit circle only when 
 , which is strictly less than . Therefore , all the of are non minimum phase , proving claim . 
 The fact that it feasible not cancel the of , which if and only if these are a subset of . In the latter case , the be given by , thus taking the form , which the given by . Therefore , this is the only controller which the closed loop system while satisfying the for equality in . This the proof . 
  
 We illustrate Theorem with a simple example . 
 Example . Consider an unstable plant with relative degree given by , with 
 , and . We have from Theorem that if 
 . 
  
 then the channel can be set to . For and real , then further into More so , the optimal controller that is then defined as 
 , which , again assuming and real , further into . 
 Thus , we have a controller without unstable zero pole which a stable such that i i , ,, and thus with s , and thus the lower bound in . 
 Remark . Claim in Theorem a perhaps surprising fact : in the setup corresponding to Figure , or its are a subset of , then the controller at least non minimum phase . This may seem since , in general , in the loop transfer function the closed loop system harder to control it the of the complementary sensitivity function and it minimum phase . 
 Remark . Despite the fact that specific satisfying the of claim of Theorem do exist , the latter theorem that for almost all with , and for all with , the minimum for stability in the scheme of Figure is in general strictly greater than the lower bound . Therefore the result is theoretical in nature , since the plant model and should not be assumed as design . This the explicit definition of a controller , as in the following section , for dealing with the practical aspect of plant model not necessarily at the i , whilst the minimal for stability only by the plant unstable . 
 Two Degree of Freedom Controller 
 When the channel output is directly fed back , then an alternative two controller solution that is possible , see Figure . 
  
 Fig . . Two , general configuration . 
 Theorem . The two controller that when the unstable plant model arbitrary with is given by 
 , where for C the are the solution of the following set 
  
 and for C the are the solution to the next set 
  
 Proof . We consider first the general structure in Figure 
 and observe that the channel closed loop is 
 . Since we want to achieve we therefore impose the need for C CoG , with as in in . We then further assume that C 
 and manipulate the above expression into 
 C 
 C mi i 
 m m 
 i i i . 
 i i 
 Since we require for stability that C the space of all proper and real rational stable transfer , , the numerator of C must contain all the 
 m unstable of , thus , for all . The structure for that the one by . The are easily by imposing the set of algebraic in , from which we then obtain C as in . To obtain C we follow a similar approach . From C CoG , at each zero of we have that C , for . To satisfy we propose C as in . Finally , to obtain the that achieve the given we then impose the algebraic in and obtain C as in , which this proof . 
 The remarkable implication of Theorem is that we can effectively reduce the requirement , the increasing effect due to the presence of the , whilst in an setting . This is by the plant model as seen by the channel input , through the second path that the channel output through C , see Figure . 
 Remark . The result from Theorem also when the communication channel is over the feedback path between the plant and controller and . 
  
 Fig . . Two solution for Example , equivalent plant model configuration . 
 Example . Consider . We recognize then z , and . For one unstable pole we also have that and . We then have from Theorem that , and . 
 From we recognize . In turn , from 
 we have that . Therefore the two controller that for the plant model studied in this example is given by 
 . 
 As a note , observe that if , then the C path up , and the plant model . We then recover the standard controller solution for of an unstable plant without . 
  
 In this work we have studied how to avoid the effect of on the minimal for output feedback stability . The first observation is that the optimal controller that the minimal for a minimum phase plant with no time delay , all its outside the unit circle . This observation allow us then to characterize a set of specific that can be now at the plant model , and would not increase the minimal for stability above the expression by only the plant unstable . We then used a two controller structure to propose , for output feedback , the synthesis of such that can retrieve the minimal , even when the unstable plant model . Future research should consider extending the for more complex communication channel and replicate this study for the continuous time setting . 
  
 ﻿ This paper novel on scalar feedback quantization with uniform . We focus on general where reconstruction is via a linear combination of frame . a deterministic approach , we derive two necessary and sufficient for to be optimal , i . e ., to produce , for every input , a sequence that is a global minimizer of the norm of the reconstruction error . The first condition is related to the design of the feedback , and can always be . The second condition only on the reconstruction , and is given explicitly in of the Gram matrix of the reconstruction frame . As a by product , we also show that the the first condition alone scalar feedback that yield the , when one quantization noise as uncorrelated , identically distributed random . 
 , Quantization , Sigma Delta Modulation . 
 INTRODUCTION 
 In many signal , have to be by a series of , so that they can be , or in digital form . This paradigm sampling , quantization and reconstruction . 
 The quantization of the , namely the sequence ,, a sequence whose are constrained to belong to a discrete set of . We focus our attention on uniform quantization , and thus require that 
  
 where U is the quantization alphabet . 
 The and most common paradigm to recover the signal from the is linear reconstruction . Here , one is able to recover the original signal , say a , via 
 a , 
 In , is a set of a frame in the reconstruction space typically a subspace of or of L . Thus , the are the frame expansion of a . of linear reconstruction are the reconstruction formula , the reconstruction stage in filter , and the inverse wavelet transform . 
 Throughout this work , we will be concerned with the squared norm of the reconstruction error , i . e ., 
  
 , 
 for every . Unfortunately , minimization of subject to is a non convex optimization problem . Moreover , the complexity of this problem exponentially with the number of to be . In addition , unless an orthogonal set , one would need to preview the entire input sequence before being able to calculate any optimal value for . This is incompatible with delay sensitive . 
 For the above , in practice quantization is often accomplished via simpler sub optimal that operate sequentially . The of these correspond to scalar feedback . At the i th iteration , these A obtain the output sample by simple scalar quantization of an auxiliary sequence , which is a linear combination of input and output , i . e ., 
 ai , , . a : i : i 
 In , the real ai ,, i , , ,..., are design , and is the nearest scalar quantization function 
 Q U , . b 
 The above can be used to describe many scalar quantization and bit Sigma Delta . The latter have been well studied in the context of shift invariant reconstruction wherein reconstruction is done by , and recently also for frame see , e .., , . 
 Not surprisingly , for a given reconstruction frame , and in return for the above , optimal vector quantization generally . However , it is not known under what this performance gap . In this paper we derive those . More precisely , we state necessary and sufficient for to be optimal , i . e ., to yield , for any input , the output sequence that , in . Our extend the work in , to more general . 
 . 
 Notation We use bold , e .., to denote both the sequence and the column vector x , where the meaning is clear from the context . We also use bold to represent matrices and their corresponding column . For example , a matrix , we use to refer to the i th column of , and , to refer to the th element of . The null space and the pseudo inverse of a respectively via and †. The notation to the sub matrix by removing the first i and i from . Similarly , the its first . The symbol N an length column vector of . We use the short hand the quadratic form . We write as an abbreviation for if and only if . to the , and we use to denote the set of all length with integer . We say a matrix or vector is integral all its are . 
  
 . . Brief Overview of 
 Here we will first present some regarding that will be used in our subsequent analysis . 
 A finite frame for a an ordered set of such that , for every , 
 , 
 where the scalar A , satisfy A . 
 The synthesis operator : of the frame is 
 defined via 
 , 
 where the set of square summable . The Gram matrix of the frame is defined element wise via 
 . 
 It thus that 
  
 which positive semi definite , and , in particular , that 
 . 
 . . Feedback Quantization of Frame 
 It is easy to show from that an cannot yield for all unless ai , di ,, i ,, where di , is the delta function . If the latter , then can be written as : 
 u ;; u , 
 where v , , is the feedback matrix the vector of quantization . In order for the above to be well defined , needs to be lower strictly triangular , i . e ., lower triangular with all main diagonal equal to zero . Notice also the only degree of freedom in the design of an . 
 In order to determine , u for , it is convenient to define the noise shaping matrix 
 S IN , 
 where IN matrix . Clearly , is constrained to be lower unit triangular , i . e ., lower triangular with all its main diagonal equal to . 
 Substituting into u . this , and substituting and into , the distortion by can be written as 
 . 
 MAIN RESULT 
 We can now state the main result of this paper . 
 Theorem For any given reconstruction frame with Gram matrix 
 G , the distortion , u of an for all the following two hold : 
 The of the associated feedback 
 mi i , i ,...,, a where , i ,...,, b 
 and where the satisfy i , but are otherwise arbitrary . 
 For every i ,...,, i such that 
 mi i i , i . e ., such that mi i is an integral vector . 
 Notice that i a matching condition between the feedback matrix and the reconstruction frame . Thus , i can always be satisfied by a proper choice of which is given explicitly by . On the other hand , condition only on the reconstruction frame , or more precisely , on its Gram matrix . 
 The proof of Theorem will be given in Section , based on preliminary given in and . The latter provide valuable insight into the problem , and stem from two alternative : lattice quantization and dynamic . 
 LATTICE QUANTIZATION FORMULATION 
 In this section we use the fact that minimization of subject to is equivalent to a lattice quantization problem . To show this , we first note that any symmetric positive semidefinite matrix can be decomposed as 
 G , 
 where is lower triangular see ., e .., . It then directly from and that 
 . Thus , one can analyze the relationship between the of any group of by looking at their in through . In particular , 
 c 
 see and . 
 Since the quantization alphabet U is uniform see , the all the UN constitute the reconstruction lattice 
 . 
 Accordingly , we say that is the generating matrix for . Every lattice a basic cell , V , associated with it , i . e ., the region of closer to the origin than to any other point in the lattice . More precisely , 
 : 
 The region around a lattice point is the region 
 . Similarly , we define the quantization cell around of an converter as 
 C , 
 where the hyper cube : , , is the set all possible quantization noise . Thus , is the set of all target for which an the sequence . 
 With the above , we can now prove the necessity of condition i of Theorem . 
 Lemma For a reconstruction frame with gram matrix , the distortion , u of an can equal for all only if condition i in Theorem . 
 Proof In view of and , an is optimal i . e ., 
 . A key property of V 
 is that it the minimum second moment among all the whose form a tessellation , see . Thus , an is a candidate to be optimal only if its second moment N . This second moment can be readily shown to be given by trace I I 
 F . By , the i th element of the trace can be written as 
 T 
 f , lower triangular lower strictly triangular . The fact that each trace term only on its corresponding column the trace is each i i i . 
 Clearly , this 
 Hi † i , i ,...,, 
 where i is an arbitrary vector in Hi and , thus , in as well . Substitution of the identity A † † AT into , thus the proof . 
 Remark If a vector of uncorrelated , uniformly distributed u . u ., random , one trace trace I I . On the other hand , an whose feedback matrix to characterize one of the noise shaping for frame in . More precisely , condition i is satisfied by the variant in which the error associated with each coefficient is onto all the ahead of the current iteration coefficient . Thus , Lemma also that , an u . u . model for quantization , the latter scheme the minimum among all . 
 DYNAMIC FORMULATION 
 Sequential quantization , such as , decide upon the value of each output coefficient sequentially . Insight can be by them from a dynamic point of view . The key point is that each of the additively to the cost defined in , leaving , after each step , a sub problem similar in form to the original one . In turn , each of these sub is determined by the already made . The following result us to formalize these 
 Lemma Cost Decomposition Let be a positive 
 , and 
 , 
 where the are defined as 
 iT i i 
 G , i ,...,, and where the satisfy . 
 Proof The result from direct algebraic manipulation , the identity A † AA † A † and from the fact that † , i ,..., which positive semidefinite . 
 Recursive application of Lemma to one to split the total cost , as : 
 t 
 see , where the are defined in , and where 
 ; 
 with t . 
 The summation on the right hand side of the irreducible reconstruction error stemming from the first i . The cost to go after decision i is the last term in . It the same form as the original cost , but it the target vector . The latter can be as a state vector which the effect of , and of previous , on the go . 
 PROOF OF THEOREM 
 Joint Sufficiency of i and It is well known in lattice theory that any two L and L , with M and 
 M non singular , are equal there an integral such that M see , e .., . On the other hand , if i and hold , then there a lower matrix such that is integral . lower unit triangular , we have that , and thus . It then that . On the other hand , if condition i , then it directly from that the product an orthogonal , lower triangular matrix . This in turn a rectangular lattice . Moreover , it is easy to verify that the associated cell V is given by the hyper rectangle , which is precisely the quantization cell of the , N see . Therefore i and guarantee that the corresponding is optimal . 
 Necessity of i and The necessity of i was shown in Lemma . Thus , it to prove the necessity of assuming that i . If i , then the target given in can be written in of the feedback 
 t . 
 lower strictly triangular , we have from that 
 , , ,. 
 If ,, then , , and see . 
 Now let us consider a that the target vector , at iteration i , 
 a , b 
 for some UN i and some e ,. With the above target , an would choose ti , i , and thus . Then , from , the cost to go for the after i can be split as 
 , 
 where Lemma and have been used . On the other hand , from 
 Lemma and , the cost to go for the choice is 
 . Therefore , 
 the minimum difference between the cost to go achievable by and that of the choice is 
  
 If is not satisfied for some i , ,...,, then 
 that . As a consequence , the first term on the right hand side of is strictly positive . It then that , u is strictly than , for sufficiently small of e , the proof . 
 ANALYSIS OF THE RESULT 
 Lattice Quantization Interpretation It been shown in the proof of Theorem that is a sufficient condition be rectangular and have a hyper rectangular cell . It is important to note that this can happen for a non diagonal reconstruction Gram matrix , i . e ., reconstruction that are non orthogonal , and even linearly dependent , not to be non singular . It is also important to note that the converse does not necessarily hold , that is , a not ensure that condition is satisfied . More precisely , the fact that a lattice is rectangular the existence of an integral such that is orthogonal . It be also lower unit triangular , as by . On the other hand , i alone is orthogonal , and thus N is . For a uniformly distributed , the gap between such an and a lattice vector is given by the difference between the second of N and V . Although no closed from are known for the second moment of V of arbitrary , preliminary suggest that it is possible to derive lower for this gap from the non integer part of the mi defined in b . 
 Reconstruction by a Single Filter By and considering the distortion per sample , as the cost function , our can be applied to where reconstruction is a discrete time filter , say . Without loss of generality , we assume that . In this case , the reconstruction frame take the form , where is the impulse response of . This setup infinite dimensional matrices , the first column . In turn , f can be seen as the impulse response of a filter . It then that the orthogonality of the of stemming from i is equivalent to . This to a whitening , which minimum , in the alternative white quantization noise paradigm . Similarly , an satisfying i also the , see Remark . On the other hand , for this case , all the mi see b are equal to the impulse response first sample removed of . Thus , into the impulse response of being integer valued . Hence , the standard th order bit converter is optimal for . This the in , for U , . 
  
 We derived necessary and sufficient that make scalar feedback quantization optimal , in the sense of generating , for any input , the sequence that the norm of the reconstruction error . The first condition , which only on the design of the scalar feedback , to characterize the best of this class , when a stochastic framework is adopted . The second condition only on the Gram matrix of the reconstruction frame , and can be satisfied for non orthogonal , and even linearly dependent , reconstruction . 
  
  
 ﻿Based on measurements for a street-canyon-type femto-cell we compare the downlink spectral efficiencies of various intra-cell interference mitigation systems. This includes Zero-Forcing (ZF), Regularized Zero-Forcing (RZF) and DirtyPaper Coding (DPC). As a reference for comparison we consider subsectorization and TDMA. Out-of-cell interference, treated as additive Gaussian noise, is included in two modes: a) all cells transmit simultaneously and b) neighboring cells transmit in alternated time slots. We find that ZF, RZF and DPC can offer increases in spectral efficiency over subsectorization and TDMA by factors of around 4 under interference-limited conditions. This contrasts with estimated gains of only around 2 when using a standard 3GPP mode instead of our measured data. This difference is due to the greater inter-cell isolation that characterizes our street-canyon-type test environment. We find that RZF achieves over 80% of the DPC’s spectral efficiency under virtually all operating conditions.
 Index Terms—MIMO, multiuser, outdoor-to-indoor, femto-cell, inter-cell interference, spectral efficiency
 I. INTRODUCTION
 F
 EMTO-CELLS [1] are being deployed to address the explosive demand for higher capacity in wireless systems, allowing an increase in user density at locations where macrocells cannot cope with the expected traffic load. Spectral efficiencies can be further improved using some of the techniques we discuss below.
 Multiple-Input Multiple-Output (MIMO) transmission techniques have received great attention. However, inter-user interference results in a low Signal-to-Interference-plus-NoiseRatio (SINR) and corresponding performance loss. This has led to the proposal of multiuser MIMO schemes (MU-MIMO), where coordinated transmission reduces or cancels intra-cell interference [2]–[5]. In multi-cell systems, inter-cell interference imposes additional limits on performance. Many schemes to reduce or avoid this interference have been proposed. For example, “almost blank subframes” (ABS) can avoid inter-cell interference [6] when a small cell (pico-cell or femto-cell) is located within a macro-cell to address a local traffic hotspot.
 Massive MIMO [7], [8] uses a large number of antennas at the Base Station (BS) to mitigate intra-cell and intercell interference, with a considerable increase in complexity and higher backbone overhead to carry inter-cell Channel State Information (CSI). A far more elaborate scheme is the coordinated multipoint transmission, alternatively known as Network MIMO [9], where neighboring BSs cooperatively encode and decode messages for multiple simultaneous users. Although, in theory, such a scheme can produce very large increases in throughput, only limited gains have been achieved so far under realistics conditions. In [10] it is shown, based on simulations, that Network MIMO achieves no gains with respect to an ABS-based scheme if the larger overheads of the former are considered.
 In this work we present an empirically based evaluation of pre-coding schemes for single antenna terminals, i.e., Multiple-Input Single-Output (MISO), concentrating on the case where only intra-cell CSI is available.
 We discuss below relevant results. Pre-coding schemes can be classified into nonlinear or linear systems. Among the nonlinear schemes, Dirty-Paper Coding (DPC) [2] is a valuable capacity-achieving bound [11], [12], even though no practical implementations have been proposed. Simpler, suboptimal linear pre-coding schemes include Zero-Forcing (ZF) and Regularized Zero-Forcing (RZF). In ZF, intra-cell interference is eliminated by choosing a pre-coding matrix that diagonalizes the channel gain matrix and then allocates the user powers via the water-filling algorithm [13]. It has been shown that ZF can asymptotically achieve the theoretical sumcapacity limit when considering the case of a large number of users [14]. ZF performs poorly at low Signal-to-NoiseRatios (SNR) [4], when spectral efficiencies are noise- rather than interference-limited. This effect becomes particularly significant for ill-conditioned channel matrices. RZF [4] has been proposed to resolve this problem. In this scheme the matrix to be inverted includes noise-dependent terms that, at low SNR, compensate for the eigenvalue disparity of the channel matrix.
 Simpler transmission schemes that need little or no CSI at the transmitter include subsectorization and Time-Division Multiple Access (TDMA). In subsectorization [15], intra-cell interference is reduced by separating the coverage sector into smaller subsectors through the use of directive antennas. The only feedback required is that resulting from the association of a user terminal to a subsector. Such a system, with no inter-
  
 	(a)	(b)
 Fig. 1. Example of measured scenario for (a) the intra-cell campaign and (b) the inter-cell campaign.
 user nulling capability, will be limited by intra-cell interference at high transmit power.
 In TDMA, the transmission frame is divided into equalduration time slots, and each user is served at full power during one of those time slots. The capacity gain of DPC over TDMA for MIMO channels was reported in [16], but without including inter-cell interference. The bounds presented in that work are used as reference for our results.
 The above techniques are especially important when outdoor femto-cells are intended to serve indoor users, yet these scenarios have only been studied relatively recently. Results on empirically-based outdoor-to-indoor channel characterizations are presented in [17]–[24], but these were not formulated in the context of MU-MIMO. Only a limited number of studies [25]– [29] include empirical data in the evaluation of multiuser MU-MIMO. In [25] ZFs spectral efficiency is evaluated for a distributed transmission system in an indoor environment, while [28] uses a similar setup (Network MIMO) to compare the spectral efficiency of several techniques, finding that ZF and DPC achieve about a three-fold increase in per user data rates over non-coordinated transmission and frequency division. In [26] the rate distribution among users is evaluated for an indoor MU-MIMO scenario when using time, frequency and spatial multiplexing. In [27] the aggregate capacity in a MU-MIMO system using ZF, RZF and DPC is presented and compared with the sum of individual capacities of various single-user MIMO channels in outdoor and indoor scenarios. Our work is related to the above studies but includes inter-cell interference and actual intra-cell channel measurements.
 We evaluate the spectral efficiency of several MU-MISO techniques in outdoor-to-indoor scenarios with femto-cells placed along the streets, below the rooftop serving the buildings of one city block. This differs from the often-used assumption of hexagonal cells which is unrealistic in our deployment scenario. Pre-coding matrices are computed using measured intra-cell channels while out-of-cell interference is included as additive Gaussian noise, as discussed in [30], with power calculated using a measurement based model. We treat out-of-cell interference mitigation through two simple approaches. The mosat basic considers time-coordinated frames across femto-cells. We also include a simplified version of the method proposed in [8] where inter-cell interference is mitigated by adding BS antennas. In particular, we evaluated the achievable spectral efficiencies of DPC, ZF, RZF and subsectorization with 4 subsectors. The BS is assumed to serve 4 single-antenna users simultaneously. Transmitted power is varied to cover noise- and interference- limited conditions. Our measured outdoor-to-indoor scenario, described in the next section, differs from those previously reported for MU-MIMO:
 indoor-to-indoor in [25]–[29] and outdoor-to-outdoor [27].
 In the following sections we describe the measurement setup and the statistical properties of our test environment. A summary of the various transmission strategies is included in Section IV. The empirical results and their comparison with those based on various channel models are presented in Section V, leading to the conclusions of our work.
 II. MEASUREMENT SETUP AND SCENARIOS
 Channel measurements were done at Universidad Tecnica´ Federico Santa Mar´ia’s (UTFSM) campus in Valpara´iso, Chile, and Universidad Diego Portales’ (UDP) campus in Santiago, Chile. Two measurement campaigns were carried out: one aimed at obtaining the channel matrices for the cell being served by the BS and another aimed at estimating the interference generated by neighboring femto-cells.
 A. Intra-Cell Channel Matrix Measurements Campaign
 To obtain the channel matrices within the cell, we used a linear array to emulate an outdoor BS. It consists of 12 omnidirectional vertically polarized coaxial antennas antennas spaced half a wavelength apart, with a reflective backplane. With the backplane, each antenna has a maximum gain of 6 dB and a 120? half-power beamwidth. This array was placed along the street at a perpendicular distance from the building wall ranging from 10 to 25 m. The antenna corresponding to the possible Subscriber Unit (SU) positions was a single 1 dBi gain vertically polarized omnidirectional coaxial dipole antenna mounted on a 40-cm long swivel arm. This antenna was rotated step-wise in 6? increments to obtain local statistics. A 19.2 dBm, 3.5 GHz Continuous Wave (CW) signal is transmitted through this antenna. For convenience, we measured the propagation channels using uplink transmission.
  
 Fig. 2. Measurement system scheme.
 SU placements  were chosen inside buildings in rooms with outside facing windows sized 1.5 m by 2.5 m, separated from the outdoor array by distances varying between 18 and 53 meters. The BS array antennas were located at 2.1 meters above ground level, i.e. a height that would allow easy installation by a service provider aiming to illuminate homes or buildings that are across the street. The indoor SU antenna was placed at desktop height on a first floor, i.e, at roughly the same height as the BS array. The perpendicular distance from the exterior wall to the SU varies from 1 to 7 m. The SU placement may be consistent with an access point installed in a street-side room, which can also act as an indoor wireless router.
 A schematic representation of one measured scenario is shown in Fig. 1(a), where the points inside rooms are the positions of the SU and the bar indicates the position of the BS array. Placing the BS array at various positions along the direction of the street allowed measuring channels to users at angular positions of up to 60? off array boresight. The buildings are made of reinforced concrete and the nonmetallized glass windows have steel and aluminum frames. The measurements were carried out during the day in the absence of pedestrian traffic, to ensure static channel conditions. A shadow antenna (not used in measurements) is included at each end of the BS array to preserve the impedance due to mutual coupling in all the receiving antennas. A reference antenna in line with the others, at a distance of about 65 cm from its closest shadow antenna, allows measuring the relative phases of the array antennas. A system of switches connects any one of three sets of four antennas to a 4-channel receiver, while the reference signal is permanently connected to the remaining channel. The receiver downconverts the carrier frequency to 10 kHz and these signals are fed to a 4-channel data-acquisition system. A computer is utilized to automatically control the positions of the swivel arm, the switching and the data acquisition. GPS disciplined oscillators synchronize the transmitter and the 4-channel receiver for phase coherence. Fig. 2 shows a schematic of the measurement system. The signals are sampled for 250 ms at a rate of
 50,000 samples/s per channel (200,000 samples/s total). This interval is partitioned into 25 contiguous sub-intervals of 10 ms per position of the swivel arm. Using a Fast Fourier Transform (FFT) algorithm, a value of magnitude and phase is obtained per sub-interval. Due to exact synchronization of sampling intervals, the data sequences correspond to an integer number of periods of the 4 sinewave outputs, allowing the FFT processing without windowing. The existence of 25 consecutive measurements for any transmit/receive combination of antennas allows verification of proper equipment operation and the reduction of residual measurement noise through averaging. We measured a total of 400 combinations of placements of the outdoor and indoor antennas, i.e. 400 60-by-12 matrices.
 B. Inter-Cell Interference Campaign
 As already mentioned, in our study we have not considered joint pre-coding among BSs. Instead we treat the out-of-cell interference as noise. To estimate this interference power we measured path-losses over a wide range of positions since it is not a-priori obvious which will cause significant interference. The sounding system was basically the same of the first campaign, except that at the BS end we used a single antenna, since only the scalar path-loss is required. We proceeded as follows. Over distances extending from 15 m to 500 m we measured the outdoor-to-outdoor path-loss. This included same-street measurements as well as “around-the-corner” measurements in the Manhattan grid type street canyons. For a subset of these measurements we also determined the path-loss from the BS to the indoor location that matches the outdoor position as shown in Fig. 1 (b).This allowed us to model the “outdoor-toindoor penetration loss”. We describe this in further detail in the next section. We found that the outdoor-to-indoor pathloss statistics can be modeled quite accurately by adding a “penetration loss” to the corresponding outdoor-to-outdoor path-loss, as reported in [31].
 The empirically based channel data allowed us to obtain the channel gain statistics and models described in the following section. From these we also assessed and compared the achievable spectral efficiencies for the various systems. These results are subsequently compared to those that would be obtained with various models. This is described in detail in Section V.
 III. CHANNEL STATISTICS AND MODELING
 In this section we statistically characterize the propagation channel for the chosen environment. As will be seen, our results are consistent with those reported in the literature for similar settings, which implies that we have chosen scenarios that are representative for urban femto-cells.
 Out	door-	to	-In	door	Pen	etra	tion	Loss
 A.
 To model this loss we used both intra-cell and inter-cell measurements to compare averaged received power (in dBm) for locations separated by the exterior wall. The average power was obtained from the 60 measurements of the swivel arm, and thus excludes the small-scale fades. The results are shown in
 10	20	30	40	50	60	70	80	90	20	30	40	50	60	70 ? [degrees]	Distance [m]
 	(a)	(b)
 Fig. 3. (a) Measured penetration loss and proposed fit vs. 3GPP model. (b) Outdoor-to-indoor path-loss at long ranges.
 TABLE I FITTED PENETRATION LOSS PARAMETERS OF (1)
 Parameter	Value
 ?L [dB]	6.4
 ?H [dB]	23.5
 ?L [dB]	41.0
 ?H [dB]	73.7
 Fig. 3. Fig. 3 (a) shows the dB difference in measured outdoor and indoor powers as a function of the incidence angle ? defined in Fig. 1. For comparison we show the mean penetration loss of the 3GPP model. We adjusted a modified version of the 3GPP model given by (1) to our data, using a Minimum Mean Square Error (MMSE) criterion to obtain the best-fit parameters for the average penetration loss ?(?). These are listed in Table I
 |?| < ?L
 ?
 (1)
 	...cos2(	L )] + Xs	?L = |?| = ?H
 L
 ?L < |?|
 where Xs is a zero-mean random variable, which we found to match a Gaussian distribution. Its standard deviation was found to be angle-dependent, with values of 4.5 dB for intracell links growing to 7.2 dB as ? exceeds ?H. The latter angles correspond to those of inter-cell interference links in our street canyon geometry. For intra-cell links the average penetration loss is essentially constant at 6.4 dB, much less than predicted by the 3GPP model. In Fig. 3 (b) we show measured pathlosses for outdoor-to-outdoor and outdoor-to-indoor links at ranges relevant for inter-cell interference. As will be discussed in subsection C, for ranges up to 100 m the average outdoorto-outdoor path loss for a linear fit model has a slope only slightly larger than that of free-space links. The outdoor-toindoor average path-loss was found to have the same slope, but as shown, its values are offset by an average penetration loss of 23.5 dB, consistent with (1).
 B. Intra-cell Average Path-loss and Shadow Fading
 Intra-cell links were in general Line Of Sight (LOS) through a window, with minor obstructions in the path. This is often referred to as Obstructed Line Of Sight (OLOS) [32]. The large-scale path-loss is calculated at each transmit/receive placement, by again averaging the received power of the 60 positions of the swivel arm. Using these values we fit a classical log-distance model [33] to the path-loss PL in dB as:
 	PL(d) = PL0 + 10?1 log(d/d0) + Xs	(2)
 where PL0 is the path-loss at the reference distance d0 = 1 m, ?1 is the path-loss exponent and Xs is the shadow fading term, a zero-mean Gaussian random variable with standard deviation s. It is assumed that . The value of ?1 is found through a MMSE regression fit of the 400 empirical values of path-loss. The values of PL0, ?1 and s thus obtained are shown in Table II. We tested various other alternatives. This included the free-space path-loss model (i.e. ?) plus the average intra-cell penetration loss from (1), a two-slope model and an exponential model based on IEEE802.16j Type-F BRTto-BRT [34].The improvement of the fit in terms of MMSE is negligible. Fig. 3 illustrate the comparison. In the same figure we also included for reference the line that corresponds to the free-space path-loss and that predicted by the 3GPP model for the outdoor-to-indoor case in urban micro-cells with a Manhattan-grid layout [35]. As will be discussed later, we found that the smaller intra-cell penetration loss with respect to the 3GPP model had a significant impact on the achievable spectral efficiencies. We observed a small proportion (less than 19%) of path-losses that are lower than those in freespace. This is likely due to ducting effects in our street canyon environment, particularly at shallow incidence angles.
 C. Inter-cell Average Path-loss and Shadow Fading
 Based on our inter-cell measurement campaign, we formulated an outdoor-to-indoor street canyon path-loss model in order to evaluate the inter-cell interference from neighboring femto-cells. We firstly found that a two-slope model accurately
  
 Distance [m]
 Fig. 4. Single slope fit and exponential fit for the measured intra-cell pathloss in function of the distance, in logarithmic scale. For comparison, free space and 3GPP models are shown.
 describes the outdoor-to-outdoor street canyon path-loss. This written as (3)
 d = dBP d > dBP
 (3)
 where the PLout is the outdoor-to-outdoor path-loss, dBP is the “break point distance” defining the change in slope and PLBP is the corresponding path-loss. The outdoor-to-indoor inter-cell path-losses were found to be well described by the sum of the average penetration and path-losses from (1) and (3), respectively, plus a shadow fade term Xs with 7.2 dB standard deviation. We note that for the angles of incidence that will characterize most inter-cell interference, the average penetration loss is 23.5 dB. This is consistent with what has been reported in the literature [36]. Table II summarizes the estimated values of the model parameters.
 Through the same outdoor-to-outdoor street canyon measurements we found that Non Line of Sight (NLOS) aroundthe-corner links show a path-loss that is at least 15 dB above that of LOS links for the same distance, which is consistent with [35]. Thus, the interference generated by around-thecorner femto-cells is negligible compared to that from neighboring same-street bases. For this reason, the former are not considered in the performance analysis of Section V. Our intercell path-loss model does not differ very significantly from previously reported results [35] and we therefore omit further details.
 D. Intra-Cell Small-Scale Fading and Correlation
 The small-scale fading statistics for the intra-cell links, from any BS array element to the SU, were obtained from the 60 complex channel gain measurements corresponding to a rotation of the swivel arm, normalized to their local spatial average. As expected [1] for LOS links rich in multi-path components, we found that a Ricean distribution provides a good fit for the channel gain envelope statistics. The corresponding K-factor was estimated using the two-moment method [37]. The average percentage of (absolute value) error in the fit of the empirical and model Cumulative Distribution
 TABLE II PATH-LOSS PARAMETERS FOR INTRA- AND INTER-CELL LINKS
 Parameter	Intra-cell	Inter-cell
 PL0 [dB]	36.3	36.3
 ?1	2.4	2.4
 ?2	-	4.9
 s [dB]	4.5	7.2
 dBP [m]	-	100
 PLdBP [dB]	-	85.1
 ?(?) [dB]	-	Eq. (1)
 Functions (CDF) was 6.7%. Higher errors were obtained when fitting other commonly used small-scale fade distributions (Nakagami, Weibull). To account for possible differences due to the separation of the 12 array elements, we estimated the fade statistics per element and subsequently averaged the individual K-factors. These were found to be similar, the differences being explained by the limited data set size. Following [38], [39], we adjusted a log-normal distribution to the observed K-factor statistics, i.e. Krice ~ Lognormal(µ,s), with its estimated parameters shown in Table III.
 The correlation between the powers received by the different array elements of the serving BS was calculated using all intracell measurements. To this effect we normalized each 60-by12 channel matrix by its Frobenius norm, in order to combine the data corresponding to locations with different large-scale path-losses. We initially adjusted a single-exponential model to the empirically-obtained values as done in [40], but found that a double exponential model provided a much better fit, which significantly improved the accuracy in the prediction of the spectral efficiencies. For example, for the ZF case, the estimation error of the capacity with the single-exponential model is 7%, which drops to 1% when using a doubleexponential. The general expression for both cases is given by (4)
 	 	(4)
 where ?j is the correlation between antennas separated by a spacing of j, i.e. j = 1 corresponds to adjoining antennas and j = M-1, with M being the number of antennas in the array. The corresponding model parameters A, B, r1 and r2 were obtained by a least squares fit, and are listed in Table IV.
 We then characterized the channel matrix as done in [41] using (5)
 	h hLOS  hNLOS	(5)
 with hLOS being the LOS component of the matrix, hLOS = exp(j2pd?msin?), where d? is the distance between adjoining antennas expressed in wavelengths ?, m = [0,1,2,...,M - 1] is a vector and ? is the steering angle of the LOS signal with respect to the boresight of the array. In our simulation-based results this angle was generated as a random variable with a uniform distribution over +/-60? to cover the range of possible user positions. hNLOS is a vector of circularly-symmetric zero-mean complex Gaussian random variables with unit variance, correlated following the procedure described in [42]. To this effect we used a
 TABLE III FITTED K-FACTOR DISTRIBUTION PARAMETERS
 Parameter	Value
 µ	-0.3
 s	1.2
 TABLE IV FITTED CORRELATION PARAMETERS
 Parameter	Single-exponential	Double-exponential
 A	1	0.62
 r1	0.85	0.92
 B	-	0.38
 r2	-	0.42
 correlation matrix with values calculated using (4) and Table IV.
 E. Inter-Cell Small-Scale Fading
 For the inter-cell propagation model all links are NLOS, due to the shallow angle of incidence between the neighboring BS and the indoor SU. We found that the small-scale fades in a neighborhood around the SU antenna are very close to Rayleigh distributed. This matches the expected results in scenarios without a dominant component [1]. The estimated K-factor using the two-moment method was essentially zero. Empirical CDFs were found on average to differ from a Rayleigh distribution by no more than 10% (absolute value). However as will be discussed in greater detail in Section V, including small-scale fades in the interference calculation was found to have little effect on the resulting spectral efficiencies. We confirmed this for several cases and subsequently omitted small-scale fades, which very considerably simplifies the calculations.
 F. Procedure for Model-Application
 When comparing our measurement-based results with the above model we proceed as follows:
 Step 1: Choose a distance d and a LOS angle theta from the BS to the SU. The distance must be chosen in the range from 15 to 55 meters, and the angles in the range within +/60? with respect to the boresight of the BS array. Also choose the number of antennas M of the BS.
 Step 2: Calculate the shadow fading and path-loss PL using (2) and the intra-cell parameters of Table II.
 Step 3: Generate Krice using a log-normal distributed random variable with parameters as in Table III.
 Step 4: Generate the correlation matrix using (4) and the parameters of Table IV.
 Step 5: Calculate hNLOS by generating a M-by-1 matrix of i.i.d. circularly-symmetric zero-mean complex Gaussian random variables with unit variance and correlate them using the correlation matrix and the procedure detailed in [42].
 Step 6: Generate the hLOS matrix using the chosen angle ? and the appropriate value of d?.
 Step 7: Calculate h. Add the previously generated path-loss according to generate the channel matrix hsim to
 hsim = 10-PL/20h
 After generating a MISO channel matrix, the interference generated by the neighboring BS femto-cells to that SU is estimated by the following steps:
 Step 8: Determine the distance dneigh between the neighboring BS and the street position directly across from the indoor SU.
 Step 9: Choose the Sum-Power Constraint (SPC) and an azimuthal gain pattern G for the neighboring BS in the direction of the street position of the previous step.
 Step 10: Calculate the shadow fading and path-loss to the indoor SU using (1) and (3) with the inter-cell parameters from Table II, the penetration loss parameters from Table I and the distance calculated in Step 8.
 Step 11: Calculate the interference power from the neighboring cell Pneigh as
 	 	(6)
 where G(?neigh) = sin(??neigh)/??neigh models the gain of the antenna array, ? is a factor to adjust the width of the lobe and ?neigh is the direct path angle to the street position across from the indoor SU,  . In order to mantain the same parameters as in our measurements, the 3 dB lobe width is set at 120?, with ? = 1.32. P is the total transmitted power and PL(dneigh) is the path-loss between the femto-cell and the user, which is dependent on the distance d as described by (3).
 IV. REVIEW OF DPC, ZF, RZF, SUBSECTORIZATION AND
 SINGLE USER TECHNIQUES
 We compute the per-user spectral efficiency (aggregate spectral efficiency/number of users) for several techniques involving a MIMO broadcast (MIMO-BC) channel in the downlink. We assume a narrowband transmission by the BSs array equipped with M antennas. There are K SUs receiving the signal each with a single-antenna. Thus, there exists an M-by-1 MISO channel, characterized by the column vector hk ? CM×1, between the transmitter and the k-th user, with k = 1,...,K. The MIMO-BC is formed by aggregating the K channel row vectors into a channel matrix H of dimension
 K × M such that H  , where [·]H denotes the Hermitian of the matrix.
 In this way, the K received signals can be described by
 	y = Hx + n + v	(7)
 where the random vector x ? CM is the transmitted signal, n ? CK is the random noise at the receiver and v ? CK is the total inter-cell interference reaching the receiver. The transmitted signal is expressed as
 	x = WTu	(8)
 where u is an independent zero-mean complex Gaussian random vector, W ? CM×K is a linear weigth matrix and T : CK ? CK is a non-linear transformation in the case of DPC, and the identity matrix in the case of ZF and RZF.
 In all the tested techniques, a SPC is imposed on the transmitted power as done in [14]. This is written as:
 K
 Tr(E[xxH]) = Tr(WE[uuH]WH) = Xpi||wi||2 = P	(9)
 i=1
 where Tr[·] is the trace of the matrix, wi is the i-th column of W, P = 0 is the maximum power and pi is
 	 	(10)
 with ui being the i-th element of u and [·]*, the complex conjugate operator. The power allocated to each user then is pk||wk||2, for k = 1,...,K.
 For our comparison we chose a receiver noise variance sn2 set at -101 dBm, which corresponds to a bandwidth of 2 MHz and a receiver noise-figure of 10 dB. As already discussed, the interference from neighboring cells is treated as additive
 Gaussian noise [30]. Thus we write , where 
 is the sum of the interference powers from all neighboring cells. The procedure for the calculation of  will be described in the next Section. We note that as the transmit power grows,   will do so in the same proportion, which will lead to the saturation of the achievable spectral efficiencies. For our analysis we assume a 4-antenna base and up to 4 users. The channel matrices will thus be 4-by-4, i.e. M = K = 4. When encoding, the BS has knowledge of the equivalent noise N at each SU. If more antennas were available at the SU, treating interference as noise would be pessimistic in that it ignores the possibility of exploiting the interference signal structure in a multiuser detection (MUD) type receiver [43]. We now briefly describe the various downlink transmit strategies considered.
 A. TDMA
 This scheme is included as baseline against which to assess the advantages of the multiuser schemes described below. Each user is served during one of the L = K time slots with power P. We note that in this scheme we are only separating users into time slots within a cell, cell coordination being treated separately. The TDMA achievable spectral efficiency is therefore
 	STDMA  	(11)
 In [16] a lower bound for TDMA spectral efficiency is proposed, which is tight for MISO channels. This bound is achieved when the best user is served all the time with power P
 	STDMA  	(12)
 where ||h||max = maxi=1,...,K ||hi||.
 B. Dirty-Paper Coding (DPC)
 This is the capacity achieving technique and it is to be considered as an upper bound of actual performance, given that its implementation is complex and to date there is no cost-effective algorithm to implement it.
 In DPC, there is no a-priori choice for the matrix W, and full CSI is required at the transmitter. The pre-coding algorithm uses this knowledge to avoid, for the k-th user, the (known) interference produced by the signals intended to the users 1,2,...,k - 1 (namely, the “previous” users). In doing so, the block represented by WTu generates a transmit vector x being the sum of K independent random vectors , as K
 	x = Xx¯i	(13)
 i=1
 where x¯i ,wiTu is the information bearing vector intended to the i-th user. Defining the covariance matrices Si ,
  , the maximization problem for the DPC spectral efficiency is as stated in [44]:
  
 where the maximization is over all covariance matrices
   satisfying
 	Si > 0,	i = 1,...,K
 K
 X
 Tr(Si) = P
 i=1
 An efficient numerical method to find the solution to this problem is proposed in [44], exploiting the duality between the MIMO-BC and the MIMO multiple access channel.
 A simple upper bound for the DPC spectral efficiency has been found in [16]:
 	 	(15)
 C. Zero Forcing (ZF)
 This pre-coding scheme chooses the weight matrix W to cancel the interference in the downlink. Thus, W is, in general, the pseudo-inverse of the channel matrix (which is assumed full rank):
 	W = HH(HHH)-1	(16)
 In particular, when K = M and H is non-singular, W is W = H-1. The spectral efficiency is therefore calculated as [45]
 	 	(17)
 subject to
 K Xpi||wi||2 = P
 i=1
 Powers are allocated to each user weighting the columns of W using the water-filling solution [45].
 Although the simplicity in the selection of the matrix W makes this scheme attractive, ZF presents poor performance if the channel matrix is ill-conditioned. In these cases, usually one or a few eigenvalues of the matrix are very large compared to the rest. At low transmit powers, where spectral efficiencies are limited by noise rather than by interference, the waterfilling solution (which maximizes sum rate) may result in some users being allocated a zero data rate [28].
 D. Regularized Zero Forcing (RZF)
 RZF was proposed to correct the problem suffered by ZF in presence of ill-conditioned H matrices. A regularization factor is introduced in the pseudo-inverse of H, which aims to normalize the eigenvalues of the matrix, allocate power to all users and avoid noise enhancement [46]. In this case, W is chosen as
 	W = HH(HHH + aI)-1	(18)
 with a being the regularization factor. In [4] it is shown that the optimum a for a large number of users K is
 	 	(19)
 with ? = P/N. Despite not being the optimal value for a finite K, for simplicity we will use this value of a. As W does not exactly invert the H matrix, intra-cell interference will now affect users. Thus, the spectral efficiency is calculated as
  
 (20)
 subject to
 K Xpi||wi||2 = P
 i=1
 In (19), the term Pj6=i pj||hHi wj||2 represents the total interference reaching the i-th user. Powers are allocated by water-filling, using an iterative algorithm that updates the powers allocated in each iteration considering the intra-cell interference generated.
 E. Subsectorization
 In this scheme the sector is divided into Q smaller angular subsectors of the same width. In practice, this can be done using a directive antenna per subsector. To simulate the effect of using various types of directive antennas in the subsectors we took advantage of our channel measurements with the 12antenna array. This allowed us to generate antenna patterns based on using between 4 and 12 dipole elements. We note that this involves using steering vectors with appropriate weights, which, however, remain fixed, i.e. which cannot be adaptively aimed according to user positions. We define the antenna weight matrix as D. The available power is distributed equally between subsectors and it is assumed that one user is associated with each of them. Then pi = P/K, i = 1,...,K. The spectral efficiency of subsectorization is thus calculated as
  
 (21)
 where di is the i-th column of D, i = 1,...,K.
 V. RESULTS AND ANALYSIS
 In this Section we present the main results of our work. The general conditions under which we compared the various systems are discussed in sub-section A. In subsection B we present the achievable spectral efficiencies based on the measured data. This includes subsectorization, discussed in B.1 and the various intra-cell interference avoidance systems discussed in B.2. Finally, in subsection C we evaluate the spectral efficiencies using channel matrices generated by various simulation models. This includes 3GPP models, a Rayleigh i.i.d. model for intra-cell small-scale fades and our own model described in Section III. These results are compared with those obtained in Subsection B.2.
 A. General Conditions for the Comparison
 Using our empirical data and models we now evaluate the per-user spectral efficiency (aggregate spectral efficiency/number of users) of DPC, ZF, RZF, subsectorization and TDMA for a 5-femto-cell system disposed along a street, as shown in Fig. 5. As a basis for comparison we considered BSs with 4 antennas. In all cases we have considered perfect CSI knowledge of intra-cell channels at the serving BS and a sum power constraint (SPC) with a range of realistic values for the transmit power. In order to establish a baseline for our comparison, we also calculate, as in [16], the upper bound for DPC capacity, the spectral efficiency for TDMA with equal time allocation to users and the achievable TDMA spectral efficiency when the sum rate is optimized. To avoid ambiguities, we will henceforth use the term “intra-cell TDMA” when referring to the system where the time division multiple access occurs only within the cell, in contrast to the case where the cells coordinate among each other, which we denominate time reuse.
 Although our treatment focuses on intra-cell interference cancellation, for RZF we have additionally included, based on [8], the case where extra BS antennas allow mitigation of inter-cell interference. We chose a very simple scheme in which the BSs have 12 antennas and the extra degrees of freedom are used to steer nulls towards the 8 users being served in the 2 adjacent cells. Given our street-canyon geometry this is likely to eliminate the strongest sources of interference. We treat 2 cases. Firstly we obtain the achievable performance when full CSI is available across 3 contiguous cells. We call this system RZF-FCSI. Alternatively, we consider the case where the information exchanged between cells is limited to channel-correlation matrices. Although this is less effective, it will not require such frequent updating, putting less burden on the backhaul network [8]. We denominate this as RZF-PCSI.
 The 5-femto-cell system arranged along a street, as shown in Fig. 4 considers BSs separated by 100 m. Each femto-cell BS is assumed to be placed close to the building facade in the middle of the block and provides service to the users across the street. This closely matches our measurement scenario. The spectral efficiencies are evaluated for the users in the central femto-cell. We found that adding more interfering cells in the system did not impact our results.
  
 Fig. 5. Topology scheme of the system. Each femto-cells BS (red bars) points towards the city block across the street.
 The evaluation of the achievable rates will consider two approaches: no coordination between femto-cells (reuse 1), and a coordination scheme that involves time slots (reuse 2), where adjacent femto-cells transmit in alternate time slots to eliminate the strongest source of inter-cell interference. For the case of reuse 2, the achievable rates described in Section IV are appropriately scaled.
 At each scenario such as depicted in Fig. 1 we measured using at least 1 placement of the BS array and 9 placements of the rotating dipole that corresponds to possible SU positions. Each such combination yields a 60-by-12 channel matrix, where each row corresponds to a possible user position. Since our work considers a 4-antenna BS array, multiple choices of adjoining antennas in the 12-antenna array can be selected. Out of this ensemble we used a subset of 800 realizations for each BS placement to obtain the statistical description of the channel spectral efficiencies. We found that further increases in the number of realizations resulted in negligible changes of the results. Consistent with 3GPP Release 10 (LTEAdvanced) [47], Rev 10, we grouped users, dividing the 120? coverage region into 4 30? subsectors. We further assume that each subsector is illuminated by a pilot-beam of a different frequency generated using the 4 BS antennas. The corresponding phase shifts are chosen so that in free space the beams would be steered in the direction of the center of the corresponding subsector. A Dolph-Chebyshev [48] power distribution with 14 dB sidelobe-level suppression was assumed. This choice was based on the fact that this level of sidelobe suppression yields good results for the subsectorization case, as will be described below. Using these 4 beams and the measured channel gains corresponding to each user position, we associated the users to the subsector that provides them with the highest power, thus creating 4 disjoint groups. One user is randomly chosen from each group, leading to one possible realization of the 4-by-4 channel matrix. There are however scenarios where no user associates with a subsector, because their positions are such that all receive more power from one of the other subsectors. When this happens, the number of users K is limited to the number of occupied subsectors. Given the extensive set of available measurements, this was found to occur only rarely. In such cases we considered a K-by-4 channel matrix.
 The per-user spectral efficiency of the techniques is obtained for each K-by-4 matrix, for a given SPC dividing the sumcapacity by the number of users. The results from all scenarios were then aggregated to generate CDFs of spectral efficiency for all systems. The total number of channel matrices used in obtaining our statistical results was 19,200 (24 BS placements x 800 realizations per BS placement).
 In the case of intra-cell TDMA, the transmitted power is the same as the SPC of the multiuser techniques and the aggregate spectral efficiency obtained from (10) is divided by the number of users, to obtain the per-user spectral efficiency.
 We found that the interference from neighboring cells, treated as additive Gaussian noise, could be included using only the scalar path-loss model described in Section III, i.e. neglecting the effect of the small-scale fades. This very considerably simplified and shortened the calculations. To validate this approach, we firstly calculated for a subset of cases, the spectral efficiencies for DPC, ZF and RZF with the small-scale fades included. For each BS placement we considered 160 randomly chosen channel realizations. Including the fades for ZF and RZF is straightforward as it only requires modifying (17) and (20) to take into account that the interference is dependent on the small-scale fade affecting each user. For DPC including small-scale fades is considerably more complex and leads to much longer calculations. Following the reasoning in [49] (Chapter 12.3, page 447), it is necessary to obtain the covariance matrices of the neighboring cells performing DPC in order to calculate the inter-cell interference they generate (as described in Section IV.B). These covariance matrices are obtained using a method proposed in [44]. Then, the received power from one neighboring cell is calculated as
 K
 	PneighDPC = XhHneighSineighhneigh	(22)
 i=1
 where hneigh is the channel vector between the neighboring cell and the user in the central cell and Sineigh is the covariance matrix for the i-th user in the neighboring cell. We found that for ZF and RZF, neglecting small-scale fades resulted on average in overestimating the spectral efficiency by less than 8%. For the case of DPC his difference was less than 2%. Based on this finding we used the simplified approach that ignores small-scale fades and calculated the equivalent noise power due to interference  as:
 	sv2 = XPneigh	(23)
 i=1
 where Pneighi is the interference power due to the i-th neighboring cell, calculated as in (6), i.e. omitting small-scale fades.
 B. Achievable Spectral Efficiencies for the Measured Channels
 1) Optimization of Subsectorization for the Single-Cell Case: We evaluate as a reference the spectral efficiencies of subsectorization when considering only intra-cell interference. As will be seen later, for subsectorization this type of interference completely overshadows that from neighboring cells. Since this dominant intra-cell interference depends on the shape of the radiation patterns that cover the cell, our initial objective is to evaluate this aspect. We found that generating 4 subsectors with only 4 omnidirectional antennas is far from optimum and thus we evaluated other options that allowed more flexibility in selecting beamwidth and sidelobe
  
  
 Lobe Width [degrees]
 Fig. 6. Per-user spectral efficiency of subsectorization vs. -3 dB beamwidth, for different number of antennas in the array, at 50% availability.
 suppression. Both beamwidth and sidelobe suppression will affect the interference that the SU is exposed to. Narrowing the beam pattern will eventually lead to the sector not being fully covered by the mainlobe and at the same time the appearance of poorly suppressed sidelobes, which will contribute to the interference in the neighboring subsectors. At the other extreme, very large suppression of sidelobes results in an increased beamwidth which may invade the neighboring subsectors. For our measurement scenarios, we found that a sidelobe suppression in excess of 25 dB produced virtually no further benefits with regard to the reduction of interference. The reason for this is that at a certain point the energy scattered from the mainlobe of a subsector into the adjoining region dominates over that due to the sidelobes. It follows from the above that for any antenna array there will be an optimum beamwidth. To observe this effect, we evaluated subsectorization using between 4 and 12 omnidirectional antenna elements to synthesize radiation patterns with sidelobe suppression levels ranging from 5 dB to 80 dB. The transmitted power was set at 20 dBm, a power level that assured interference-limited operation.
 Fig. 6 shows the results. We have plotted the median per user spectral efficiency for various choices of directive antennas. In this and in subsequent results we will refer to the spectral efficiency available to X% of users as the “spectral efficiency at X% availability”. We note that the independent variable chosen for Fig. 6 is the -3 dB antenna array beamwidth, which is actually a result of the choice of sidelobe suppression and number of antenna elements used in synthesizing the directive array. As can be seen, using more antennas to synthesize the beams allows the achievement of higher spectral efficiencies as it adds degrees of freedom in the reduction of interference. In Table V we show results for the median spectral efficiency that can be obtained in our scenarios, using the optimum choice of beamwidth for various types of directive arrays. We include the relevant parameters that characterize the antenna arrays in free space and the attenuation of the mainlobe at the sector border. As seen, under interference limited conditions the mainlobe width must be made much narrower than the sector width to achieve the best possible spectral efficiency.
 2) Spectral Efficiency of Intra-Cell Interference-Reduction Systems: We now evaluate the per-user spectral efficiency of the interference-reduction techniques in the non-coordinated
 TABLE V ACHIEVABLE MEDIAN BEAMFORMING PER USER SPECTRAL EFFICIENCIES
 Parameter	Number of elements
 	4	8	12
 3 dB beamwidth [?]	28.6	16.1	13.5
 Mainlobe attenuation at edge[dB]	3.6	13	17.8
 Sidelobe suppression [dB]	14	26	50
 Median spectral efficiency [bps/Hz]	1.5	2.1	2.2
 femto-cell system, varying the power limit from -30 dBm to 30 dBm in steps of 5 dB. From the CDFs of the spectral efficiencies we then obtain the spectral efficiencies available to 90% and 50% of users. Fig. 7 shows the results. For reference we include subsectorization (referred to as SubS) and intra-cell TDMA systems, both considering inter-cell interference. For subsectorization we used the best possible radiation patterns for both 4 and 12 antenna systems as previously presented in Table V. When the BS is limited to 4 antennas, the theoretical capacity aciheving DPC upper bounds all other techniques at any power level and any availability. However, ZF and RZF can achieve an important proportion of DPCs spectral efficiency. In fact, ZF reaches 88% and 95% at 30 dBm for 90% and 50% availability respectively, while RZF achieves 92% and 95%. The improvement of RZF over ZF, particularly at 90% availability, is attributable to RZF dealing effectively with poorly conditioned channel matrices and high intercell interference. As we will see later, these results differ significantly from those obtained through simulation using a 3GPP model with default parameters. Our results predict spectral efficiencies much higher than those obtained from that model.
 The comparison with the case where the BSs are assumed to have 12 antennas (RZF-FCSI and RZF-PCSI) is shown in Fig. 8. We here repeated the results of RZF and DPC using 4 antennas to contrast them with RZF using 12 antennas. For the latter we considered systems with and without inter-cell interference mitigation. Improved performance at the expense of added transmit channels is of course present in the noiselimited region. However the more significant gains occur as the transmit power reaches levels where the spectral efficiency of the systems without inter-cell interference cancellation approach saturation (around 10 dBm). Full CSI exchange across cells (RZF-FCSI) will of course be best and in our case requires a relatively modest amount of information exchange. Using only the channel correlation matrices, which may require less frequent CSI updating, offers more limited benefits.
 Subsectorization shows a very clear saturation for much lower powers than the interference- cancelling systems. The reason for this is that with growing transmit power, for subsectorization intra-cell interference limits spectral efficiency before the effect of neighboring cells sets in. This is illustrated by the fact that the saturation levels for these systems match the best values presented in Fig. 6, where no outof-cell interference was included. As a result of this intracell interference, subsectorization will only achieve spectral efficiencies comparable to the interference-cancelling schemes in the noise limited case, i.e., for low transmit powers. In
 -30	-20	-10	0	10	20	30	-30	-20	-10	0	10	20	30 Power [dBm]	Power [dBm]
 	(a)	(b)
 Fig. 7. Per-user spectral efficiency vs. power constraint of various techniques for a) 90% availability and b) 50% availability.
  
 Power [dBm]
 Fig. 8. Per-user spectral efficiency vs. power constraint of inter-cell interference mitigation techniques for 50% availability. RZF with 4 and 12 antennas and DPC with 4 antennas are shown for comparison.
 the saturation region it performs no better than intra-cell TDMA, which is particularly simple to implement. In this region, subsectorization achieves around 25% of RZFs spectral efficiency and 23% of DPCs spectral efficiency for 90% and 50% availability.
 As seen in Fig. 7, the DPC bound proposed in [16] considerably overestimates its actual spectral efficiency, which is 65% and 71% of the bound at 90% and 50% availability, respectively. The spectral efficiency gain of DPC over intracell TDMA is characterized in [16] without taking into account inter-cell interference. It is shown that this gain tends to one for low SNR and is bounded by min(M,K) = 4 for high SNR. This gain is shown for our data in Fig. 9 for 90%, 50% and 10% availability as a function of the SPC. We have plotted the spectral efficiency gains for our multi-cell system and, for comparison with the results in [16], for the case when the neighboring cells are turned off, referred to as “single-cell”. As seen, the DPC spectral efficiency is always above that of intra-cell TDMA, even for low powers. For high power, the gain asymptotically approaches the bound in the single-cell case, but saturates well below this value for the multi-cell case.
 Since inter-cell interference limits the asymptotic spectral efficiency, we compared the performance of the above reuse 1 system with the reuse 2 system, considering only the case where the BSs have 4 antennas. Fig. 10 shows this comparison
  
 Fig. 9. Spectal efficiency gain of DPC over intra-cell TDMA for 90%, 50% and 10% availability in the single-cell and multi-cell scenarios, in function of the SPC.
 for DPC, RZF and 4-antenna subsectorization. Under our conditions, reuse 2 performs worse than reuse 1 for 90% and 50% availability. In the subsectorization case, which is intra-cell interference limited, reuse 2 results in a net loss of about half the spectral efficiency at all powers. It was found that for our data reuse 2 only presents an advantage over reuse 1 for 96% availability and above in the case of DPC. The reason for the advantage at high availability is that in such cases the spectral efficiency is limited by a small number of poorly placed users, subject to particularly high inter-cell interference. In contrast, for the rest of availabilities, the increased SINR of reuse 2 will not offset the disadvantage of transmitting only half the time. Similar results have been found for hexagonal macro cellular systems with techniques such as frequency reuse, fractional frequency reuse etc., where it is also found that coordination essentially helps those few users located at the boundaries between cells experiencing the strongest interference [50]. The proportion of such locations is even smaller in our linear layout.
 We also evaluated the effect of the inter-cell interference on the spectral efficiency of the users most exposed to it. For this purpose we grouped the users into “edge users” (placed in the external 30? subsectors) and “central users” (placed in the 2 central subsectors). We compare their per-user spectral efficiencies by plotting the Complementary CDF (CCDF) for RZF at 30 dBm of SPC. We evaluated this for reuse 1 and reuse 2. The results are shown in Fig. 11. As seen, in both
  
 -30	-20	-10	0	10	20	30	-30	-20	-10	0	10	20	30 Power [dBm]	Power [dBm]
 	(a)	(b)
 Fig. 10.	Comparison between reuse 1 and reuse 2 transmissions for the per-user spectral efficiency vs. power constraint of DPC, RZF and 4-antenna
 subsectorization, for (a) 90% availability and (b) 50% availability.
  
 Spectral Efficiency [bps/Hz]
 Fig. 11. Comparison of CCDFs of the per user spectral efficiency of RZF for 30 dBm, for edge users (red) and center users (black) when using reuse 1 and reuse 2.
 cases reuse 1 is on average a better option than reuse 2. We illustrate this effect for RZF, as due to the form in which spectral efficiencies are obtained for DPC, it is not possible to obtain the individual per-user values separately.
 In order to test the sensibility of the results to the level of inter-cell interference, we repeated the above calculations assuming penetration losses of 20 dB and 16.5 dB at values of ? exceeding 73.7?. As expected, this results in lower spectral efficiencies and the interference-limited zone starting at a slightly lower transmit power. We show this for DPC and RZF in Fig. 12. In particular, for a 20 dB maximum penetration loss at 90% availability, DPC and RZF come within 10% of the saturation spectral efficiency at powers 3.2 dB and 2.4 dB lower than in the 23.5 dB penetration loss cases. The corresponding values for 16.5 dB penetration loss are 5.9 dB and 5.5 dB. Not surprisingly, the benefit of using reuse 2 increases as the penetration loss diminishes. In fact we found that at 90% availability, reuse 2 will perform on par with reuse 1 in the saturation region when the penetration loss is 20 dB. At the same availability, when the penetration loss is 16.5 dB, the spectral efficiencies of reuse 2 at saturation are around 10% higher than those of reuse 1 for both DPC and RZF. However, reuse 2 is still worse than reuse 1 at 50% availability.
 C. Comparison of Empirical Results with Model Based Predictions
 Finally we compared our empirically based results with those that are obtained using 4 different simulation models. This includes: the model based on our empirical data as discussed in Section III, a model based on our observed pathloss (see Eq. (2) and (3)) combined with small-scale Rayleigh i.i.d. fades and two models based on the 3GPP standards. We compare the per-user spectral efficiency at 50% availability vs. power constraint for DPC and subsectorization under the same conditions used to obtain the results shown in Fig. 7. The simulated results are obtained replicating the empirical setup but using the various channel models to generate the gain matrices. 20 placements for the BS array were simulated, each with a distance between the BS and the center of the room determined by a uniform random distribution in the range from 15 to 60 meters. For each simulated BS placement a set of 4 users (one per subsector) is created, all within a range of +/2 meters with respect to the previously chosen distance. 800 realizations are evaluated per BS array placement. The results are shown in Fig. 13.
 The 3GPP model considered is described in detail in [35]. We started by evaluating the 3GPP model with the outdoorto-indoor urban microcell default parameters. We used these parameters for both the cell being served and for the interfering neighboring cells. This is denoted as the “3GPP default” model in Fig. 13. As seen, this did not yield a good prediction, as it underestimates spectral efficiency by a large margin (around 40% of empirical spectral efficiencies). We thus introduce a modified version that we refer to as “modified 3GPP”, which better fits our measured results. This differs from the default model in that for the central femto-cell (i.e. the cell being served) we use the 3GPP outdoor-to-outdoor LOS model to calculate the path-loss, which we combine with outdoor-toindoor small-scale default parameters. For the neighboring femto-cells we use as before the outdoor-to-indoor urban microcell scenario as formulated in the model. This choice was motivated by our empirical data. As discussed in Section III,the observed intra-cell path-loss for the outdoor-to-indoor scenario was close to that of a LOS link, but at the same time the K-factors were quite small, typically below one. Thus
  
  
 Power [dBm]
 Fig. 12. Effect of maximum penetration loss on the per-user spectral efficiency of DPC and RZF for 90% availability.
 despite an “excess path loss” that is much smaller than that of the 3GPP model, the scenario is still characterized by very rich multipath propagation. The resulting modified 3GPP model achieves a better prediction with an error of 18% for DPC.
 The two models based on our empirical data result as would be expected in the best match and provide added insight into the effect of the channel. The model that only uses empirically based path-loss combined with Rayleigh i.i.d. small-scale fades overestimates spectral efficiency, but the error is in general not very large. For DPC, it is 7% in the saturation region. Our model including the empiricallybased small-scale fades slightly underestimates the spectral efficiencies. We found that the difference between both models is essentially due to the inclusion of channel correlation. In fact, when omitting this correlation in our proposed model, the resulting spectral efficiencies become very close to those of the Rayleigh i.i.d. model. This is consistent with what was hypothesized in this regard in [51].
 VI. CONCLUSIONS
 We have evaluated the advantage of intra-cell interference canceling systems by comparing their spectral efficiencies with that of subsectorization, which only mitigates interference using fixed antenna beams. We found that for a typical femtocell scenario, characterized by a street canyon type setting, the spectral efficiency gains over subsectorization can reach factors between 3 and 5, the exact value depending on the specific system and the percentage of users being considered. Subsectorization is limited by intra-cell-interference and in fact does not perform better than using intra-cell TDMA. Among the intra-cell interference canceling systems, RZF can achieve more than 80% DPC’s spectral efficiency. Interference from neighboring cells limits the performance, but we found that attempting to improve this by alternating the transmission of contiguous cells results in general in a net loss of throughput. Considerable gains are achievable if the interference of the closest neighboring cells is mitigated, but at the expense of added transmission channels and extra CSI overhead. Our assumed service environment yields significantly higher spectral efficiencies (by a factor of 2 or larger) than predicted by the standard 3GPP model. This is because we observed that same-cell links had significantly less path-loss than predicted
  
 Fig. 13. Per-user spectal efficiency versus power constraint comparison using empirical and simulated data for 50% availability.
 by the 3GPP model when the SU is placed at indoor locations free of significant blockage to the BS (for example close to an outdoor facing window). The resulting advantage in spectral efficiency suggests that choosing an adequate position for the SU in combination with indoor repeating using WiFi, will provide considerable gains over attempting to directly serve indoor users at all positions.
 
 ﻿In this work we obtain capacity gaps for a class of N-pair bidirectional Gaussian relay networks, where one relay can help communications between the corresponding user pairs. For the uplink, we apply the generalization of successive compute-andforward strategy (SCAF) for decoding the linear combinations of the messages of each user pair at the relay. The downlink channel is considered as a broadcast network with N receiver groups. It is shown that for all channel gains, the achievable rate boundary lies within gaps of (N- 1 + log2N)/2N and (N + log2N)/2N bits/sec/Hz below the cut-set upper bound for restricted and nonrestricted models, respectively. These gaps tend to 1/2 bits/sec/Hz per user as N goes to infinity. We first derive a comprehensive formulation for the N-step asymmetric SCAF and use it to derive the capacity result for our problem. 
 In [1], a compute-and-forward strategy (CAF) has been proposed for Gaussian relay networks with equal power constraints and asymmetric channel gains based on nested lattice codes [2]. The receiver can recover the associated linear equations which are closer to the channel fading coefficients. This strategy simultaneously provides protection against noise and the opportunity to exploit interference for cooperative gains [1]. In [3], a scheme has been proposed for Gaussian relay networks with unequal power constraints and symmetric channel gains based on nested lattice codes where it computes an achievable multi-cast rate within a constant gap below the capacity. In [4], a successive CAF (SCAF) scheme has been presented for the same network as defined in [1]. In this method after decoding a linear combination of transmitted codewords, the receiver can combine it with its channel observation to obtain a new effective channel that is better for decoding the next targeted linear combination. In [5] and [6] an asymmetric CAF has been proposed for MIMO networks and Gaussian relay networks, respectively, with unequal power constraints and asymmetric channel gains based on nested lattice codes. 
 In [7] and [8], a modified asymmetric CAF strategy has been presented. The method utilizes a set of scaling factors to decode integer linear combinations of transmitted codewords. The use of scaling factors in fact is equivalent to decoding non-integer linear combinations of lattice codewords. It allows different users to have different coding rates. Thus, by appropriately adjusting those factors, different points on the boundary of the rate region can be achieved. Also, in [9], the idea of decoding non-integer linear combinations of lattice codewords has been presented which can be considered as a special case of the methods of [7] and [8]. 
 In this paper we generalize the method of [6] to Nstep SCAF. We also consider scaling factors as defined in [8]. Then we use these results to address Multi-Pair TwoWay Relay Networks (MPTRN), where one relay can help communications between the user pairs of each of the twoway relay channels (TRC). We present an achievable rate region for the MPTRN based on the generalization of the SCAF strategy. It is shown that this method achieves rates within (N -1+log2 N)/2N and (N +log2 N)/2N bpcu of the cut-set upper bound for the restricted and non-restricted MPTRN, respectively. As N goes to infinity, these gaps tend asymptotically to 1/2 bpcu. Some of the previous works about these topics are as follows: 
 In [10], an achievable rate region was proposed for twopair two-way relay networks (TPTRN) based on using the combinations of lattice and Gaussian codewords. In that network, a relay node facilitates the communication between two pairs of users. They assume a complex AWGN channel model. It was shown that for all channel gains, rates to within 3 bits/sec/Hz per user of the cut-set upper-bound are achievable. In [11], we studied the same network model as in [10] but with the assumption of real AWGN channel model, obtaining a larger achievable rate region for that network by exploiting nested lattice codes and the successive compute-and-forward approach of [4]. It was shown that this method achieves within 1/2 and 3/4 bits/sec/Hz per user of the cut-set upper bound for restricted and non-restricted network models, respectively. The paper is organized as follows: In Section II the system model for the general Gaussian relay network is defined. In Section III we present our generalization of the SCAF approach. The system model, achievable rate regions and capacity gaps for the multi-pair two-way relay networks are presented in Section IV. Some concluding remarks are provided in Section V. 
 In this section we consider a Gaussian relay network with L transmitters and M relays. We use the same model as defined in [1], but with the assumption of unequal power constraints and asymmetric channel gains. Each relay (indexed by m = 1,2,··· ,M) observes a noisy linear combination of the transmitted signals through the channel, 
 where hml ? R are the channel gains and zm is i.i.d. Gaussian noise, zm ~ N(0,In×n). Let hm = [hm1,··· ,hmL]T denote the vector of channel gains from the L users to relay m. Each channel input x` is a n-length sequence subject to the average power constraint P`, for all `, i.e.,  . The channel gains are assumed to be known and constant. 
 [1;n] denote the set of integers {1,··· ,n}, and dxe denote x rounded to the nearest integer value. Throughout the paper, vectors are shown with boldface letters. 
 In this section we propose a straightforward and comprehensive upper bound to the rate of the multi-step asymmetric successive compute-and-forward strategy (SCAF). We consider the system model as defined in Section II, which assumes unequal power constraints and asymmetric channel gains. We also consider real-valued scaling factors ß for decoding the non-integer linear combination of lattice codewords. 
 In N-step SCAF, at each step, the receiver can combine its estimation from the previous step with its channel observation to obtain a new effective channel that is better for decoding the next targeted linear combination. This continues for N steps. The general formulation N-step SCAF is expressed in the following theorem. 
 Theorem 1. Consider the Gaussian relay network defined in Sec. II, with unequal power constraints P1,··· ,PL and equation coefficient vectors ami ? ZL, where ami = [ami,1,··· ,ami,L]T and i ? [1;N]. Let ß1,··· ,ßL be L nonzero real numbers. By N-step SCAF strategy, if the computation rate tuple (R1,··· ,RL) is achievable, then 
 Remark 1. For N = 1, and P` = P, for all `, (2)-(3) reduces to the results presented in [7]-[8]. 
 Remark 2. (Equal power constraints and asymmetric channel coefficients) For N = 2, P` = P, and ß` = 1, for all `, (2)-(3) reduces to the results presented in [1] and [4]. 
 Remark 3. (Unequal power constraints and symmetric channel coefficients) For M = 1, N = 1, ß` = 1 for all `, and h = a = I1×L, (2)-(3) reduces to the results presented in [3]. 
 As it is seen from the above remarks, the proposed formulation in (2)-(3) is capable of manipulating both unequal power constraints and asymmetric channel coefficients conditions even if we omit the scaling factors from the equations. 
 In this section we present the system model for a class of multi-pair Gaussian two-way relay channel (MPTRN) consisting of N TRC pairs. We express the cut-set upper bound, achievable rate regions based on the proposed asymmetric SCAF strategy and calculate the capacity gaps. We also show that allocating the users powers according to the channel gains results the larger achievable rate region. 
 A MPTRN with N pairs is shown in Fig. 1, where nodes (2i - 1) and (2i) denote the ith pair of users which can communicate to each other via node r (a relay). There is no direct link between users. The relay is assumed to be able to listen and transmit at the same time. Uplink and downlink channels related to the ith pair are denoted as   and 
 For each S ? [1;N], let TS = {Tk}k?[1;K] denote the set of all the sets of nij, where i ? S, and j ? {1,2} such that if nij,nil ? Tk then j = l, i.e., Tk doesn’t include two nodes of a pair. For example for S = {1,3},   denote 
 the set of (i,j) such that nij ? Tk, for k ? [1;K], where K denotes the number of the members of TS. For j ? {1,2}, let ?j ? {1,2} denote the other node in a pair which communicates with j, i.e., if j = 1 then ?j = 2. Let mij?j ? [1;M] denote the message that node j of pair i communicates to 
 Fig. 1: The multi-pair Gaussian two-way relay channel. node ?j of pair i. This message is encoded into a codeword xij using an encoding function xijq = fjti (mij?j,yji,q-1), for q ? [1;Q], where, Q denotes the number of channel uses, xiqt is a realization of a real random variable Xjqi , satisfying the power constraint  , and yji,q-1 denotes the previously received symbols at node j ? {1,2} of pair i ? [1;N]. This mode, called non-restricted encoding, can introduce some dependency between the signals transmitted by different users. In contrast, restricted encoding uses the encoding function xij = fji(mij?j). The messages are assumed to be independent. The rate of transmission is defined as R = 1/Llog2 M. 
 The received signals at node nij, for all i,j, and at the relay node, r, at time instant q, are given by 
 respectively, where xrq denotes the transmitted signal by the relay at instant q. zjqi and zrq are independent and realizations of i.i.d. real-valued Gaussian noise N(0,1). hirj and hijr denote the downlink and uplink channel gains, respectively, for all i,j. Node nij uses a decoding function gji to decode  as , where y . 
 In this section the cut-set upper bound for restricted and non-restricted MPTRN are given. These are extensions of the cut-set upper bound presented in [10] and [11] for two-pair two-way Gaussian relay networks. 
 Theorem 2. The capacity region of the non-restricted Gaussian MPTRN is upper bounded by, 
 Proof: Consider the cut S ? [1;N], the first and second terms in the right-hand side of (9b) denote the upper bounds for the multiple access and the broadcast cuts of the Gaussian relay network, respectively. 
 Corollary 1. For the capacity region of the restricted Gaussian MPTRN, we have the outer bound (9a) but (9b) is changed as follows, 
 where k ? [1;K]. The proof can be realized considering the fact that the inputs are mutually independent in the restricted network. 
 Lemma 1. The non-restricted cut-set upper bound is within 1/2 bit/ sec/Hz of the restricted cut-set upper bound. 
 Proof: The proof can be done by the same way as done for two-pair two-way relay network in [10]. 
 In this section we present an achievable rate region for the described MPTRN. In our scheme, we use a restricted encoding function, so it will be an achievable rate region for both restricted and non-restricted network models. The idea is based on the fact that in the uplink communication, MPTRN can be considered as an AWGN network with 2N transmitters and one receiver, and so we can apply the proposed asymmetric successive compute-and forward method to decode the linear combinations of the codewords of each pair successively. 
 In the downlink, MPTRN is considered as a broadcast channel with one transmitter and N receivers and decoding at the users is done by successive interference cancellation. Note that we consider N receivers instead of 2N receivers, because of the fact that each pair is a two-way relay channel and the downlink channels of each pair is not considered as a broadcast channel since each receiver knows about its own message and can subtract it from the its observed signal. 
 1)	Encoding at the Users:   2N nested lattices are constructed such that ?1 ? ?2 ? ···?2N ? ?. For each ` ? [1 : 2N], ?` has second moment P` = aji?jP, for some distinct i ? [1 : N] and j ? {1,2}, where P1 = P2 = ··· = P2N. All lattices are assumed to be simultaneously good. For each message of transmitters, the codebook C` = V` T? is constructed, where V` denotes the Voronoi region of ?`, and ` ? [1 : 2N]. The transmitter i sends 
 where t` ? C` and d` is a random vector uniformly distributed in V`. So,   and xij?j belongs to an ensemble 
 of dithered lattice codes with sizes  , with xij?j independent of t` and uniformly distributed in V`. 
 2)	Decoding at the Relay: Decoding at the Relay is done according to the successive compute-and-forward method described in Theorem 1. Here we have one relay, so M = 1. Without loss of generality, we assume, 
 At the ith stage of successive compute-and-forward, the relay decodes the ith linear combinations of lattice code ensembles 
 Theorem 3. The coefficient vectors ai can be successfully decoded at the ith stage successive compute-and-forward, so long as, 
 Proof: The combination of the uplink channel gains and node transmitted powers yields the following vector of incoming signal amplitudes at the relay: (hp)T is defined as follows 
 More similarity between vectors ˜api and (hp)T results in a larger achievable rate region (see Theorem 1). So we select   and  . Also in order to attain simpler equations and also a larger achievable rate, we consider power allocation of the users as follows, 
 3)	Encoding at the relay: The relay maps N lattice codes ti to Gaussian codewords   from codebooks with sizes {2nRrti } for i ? [1;N], respectively, where 
 4)	Decoding at Users: Decoding at users is done by using the successive interference cancellation method. In this way, the user with the largest channel gain first decodes the messages related to the users with worse channel gain conditions. Then, it decodes the message related to itself, i.e., the message of the other user which belongs to its pair. Thus, at each user with a specific channel gain, only the users of other TRC pairs with higher channel gains can cause interference. For each nij, let Sji ? [1;N] \ {i} denote the pairs such that for each k ? Sji, |hkrj0| = |hirj| for some j0 ? {1,2}. By the described strategy, it can be seen that the following message rates are obtained: 
 For example, let N = 3, and assume that |h1r1| = |h2r2| = |h3r1| = |h1r2| = |h2r1| = |h3r2|, so we have S11 = f, S21 = {2,3}, S12 = {1,3}, S22 = {1}, S13 = {1,2}, S23 = {1,2}, and decoding at the users is done as follows: 
 Decoding at the users of the first pair, i.e., users 1, 2, with channel gains |h1r1| and |h1r2| can be done with an arbitrary small probability of error if the message rates associated to 
 User 1 of the first pair has the highest channel gain, thus it first decodes the other messages and then cancels them from its received signal. Then it decodes the message of user 2 of the first pair. For user 2 of the first pair, , so the 
 parts part2 x2rt and part3 x3rt of xr make interference in the decoding of part1 x1rt. 
 By the same reasoning, the following message rates are obtained for decoding at the other users, 
 In this section we state the capacity gap for the uplink and downlink channels of the restricted MPTRN in the following Lemma: 
 Lemma 2. By using the described strategy, for any rate tuple r = {rji?j}i?[1;N],j?{1,2} satisfying 
 where k ? [1;K], there exists a choice of power assignments such that decoding of codewords at the users in the downlink with rates r can be done with arbitrary small error probability for all channel gain coefficients. 
 Proof. We must show that if (14), (18) and (21a)-(21d) are satisfied, all power scaling factors between zero and 1 are obtained. Next we prove the theorem for uplink (21a) and (21b), the proof for the downlink can be done similarly. We need the following inequality: if x = 0 then 
 From the above Lemma, it is seen that the maximum gap between inner and outer bounds is  , and from Lemma 1 for the non-restricted Gaussian MPTRN, this gap is  bits/sec/Hz per user. 
 1) For N = 1, i.e., the two way relay channel, the gap for the non-restricted channel model is equal to  which is compatible with the result of TRC in the literature. 2) For N = 2, i.e. the two pair two way relay networks, the 
 for restricted and non-restricted channel models, respectively which are the same results as obtained [11]. 
 3) As N ? 8, the gaps for restricted and non-restricted channel models, i.e., GR and GNR asymptotically goes to 1/2. 
 In this work, we presented a comprehensive asymmetric multi-step successive compute-and-forward scheme which includes the previously proposed schemes. Based on the proposed approach, we obtained the capacity gaps for a class of multi-pair two-way Gaussian relay networks (MPTRN), where one relay can carries communications between N asymmetric TRCs. It was shown that for all channel gain conditions, the proposed compute-and-forward scheme achieves rates to within constant gaps (N - 1 + log2 N)/2N and (N + log2 N)/2N bits/sec/Hz per user of the cut-set upper bound for the restricted and the non-restricted network models, respectively. These gaps tend asymptotically to 1/2 bits/sec/Hz per user as N goes to infinity. 
 ﻿ We present empirical on the achievable cellular system throughput gains stemming from the use of remote radio in an urban environment . Our work is based on simultaneous path loss of the base station and links to outdoor street level . We calculated the increase in received power , when a is added to improve the coverage by a . We consider diverse for the and diverse coverage for the mobile station , the effect of height and position with respect to the intended . We also compare the power gains that would be in practice from combining such as selection combining and maximum ratio combining . 
 We conclude that under practical , the of will depend very strongly on the existence of line links between the and the intended . For at low , below the clutter , only in a position with respect to the will obtain a significant benefit . Our data also that the gains in signal to noise ratio when are only marginally better than those of the much simpler . 
 Index Channel modeling , maximum ratio combining , remote radio , selection combining , small , wireless . 
 NE of the great for today wireless communication is to provide adequate spatial coverage in a cost effective way , while efficiency and interference adequate for high frequency re use . To meet this challenge there been a growing interest in the study of , relay and low complexity , . These may constitute relatively simple , and easy to install when to the deployment of an additional base station to serve mobile within the cell . 
 While are as a small coverage with low transmit power connected to a wired network , a is 
 connected to a through a wireless link , being able to repeat or re code the data by amplify and forward or forward , among . A repeater may be thought of as an amplify and forward relay with no or ability . In this context , there are two basic of : wireless , and remote radio , also known as fiber , connected to a by an optical fiber . will suffer large and small scale fading at both and links . In contrast , for wireless , achievable gains will only depend on the quality of the connection , which it an attractive solution to provide connectivity to wireless in dense urban , where the links to the may experience significant shadowing . 
 Proper placement of a is obviously a fundamental factor in the compromise between the desired gains and the cost associated with its installation . In this regard , in an urban environment it is reasonable to expect that while coverage will improve with antenna height , this will at the same time have a negative impact on deployment and on channel interference , thus affecting frequency reuse in a large system , . If the is to cover an area of a size comparable to a small cell , then it is reasonable to assume that this is best by its antenna in normally used by . In such well established propagation such as those of and al . will be adequate to predict the coverage by the . Alternatively , they may be positioned at lower with the aim of in more limited , i . e ., generating within a large cell . Coverage in growing interest as it can provide local in signal to noise ratio and thus high data , . This may be without generating excessive interference in neighboring and at lower implementation when to a , , , particularly when below clutter height . Numerous empirical have been for the statistical characterization of path loss in relatively low height radio links . Analytical based on optical geometry have also been for in urban , . Goldsmith al . , based on a collection of , a mathematical description of the radius of coverage of a for an urban environment with and without line of sight . of local mean attenuation are for two , and it is found that these have the shape of convex . al . in an indoor outdoor environment operating under Amplify and Forward and Decode and Forward . In , the studied different of and in cellular , concluding that careful placement of can improve capacity substantially , transferring traffic from heavily loaded to lightly loaded , thereby improving network capacity . They also conclude , based on their , that it is best to place on a horseshoe layout with a sum transmission power of all comparable to the transmission power of a single macro base transceiver station . 
 The . Relay Task Group and the WINNER Consortium have the use of both empirical and theoretical to predict path for wireless links with transmission below the clutter of , also applicable to links . While the accuracy of for diverse been the subject of extensive , their use in wireless more than treating each link individually , since the joint statistics of and links may not correspond to those of independent random . 
 In this work , we report an empirical study that the joint statistics for the path of the links involved in a cellular system by . Specifically , our are based on simultaneous path loss of the and links in an outdoor urban environment . Based on our we evaluate diverse related to the performance improvement that can be when a in an area by a . We focus on modeling the statistics of the radio links involved and the resulting gains in received power by the mobile user . Our will be useful to calculate the achievable gains in transmission experienced by mobile . 
 Our empirical study firstly considered the influence of the height . Toward that end , we by the in a tall building position , typical for an urban radio cell , and then lowering it stepwise to a height of . In this study , we considered street level user spread over a disk with a radius of centered at the . Path loss data for all links involved was collected at each height . The us to quantify the between height and the achievable gains in coverage and received power . For our test , it was found that on average an increase in height of the an increase in received power of about for every . Overall , the suggest that the effectiveness of a system is quite limited if a large area is to be covered , unless the is positioned at such a height and at such that in practice it becomes another urban . This conclusion led to the second part of our study , where we restricted to a disk with a radius of only centered at the . In addition , we the at lamp post , considering that this type of setting will be typical for a practical deployment of low cost . In this part of the study we also considered two of . One was chosen so as to maximize the likelihood of to the and the other chosen in close proximity to the first , but from direct street view by construction . In this way we were able to evaluate the effect of blocking a , as may occur when a surrounding construction is after the placement of the fiber repeater . Our are only directly applicable to narrow band transmission , for example a single carrier of an transmission , as our were done with unmodulated . We also report that involve spatial , i . e ., the elimination of small scale . This is equivalent to spatial diversity , which often similar to frequency diversity . 
 From the joint data of path loss for the and links we were able to compare the effectiveness of Selection Combining and Maximal Ratio Combining at the mobile terminal . To this effect we considered typical transmit and antenna gains at the and and calculated received signal power at the under the condition of equal noise power for both . It was found that the statistical gain of over is less than under all tested , a consequence of the random power imbalance among the links . 
 Our also us to calculate between for the and links for all . The low validate the approach based on considering them as independent random . 
 The rest of this paper is organized as : In Section we present a detailed description of the measurement scenario and . The related to the effect of height on the achievable gains are in Section . In Section , we present the empirical when a at lamp post height . are in Section . 
 The measurement campaign extended over a period of during summertime . The urban area used as in Mar , Chile , a mix of high rise and two story with ranging from to , built on a plane region at sea level . of received power at were carried out at . The area is by nearby that a transmitter at a location typical for a covering a relatively large urban area . The height was above the measurement region at a distance of to the position . The was mounted at various on the external wall of a high building as will be later . The streets in the measurement area are lined with with ranging from to . All links were of sight , with due to the surrounding construction . A schematic description of the scenario and terrain profile is in . and . 
 The second scenario was based on the same urban for both base and but with all within a disk with a radius of centered at the position of a . The was this time at above street level . The disposition of the user is shown in Fig . . 
 Fig . . Placement of , and in urban environment for the first part of this study . a Tested , D view . 
 A block diagram of the measurement system is shown in Fig . . At the position , a continuous wave source based on a oscillator a . unmodulated carrier with output power through a sector type antenna , corresponding to an of . The antenna used had azimuth and elevation 
 Fig . . Placement of and in urban environment for the second part of this study . 
 at . All were within this . At the , the antenna used was a vertically dipole with gain , a signal at . with output power , corresponding to an of . The choice of was based on the fact that they fall inside a band used for Metropolitan Area such as and that considerable previous work in this band been , providing a reference framework on propagation in urban . The was to contain a transmitter and a receiver tuned to the frequency . This us to remotely detect any possible anomaly at the , which was at a considerable distance from our measurement scenario . The separation between and provided enough isolation to allow simultaneous transmission and reception by the . 
 Power at the were carried out an model NA spectrum analyzer that simultaneously tracked the at . and . . The antenna used was a gain vertically dipole at a . height . The dynamic range of the measurement setup is limited from below by the system noise floor . only the spectrum analyzer as receiver , this proved to be inadequate for several of the user and would have our if we had only selected the where were feasible . We thus included a gain amplifier at the mobile antenna terminal to achieve a system noise figure of and thus a noise floor of in a . The resulting link budget us to measure path of up to in the link and in the link . At all selected the average received power the noise floor by at least . The measurement system included a computer that acquired the spectrum analyzer at a rate of per second . The received power from the and us to calculate the corresponding path for both links . 
 The two measurement involved moving the along a straight path of about . at each of the diverse in the region tested . This was done a very slow moving vehicle on which our measurement equipment was . We traversed each . sector at a constant speed in such a way that approximately equally spaced power were collected . At the frequency , this that more than of the are at spaced at least half a apart . From these we the average path loss at the location and the small scale fade statistics with respect to this average . 
 The first measurement campaign was at the effect of height . This involved the at different , ranging from to above street level . measurement for the were selected at various from the : within , between and and between and . These are marked with in Fig . . for in the range from to did in some result in path exceeding the reliable measurement range for received power . Thus , to avoid our , the statistics for this part of our study exclude data for below . 
 The second set of , at the practical performance gains for low , was based on , but all within of the , as in Fig . . Of these , were within , between and , and between and of the . The at a height of above street level , was at two different : one at an intersection so as to simultaneously illuminate two streets and the other one within of the first placement , but with no direct path to the adjacent streets . In the first case there are and user , while in the second all are . 
 In this section we quantify the effect of lowering the antenna from a position where in practice it can be considered another , to close to street level . To characterize our scenario , we first contrast the measured path with the corresponding by propagation . In various for path loss prediction are , some of which correspond to similar to the one used here as a test bed . These do not explicitly consider the height variation of the or relay , but are based on the relative position of these with respect to the user , i . e ., , above or below clutter . Among these , we chose the one that best our . Specifically we considered the alternative WINNER model for urban Type E links , with a above height and mobile below . The by this model were to the path loss link , considering the various . The for these links range to . The comparison is shown in Fig . where at all and for all are included . For this comparison we out small scale , thus generating one path loss value for each combination of height and position , which is to be to the model prediction . The separation of the empirical data into and was based on whether or not the line of sight path was blocked by a large structure such as a building . We considered that a tree in the direct path does not alter a condition . To avoid the figure we combined the for the various into three : to , to and to . The corresponding by the model is plotted considering a at a height in the center of the range of for each group . We note that the model is little affected by this height . We also show for reference the free space path loss . As can be seen , the path loss are within range of the model , although we some path loss reduction with height , not for by the model . The same figure also the of the path loss considering all , which as fall well below the model prediction . 
 We further the statistics of our empirical path for each height to those of the classical log distance model with log normal shadow fading and Rice small scale . As is common practice , we chose the model to adjust to the free space path loss at the reference distance of . We found that this model provided a very good fit , with a path loss exponent ranging from . to . when considering . When considering only the , the path loss exponent varied between . and . . The were at the highest position , with a clearly observable increase as the was towards street level . The standard deviation with respect to the regression line was in the range of to , with little difference between and links . For all of the , the statistics of the small scale fit the distribution , within the accuracy that result from a finite data set . For the links the Rice distribution 
 Fig . . Empirical path loss to WINNER model according to . j recommendation . 
 provided a similarly good fit , with that were quite small , no than . 
 The above indicate that our choice of measurement scenario the propagation behavior of an urban environment , as in the literature , by shadowing and by strong propagation . 
 To evaluate the achievable received power gain as a function of the height , we calculated the received power at the , assuming realistic for transmit power and antenna gains . We note that once the path for all links have been , we are free in subsequent to assume any transmit power for the and the , not necessarily those used before in the channel sounding process . In the calculation of received power at the , we thus used the actual measured path for the links , and transmit power that we reasonable for an actual deployment . From the collection of calculated power at the , we the cumulative distribution function of the received power . For this we considered transmission by alone , by alone , and transmission by both and with or at the . We considered a with of transmission power , typical for a . The and are assumed to be the same as the used in our and , respectively . For the we assumed that in most practical the would be attached to a wall and consequently only illuminate a sector of in azimuth . All our are in fact within a sector of such angular width . We thus considered that a typical , sector antenna would be used , consistent with in . For the transmit power at the we used two that cover what could be considered the high and low of a practical deployment : and . The lower value is representative for , while the high value is in the power range for and . 
 Figure the of the received power assuming that the at . The consider all power at all . We 
 Fig . . of received power at for , coverage radius and power . 
 for all between and but we here only show the corresponding to . The for essentially match the of the power received from the alone , with a shift to the right of less than at all probability . We do not include them in the figure to avoid the graph . All other fall between these two and are also for the sake of clarity . The improvement in coverage over that by the alone was only found to be significant when the a high position . Not shown here is the case where the at , which in virtually no gain at any position . 
 Fig . that the received power gain of over is almost insignificant . This is due to the fact that the likelihood of similar received power from and is quite small , and as well known , even for equal power the gain is only . We repeated these for diverse of to power with the result that the improvement in received power of over under all was no greater than . As before , this equal receiver noise in both , thus the power gain is equivalent to gain . Based on the above , we describe below the that were for the link in this setting . All our subsequent are based on the assumption of a at the user terminal , but for all practical the would be no different a . 
 From Fig . it is seen that , under the stated , of will receive at least when only the is operating . a at the maximum height , at this coverage to . At the other extreme , a at will provide virtually no statistically significant improvement in coverage , as the corresponding of received power was found to exhibit a right shift of less than . Obviously lower will further reduce any . We note that these rather limited gains were considering a relatively 
 Fig . . Power gain of over alone , for diverse as function of height with transmission power of . 
 high transmit power , only less than that of the base , which does however have a advantage over the , due to the difference in the corresponding antenna gains . 
 To quantify the gains we define as the difference in received power that can be to a proportion of . We refer to this proportion as the availability level associated with that power gain . We denote the of received power from the alone and from of and as and respectively . The gain in received power is then : 
 The same definition of course to the gain through . We now use to calculate , at various availability , the power gain resulting from the use of a . This is shown in Fig . for the full range of at of , and , considering of transmit power at the . To construct this figure we considered the empirical as in Fig . , but calculated for each height . In Fig . we also indicate as a reference the that would have been if instead of the measured for path , these had been calculated at each location a fixed path loss equal to the average value by the before . Specifically , for the link we used the alternative WINNER model for type E in while at the links we used the model , to a frequency of . . Since height dependence is not part of the model in , the resulting gain , which we found to be . , is only a function of the in the region . In contrast , the empirical gains show considerable height dependence . 
 From the data that Fig . is based on , we calculated by linear regression the increase in received power . height of the . The result was that under the stated , 
 Fig . . and power gains of over alone , for diverse as function of height with transmission power of . 
 the power gain is approximately for every in height increase , at of and . If the power is reduced to this gain becomes only . for every . We note that these represent the range of height related gains for our particular choice of and thus cannot be easily generalized . From a qualitative perspective however , the may suggest that the gain with height is mostly due to the fact that at the higher , the number of that exhibit a link to the is . To investigate this aspect further , we segmented the , separating the into those with , and those without , for each height . The resulting power gain . height is shown in Fig . . In this figure we also show the percentage of . As seen , for the there is little gain improvement as the height . On the other hand , for the , there is more evidence of gain increase with height . The main conclusion that may be derived from this figure is that the benefit significantly more from increasing the height of the than those that are . We also note some gain with height , even when the percentage of location a saturation level . Thus , the growth in the percentage of links with does not by itself account for the gains with height . 
 Finally , to evaluate the degree of dependence of the in the and links we calculate the coefficient between these for each height as 
 where and represent respectively the path , the small scale , from the and the to a specific position . E and E are the statistical of these path at the distance under consideration , from a linear regression of path loss . distance . and are the standard of the with respect to these . 
 This calculation was repeated for each height . The were very small . Only at the height did approach . , while at all it was less than . in modulus . We also calculated the of the shadow , i . e . the after out the small scale . This would be more representative for links with space or frequency diversity , which to suppress small scale . In this case was somewhat , but still not significant , reaching . at the height and between positive and negative less than . in modulus at above . 
 The of the previous section suggest that even with a position at a height that is comparable to that of an urban cell , only modest gains can be at a large coverage radius . This even at a relatively high transmit power . In this section we therefore explore more practical , limited to much smaller coverage and a lower height above street level , as we have in Section . In this setup we also the effect of choosing a position with an uncluttered path to two streets , in contrast with it in a nearby position by construction . The first placement is here as Non and the second as O . The position links to some of the chosen . For a setting where both are below clutter , links are as being in a street canyon . Correspondingly , we refer to the links as non street canyon . In the radius , half of the links are of the type while all O links are non street canyon . Within the radius all links to the become of street canyon type . This classification according to the link is , as before , at which can be in practice to benefit most from a given placement . We again first that the chosen are such that the path loss statistics for the environment correspond to well established propagation . 
 For the links , we found a good match to the model and to the alternative WINNER path loss model for the type case in , an operating frequency of . . With respect to these , our measured were slightly higher , and on average , with root mean square ... of and respectively . The measured for the street canyon links were far lower than those for links at the same distance , from to , with on average . They were however higher by about on average than those by the advanced model for Type with both and below . The path loss these are shown in Fig . . As before , we also that our data fit the statistics of the log distance model , with log normal shadow fading and Rice small scale . The resulting were . and . for and links respectively . We note that , as before , most of our links were at least partially by relatively large . 
 Fig . . Empirical path loss to reference for low height . 
 Fig . . of received power at for coverage radius and power . height was . 
 Fig . the of the received power at the as previously for Fig . but within the radius . We illustrate as an example , only the case where the at for both . All other are as before . As seen , the achievable gains very much depend on the specific placement of the . For example , at coverage , the will guarantee a power of at least . an O will guarantee the same power to of , while an will increase this coverage to . When this calculation under the assumption of a transmit power of , the coverage to and respectively . We summarize the gains for various in what . 
 To evaluate the effect of coverage range we divided the where the power were carried out into three with disk radii of , and , to the . Table I the power gain as 
 defined in , with a at the availability of , and , for two transmit and for the two . The are almost identical . We recall that for a radius of or less the placement street canyon type links to all , while only of the are in that condition for the radius . The tabulated provide some interesting insight into the that can be from the use of a . We first note that for and availability , there are consistent in power gain as the coverage radius , particularly when all user become of street canyon type with respect to the . This increase is especially sharp at availability . The at availability , while not as relevant in practice , serve to illustrate the gains available to a minority of that have a particularly low path loss to the , for example due to an unobstructed path at a short range . We in fact see that the gains available to of at a radius are comparable to those for within the shorter . The two smaller radii include only street canyon type links for the case , however the variation in distance from the various user to the is obviously for the than for the case . At high availability this significantly power gains for the smaller radius , as it will exclude most user with higher path to the . Not as obvious is the fact that when considering availability , the power gains can actually decrease with the radius , as seen in the table . This is due to the fact that the smaller radius may also exclude some user that exhibit particularly low path to the . It is precisely these few well with respect to the that dominate the achievable gains for low availability . In the same context , we observe that for the , a increase in transmit power in almost exactly the same increase in received power to the best . This again that for such , the received power is completely dominated by that of the . 
 Both Fig . and Table I illustrate the importance of proper of the . This can also be associated with the fact that the position street canyon type links , particularly at the radius of and . We further explore this below . 
 Based on our above we divided the for all links with up to length into street canyon and non street canyon , rather than by distance as before . Table the for the power gain under this classification , again the previously detailed in Section . 
 The illustrate that very considerable power gains are available for street canyon links , even at low . In contrast , the row corresponding to the non links very modest gains regardless of the position . The latter were considering only that are of non street canyon type under both , so that are based on a common set of data . 
 SELECTION COMBINING GAIN WITH LOW HEIGHT , WITH . 
 To illustrate the gains achievable under the most favorable and , we present in Fig . the for received power considering all street canyon within the disk of radius , at a power of . When this figure with Fig . , it becomes clear that the street canyon within the radius are those that contribute most significantly to the in received power . For example the will provide at least to of . This same minimum power will be available to of if a is included . this for an assumed transmit power coverage to virtually . 
 Finally we again calculated correlation of for the and links , for O and . In both these were found to be below . . When are out , this to . . 
 Our work that in an urban environment a cannot be to yield significant for an ensemble of that is distributed over a disk region with a radius 
 Fig . . of received power at street canyon for coverage radius and power . 
 of centered at the . Under our , based on typical of power and antenna gains , only limited in received power or coverage are available even when the is at considerable height and at only less power than the . Limiting the coverage radius to , significantly the from a . It important gains even when at as low as and operating at the relatively low power of . However , these gains are basically associated with the existence of or , equivalently , links to , and thus heavily depend on site specific and user . 
 In all , the gains achievable are only marginally than those by a , to the fact that , in practice , the likelihood of the and the base providing comparable is very small . 
 Our show that the of the user link and the base user link are essentially independent . Moreover , measured path for such links were found to be quite consistent with average from accepted for the corresponding urban setting . Thus such can lead to a basic prediction of the gains achievable from the use of a . 
  
 ﻿Fundamental limitations in networked control systems (NCS) have been researched for the last years with many stability results, from channel transmission minimal rate based on information theory, to minimal signal-to-noise (SNR). For the latter, it has been confirmed early on that the usual culprits increase the minimal SNR for stability, such as unstable plant poles, non-minimum phase (NMP) zeros, time delay, together with new ones such as communication channel bandwidth and colored transmission noise. In this work we specifically propose two approaches to completely avoid the effect of NMP zeros on the minimal SNR for stabilityindiscrete-time.The first approach stems from the observation that the controller that achieves the minimal SNR for a minimum phase plant in discretetime, has all its zeros located outside the unit circle (NMP zeros). Such observation allow then to characterize this set of NMP zeros as candidate NMP zeros of alternative plant models with the same unstable poles, which in turn will not increase the minimal SNR for stability above the expression imposed only by the plant unstable poles. Our second approach extends the set of possible NMP zeros that do not increase the SNR limitation to any location, by proposing the synthesis of a two-degree of freedom linear time invariant controller solution that achieves the minimal SNR for stability imposed only by the plant unstable poles.
 Index Terms—Control over communications, Linear systems, Networked control systems, Optimal control.
 Introduction
 N
 ETWORKED control systems (NCS) have been a subject of focused research for at least the last two decades, with review articles available in [1], [2]. Results on fundamental limitations on stability in this NCS framework were reported for example in [3], [4]. NCS performance limitations have also been extended using information theory arguments to include disturbance rejection, reference tracking and multivariable systems, as in [5], [6].
 A different approach for NCS is, on the other hand, proposed in [7] where an LTI framework for stability of feedback loops, both in continuous-time and discrete-time, is introduced based on the channel model signal-to-noise ratio (SNR). The SNR fundamental limitation obtained in [7] is presented as an infimal lower bound on the channel
 M. Derpich is with the Departamento de Ingenier´ia Electr´onica, Universidad T´ecnica Federico Santa Mar´ia, Chile.
 A.J. Rojas is with the Departamento de Ingenier´ia El´ectrica, Universidad de Concepcio´n, Chile. Email: arojasn@udec.cl .
 The authors thankfully acknowledge the support from CONICYT, through Basal Project FB0008.
 SNR required for the stabilization of an unstable plant model by means of output feedback over a memoryless additive white Gaussian noise (AWGN) communication channel, such as the case depicted in Figure 1. More so, in
 	r 	+
 Fig. 1. One-degree of freedom NCS LTI, general configuration.
 recent years it has been shown that for second order statistics, control problems over a power constrained erasure channel are equivalent to control problems subject to an SNR constraint [8], [9]. Furthermore, the SNR equivalence, in a second order sense, has been extended to include fading channels in [10]. As a result, the SNR approach has been able to capture the most important communication features and characterize their impact on fundamental limitations, as well as performance limitations, see also for example [8], [11]–[15]. More so, the SNR approach has also motivated a reinterpretation of the classic control feedback loop by means of the reference to disturbance ratio (RDR), [16], [17] , which quantifies performance as the trade-off between reference tracking and closed loop input disturbance rejection.
 A common observation, remarked in particular in [7], is that the SNR limitation required for LTI output feedback stabilization of an unstable plant model with NMP zeros, is strictly greater than the one required for state feedback (emphasis added by the present authors). As an alternative the authors of [7] propose a linear time-varying alternative control scheme to eliminate the effect of the NMP zeros on the infimal SNR for stabilizability.
 Our first contribution in this work is to explicitly characterize the one degree of freedom, see Figure 1, optimal controller that achieves the minimal SNR in discretetime. Furthermore we will characterize the zeros of such controller and prove that these zeros are all located outside the unit circle. To the best of our knowledge such a characterization is novel. The controller zeros outside the unit circle are then by definition NMP zeros. As a result, if the zeros of an alternative plant model (with the same unstable poles) belong to this specific set of NMP zeros, then both SNRs, output feedback and state feedback, will coincide thus avoiding the effect of NMP zeros over the SNR limitation.
 Our second contribution extends the set of potential NMP zeros to an arbitrary set, by proposing and synthesizing a specific two-degree of freedom LTI controller solution. The use of a two-degree of freedom controller has been explored before in order to eliminate the effect of NMP zeros in different NCS setups (including the SNR approach), see for example [13], [18]–[22]. The contribution here instead is the explicit definition of a two-degree of freedom (DOF) controller to avoid the deleterious effect of arbitrary many NMP zeros, recovering the minimal SNR for stability imposed only by the plant unstable poles. A preliminary result for first order plant models was presented in [23].
 As a result of our contributions we update the common observation about minimal SNR and NMP zeros as: the SNR required for stabilization of an unstable plant model with NMP zeros, via output feedback, is greater or equal than the required for state feedback, in an LTI setting.
 This paper is organized as follows: Section II states the fundamentals behind the minimal SNR in discretetime. Section III characterize the structure for the optimal controller that achieves the minimal SNR for an unstable plant model and analyzes the zero locations for this optimal controller. Section IV describes the synthesis of the two DOF LTI controller that avoids the effect of any arbitrary plant NMP zero. We conclude the exposition in Section V with final remarks and possible future research directions.
 Preliminaries
 In this section we present the general plant model assumptions, and summarize the discrete-time SNR for stabilizability solution.
 A. Assumptions
 Plant model: the plant model is defined as
 	 ,	(1)
 where |?i| > 1, ?i = 1,··· ,m are the m unstable and distinct plant model poles. The term Gs is the stable, minimum phase (MP), part of G. The relative degree of G is ng = 1 (the choice of ng = 1 is to avoid introducing a plant time delay that would further increase the later minimal SNR for stability). Channel model: we consider here the memoryless AWGN channel model, see for example Figure 1. This type of channel is characterized by the channel input power P > 0 and its channel additive noise process n. Channel additive noise process: The channel additive noise process n is a zero-mean i.i.d. white noise process with variance s2.
 Setpoint assumptions: The setpoint signal r is assumed to be zero, that is we consider here only a regulation problem, not a setpoint tracking problem.
 B. Minimal SNR for Stability
 Consider the feedback loop in Figure 1 where the problem is to stabilize an unstable plant subject to a channel power constraint P. From Figure 1 we observe that the closed loop relationships between the channel input u and the exogenous signal n is given by u = -Tn, with T = CG/(1 + CG) the closed-loop complementary sensitivity function. The channel input is required to satisfy the power constraint P > kuk2Pow, for some predetermined input power level P > 0. We assume that the closed loop feedback system is stable, in the sense that for any distribution of initial conditions, the distribution of all closed loop signals in Figure 1 converges to a stationary distribution. Without loss of generality, we therefore consider the properties of the stationary distribution of the relevant signals. The power of the channel input signal then satisfies
  . The channel input power constraint can be restated from this, as a constraint imposed on the channel SNR,  . We thus observe that for the setting in Figure 1, the SNR limitation is uniquely defined by the H2 norm of T.
 We now present a novel lemma which establishes a lower bound to the channel SNR in discrete-time that exists when the closed-loop system is stable. This lemma also establishes sufficient and necessary conditions, stated in terms of the transfer function from n to v, Tvn, so that the channel SNR is equal to this lower bound. The latter is given only by the unstable poles of G and is universal in the sense that it holds for any choice of the blocks G and C in Figure 1.
 Before proceeding, it is convenient to note that, since n is i.i.d., it holds that, for every k, n ? u, and thuskvk2Pow = s2 + kuk2Pow. This reveals that the channel SNR is given by
 	 .	(2)
 Lemma 1. If the closed-loop system shown in Figure 1 is stable, then
 	 ,	(3)
 with equality if and only if the following three conditions are satisfied:
 There are no external disturbances (r in Figure 1 is zero).
 The non-minimum phase zeros of Tvn are exactly the unstable poles of G.
 Tvn is an all-pass transfer function. Conditions (ii) and (iii) are equivalent to
 m
 	|Tvn(ej?)| = Y|?i|,	?? ? [-p,p].	(4)
 i=1
 Proof. Since the disturbances are independent of the channel noise, we have that
 	 ,	(5)
 with equality in (a) iff v has zero mean, and equality in (b) iff n is the only exogenous signal in the system in which case v has zero mean. The external disturbance case is treated for example in [5], [6] for establishing performance limitations, however here we are interested in stabilizability limitations, thus the no external disturbance stated in condition (i). The channel output power is thus, kvk2Pow = kTvnk22s2 iff condition (i) holds.
 If the closed-loop system is stable, then the sensitivity function Tvn is stable and there can be no unstable zeropole cancellations. Thus
  
 where (c) is due to Jensen’s inequality and the fact that log(·) is a concave function, with equality if and only if |Tvn(ej?)| does not depend on r. On the other hand, (d) is due to Bode’s integral theorem (and the fact that the unstable poles of G, which cannot be cancelled, appear as zeros of Tvn), with equality if and only if the NMP zeros of Tvn are exactly the unstable poles of G [24, Theorem 3.4.4]. Combining this with (2) and (5), it follows that conditions (i), (ii) and (iii) in the proposed statement are necessary and sufficient for achieving equality in (3), and that the latter two are equivalent to (4), completing the proof.  
 It is worth emphasizing that Lemma 1 is valid regardless of whether there are NMP zeros in the plant model or its relative degree. It is well known, see [7], that the minimal SNR ?d coincides for a state feedback strategy and an output feedback strategy, as in Figure 1, if the plant model G is unstable, minimum phase with no time delay. As stated in [7] the presence of NMP zeros increases the infimal SNR to a value ?o such that ?o > ?d. We will show in the next section that, for a one-degree of freedom controller solution, this is not always true, and on occasions we can still have ?o = ?d, even if the plant model contains NMP zeros.
 Optimal Controller Characterization
 We next present a theorem which characterize the (unique) stabilizing controller which achieves the lower bound ?d.
 Theorem 2. For the system shown in Figure 1, assuming G is unstable, minimum phase with relative degree ng = 1, it holds that . Furthermore, the infimum
 SNR is reached by a unique controller Co ? K the set of stabilizing controllers, given by
  
 Proof. We will show that, in this case, there exists a controller C ? K satisfying conditions (ii) and (iii) of Lemma 1 and that such controller is unique. For this purpose, let us define the coprime polynomials BN and BD, respectively, as the numerator and denominator of
 Tvn, i.e.,
 	 .	(8)
 Notice that Tvn is a stable all-pass transfer function if and only if all the zeros of BN are outside the unit circle. On the other hand, from (8), the controller can be expressed as
 	 .	(9)
 Being G minimum phase leaves no unstable zeros of G which C could cancel. In order to ensure that C does not cancel the unstable poles of G and that those poles become the only zeros of Tvn, one must choose  ?i). Since Tvn must have an all pass frequency response, the denominator of Tvn must be  ), automatically yielding a stable Tvn.
 In summary, we have found that there exists a Tvn which meets conditions (ii) and (iii) of Lemma 1, and that it is unique. This proves  and that the corresponding minimal SNR stabilizing controller is the one defined in (7).	 
 Theorem 2 illustrates how the unstable poles of the plant model G play a fundamental role in defining the minimum SNR of the communication channel. It is also easy to see that, for a stable plant, the minimal SNR is zero.
 Remark 1 (Without disturbances, ?d is a minimum.). Theorem 2 shows that, in this case (one-degree of freedom, minimum phase, ng = 1 and without disturbances), one can reach an SNR equal to ?d and obtain a stable closed-loop system. Thus, the infimum SNR for stability is actually a minimum. However, it shall be noted that the SNRminimizing sensitivity function Tvn satisfies (4), and thus it is all-pass. This means that the channel noise (the only exogenous signal in the system) is not being mitigated at any particular frequency.  
 Notice also that the stability of the minimum SNR system guarantees that if one implements the controller Co and then perturbations are added, closed-loop stability is not compromised. However, any additional external disturbance will increase the variance of u (as well as that of the other signals in the system), increasing the SNR above ?d.
 After the results presented in the previous sections it is natural to ask ourselves the following question: Can the lower bound ?d given by (3) be achieved if the plant has NMP zeros? We next show that if ng = 1, the answer is “yes”, for very special cases. In doing so, we will also provide some insight into the reasons why in general the answer is “no”.
 Revisiting the reasoning in the proof of Theorem 2, let BN and BD be as in (8), so that Tvn = 1/(1 + CG) = BN/BD. In order to reach the lower bound in (3), condition (4) must hold, which implies that
 	 ,	(10)
 for some complex ß such that  , and a set of complex roots  , with a correspondence between each root outside the unit circle and one of the unstable poles of G (from condition (ii) in Lemma 1). The required stability of Tvn implies that Tvn can only have stable poles and thus, in view of (10), only NMP zeros (i.e., m' = m and ai = ?i, 1 = 1,...,m).
 This fixes ) and  ),
 yielding
 	,	(11)
 and, from (9), a C whose zeros do not cancel the unstable poles of G (a requirement for C ? K).
 We now lift the MP assumption and propose an unstable plant model that also contains NMP zeros G?(z) =
  ), and to stress the difference with G, such an NMP unstable plant model is labelled G?. The term Gs? is the stable, minimum phase, part of G?. As for G the relative degree of G? is also one. From (9), the only way in which C does not cancel these zeros is that the latter are also zeros of (1/Tvn - 1). Clearly, this is not possible in general, since, as we have seen, satisfying conditions (ii) and (iii) in Lemma 1 demands that Tvn takes the specific form given by (11).
 This shows that, in general, if the closed-loop system is stable and if G? indeed has NMP zeros, then the SNR cannot reach the lower bound in (3). At the same time, the above analysis raises the following question: Are there special cases in which the plant model has NMP zeros and yet the lower bound (3) is compatible with closed-loop stability? The following theorem gives an answer to this question.
 Theorem 3. Let  be such that
  
 Then:
 In the systems shown in Figure 1, an SNR equal to the lower bound in (3) is reachable, while yielding a stable closed-loop system, if and only if ng = 1 and the NMP zeros {?i}qi=1 of G? constitute a subset of .
 For all i = 1,...,m - 1, it holds that |?i| > 1.
 If the conditions required in (i) are met, then the unique stabilizing controller Co, which when replaced in Figure 1 yields an SNR equal to ?d, is given by
 	 ,	(13)
 where .
 Proof. (i) As discussed above, the lower bound in (3) requires Tvn to take the form given in (11), which happens if and only if the C is given by (9) as C = (1/Tvn -1)/G. A construction of the optimal controller is also offered for example in [7, Theorem III.2] using the Youla parametrization approach, but such approach makes the characterization of the controllers zero locations obscure. Since (11) yields that (1/Tvn - 1) has relative degree equal to 1, it follows that when ng > 1 the required C has negative relative degree, which is not realizable causally. If ng = 1, this required controller is biproper, yields the stable Tvn given by (11) (thus satisfying conditions (ii) and (iii) in Lemma 1) and does not cancel the unstable poles of G. The only remaining condition for C to be a stabilizing controller is that it does not cancel the unstable zeros of G? either, which is equivalent to  being a subset of the roots of 1 - 1/Tvn. This proves claim (i).
 (ii) When Tvn satisfies (11), the set  comprises the m-1 roots of 1-1/Tvn. These values can be studied using standard root-locus analysis, which characterizes the roots of the expression 1 + KL, as the scalar K is varied, for any given rational transfer function L [25]. Letting L = 1/Tvn, we will show that when K = -1, all the roots of 1 + KL lie outside the unit circle.
 Since Tvn is as in (11), it follows that L has all its poles outside the unit circle and all its zeros inside the unit circle. Recall that the roots of 1 + KL continuously “migrate” from the poles of L (at K = 0) to the zeros of L (as K is decreased toward -8). Hence, for K sufficiently close to zero, the m zeros of 1 + KL lie outside the unit circle.
 Suppose that 1 + KL = 0 for some z = ej?c when K = Kc, for some Kc < 0 and some ?c ? [-p,p].
 Then L(ej?c) = 1/Tvn(ej?c) is real and positive. Recalling that ] (see (10)), we conclude that  . Thus, as K is decreased from 0, all the roots which start outside and end inside the unit circle lie exactly on the unit circle only when
  , which is strictly less than -1. Therefore, all the m - 1 zeros of 1 - 1/Tvn are non-minimum phase, proving claim (ii).
 (iii) The fact that (ii) holds makes it feasible that C does not cancel the NMP zeros of G?, which happens if and only if these zeros are a subset of . In the latter case, the controller C must be given by (9), thus taking the form (13), which yields the SNR-minimizing Tvn given by (11). Therefore, this is the only controller which stabilizes the closed-loop system while satisfying the conditions for equality in (3). This completes the proof.
  
 We illustrate Theorem 3 with a simple example.
 Example 1. Consider an NMP unstable plant with relative degree ng = 1 given by  , with
 |?1| > 1, |?2| > 1 and |?1| > 1. We have from Theorem 3 that if
 .
 2(1 - |?1| )
 then the channel SNR can be set to ?d. For ?1 and ?2 real numbers, then ?1 further simplifies into   More so, the optimal controller that achieves ?d is then defined as
  , which, again assuming ?1 and ?2 real numbers, further simplifies into .
 Thus, we have obtained a biproper controller without unstable zero/pole cancellations which yields a stable Tvn such that |Tvn(ej?)| = 2i=1 |?i|, ?? ? [-p,p], and thus kuk2Pow coincides with ?dQ· s2, and thus achieves the lower bound in (3).
 Remark 2. Claim (ii) in Theorem 3 reveals a perhaps surprising fact: in the setup corresponding to Figure 1, when G is MP or its NMP zeros are a subset of , then the SNR-minimizing controller has at least m-q -1 non-minimum phase zeros. This may seem counterintuitive since, in general, introducing NMP zeros in the loop transfer function makes the closed-loop system harder to control (it limits the bandwidth of the complementary sensitivity function and makes it minimum phase) [26].
 Remark 3. Despite the fact that specific NMP plants satisfying the conditions of claim (ii) of Theorem 3 do exist, the latter theorem asserts that for almost all NMP plants with ng = 1, and for all plants with ng > 1, the minimum required SNR for stability in the scheme of Figure 1 is in general strictly greater than the lower bound ?d. Therefore the proposed result is theoretical in nature, since the plant model poles and zeros should not be assumed as design variables. This motivates the explicit definition of a 2 DOF controller, as discussed in the following section, for dealing with the practical aspect of plant model NMP zeros not necessarily at the locations z = ?i, whilst achieving the minimal SNR for stability imposed only by the plant unstable poles.
 Two-Degree of Freedom Controller
 When the channel output is directly fed back, then an alternative two DOF controller solution that achieves ?d is possible, see Figure 2.
  
 Fig. 2. Two DOF NCS LTI, general configuration.
 Theorem 4. The two DOF controller that achieves ?d when the unstable plant model G? contains arbitrary NMP zeros ?j with j = 1···q is given by
  ,	(14) where for C1 the coefficients bi are the solution of the following set of m algebraic equations
  
 and for C2 the coefficients cj are the solution to the next set of q algebraic equations
  
 Proof. We consider first the general structure in Figure
 2 and observe that the channel input s in closed-loop is
  . Since we want to achieve ?d we therefore impose the need for C1G? - C2 = CoG, with Co as in (7) and G as in (1). We then further assume that C1 =
 zq-mC˜+11 Gs? and manipulate the above expression into
 C˜1qj=1(z - ?j)
 C2 = zq-m+1mi=1(z - ?i)
 	m	m
 -i=1(z -Q1m/?¯i) - Qi=1(z - ?i).
 i=1(z - ?i)
 Since we require for stability that C2 ? RH8 (the space consisting of all proper and real rational stable transfer functions, [27]), the numerator of C2 must contain all the
 m unstable poles of G, thus, for all l = 1,··· ,m. The simplest structure for C˜1 that satisfies these m interpolations is the one represented by  . The values bi’s are easily obtained by imposing the set of algebraic equations in (15), from which we then obtain C1 as in (14). To obtain C2 we follow a similar approach. From C1G? -C2 = CoG, evaluating at each NMP zero of G? we have that C2(?l?) = -Co(?l?)G(?l?), for l? = 1,··· ,q. To satisfy this q interpolation we propose C2 as in (14). Finally, to obtain the coefficients cj that achieve the given interpolations we then impose the algebraic equations in (16) and obtain C2 as in (14), which concludes this proof.  
 The remarkable implication of Theorem 4 is that we can effectively reduce the infimal SNR requirement, eliminating the increasing effect due to the presence of the NMP zeros, whilst remaining in an LTI setting. This is achieved by changing the plant model as seen by the channel input, through the second path that feeds the channel output through C2, see Figure 3.
 Remark 4. The result from Theorem 4 also applies when the communication channel is located over the feedback path (between the plant and controller) and r = 0.
  
 Fig. 3. Two DOF NCS LTI solution for Example 1, equivalent plant model configuration.
 Example 2. Consider . We recognize then Gs? = 1z, m = 1 and q = 1. For one unstable pole ? we also have that  and . We then have from Theorem 4 that  , and .
 From (15) we recognize  . In turn, from
 (16) we have that . Therefore the two DOF controller that achieves ?d for the plant model G? studied in this example is given by
 	 .	(17)
 As a note, observe that if ? ? 0, then the C2 path opens up, and the plant model G? ? G. We then recover the standard infimal SNR controller solution for stabilizability of an unstable plant without NMP zeros.
 Conclusions
 In this work we have studied how to avoid the effect of NMP zeros on the minimal required SNR for output feedback stability. The first observation is that the optimal controller that achieves the minimal SNR for a minimum phase plant with no time delay, has all its zeros located outside the unit circle. This observation allow us then to characterize a set of specific NMP zeros that can be now located at the plant model, and would not increase the minimal SNR for stability above the expression imposed by only the plant unstable poles. We then used a two DOF controller structure to propose, for output feedback, the synthesis of such controllers that can retrieve the minimal SNR ?d, even when the unstable plant model has NMP zeros. Future research should consider extending the results for more complex communication channel models and replicate this study for the continuous-time setting.
 ﻿ This paper control closed over noiseless digital . We focus on noisy linear with stationary , initial state , scalar valued control and sensor . For this set up , we show that the absolute minimal directed information rate that one to achieve a level of performance not necessarily stationary , over all of controller is when the output is jointly with the other in the system . This directed information rate lower the achievable operational data . When our attention to controller which make the random in the loop strongly asymptotically wide sense stationary , this bound can be expressed in of their asymptotic power spectral . Then we show that the directed information rate and stationary performance of any such scheme can be when the , channel , controller and behave as an channel with . We also present a simple scheme that one to achieve operational average data that are at most approximately . away from the derived lower bound , while satisfying the performance constraint . A numerical example is to illustrate our . 
 Index control ; optimal control ; average data rate ; information theory ; signal to noise ratio . 
 I . INTRODUCTION 
 This paper control for linear time invariant where communication place over a digital communication channel . Such have received much attention in the recent literature , . This interest is by the theoretical inherent to control subject to data rate , and by the many practical that the understanding of fundamental in such a set up may have some are in , e .. . 
 The literature on control subject to can be broadly classified into two . A first group , which , that are rooted in non linear control theory . An alternative approach that information theoretic been adopted in , e .., . A key question by the works in the latter group is how to extend , or adapt if necessary , standard information theoretic to reveal fundamental in data rate limited feedback . Related have been in , where the interplay between information and disturbance attenuation is . 
 The most basic question in a data rate limited feedback control framework is whether closed loop stabilization is possible or not . Indeed , stabilization is possible only if the channel data rate is sufficiently large , . These early several works that study minimal data rate for stabilization and observability see , e .., , . A fundamental result was in . For noisy over a noiseless digital , it is shown in that it is possible to find causal , and such that the resulting closed loop system is mean square stable , if and only if the average data rate is greater than the sum of the logarithm of the absolute value of the unstable plant . A thorough discussion of this and related work can be found in the survey paper . Recent , stabilization over time , are in . 
 It is fair to state that , for , stabilization subject to data rate are well understood . However , the question of what is the best closed loop performance that is achievable with a given data rate is largely open . Such are related to causal and zero delay rate distortion see , e .., . In the latter context , the best are , to our knowledge , algorithmic in nature , derived for open loop and , at times , rely on arbitrarily long , . It thus that the in the above are not immediately applicable to feedback control . 
 In the rate constrained control literature , lower on the mean square norm of the plant state have been derived which show that , when are present , closed loop performance becomes arbitrarily poor when the feedback data rate the minimum for stability , . This result no matter how the coder , and controller are designed . Unfortunately , the in , do not seem to be tight in general . In contrast , for fully observable noiseless with bounded initial state , that one can essentially recover the best non performance with data arbitrarily close to the minimum average data rate for stabilization . Other valid in the noiseless or bounded support noise can be found in , e .., . 
 Relevant work on optimal control subject to rate , and dealing with unbounded support noise , include , . Those works establish for separation and certainty equivalence in the context of quadratic stochastic for fully , when data rate are present in the feedback path . It is shown in that , provided the a recursive structure , certainty equivalence and a partial separation principle hold . The latter result is relevant . However , does not give a practical characterization of optimal . The in share a similar drawback . Indeed , performance related in are in of the sequential function , which is difficult to compute in general . Moreover , even for the where an expression for such function is available , it is not clear whether the sequential rate distortion function is tight , Section . Partial separation in optimal control been recently in . 
 Additional related to the performance of control subject to data rate are in , and . In , noiseless state estimation subject to data rate are studied . The case most relevant to this work an asymptotic in time quadratic criterion to measure the state reconstruction error . For such a measure , it is shown in that the bound established in is sufficient to achieve any asymptotic distortion level . This is , however , at the expense of arbitrarily large estimation for any given finite time . On the other hand , non linear stochastic control over noisy , and a functional i . e ., not explicit characterization of the optimal control is . In turn , a intensive iterative method for and controller design for over noisy discrete memoryless . for separation and certainty equivalence are also in for some specific set . 
 In this paper , we focus on the feedback control of noisy , with one dimensional control and sensor , that are over an error free and delay free digital channel . The plant initial state and the disturbance assumed to be jointly . By considering causal but otherwise unconstrained , we study the minimal operational average data rate , say , that that the steady state variance of an error signal is below a level . Our approach is mainly information theoretic and thus some of our complement previous in , . 
 We have previously this problem in and . In we have shown that is lower bounded by the directed information rate I u , u are the input to the and output from the , respectively . Then , for a restricted class of , independent by as a unit transfer function u plus additive wide sense stationary noise independent of , we that I u is only u are jointly . For the latter case , it was shown that this information rate can be written as where is the asymptotic power spectral density of u and is the asymptotic variance of the error in u i from u u i and i . It was also shown that an operational average data rate exceeding I u by less than approximately . sample was achievable by an entropy uniform . In , and also for the class of independent , we then derived the minimum feedback directed information rate I u for an asymptotic quadratic performance measure . 
 An important departure of this paper from our previous work is that here the is not constrained to exhibit a unit transfer function u i . e ., it is not restricted to be an independent scheme . As a result , the pair also as a controller for the plant , and thus reaching designing the jointly optimal controller system . For this context , the main of this paper can be as : 
 We show that , for any given performance , I u is if and only if u jointly in Section . 
 For the jointly case , we also show that I for the class of 
 yielding strongly asymptotic wide sense stationary u and . This class namely , is much than and the family of independent . For instance , it for controller built any combination of linear and non linear causal , provided the behaviour is . This result is in Section . 
 In Section we show that the asymptotic of any scheme can be also by a set of and an exogenous additive white noise . 
 In use the latter result to show how to minimize I u within the class of by a related stochastic control problem subject to an constraint in the feedback channel Section . This same constrained problem been in and in for different but related control subject to , see , e .., . 
 the fact that the latter problem was shown to be convex in , and the convenient procedure to solve it in , we explain how to design a simple controller scheme which within approximately . sample of within the class of , for any performance . This result is in Section . 
 To illustrate the above , section a numerical example . Concluding are in Section . 
 Notation : the set of real , the set of strictly positive real 
 N , ,. In this paper , log for natural logarithm , and for the magnitude absolute value of . We work in discrete time and the time index . An said to be proper i . e ., causal if its transfer function remains finite when , and it is said if it is proper and . We define the set U as the set of all proper and stable with that are also stable and proper . 
 In this paper , all random are defined for N . All random and are assumed to be , unless stated otherwise . Given a process , we denote its sample by and use as shorthand for ,...,. We say that a random process is a one if it first and second order that are bounded for that also remain bounded as . 
 are , by definition , second order . We use E to denote the expectation operator . A said to be asymptotically wide sense stationary if and only if there exist and a function , both independent of the statistics of , such that E and E E E 
 for . The steady state spectral density of an process is by and defined as the transform of extended for according to . The corresponding steady state covariance matrix is by , and trace . Jointly second order and jointly are defined in the obvious way . The covariance matrix of a random sequence is by E un , where un u u . For a matrix A , the notation A , to the element of A on the th row , th column , while A and A denote the of A with the and magnitude , respectively . Two of matrices , with An , , are said to be asymptotically equivalent see if the following two are met : 
 for some . useful notation and from Information Theory . 
 . PROBLEM SETUP 
 This paper on the control system of Fig . . In that figure , is an plant , e u is the control input , is a sensor output , e is a signal related to closed loop performance , and is a disturbance . The feedback path in Fig . a digital channel and thus quantization becomes mandatory . This task is carried out by an whose output to a sequence of binary . These are then over the channel , and back into real by a . The and also embody a controller for the plant . 
  
  
 Fig . . Control system over a digital channel . 
 We a way such that 
 , 
 where are proper transfer of suitable . We will make use of the following . 
 Assumption . : is a proper plant , free of unstable hidden , such that the open loop transfer function from u to i . e ., P in is single input single output and strictly proper . The initial state of the plant , say , and the jointly , is zero mean white noise with unit variance I , and finite differential entropy i . e ., the variance of is positive definite . 
 We focus on error free zero delay digital and denote the channel input alphabet by , a countable set of prefix free binary . Whenever the channel input symbol to , the corresponding channel output is given by . The length of is by , and the average data rate across the channel is thus defined as 
 R . 
 We assume the to be an arbitrary hence possibly non linear and time causal system such that the channel input 
 , 
 where ak is shorthand for a ,..., a , SE side information that becomes available at the at time instant , and is a possibly non linear and time deterministic whose range is a subset of . Similarly , we assume that the is such that the plant input u is given by 
 , 
 where side information that becomes available at the at time instant , and is a possibly nonlinear and time deterministic . 
 Assumption . : The E Fig . are causal , possibly time or non linear , by . The side information SE and are jointly independent of ,, and the is invertible upon knowledge of and , i . e ., i N , there a deterministic i such that . 
 The assumption on the side information is by the requirement that causal and use only past and present input , and additional information not related to the message being sent , to construct their current see also page in . On the other hand , if , for some E and , the is not invertible , then one can always define an alternative and pair , where the is invertible , yielding the same input output relationship as E and , but a lower average data rate , Lemma . . Accordingly , one can focus , without loss of generality , on where the is invertible . 
 In this paper , we adopt the following notion of stability see also : 
 Definition . : We say that the of Fig . is asymptotically wide sense stationary if and only if the state of the plant , the output , the control input u , and the disturbance , are jointly second order . 
 Remark . : The notion of stability above is than the usual notion of mean square stability where only N E is to hold 
 see , e .., . 
 In what we will be interested on information in of the asymptotic spectral of the in the system . To do so , it will be necessary to use a notion of asymptotic wide sense : 
 Definition . Strongly Process : An scalar random process u which to a process u is said to be strongly asymptotically wide sense stationary if the are asymptotically equivalent . Likewise , a is said to be if the covariance and cross covariance matrices of all the in it are asymptotically equivalent to their stationary . Clearly an is also , but the converse may not be true , in general . The same for . 
 The goal of this paper is to characterize , for the of Fig . , the minimal average data a given performance level as measured by the steady state variance of the output e . We denote by the steady state variance of e that can be by setting u , with being a possibly non linear and time deterministic , under the constraint that the resulting feedback loop is . With this definition , we formally state the problem of interest in this paper as : Find , for any , and whenever Assumption . , 
 R , se D 
 where se trace , is the steady state covariance matrix of e , and the optimization is carried out with respect to all E satisfy Assumption . and render the resulting . 
 It can be shown that the problem in is feasible for every , see Appendix A . If , then the problem is clearly unfeasible . On the other hand , an infinite average data rate , except for very special . We will thus focus on , without loss of generality . 
 The remainder of this paper within a gap smaller than approximately . per sample . Such characterization is given in of the solution to a constrained quadratic optimal control problem . We also propose and which achieve an average data rate within the above gap , while satisfying the performance constraint on the steady state variance of e . 
 . AN INFORMATION THEORETIC LOWER BOUND ON 
 This section that a lower bound on can be by the directed information rate across an auxiliary scheme comprised of and an additive white noise channel with feedback . The starting point of our presentation is a result in , which does not require any . 
 Theorem . Theorem . in : Consider the of 
 Fig . and suppose that . and . hold . Then , 
 R 
 where I ; ¦ conditional mutual information see Appendix . 
 The quantity I u to the directed information rate across the source scheme of Fig . i . e ., between the the output u of the source scheme . Note that I u is a function of the joint statistics u only . 
 We will now derive a lower bound on the directed information rate across the considered scheme , in of the directed information rate that would appear if all the involved were . 
 Lemma . : Consider the of Fig . and suppose that . and . hold . If , in addition , ,,, u are jointly second order , then I u I uG , where and uG are such that , uG are jointly with the same first and second order cross as ,,, u . 
 Proof : Our claim is due to the following chain of and : I u i ; a I , ; i 
 I , ; I uG i ; , 
 where a from Assumption . and Lemma . with 
 x , o , d ,, , u u and x , o , d , SE , and from Lemma . in Appendix . In turn , equality in since 
  
 I , di ; uG i 
 i 
 I , di , ; uG i 
 i 
 I ; uG i di 
 I ; uG i u I , ; uG i u , 
 i 
 where a , and e hold from the chain rule of mutual information , from b in Theorem . , is a consequence of being a deterministic function of , and from a in Theorem . . This the proof . 
 It from Theorem . and Lemma . that , in order to bound from below , it to minimize the directed information rate that would appear if the source scheme of Figure the channel were by a block u which are jointly . Again , this irrespective of the of the involved . 
 Now we can relate the directed information rate from to uG to their associated spectral . For that purpose and from here on , we shall focus on which render the . 
 Lemma . : Assume that u jointly and that u is and such that , for some . Then , 
  
 where is the steady state power spectral density of u , and is the steady state variance of the sequence of independent random , defined via u , E u , . 
 Proof : We start by that , since u , are jointly , a simple modification of the proof of Theorem . in ,. the conclusion also and . To proceed , we note that 
 I u i ; a u i u i , 
 u i i i , 
 u i i , 
 u i i , 
 where a from Property in Appendix from the definition of , from Property in and the fact that , by construction , i is a deterministic function of , , and from Property in Appendix i is independent of , . Now , and the definition of directed information rate 
  
 where a from and in Appendix and the fact that , by construction , is independent of , and from Lemma . in the Appendix and the fact and that u is with 
 , for some . The result is now 
 immediate from . 
 Lemma . the directed information rate between in of the spectrum of the process towards which the mutual information is directed . Lemma . Theorem . in , where the author directed information between that are linked by an additive white noise channel with unit transfer function . Thus , Lemma . the latter theorem by considering a channel with noise and with an input output transfer function different from unity . 
 Remark . : It is worth that simply u to be instead of with for all may yield a left hand side of smaller than the term on its right . Indeed , to the best of our knowledge , the only result related to available for is , Lemma . , which an inequality in instead of equality . To see why is not enough for equality , consider the following example : 
 an unstable system with zero initial state that can be by unit feedback . a white process with zero mean and variance . Construct u as 
 . This a unit 
 gain closed loop with feedback noise . In this case , u can be written as will be with asymptotic power spectral density . Then , the entropy rate of the asymptotic process u is 
  
 where the last equality from formula Bode Integral Theorem and pi are the of . 
 However , it turns out that , for all , for some lower triangular matrix with along its main diagonal . Therefore , 
  
 and hence which is strictly smaller than compare with . 
 Thus , the notion of is too weak to provide the equality we need . 
 x 
 e 
 d o 
 P 
  
 v y 
 z 
  
  
  
 u 
 q 
 Fig . . Auxiliary system that when the and of Fig . are by an additive white noise channel with one step feedback . 
 . OF 
 In this section we show that , for any given performance , the directed information rate by any scheme can also be by an pair built with only and an exogenous source of white noise . To that end , we begin by that Theorem . and Lemma . readily imply that for any and satisfying Assumption . , and rendering the resulting , I uG , where , uG are such that ,, uG , are jointly with the same first and second order cross as ,, u ,. We also note that the adopted performance measure is quadratic . The above imply that one can always match or improve the rate performance trade off of a given pair by choosing , instead , an and a which , besides rendering the , u , jointly with ,. Since the plant initial state and the disturbance are , and the plant is , one possible way of such pair of u , is by the feedback architecture of Fig . . We formalize these below . 
 Define the auxiliary feedback scheme of Fig . , where everything is as in Fig . except for the fact that we have the link between the plant the plant input u by a set of proper , and , and an additive noise channel with one step feedback and noise such that 
 u , , , , 
 y 
  
 where for the unit delay . In Fig . , we assume that the plant , the the plant initial state satisfy Assumption . , that the initial of , and of the delay are deterministic , and that is zero mean white noise , independent of ,, and constant variance . 
 In Fig . , we have added as in e to all that refer to that have a counterpart in the scheme of Fig . with possibly different statistics . To streamline our presentation , we adopt the convention that , whenever we refer to the auxiliary feedback system of Figure , it is to be understood that we are implicitly working under the stated in the above paragraph . 
 Theorem . : Consider the of Fig . and suppose that . and . hold . If , , then 
 R 
  
 where the optimization u is with respect to all proper , and auxiliary noise , that render the feedback system of Fig . with 
 F internally stable and well , and and se denote the steady state power spectral density of u and the steady state variance e in Fig . , respectively . 
 Proof : Denote by the set of all E that , when at each end of the discrete channel of Fig . satisfy Assumption . , render the of Figure and guarantee that se . Also , define , to be the set of channel which consider a unit gain i . e ., continuous alphabet noisy channel with possibly time linear as which render u and yield se . Since , both and , are non empty ; see Appendix A . The fact existence of at least one pair in , say E ,, and u , such that its average data rate 
 R is bounded . From Theorem . , it that 
 R 
  
 where the last equality is a consequence of Lemma . . u are jointly , their statistics and corresponding variance of e are by an triplet in ,, of a sequence of linear , N , such that 
 , 
 where is zero mean and independent of 
 . Since is linear and causal , it a relationship between and which can be expressed 
 as 
 u ,, 
 where and are of lower triangular matrices such that , , and are the top left of and , respectively . Now , since , u are jointly , the covariance matrices , and associated cross covariance matrices are asymptotically equivalent to matrices as well . the transitivity of asymptotic equivalence for and of matrices in , it is possible to show that and must be asymptotically equivalent to a sequence of lower triangular matrices as well see , e .. , Section . . Also , the associated limiting the resulting internally stable and well otherwise the underlying and would not be in ,, and the steady state spectrum of u and the steady state of both and e . Here , we use the fact that is also ; see the proof of Lemma . . 
 Now , consider the auxiliary feedback system of Figure before . Assume that , steady state behaviour of in i . e ., is comprised of two , as impulse the last of 
 variance equal and see previous paragraph . With the , respectively , and that a 
 n for , and , and since the matrix asymptotically equivalent to the sequence 
 , it that the feedback system of Figure is internally stable and well . In particular , it the an set of in the closed loop such that the plant input u a steady state power spectral density that , by construction , in the previous paragraph . Similarly , the error signal e in Figure a steady state variance se that . It thus from Lemma . 
 that 
  
 We thus conclude that , for any and E , in and u , there exist a proper a white noise source such that , when , the mutual information rate I u in Fig . I u while . that is the , it from and that is lower bounded by u as in , the proof . 
 Theorem . that a lower bound on the minimal average data rate that a given performance level , can be by an optimization problem which is stated for the auxiliary feedback system of Fig . , where communication place over an additive white noise channel with feedback . 
 We finish this section by a simpler lower bound on . To that end , we will first state an auxiliary result . 
 Lemma . : Consider the feedback system of Fig . . Fix and define whenever the involved exist 
  
 where is the steady state power spectral density of . If the pair , , the feedback system of Fig . internally stable and well , then there exist a second pair of , namely , , , with , that also an internally stable and well feedback loop , leaves the steady state power spectral density of e unaltered , and is such that for any arbitrarily small . 
  
 Fig . . Auxiliary feedback system for stability analysis . 
 Proof : Consider Fig . and the partition . Introduce proper transfer Ly and such that Ly see . A standard argument that the feedback system of Fig . is internally stable and well if and only if the transfer n n and e u in Fig . is stable and proper . It is straightforward to see structure shown in the unnumbered equation at the top of the next page , where 
 S . 
 We will write i to refer to the when , i , i , i , . Similarly , Ly i and wi refer to the of , when i . Set 
 F , , 
  
 L , 
 where . Given and the fact thatn is the relative degree U , X , it that U and F 
 is and that 
 T , ,, 
 I , nI , nI , nI . 
 The definition of n the pair 
 , the feedback system of Figure internally stable and well if and only if , does so . It also immediately that , the same stationary spectral density for e than , . 
 To complete the proof , we now propose specific choice for . Denote by i the signal that when , i , i . Write , where is stable and all its in : . Denote by c ,..., the of that lie on the unit circle . Define , for , , 
  
 , c 
 i 
 X . 
 i 
 By construction , and U for every , . It now , by proceeding as in the proof of Theorem . in , that there , such that setting in that , is such that for any . 
 , 
 Corollary . : Consider the of Fig . and suppose that . and . hold . If , , then 
 R 
  
  
 where the optimization is with respect to all , and auxiliary noise , that render the feedback system of 
 Fig . internally stable and well , and and se denote the steady state of and e in Fig . , respectively . 
 Proof : Consider the feedback system of Figure and recall the definition of both u and in and . Since , the problem of finding u is feasible see Appendix A . Thus , for any , there exist a proper filter , and , such that se and u ,, , 
 where we have used the fact that u whenever . On the other hand , Lemma . that there a pair of proper ,, with , such that the auxiliary feedback system of Figure is internally stable and well , 
 se 
 where the inequality from the definition of . Since for any , , our claim is now immediate from Theorem . . 
 Corollary . that a lower bound on can be by first , i . e ., by first , for the auxiliary feedback system of Fig . , the minimal steady state that that the steady state variance of the error signal e is upper bounded by . Section A how to obtain a numerical approximation to . 
 V . AN UPPER BOUND ON 
 This section that it is indeed possible to achieve any distortion level , while an average data rate that the lower bound on in Corollary . by less than approximately . per sample . 
 Definition . : The source scheme by and is said to be linear if and only if , when used around an error free zero delay digital channel , is such that its output u are related via 
  
 scalar valued auxiliary , is an independent second order zero mean i . i .. sequence , and the transfer of proper that , together with the unit delay , have deterministic initial . ¦ 
 Remark . : In Definition . , the requirement independent without reference to other random or is to be understood be independent of all exogenous and initial in the feedback system in which the source scheme is . In particular , when an independent source scheme is used in the of Fig . , is to be assumed independent of ,. ¦ 
 The class of linear source is by the of Section and the class of independent source in . We note that independent source do not necessarily satisfy Assumption . . 
 Linear source are defined in of their input output relationship with no regard as to how the channel input is related to the source scheme input . A simple way of making that relationship explicit is by an entropy ; , . When such a device , , and the channel input and output , are related via 
  
 where is a dither signal available at both the and sides ,: i ; i a uniform with step size , is a an entropy coder i . e ., a loss less whose output symbol is chosen according to the conditional distribution of , given , and is a the entropy that is complementary to the entropy coder at the side . 
 Lemma . Theorem . in : Consider the set up of Figure , where the is as in and a finite quantization step . Assume that is a proper real rational transfer function , that the open loop transfer function single input single output and strictly proper , and that the signal is a white noise sequence jointly second order with the initial state o of . If the dither is i . i .., independent of , and uniformly distributed on , , then 
  
 Fig . . Entropy inside a feedback loop . 
 w is i . i .., independent of ¦ , and uniformly distributed in , . 
 It that any scheme by and , with dither as in Lemma . , is a linear source scheme . Any such scheme will be to as an based linear source scheme . Figure an based linear source scheme where we have made explicit the fact that , since the channel is error free and zero delay , and , thus , can be at the side without making use of any additional feedback channel . 
 The next lemma an upper bound on the operational average data rate in an based linear source scheme . 
 Lemma . : Consider the of Fig . and suppose that that Assumption . . Then , there an based linear source scheme such that the resulting is . For any such scheme , 
 R 
 where is the steady state variance of the auxiliary signal , and is the linear source scheme noise variance see . 
 Proof : Consider the of Fig . and assume that the source scheme is linear . Since Assumption . , there exist that the resulting is internally stable and well one possibility is to to pick internally . For any such choice of , the open loop system with unity feedback . Our claim now immediately upon Corollary . in and the description for the noise in Lemma 
 . . 
 We are now in a position to prove the main of this section : 
 Theorem . : Consider the of Fig . and suppose that Assumption . . If , , then there an based linear source scheme satisfying Assumption . such that the resulting is , se , and 
 R 
 where is as in . 
 Proof : Since , the problem in is feasible see Appendix A . Thus , there exist 
 F rendering the feedback system of Fig . internally stable and well , and , such that , in the scheme of Fig . , and for any , se and 
  
 Denote the above for , and by , and , respectively . Given Lemma . and inequality , can be assumed to be without loss of generality . 
 Consider the of Fig . and assume that the link u is given by an based linear source scheme with ,, ,, s , and set the initial of , and of the channel feedback delay to zero . The definition of , and , together with Lemma . , guarantee by construction that the that from the above choice of scheme is and that , in addition , the plant output e and the auxiliary have steady state satisfying 
  
 By Lemma . we also conclude that , for the above based linear source scheme , the average length of the channel input , for some suitable , 
 R 
  
 where we have used . Thus , inequality upon choosing a sufficiently small . 
 To complete the proof , we now show that the source scheme Assumption . . Except for the invertibility of the , the of guarantee that Assumption . note that , in our case , SE . Since is and its initial state is deterministic , knowledge of is equivalent to knowledge of . If one now proceeds as in the proof of Corollary . in , it that one can recover from upon knowledge of . Thus , upon knowledge of , one can recover from and the is invertible as . 
 Remark . : The proof of Theorem . is constructive . Indeed , it a way to build a source scheme that the resulting of Fig . , and se while an average data rate that is upper ¦ bounded by the right hand side of . 
  
 Fig . . source scheme . If the channel is noiseless and delay free , then and . 
 Theorem . that the lower bound on derived in Corollary . is tight up to per sample i . e ., tight up to approximately . per sample . Whilst the lower bound in Corollary . was derived by an information theoretic argument , the upper bound in on a specific source scheme that suitably chosen in conjunction with an . It from the discussion in that the gap between the derived upper and lower on from two : First , introduce a noise which is uniform and not this to the additional per sample . Second , the scheme works on a sample by sample basis and practical entropy are not perfectly efficient , Chapter this to an additional log per sample . We emphasize , however , that the above gap to a worst case gap and it can be significantly smaller in practice see Section . 
 A key aspect of our is that they are stated in of the solution to the constrained minimization problem in . As such , they highlight the role by in control , and thus complement , e .., where the connection between and other communication been . As already before , a way of a solution to the problem in will be in Section below . 
 Remark . : It is well known that , when causal source of arbitrary complexity are employed , it is possible to mean square stabilize an plant if and only if the corresponding average data than , where pi the unstable plant pole . On the other hand , it is straightforward use Theorem in , in conjunction with the proof of Theorem . , to show that any plant satisfying Assumption . can be in the sense of Definition . by an average data rate that 
 R . 
 The above observation , for satisfying Assumption . , that it to use an based linear source scheme to achieve stability at which are at most per sample away from the absolute minimal average data rate compatible with stability see also 
 . ¦ 
 . AND APPROXIMATE IMPLEMENTATION 
 A . the on 
 The on in Corollary . and Theorem . are of the minimal in . In this section , we show that the problem of finding is equivalent to an constrained optimal control problem previously in , , . 
 To proceed , we first note that a straightforward manipulation based on Fig . , for any and any render the feedback system of Figure 
 internally stable and well , 
  
 as in , FLy , and 
 Ly are such that Ly see , and we have used that fact that , internally , is proper and P is assumed to be strictly proper , is stable , 
 S and hence . 
 We now define , for the feedback system of Figure , the auxiliary problem of finding 
 J se , G 
 where the minimization is with respect to all , and auxiliary noise , that render the feedback system of Fig . internally stable and well . Given our , if the unstable , then the problem in is feasible if and only if , where the that is compatible with mean square stability in the feedback system of Fig . see , . stable , then the problem in is feasible if and only if . 
 Lemma . : Consider the of finding both and in and , respectively . Assume , in addition , that the such that P and P . 
 If , , the plant is unstable , or stable with 
 , then is a strictly decreasing function the inequality constraint in is active at the optimum . 
 If , then is a strictly decreasing function the inequality constraint in can be assumed to be active at the optimum without loss of generality . 
 Proof : 
 Consider the definition of in and define 
 . We first show 
 D at the 
 optimum . Since , is always non negative for any feasible set of , and . Indeed , assume on the contrary that at the optimum . Given , this would imply that or at the optimum . Given our and the definition of , only is possible . However , is not compatible with internal stability when the plant is unstable . In the stable plant case , 
 note that . The latter equality is however unfeasible since , by assumption , 
 . 
 Given the above , if , and the plant is unstable or is stable with , then at the optimum . Hence , the performance constraint se in the definition of is equivalent to 
  
 at the optimum see and . Since is a function of , it that the optimal choice for is such that the inequality constraint is active at the optimum . 
 We now show that is strictly decreasing in . Our guarantee that and hence FLy . By in , and the fact that the optimal choice for equality in , the result immediately . 
 Consider the definition of in . By an argument similar the one used in Part above , it that our imply that one can assume , without loss of generality , that at the optimum see also , . Our now follow by proceeding as in Part above . 
  
 Lemma . , for almost all of interest , that the inequality in the optimization both and can be assumed to be active at the , without loss of generality . This fact is below to relate the to these . 
 Theorem . : Consider the optimization both and in and , respectively . Assume that ,, that the such that P and P , and that , stable , then . 
 Then , 
 D , . 
 Proof : We will only prove that . Our claim by a similar argument . Since , the problem of finding is feasible . Thus , for any , there exist proper and , and , that render the system of Figure internally stable and well , and guarantee that 
  
  
 where we have used Lemma . to write an equality in the constraint . Since the inequality in is valid for any , it that there exist a feasible point for the problem of finding and , in addition , that . The proof of our second claim would follow if we show that is impossible . Assume that is indeed true . Then , there exist decision such that and se . Again , we 
 If , then either the problem of finding is unfeasible unstable plant case or stable plant case . In the latter case , no information can be through the channel . On the other hand , if the plant is stable and and it is optimal to leave the plant in open loop . The above are clearly uninteresting and have thus been from the discussion in Lemma . . 
 use Lemma . to write an equality in the constraint . Thus , we conclude that 
 , 
 where the first equality from the fact that the constraint is active at the optimum when calculating . The above inequality the fact that , given our , Lemma . that is a strictly decreasing function of . The proof is thus . 
 Theorem . , for almost all of interest , that the problem of finding in is equivalent to that of finding in . The latter problem was shown to be equivalent to a convex problem in . For doing so , that the problem of finding is equivalent to the open loop causal rate distortion problem which was shown to be convex in . Shortly thereafter , the convexity of the constrained optimal control problem in was re derived independently in , where a formulation more amenable for numerical is . We will thus not delve into the on how to numerically find here , and refer the interested reader to Section . in for . 
 B . the behavior of an in practice 
 The previous subsection how a numerical characterization of can be . Here , we will briefly comment on the implementation of a source scheme which the desired level of performance , while an average data . In principle , such scheme can be designed as see proof of Theorem . : 
 • Use the procedure in and Theorem . to , and the auxiliary noise variance , 
 which solve the problem of finding . 
 • Use these in the based linear source scheme of Fig . and set all initial to zero . Choose the quantization step as , an i . i .. dither signal uniformly distributed on , and independent of ,, and appropriate entropy coder and and , for instance , the algorithm . 
 an the availability of the dither at both the and the sides . Additionally , the entropy coder needs to generate a binary word for each input value according to the conditional probability of that input , given the current dither value . The above are impossible to meet exactly in practice . Indeed , the first one is tantamount to an additional perfect channel for being able to communicate the dither from the to the . The second one would require an uncountable number of , one for each dither value . 
 Leaving finite range and precision aside , the behavior of an can be in practice by synchronized uniformly distributed pseudo random dither , at both the and the from the same seed , and entropy and which work conditioned upon a uniformly version of the dither . By such an approach , all in the of Figure , except for the channel input and output , will have the same statistics as if an ideal was employed . For each possible dither value , one can build the corresponding conditional dictionary in by , for example , the algorithm . The conditional statistics of the for this purpose , can be by the corresponding stationary statistics which can be by simulation . 
 . A NUMERICAL EXAMPLE 
 that more than dither only negligible in of rate reduction . The curve Measured entropy of output dither to an empirical estimate of the conditional entropy of the output , given the dither . 
 Our show that our upper bound is loose . This is consistent with the fact that our upper bound was derived by worst case . The gap between the measured rate with and our lower bound is about . per sample , which is smaller than the worst case gap per sample about . per sample . On the other hand the conditional entropy of the output , given the dither , is about . per sample above the lower bound . This that , in our , the . bit per sample gap is composed by about . per sample due to the inefficiency of the considered entropy , and by about . per sample due to the fact that the uniform and not noise . 
 . , converge rapidly as . Thus , whilst an average data rate arbitrarily close to the minimal rate 
 . for stabilization severely performance , our 
 Our show that , as , a closed loop performance arbitrarily close to the best non performance arbitrarily high data . Interestingly , however , for this example , it to use less than per sample to achieve a performance that is essentially identical to the best non performance . It is also interesting to observe that our , and the measured average data 
  
  
 Assume that the plant . in Fig . is such that 
  
 and that , is unit variance white noise . By the of upper and lower on for several of . . We also an actual linear source scheme for each considered value for . To that end , we the at the end of Section and where the dither is uniform and perfectly known at both of the , and where the entropy work conditioned upon a version of the dither . The are in Figure . In that figure we plot our upper and lower , and several other which report simulation . All simulation to as Measured in Fig . are over twenty long . In particular , Measured rate no to the average data rate in a case where an tuned entropy coder is employed which does not make use of the knowledge of the dither . Even in this case our upper bound to be rather loose . The curve Measured rate cond . dither to the rate when and entropy coder that works conditioned upon uniformly dither . As our show that the average data rate . suggest that the performance loss when forcing the average data rate to be low might be modest in some . 
 . 
 This paper studied control subject to average data rate . In particular , we have a characterization of the minimal feedback directed information rate I u average data rate to within . sample that a level of quadratic performance , over all controller . Our have been derived for that have one scalar control input , one scalar sensor output , and that are subject to stationary and initial . The digital feedback channel considered was assumed to be free of and . Where no besides causality are on the considered , the directed information rate between the output u a known lower bound to the mean operational data rate was shown to be only u are jointly 
 . This , together with the introduction of the notion of strong asymptotic wide sense , us to define a wide class of namely , for which a data rate lower bound in of the asymptotic power spectral u was derived . We then that , for a given stationary performance , the of this lower bound with that of the directed information rate when , channel and are by an channel surrounded by , 
  
 Fig . . Standard one degree of freedom feedback loop around the plant . 
 taking the over all causal which satisfy the same performance constraint . Such insight was then used as motivation for building a source scheme capable of which are less than per sample away from our derived lower bound , while satisfying the desired performance level constraint . Such are based upon entropy and constitute conceptually simple . A numerical example been include to illustrate our proposal . 
 Future work should focus on multiple input and multiple output plant and on ways of reducing the gap between the derived upper and lower on the minimal average data rate that a given performance level . 
 . 
 We would like to thank the AE and the anonymous for their careful as well as for their helpful , which to improve the technical presentation of this paper . 
 APPENDIX 
 A . Three of assuming D 
 In this appendix we show sufficient for the optimization in , and to be feasible . We will make extensive use of the definition of in , the related in and , the regarding the feedback scheme of Fig . made on the paragraph preceding Theorem . , and the of and based linear source made in Section . 
 Consider the feedback system of Fig . , where , and satisfy Assumption . , and the such that u for some arbitrary . and all the involved random are , it from well known that 
 se , 
 K S 
 the set of all proper which render the the feedback system of Figure internally stable and well . Our that the above problem is feasible . 
 The fact that the problem of finding is feasible , that for every , , there K such that , in Figure , 
 . Consider the feedback scheme of Fig . with 
 F and L , where L is such that K . Since K , the above choice the feedback system of 
 Fig . internally stable and well for any additive noise variance . This that the resulting variance of , say , will be finite . It also that if in Fig . is zero mean with variance , then the of e and of will increase to , and 
 , respectively , for some finite which depend only upon K . As a consequence , for every , there K such that in Fig . and for the above choice of ,, 
 by and as zero mean with variance . It immediately that the above choice of is also such that , in Figure , 
 . 
 The latter inequality that the problem of finding in is feasible for any indeed , feasible while yielding all in the system jointly . Now , from inequality and the concavity of log , it also from that the problem of finding in is feasible for any . 
 We end this section by showing that the problem of finding in is also feasible when . To that end , it to consider an based linear source scheme to u in Fig . , with 
 . Indeed , by 
 the of the latter choice of see preceding paragraph , our claim by proceeding as in the proof of Theorem . to show that the above defined based linear source scheme Assumption . , the of Figure , and se at a finite average data rate . 
 B . Auxiliary information theoretic and 
 The following and are standard and , unless otherwise stated , can be found in . We assume all random to have well defined joint probability density . The of , is ,. to the conditional of , given . Ex mean with respect to the distribution of . 
 The differential entropy defined via Ex . The conditional differential entropy of , given , is defined via Ex , . The mutual information between two defined via I ; Ex , log ,. The conditional mutual information , given , is defined via I ; I ,; I ;. The following are of the above : 
 Property I ; ,. 
 Property a deterministic function , then y 
 Property If are independent , then . 
 Property , where can be taken to be a deterministic constant , in which case x x . 
 Lemma . : Assume that , are jointly second order random , is , arbitrarily distributed . 
 Then , I ; ; , where is such that , are jointly and have the same first and second order cross as ,. 
 Proof : Immediate from the proof of Lemma in . 
 Lemma . : Let ,, be arbitrarily distributed random satisfying the chain 
 x . 
 Let be jointly random with the same first and second order statistics as ,,. In addition , suppose that E Ly , for some appropriate . Then the chain 
 . 
 . 
 Proof : The statistics between and ,, imply that E E . The E Ly that E E Ly . With this we obtain that 
 E E E a 
 E E E , b 
 where the last equality is due to . But for jointly , E E if and only if , the proof . 
 Lemma . : Let the random , be such that , for all N and i , 
 i Li , di for some linear and deterministic . 
 si , for some sequence of deterministic 
 and for some exogenous Then the 
  
 hold for all N . 
 Proof : The , are as L , u g , g , L , L , d Mu 
 L , d M g , L , u g s , y 
 g s , L , , 
 ... L , d M g , L , 
 This that , i si , Li , di for some deterministic i , from where since 
 Lemma . is a version of Lemma . in , since the statement of the latter the existence of a linear that the estimation error Ly is independent of , while Lemma . only E for all . 
 It to have in the argument of i instead of because 
 L , , L , d ,..., Li , are sub of the sequence Li , di . 
 Theorem . : Let the random , correspond to those in the feedback system shown in Fig . . 
 Let be jointly with the same second order as Then , for N , 
 uG i , i uG i di , i a 
 b 
  
 Proof : In the scheme of Fig . , the plant causally its di to its output . This that that Li , di for some linear 
 . Therefore , we can invoke Lemma . to conclude that 
  
 . The linearity of the Li that 
 Li , di and , are jointly , and thus E , Li , di , di for some sequence of linear . Hence , we can directly apply Lemma . and obtain from that 
 , Li , di i a 
 Hence I , ; , di 
  
  
 , which is equivalent to a . The inequality a is due to the chain rule and the of mutual information which also , and since . Starting 
 uG 
 , which is equivalent to b . The 
 inequality from the chain rule and the non negativity of mutual information . This the proof . 
 , o 
 d 
  
 S 
 x 
 x , o Fig . . Generic feedback system . 
 Lemma . : Consider the generic feedback system of Figure , where S is an arbitrary hence possibly non linear and time causal dynamic system with initial state x , o and disturbance d , such that for some possibly non linear and time deterministic S ,, and S is an arbitrary causal dynamic system with disturbance d and initial state x , o , such that for some possibly non linear and 
 time deterministic S ,. If x , o , d are jointly independent of x , o , d , then 
 . Proof : Immediate from , Theorem . 
 Lemma . to a version of Theorem . in . Indeed , the latter result use of additional on system S , does not take side information into account , and only that the left hand side of is lower 
 bounded by the corresponding right hand side . , 
 Lemma . : be an process with 
 , for some . Then 
 where is the stationary of u . 
 Proof : The definition of an process that and are of asymptotically equivalent matrices . This , together with the fact that , and that log 
 is continuous for all , one to apply , Corollary . to obtain 
  
 Since the matrices are positive definite with each row being absolutely summable for all , it from the fundamental eigenvalue distribution theorem of see , e .., , Corollary . or Theorem . that ¨ 
  
 The proof is by that 
 . 
  
 ﻿ This work a necessary and sufficient condition for a stationary and ergodic process to be compressible in the sense by Amini , and Compressibility of deterministic and random infinity Signal Process ., vol . , no . , . The condition to check that the moment of the invariant distribution of the process is well defined , which and the result by , and in Compressible for high dimensional statistics , Theory , vol . , no . , , Prop . . Furthermore , for the scenario of non compressible ergodic , we provide a closed form expression for the best term relative approximation error in the norm sense when only a fraction rate of the most significant sequence are kept as the to infinity . We analyze basic of this rate approximation error curve , which is again a function of the invariant measure of the process . the case of i . i . we completely identify the family of compressible , which to look at a polynomial order decay heavy tail property of the distribution . 
 Index Asymptotic analysis , best term approximation error analysis , compressed , compressibility of infinite , compressible , ergodic , heavy tail . 
 of compressibility for a stochastic process , meaning that with high probability of the process can be well in some sense by its best term sparse version , been a recent topic of active research , , . compressibility for random and the identification of compressible and sparse are relevant considering the recent development of the compressed theory and its . These can play an important role in regression , signal reconstruction for instance in the classical compressed setting , Th . , inference , and decision making , . One important case is such a compressibility notion for i . i .. where the probability measure is with a density function , . In this context , of the process are non sparse almost surely , and conventional ways of compressibility for finite dimensional , based on the power law decay of the best term approximation error or that belong to the weak ball , are not applicable either , as shown in , . 
 by this problem , Amini al . and al . have new for compressible random . These are not based on the typical absolute approximation error decay pattern of the , but on a relative best term approximation error behavior . In particular , Amini al . formally define the concept of compressible process in Section below . This new definition a meaningful way of i . i .. random and their , in of the probability that almost all the relative energy of the process is concentrated in an arbitrarily small sub dimension of the domain , as the block length to infinity . Under this context , they provide two important the theory of order statistics . First of all , , Theorem that a concrete family of i . i .. heavy tail is compressible the generalized , and log logistic , while on the other side , , Theorem that with exponentially such as generalized are not compressible . Therefore , it is interesting to ask about the compressibility of i . i . not considered in that analysis . In this direction , we highlight the work of al . , which under an alternative notion of relative 
 compressibility almost sure instead of convergence in measure , which was the criterion adopted in and a different analysis setting fixed rate instead of the variable rate used in , an exact dichotomy between compressible and non compressible i . i . This the question of whether it is possible to connect Amini al . compressibility with the more refined almost sure a .. convergence analysis of the best term relative approximation error in , Prop . , with the idea of the analysis of and . 
 X . Personal use is permitted , but republication redistribution permission . See : index . for more information . 
 To address this question , we extend the analysis from i . i .. to stationary and ergodic . In this setting , the main result Theorem a necessary and sufficient condition for a stationary and ergodic process to be compressible in the sense of Amini al . , for any arbitrary . Furthermore , for the case of non compressible ergodic , we provide a closed form expression for an achievable rate approximation error function . The key element in the proof is the application of the ergodic theorem and the derivation of intermediate almost sure convergence Lemma and in Section that match and extend the approximation result by al . , Prop . for the i . i .. case . A corollary of Theorem a necessary and sufficient condition to categorize i . i .. random in of compressibility , which the analysis in and . In addition , for the class of non compressible ergodic , we provide an analysis of its rate approximation error curve that is continuous , differentiable Theorem and is convex under some Theorem 
 . Finally as an application , we revisit the interplay between compressible ergodic and the performance of the classical compressed setting , in the asymptotic regime when the block length to infinity . the well known instance performance guarantee of the scheme , , , we show Theorem that an arbitrarily small number of linear is to achieve zero distortion , in an noise to signal ratio sense . A preliminary version of this work was in . The current version the presentation and analysis of the main result , further analysis of noncompressible ergodic and with compressed . 
 The rest of the paper is organized as . Section some preliminary and . and are devoted to the presentation of the main result on the characterization of compressible ergodic and its proof , respectively . of the the rate approximation error curve for non compressible . Finally , Section an interplay between 
 compressibility and compressed . Some of the and are in the Appendix . 
 denote the norm of the best term approximation of , where by definition . In addition , 
 the best term approximation error of , in the sense that if is the collection of sparse , then . For the analysis of infinite , Amini al . and 
 al . have the following relative best term distortion indicator : 
 with the objective of extending of compressibility to that have infinite norm . 
 Definition : For a sequence , the rate distortion pair is if , there sequence of positive such that and 
 Note that the use of the relative best term distortion in the analysis of with infinite norm . 
 Definition : For a sequence and , we define its rate distortion approximation function by 
 Proposition : For all such that then . The proof is in Appendix A 
 Hence , can be seen as the critical asymptotic rate of innovation of when a relative best term approximation error of magnitude is . 
 Alternatively , Amini , and have a notion of critical dimension for finite length , and from this , a notion of compressibility for infinite . We revisit those here : 
 This notion of compressibility that when the block length to infinity , a negligible fraction of the is to represent with an arbitrary small distortion in the sense of . Note that is signal dependent and a variable rate sequence . In addition , it the critical number of to achieve a best term approximation error smaller or equal to in the sense of . From this , it should be related with the critical rate from a fixed rate analysis in Definition . That relationship is in the following result result : 
 . In particular from Lemma , if is compressible , then for all . We refer the interested reader to Amini al . for further discussion and of compressible . 
 B . Rate of Innovation . Distortion for Random Analogous of rate of innovation . best term 
 distortion and compressibility can be stated for the case of random or . Let be a random sequence with in and by its consistent family of finite dimensional 
 , where and the space of probability for the measurable space . As a short hand , we denote by the process distribution of 
 where the equality is by . Then in analogy with Definition , Amini al . the following : 
 Definition : and Let be a random sequence with . Then for any and 
 is the critical number of that the set typical with respect to . The process and , respectively is said to be compressible , if 
 Definition : Let be a process by , and let us consider , and . We say that the rate distortion pair , is achievable for with 
 Definition : The rate . best term approximation error function of in short the rate approximation error function of with probability is given by : 
 A simple relationship between and the critical number of in can be established in the asymptotic regime when goes to infinity , showing that our fixed rate concept is a one . 
 In the next section , we will study the class of stationary and ergodic , where the best term approximation measured in of will be in closed form . Furthermore , it will be shown for this class of random that 
 Let be a stationary and ergodic process with distribution , where its marginal shift invariant distribution . For simplicity , we assume that where the measure . 
 Theorem : Let be a stationary and ergodic process with shift invariant distribution such that . Then for any , we have the following dichotomy : 
 If : then is not compressible . Furthermore , if we introduce the induced probability measure in by : 
 : Theorem a necessary and sufficient condition for a stationary and ergodic process to be compressible in the sense in Definition . 
 achievable rate distortion region for the process , given by the set of critical rate distortion : 
 This region solely on the shift invariant measure and its induced measure in . More on the characterization of this region will be in Section . 
 are achievable see proof in Section and more in Section . This fact is used to derive a concrete analytical expression for in . Furthermore , from the characterization in and , it can be shown that is a continuous and differentiable function with respect to see Theorem in Section . 
 : In both i and , the critical a stationary and ergodic process is independent of . The reason is that asymptotically as goes to infinity , the characterization of to compute on that belong to the tail field of the process , which is known to be trivial i . e ., their have zero or one probability for the case of ergodic , , . Therefore , we obtain almost sure convergence that make independent of the value of our object of interest see Section for . 
 : A natural order among stationary and ergodic process can be established from Theorem . Proposition : If is compressible for some , then is compressible for all . 
 : the i . i .. scenario , we want to highlight the by Amini al . related to compressibility in the sense of . In particular , , Theorem that if is such that for some , 
 then the i . i .. process is not compressible . In contrast , , Theorem that if to the domain of attraction of an stable distribution , Chap . . 
 with , then the process is compressible . First for , Theorem a refined result , revealing a indeed , the complete family of i . i .. that are not compressible . In fact , in addition to that go to zero exponentially , and consequently , Gamma , heavy tail whose density function are tail lower and upper dominated by a power law decay of the form with are not compressible either . On the other hand , concerning , Th . , it is simple to verify that any that is in the domain of attraction of an stable law with that 
 see Appendix E for , and consequently , part i of Theorem this family of compressible i . i . 
 Therefore , stationary and ergodic with a shift invariant distribution that a , generalized , and Gamma are not compressible in the sense of Definition , for any . In addition , if is finitely , i . e ., where , then its process is not compressible for any . 
 Corollary : Let be a ergodic process with invariant distribution and density If as for some , then 
 Therefore , for shift invariant by a power tail behavior , which belong to the category of heavy tail , a complete picture of the range in which its ergodic process is compressible is . 
 : For the proof of Theorem , we derive almost sure convergence see Lemma and in Section . 
 Furthermore , for for some , it that In the case when : if , then 
 and extend the result by al . , Prop . , which for the i . i .. case the same almost sure convergence limit for the object . Their proof was based on the lemma of order statistics see in , Th . . In contrast , our proof is based on the use of the tail in , some induced empirical on those , and the convergence of those empirical through the application of the ergodic theory see Section for . The idea adopted in our proof was to look at the empirical of and as the of interest , instead of the partial 
 A measure is tail lower and upper dominated by a no negative function , if there and such that for any such that then . Here the of . 
 Fig . . Graphical representation of the relationship between , and in Theorem . Notice that is the total area under the bottom curve . 
 of the ordered statistics considered in , . That difference was essential to extend the almost sure convergence in Lemma and to the family of stationary and ergodic . 
 , respectively . The numerator in the last expression to the value of , for a random variable where . Similarly , from , the optimal rate 
 the value of . Thus , to the area under the tail of , which the of , in Fig . top , while with the area under the curve to the left of , in Fig . below . This graphical representation for an intuitive interpretation of the relationship between and the compressibility of a given stationary ergodic process . In order for this process to be compressible , must be zero for every and for every . Equivalently , and from that is a limit , it must be possible to achieve any while keeping an arbitrarily small fraction of the of the process , as . Such requirement is satisfied if and only if i . e ., if , which that no matter how large is chosen , the shaded area in Fig . bottom , being infinite , will yield a zero . 
 The second almost sure convergence is from the assumption that . Then , we can state the following : 
 Lemma : Let be a stationary and ergodic process with distribution and . Then for any and sequence such that , 
 , almost surely to a distortion strictly less than , and then for all : 
 Hence from the definition of in , we have that eventually in , which that 
 The first inequality comes from Proposition and the last equality from the fact that the function is continuous with respect to as . 
 Lemma : Let be a stationary and ergodic process with distribution and . Let us consider an arbitrary and such that , 
 and therefore eventually in . From this , for all , which the result from Proposition . 
 Proof : To begin let us prove the fixed rate result in . It is first important to concentrate in the case when and to show that 
 Let us take an arbitrary . From the assumption on , the definition of and the fact that 
 the same for the sequence and accordingly , we have from that 
 with this result , for an arbitrary let us consider such that . We know that there such that , and for this we consider 
 Furthermore , from definition of ordered , it is simple to verify that see : 
 This is where the zero rate result in is used . In particular , if we consider , from , and the fact that is in 
 the last equality in from definition of in . Finally from b and c , 
 let be such that . Let us consider an arbitrary where and consequently note that and are mutually absolutely continuous . Again for this , we use the in , 
 The first equality from the continuity of the function with respect to as . Then from the fact that , we have that , 
 , a .. Finally , proving that a .. an equivalent symmetric argument and we omit it . 
 and , we have that from and . Let us fix an arbitrary . Considering that 
 , then eventually in , and therefore eventually , which from definition of that . Finally , the fact the event almost surely the result . 
 V . OF THE RATE APPROXIMATION ERROR CURVE FOR NON COMPRESSIBLE 
 For the family of non compressible ergodic , in this section we study two tail that characterize the achievable rate distortion region in . Let be stationary and ergodic with its invariant probability measure . Here we focus on the case where , then the measure in is well defined and by construction , where the Radon derivative or density of with respect to is given by for all . Furthermore , from the strict positivity of 
 all the in , and any distortion is in with a given rate . 
 In summary , the rate distortion approximation function is continuous , and all the , in the sense that for any there is only one such that . In addition , it is strictly decreasing and the following boundary : and . Furthermore , it is simple to verify that and 
 should be a non increasing function as progress to considering that , and consequently , 
 should present a convex behavior eventually as to . The next section the convexity of more formally . 
 First in this section we show that is a convex function of . Then , we provide a necessary and sufficient condition for to be a convex function of . 
 Theorem : Let by a non compressible stationary and ergodic sequence with . Then 
 Remark : The condition in is implicit and may be difficult to verify . A simple to check sufficient condition for the convexity of is the following : 
 where . In particular , a non increasing i . e ., almost everywhere in a convex rate approximation error function . 
 We present few of rate approximation error of non compressible i . i . In particular following , we consider the exponentially distribution , which is non compressible for any , from Corollary , and the family of Student distribution with parameter 
 , whose goes to cero as . From Corollary , the i . i .. process with a Student distribution is compressible for any and non compressible for 
 , for all . For this we consider an estimation approach . Considering a sufficiently large set of i . i .. of let say , the law of large us that for any and , 
 The of a Student distribution with of freedom is given by , where is the gamma function . 
 Fig . . Numerically rate approximation error for several non compressible i . i .. and one compressible i . i .. process . 
 the use of . Then , by sampling the space of and considering a sufficiently large , we can estimate with an arbitrary good precision the rate distortion region 
 . Following this path , Fig . the rate approximation error for the , and several Student distribution for . We verify that some Student distribution are compressible and and are non compressible , and 
 as the Theorem . More interesting is to validate in all the of non compressible , that the have a convex behavior , which is from . Furthermore , the density with the exponentially tail is less compressible than any prior with a power law decay , in the sense that for a distortion the i . i .. process needs a higher rate . From these , as goes to infinity the i . i .. process with a heavy tail distribution the approximation error behavior of the law . 
 Fig . the rate approximation error for the prior for different of . It is interesting to observe the increasing monotonic behavior of as , for any fixed value of . Again all have a convex behavior . To contrast , Fig . a set of for the distribution i . e ., Student distribution with 
 We conclude this work compressible stationary and ergodic , as in Theorem , in of their ability to be with an arbitrary small proportion of linear for that the classical compressed measurement and reconstruction setting . In particular , the focus is on compressible , as the standard i . i .. linear acquisition and 
 minimization sparsity of , offer a well known instance guarantee stated below in Lemma that the modeling assumption of compressible . 
 is a linear operator , that given a signal a measurement vector . The case of interest is on the under regime , i . e . where under sparse or compressible on , can offer perfect or near optimal reconstruction by the solution of the following linear problem : 
 Notably , the theory , based on the restricted isometry property RIP , sufficient over and implicitly over the number of in order that 
 , when for some . The next result , in its original form stated in , that random offer a solution to that problem with a near optimal relationship between and . 
 Lemma : , Th . . and , Th . . Let be a random matrix whose are driven by i . i . of a distribution or a binary variable with uniform distribution over . For any arbitrary and , we have that : 
 with a probability , over the sampling space , at least equal to . Here is the solution of 
 The proof of this result directly from , Th . . and , Th . . 
 Here we formalize the reconstruction of infinite . For this , we consider a finite length or fixed rate approach , where the idea is to analyze consecutive finite block of the sequence , i . e ., to sense and reconstruct for any , and study reconstruction in the limit when the block length to infinity . 
 More precisely , let be a sequence of positive such that . From this sequence , we consider the family of where for any , is the random matrix of by i . i .. as in Lemma , and is the function from to that the minimization problem in . Given a sequence and any finite block length , we can apply the approach over to recover , which is a random reconstruction function of the matrix . In relation with the relative approximation error in , we consider as a fidelity indicator the noise to signal ratio given by : 
 More generally , if we have a process with distribution and a sequence of with its associated finite block scheme , we can also analyze the finite block performance of the scheme by the object 
 of two independent random : the vector and the random matrix . Therefore , it is important to consider the average with respect to the statistics of the source i . e ., 
 Then the question we focus here is : for an compressible process that , what is the minimum rate of i . e . or more generally 
 with probability one with respect to the statistics of the sequence of random matrices 
 From Theorem and the RIP based instance result of the setting in Lemma , we can state the following result : 
 Theorem : Let be a stationary ergodic process . If is compressible , then for any sequence such 
 : This result that in order to achieve zero distortion in the reconstruction for an compressible process , almost surely in the sense of , the scheme needs an arbitrary small number of per sample . In other , under the compressibility model assumption for the process , the minimum rate to achieve zero distortion is zero for the scheme . Then , it is remarkable to validate that is able to achieve the same zero critical rate that it is by the analysis of the pure oracle best term approximation error of compressible process see the result in Lemma . 
 : This result that the lucid notion of compressibility by Amini al . really in a meaningful performance result for the classical setting in the asymptotic regime when the goes to infinity . In other , we can say that 
 compressibility , meaning a sort of zero rate of innovation in the process , zero rate of per signal dimension for perfect recovery in the sense of distortion for the scheme . This result a gap not in between their notion of compressibility and performance guarantee in the asymptotic regime . 
 : Concerning compressibility of random and performance guarantee , we want to highlight the work of al . for the case of i . i . They show in , Theorem that if then 
 of Theorem for the i . i .. case , Remark . Then , we want to give credit to this contribution to be the first result that a connection between of compressibility for i . i .. based on relative approximation and the performance in the asymptotic regime of the classical scheme . In this context , Theorem can be seen as an extension of these to the case of stationary and ergodic and , in the technical side , an extension on the use of the instance property of the 
 minimization . On the other hand , on the i . i .. context , and offer a way to verify that Amini al . compressible notion variable rate in nature a connection with the in al . , Th . and . in of what can for the case of compressible . 
 The main result of this work Theorem a connection between al . , Prop . almost sure convergence result of relative approximation , and Amini al . notion of compressibility for random . More importantly , Theorem new to extend that connection and , consequently , a dichotomy between being and non being compressible random to the family of stationary and ergodic . This extension is over the almost sure convergence of the empirical of and , respectively see in the statement of Theorem to the true on the family of tail in Section . 
 The idea of looking at specific empirical as the basic object of interest , in b and c , instead of the statistics of the sum of the ordered sequence as considered in , Prop . and , was essential to extend the analysis from the i . i .. case to the case of stationary ergodic . 
 Finally , one can notice from the proof of Theorem that this result does not rely on a stationary property , as it is essentially over the family of indicator of the tail in . Then , we conjecture that the analysis of compressible can be extended over a family of random with a specific ergodic property over the tail , which is an interesting direction for future work . This observation us to put the attention on the general theory of non stationary with ergodic , , . 
 Point : of all and in : Proposition and and the hypothesis that 
 in . Then , Proposition e , we have that all the and in the range . 
 First , it is important to verify that the implicit characterization of in and a well defined function . By contradiction , let assume that such characterization is not a function in the sense that for a given distortion 
 there are two solution of associated to two different . This last condition that from , which the fact that and are of . 
 Moving to the continuity , let us fix an arbitrary and . Then by the of the , 
 such that . On the other hand , by the of the , there , where 
 and without loss of generality we assume that . Then from of we have that for any , 
 we have by the of the function that there such that , and consequently , 
 First , it is clear that both and are differentiable by construction . In fact from 
 Furthermore , we can introduce the auxiliary function that is differentiable , and 
 Proof : Considering that , let be its . In view of Theorem , for a fixed , there such that can be expressed as : 
 , the middle term in is negative and with , proving the convexity for that case . For the case , from the right hand side of convexity will hold , if and only if , 
 Proof : Let fix and . Assuming that is compressible , from Theorem we have that and , consequently , it that : 
 this inequality is valid with probability over sampling space of the random object . There 
 , which is valid for any arbitrary small and . In other , if we define the set 
 , we need a slightly different argument . Under the assumption that , it is simple to verify that there a sequence of positive such that and , more importantly , it that 
 from the Lemma and the fact that as by hypothesis . 
 Following similar than before , there such that we have that , and therefore , from Lemma , 
 with probability in . It is important to define the set where Lemma us that . Furthermore , from 
 with probability one with respect to the process distribution of . In other , if we define the set 
 where it is simple to show that , by and the of and . Hence , the problem to evaluate , 
 the last equality from the fact that . Then from the additivity and monotony of the measure , which the result by the definition of . 
 and . Consequently eventually in which that eventually . This the result . 
 For the other inequality , we consider the case when . We prove it by contradiction assuming that . Then from , there and a sequence such that 
 . Under the fact that , there such that this and the definition of in 
 This approach can be a finite number of times independent of the length 
 Proof : the to prove Theorem Point , if we consider , then for any there such that . This last auxiliary function is with respect to and we have that : 
 with , it that is negative and increasing with , i . e ., is a convex function of . 
 The family of stable is the class of non degenerate that are limit in distribution of of random of the form : 
 where are i . i . of a random variable , and and are a of real . For the scenario when , the Central Limit Theorem us that the limit is a normal law . For the case , we have the less known family of stable , whose characteristic function is given by , Th . . : 
 Definition : . The distribution is said to be in the domain of attraction of an stable law with 
 , which we denote by , if there and such that : in distribution and the stable distribution in . 
 Proof : Let and . Without loss of generality let us assume that is slowly . Then it is simple to verify that , and such 
  
 ﻿We deal with zero-delay source coding of a vector
 Gaussian autoregressive (AR) source subject to an average mean squared error (MSE) fidelity criterion. Toward this end, we consider the nonanticipative rate distortion function (NRDF) which is a lower bound to the causal and zero-delay rate distortion function (RDF). We use the realization scheme with feedback proposed in [1] to model the corresponding optimal “testchannel” of the NRDF, when considering vector Gaussian AR(1) sources subject to an average MSE distortion. We give conditions on the vector Gaussian AR(1) source to ensure asymptotic stationarity of the realization scheme (bounded performance). Then, we encode the vector innovations due to Kalman filtering via lattice quantization with subtractive dither and memoryless entropy coding. This coding scheme provides a tight upper bound to the zero-delay Gaussian RDF. We extend this result to vector Gaussian AR sources of any finite order. Further, we show that for infinite dimensional vector Gaussian AR sources of any finite order, the NRDF coincides with the zero-delay RDF. Our theoretical framework is corroborated with a simulation example.
 I.	INTRODUCTION
 Zero-delay source coding is desirable in various real-time applications, such as, in signal processing [2] and networked control systems [3]–[5]. Zero-delay codes form a subclass of causal source codes (see [6]), namely, codes where the reproduced source samples depends on the source samples in a causal manner. However, zero-delay source coding compared to causal source coding allow the reproduction of each source sample at the same time instant that the source sample is encoded. Unfortunately, causal source coding does not exclude the possibility of long blocks of quantized samples, which may cost arbitrary end-to-end delays.
 Zero-delay codes (and causal codes) in constrast to noncausal codes cannot achieve the classical rate distortion function (RDF). Indeed, an open problem in information theory is quantifying the gap between the optimal performance theoretically attainable (OPTA) by non-causal codes, and the OPTA by causal and zero-delay codes, hereinafter denoted by Rcop(D) and RZDop (D), respectively. Notable exceptions where this gap is explicitly found are memoryless sources [6], stationary sources in high rates [7], and zero mean stationary scalar Gaussian sources with average mean squared error (MSE) distortion [8].
 Throughout the years, the interest in zero-delay applications is growing, thus, initiating further research on characterizing the fundamental limitations of the OPTA by zero-delay codes. Unfortunately, it turns out that RZDop (D) is very hard to compute and for this reason there has been a turn in studying variants of classical RDF that perform as tight as possible to
 RZDop (D).
 In this paper, we derive a tight upper bound to zero-delay source coding for vector Gaussian AR sources subject to an average MSE distortion. We consider nonanticipative rate distortion function (NRDF) (see, e.g., [1], [8], [9]), which gives a tighter lower bound to RZDop (D) compared to the classical RDF (see, e.g., [8, eq. (11)]). Then, we employ the feedback realization scheme proposed in [1, Fig. IV.3], that corresponds to the optimal ”test-channel” of NRDF for vector Gaussian AR(1) sources and average MSE distortion. Further, we give conditions to asymptotically stabilize the performance of the specific scheme. By invoking standard techniques using entropy coded dithered quantizer (ECDQ) [10], [11] on the innovations’ encoder of the feedback realization scheme, we derive the tight upper bound. In addition, we show how to generalize our scheme to vector Gaussian AR sources of any finite order. If the vector dimension of the Gauss AR source tends to infinity, we show that the RZDop (D) coincides with the NRDF. We demonstrate our results with a numerical example. Notation: We let R = (-8,8), N0 = {0,1,...}.
 We denote a sequence of RVs by x  and its realization by xn = xn,xj ? Xj, j = 0,...,n. The distribution of the RV x on X is denoted by Px(dx) = P(dx). The conditional distribution of RV y given x = x is denoted byis denoted byPy|x(dy|xS=T. For a square matrixx) = P(dy|x). The transpose of a matrixS ? Rp×p with entriesS
 Sij on the ith row and jth column, we denote by diag{S} the matrix having Sii, i = 1,...,p, on its diagonal and zero elsewhere.
 II.	PROBLEM STATEMENT
 In this paper we consider the zero-delay source coding setting illustrated in Fig. 1. In this setting, the p-dimensional (vector) Gaussian source is governed by the following discretetime linear time-invariant state-space model
 xt+1 = Axt + Bwt, t ? N0, (1) where A ? Rp×p, and B ? Rp×q are known, x0 ? Rp ~
 N(0;Sx0) is the initial state, and the noise process wt ? Rq is an i.i.d. Gaussian N(0;Iq×q) sequence, independent of x0. We allow A to have eigenvalues outside the unit circle which means that xt can be unstable.
 The system operates as follows. At every time step t, the encoder observes the source xt and produces a single binary codeword zt from a predefined set of codewords Zt of at most a countable number of codewords. Since the source is random, zt and its length lt are RVs. Upon receiving zt, the decoder produces an estimate yt of the source sample. We assume that both the encoder and decoder process information without delay and they are allowed to have infinite memory of the past.
  t
 Fig. 1: A zero-delay source coding scenario.
 The analysis of the noiseless digital channel is restricted to the class of instantaneous variable-length binary codes zt. The countable set of all codewords (codebook) Zt is timevarying to allow the binary representation zt to be an arbitrarily long sequence. The encoding and decoding policies are described by sequences of conditional probability distributions as {P(dzt|zt-1,xt) : t ? N0} and {P(dyt|yt-1,zt) : t ? N0}, respectively. At t = 0, we assume P(dz0|z-1,x0) = P(dz0|x0) and P(dy0|y-1,z0) = P(dy0|z0).
 The design in Fig. 1 is required to yield an asymptotic average distortion  
 D, where D	>	0 is the pre-specified distortion level,
  . The objective is to min-
 imize the expected average codeword length denoted by
  , over all encoding-decoding
 policies. These design requirements are formally cast by the following optimization problem:
 	 ,	(2)
 	s. t.	 
 i.e., the OPTA by zero-delay codes.
 III.	PRELIMINARIES
 In this section, we give the definition of NRDF of vector Gaussian AR sources subject to an average MSE distortion.
 	Define	the	source	distribution	by	P(dxn) 
  ,	the	reconstruction	distribution	by P	 ,	and	the	joint distribution by   P(dyn||xn).
 The marginal on yt ? Yt, P(dyt|yt-1), is induced by the joint distribution P(dxn,dyn). We assume that at t = 0, P(dy0|y-1,x0) = P(dy0|x0).
 Given the previous distributions, we introduce the mutual information between xn and yn as follows
  ,
 where E{·} is the expectation with respect to the joint distribution P(dxn,dyn).
 Definition 1. (NRDF with average MSE distortion) (1) The finite-time NRDF is defined by
  
 assuming the infimum exists.
 (2) The per unit time asymptotic limit of (3) is defined by
 	 ,	(4)
 assuming the infimum exists and the limit exists and it is finite.
 The optimization problem of Definition 1, in contrast to the one given in (2) is convex (see e.g., [12]). In addition, for the source model (1) and the average MSE distortion, then, by [1, Theorems 1], the optimal “test channel” corresponding to (4) is of the form
 P*(dyt|yt-1,xt) = P*(dyt|yt-1,xt), t ? N0, (5) where at t = 0, P*(dy0|y-1,x0) = P*(dy0|x0), and the corresponding joint process {(xt,yt) : t ? N0} is jointly Gaussian.
 IV.	ASYMPTOTICALLY STATIONARY FEEDBACK REALIZATION SCHEME VIA KALMAN FILTERING
 The authors in [1, Theorem 2] realized the optimal “test channel” of (5) with the feedback realization scheme illustrated in [1, Fig. IV.3] that corresponds to a realization of the form: yt  
 where   is a scaling matrix; vt is an independent Gaussian noise process with N(0;Svt), Svt = diag{Vt} independent of x0; the erroris Gaussian with
    is
 Gaussian with N(0;?t|t), and  xt|t . Moreover,   are given by the following Kalman filter
 equations:
 Prediction:
 	 ,	(7a)
 	T	T
 ?t|t-1 = A?t-1|t-1A + BB ,
 Update:	?0|-1 = Sx0,	(7b)
  G 0 = E{x0}, (7c) k˜t  yt   (innovation), (7d)  x0,	(7e)
 	 	(Kalman Gain),
  ,
 where  ,
  
 Fig. 2: Asymptotically stationary feedback realization scheme corresponding to (6).
 ?˜ t  diag 	= diag  0, and Et ? Rp×p is an orthogonal matrix. It is easy to verify that the following hold:
  
 where I ? Rp×p denotes the identity matrix. By substituting (8) in (6), we can also observe that P*(dyt|yt-1,xt) =
 P*(dyt|yt-1,xt).
 The realization scheme of (6) becomes asymptotically stationary (stable) if one of the following two conditions hold: (1) A is stable, i.e., its eigenvalues have magnitude less than one; (2) the limit of the covariance matrix ?t|t exists, i.e.,   with	 [13]. This means that   with  , and
 Svt = Sv.
 Next, we briefly discuss the resulting asymptotically stationary realization scheme depicted in Fig. 2.
 Preprocessing at Encoder: Introduce the estimation error
 {kt ? Rp :	t ? N0}, where  
 with (error) covariance ?t|t-1, t ? N0. Under conditions
 (1) or (2), we ensure that   and it is unique. The error covariance matrix ? is diagonalized by introducing an orthogonal matrix E (invertible matrix) such
 T
 that E?E = diag. To facilitate the computation, we introduce the scaling process  , where
  , has independent Gaussian components.
 Preprocessing at Decoder: Analogously, we introduce the innovations process {k˜t : t ? N0} defined by (7d) and the scaling process {?˜t : t ? N0} defined by , with
  , and {F, T} are the
 asymptotic limits of Ft and Tt, respectively. The fidelity criterion ||kt - k˜t||22 at each t is not affected by the above processing of {(xt,yt) : t ? N0}, in the sense that the preprocessing at both the encoder and decoder do not affect the form of the squared error distortion function, that is,
 	 .	(9)
 T
 The steady state values of (7b) is . The end-to-end MSE distortion of the scheme in Fig. 2 is
 T
 lim E{(xt - yt) (xt - yt)}
 t-?8
  = trace(?  Hence, following [1, Theorem 2], the per unit time asymptotic limit of Gaussian NRDF subject to the total MSE distortion can be expressed as follows.
   	 	.
 (10)
 Clearly, the optimization problem in (10), is a logdeterminant minimization problem and can be solved using, for instance, Karush-Kuhn-Tucker conditions [14, Chapter
 5.5.3] or semidefinite programming (SDP). A way of solving (10) is proposed in [15]. However, compared to that work, our realization scheme is implemented with feedback to take into account the effect of unstable sources in the dynamical system.
 V.	UPPER BOUND TO ZERO-DELAY GAUSSIAN RDF
 In this section, we derive an upper bound to the zero-delay Gaussian RDF using a subtractively dithered uniform scalar quantizer (SDUSQ) on the feedback realization scheme of Fig. 2. The SDUSQ scheme was introduced in [10] and since then it has been used in several papers (see, e.g., [4], [8], [16]) under various realization setups. However, it has never been documented for the realization scheme proposed in this work. Here, we consider the vector Gaussian AR(1) source of (1), and we quantize each time step t over p independently operating SDUSQ, with their outputs being jointly entropy coded conditioned to the dither. We extend our results when using vector quantization showing that at infinite dimensional vectors, the space-filling loss due to compression and the entropy coding extinguishes, i.e., Rna(D) and RZDop (D) coincide.
 A. Scalar quantization
 Next, we use the asymptotically stationary feedback realization scheme illustrated in Fig. 2 to design an efficient {encoder/quantizer,decoder} pair.
 We select the quantizer step size ? so that the covariance of the resulting quantization error meets Sv. The encoder does not quantize the observed state xt directly. Instead, it quantizes the deviation of xt from the linear estimate   of xt. This method is known in least squares estimation theory as
  
  
 (b) Realization over p independently operating SDUSQ.
 Fig. 3: Scalar quantization by replacing a p-dimensional AWGN channel with p independently operating SDUSQ.
 innovations approach and, therefore, the encoder is named as an innovations’ encoder. We consider the zero-delay source coding setup illustrated in Fig. 2 with the additional change of the p-parallel AWGN channels with p independently operating SDUSQ. This is illustrated in Fig. 3. Note that, all matrices and scalings adopted in Fig. 2 still hold when the aforementioned replacement is applied.
 For each time step t, the input to the quantizer, is a scaled estimation error defined as follows
 	at = Akt, A = FE.	(11)
 Moreover, at is an Rp-valued random process. The parallel p-dimensional AWGN channel is replaced by p independently operating SDUSQ, hence we can design the covariance matrix Sv of the AWGN corresponding to the p-parallel AWGN channels in such a way, that for each t, each diagonal entry of Vii,i = 1,...,p, i.e., Sv  diag{V }, to correspond to a quantization step size ?i,i = 1,...,p, such that
 	 	(12)
 This results creates a multi-input multi-output (MIMO) transmission of parallel and independent SDUSQ. We apply SDUSQ to each component of at, i.e.,
 	 	(13)
 and we let rt be the Rp-valued random process of dither signals whose individual components {rt,1,...,rt,p} are mutually independent and uniformly distributed RVs rt,i ~ Unif  independent of the corresponding source input components at,i, ?t,i. The output of the quantizer is given by
 	ß˜t,i = Q?i(at,i + rt,i), i = 1,...,p.	(14)
 Note that ß˜t = (ß˜t,1,...,ß˜t,p) can take a countable number of possible values. In addition, by construction (see Fig. 2), the sequences {at : t = 0,1,...} and {ß˜t : t = 0,1,...} are not
  2017 IEEE
 Gaussian any more since by applying the change illustrated in Fig. 3, {at : t = 0,1,...} and {ß˜t : t = 0,1,...} contain samples of the uniformly distributed process {rt : t = 0,1,...}. As a result, the Kalman filter in Fig. 2 is no longer the least mean square estimator.
 Entropy coding: In what follows, we apply joint entropy coding across the vector dimension p and memoryless coding across the time, that is, at each time step t the output of the quantizer ß˜t is conditioned to the dither to generate a codeword zt. The decoder reproduces ßt by subtracting the dithered signal rt from ß˜t. Specifically, at every time step t, we require that a message ß˜t is mapped into a codeword zt ? {0,1}lt designed using Shannon codes [17, Chapter 5.4]. For a RV x, the codes constructed based on Shannon coding scheme give an instantaneous (prefix-free) code with expected code length that satisfies the bounds H(x) = E(l) = H(x)+1.
 Since the SDUSQ operates using memoryless entropy coding over time, the following theorem holds.
 Theorem 1. (Upper bound)
 Consider the realization of the zero-delay source-coding scheme illustrated in Fig. 2 with the change of AWGN channel with p-parallel independently operating SDUSQ illustrated in Fig. 3. If the vector process {ß˜t : t = 0,1,...} of the quantized output is jointly entropy coded conditioned to the dither signal values in a memoryless fashion for each t, then the operational Gaussian zero-delay rate, , satisfies
 	 	(15)
 where p is the dimension of the state-space representation given in (1), while the average MSE distortion achieves the end-to-end average distortion D of the system.
 Proof. The derivation is shown in [18, Appendix A].	 
 The previous main result combined with the lower bound on Gaussian zero-delay RDF, leads to the following corollary.
 Corollary 1. (Bounds on zero-delay RDF)
 Consider the realization of the zero-delay source-coding scheme illustrated in Fig. 2 with the change of AWGN channel with p-parallel independently operating SDUSQ as illustrated in Fig. 3. Then, for vector (stable or unstable) Gaussian AR(1) sources the following bounds hold
  
 Proof. This is obtained using the fact that Rna(D) = RZDop (D), (10) and Theorem 1.
 Theorem 2. (Generalization)
 The bounds derived in Corollary 1 based on the realization scheme of Fig. 2 hold for vector Gaussian sources of any order.
 Proof. This is shown by augmenting the state of the statespace model of (1). For details see [18, Appendix B].  
 In the next remark, we draw connections to existing results in the literature.
 Remark 1. (Relations to existing results)
 (1)	For stationary stable scalar-valued Gaussian AR sources, our upper bound in Theorem 1 coincides with the bound obtained in [8, Theorem 7]. However, the upper bound in [8] is obtained using a realization scheme with four filters instead of only one that we use in our scheme. In addition, our result takes into account unstable Gaussian sources too.
 (2)	Compare to [16], we use ECDQ based on a different realization setup that results into obtaining different lower and upper bounds.
 Next, we employ Theorem 1 to demonstrate a simulation example.
 Example 1. We consider a two-dimensional unstable Gaussian AR(1) source as follows:
 x ,	(17) A	B
 where xt ? R2, the parameter matrix A is unstable because one of its eigenvalues, denoted by ?i(A), has magnitude greater than one, the pair (A,B) is stabilizable and wt ~ N(0;I2×2). By invoking SDPT3 [19] we plot the theoretical attainable lower and upper bounds to the zerodelay RDF. This is illustrated in Fig. 4. As expected from theory,bits/source sample.
  
 Fig. 4: Bounds on RZDop (D) via the scheme of Fig. 2.
 B. Vector Quantization
 It is interesting to observe that if instead of uniform scalar quantization we quantize over a lattice (vector) quantizer followed by memoryless entropy coded conditioned to the dither, then the upper bound in (15) becomes
 	 	(18)
 where Gp is the normalized second moment of the lattice [11]. If we take the average rate per dimension and assume an infinite dimensional vector Gaussian source, then by [11, Lemma 1], Gp ? 2pe1 , and the terms due to space-filling loss and the loss due to entropy coding in (18) asymptotically goes to zero. Utilizing the latter, and the fact that Rna(D) = RZDop (D), we obtain
  p?8 p
  2017 IEEE
 VI.	CONCLUSIONS AND FUTURE DIRECTIONS
 We considered zero-delay source coding of a vector Gaussian AR source under MSE distortion. Based on a feedback realization scheme that quantizes the innovations of a Kalman filter with a SDUSQ, we derived an upper bound to the zerodelay RDF. We discussed the performance of this scheme when using lattice quantization. For infinite dimensions we observed that the NRDF coincide with the zero-delay RDF. An illustrative example is presented to support our findings.
 As an ongoing research, we will apply the proposed coding scheme based on SDUSQ to find the actual operational rates corresponding to the zero-delay RDF. Moreover, we will examine similar coding schemes for fixed-length coding rate.
 
 ﻿This work addresses the problem of universal density estimation under an operational data-rate constraint. We present a coding theorem that stipulates necessary and sufficient conditions to learn and transmit a memoryless source distribution with arbitrary precision (in total variations), under an asymptotic zero-rate regime, in bits per sample. In the process, we propose a concrete coding scheme to achieve this learning objective, adopting the Skeleton estimate developed by Y. Yatracos [1], [2]. 
 This work studies the problem of universal density estimation under an operational data-rate constraint. The basic setting consists of an agent (the sensor) observing i.i.d. samples from an unknown distribution µ with the objective of jointly learning and transmitting a finite description of µ to a second agent (the receiver), which decodes that information to construct an estimate µˆ. This density estimation and coding problem has taken the attention of the community because of its role in sensor networks, and because of its strong connection with 
 Making echo of the seminal work of Rissanen [3], it is well understood that the problem of universal lossless-source coding is connected with the problem of distribution estimation, as there exists a one-to-one correspondence between prefixfree codes and finite-entropy discrete distributions (models), in the finite-alphabet case [4]. This interplay, however, is less obvious when we move to the lossy-source coding scenario. Addressing this issue, Raginsky [5] has recently stipulated results that connect the problem of fixed-rate universal lossy source coding, with the problem of transmitting the source distribution with arbitrary precision, from one point to another, under an asymptotically zero-rate operational constraint [5]. This connection was made under the two-stage joint modeling and coding framework [5]. Taking ideas from statistical learning, the data was split in training and testing samples, where first, the training data is used to construct a finite description of the source distribution (first stage), and the second stage uses the first bits to pick a matched (with respect to the estimated distribution) lossy source code to encode the test data. Remarkably, in this joint modeling-coding framework, the existence of a zero-rate consistent estimate of the distribution (in total variations), is sufficient to show the existence of a universal fixed-rate source coding scheme, achieving the 
 Shannon distortion-rate function [4], for any given rate, and for any distribution within a bounded parametric family with some needed regularity conditions [5, Th. 3.2]. This raises the question of whether there are broader families of measures (non-parametric) for which this result is also valid. 
 In this work we study in deeper details the problem of universal density estimation under an asymptotically zerorate constraint. Our main result is a coding theorem that stipulates necessary and sufficient conditions to guarantee that zero-rate is achievable for this learning-coding problem. Interestingly, there is a tight connection with the rich nonparametric collection of L1-totally bounded densities [6]. Furthermore, we propose a concrete coding scheme, the Skeleton estimate developed by Yatracos [1], [2], [6], to achieve our coding objective, which is a concrete demonstration of its information theoretic attributes, something that was mentioned by Devroye and Lugosi [6, Ch. 7.1] and which, to the best of our knowledge, has not been presented before. In the parametric scenario considered in [5], the Skeleton scheme 
 offers an optimal learning rate of O(p1/n) under the zerorate regime, where, furthermore, this rate is extended for general non-parametric families. 
 Let X ? B(Rd) be a separable and complete subset of Rd (i.e., X is a Polish subspace of Rd). Let P(X) be the collection of probability measures in (X,B(X)) and let AC(X) ? P(X) denote the set of probability measures absolutely continuous with respect to the Lebesgue measure ? [7]1. For any µ ? AC(X),  ?µ??(x) denotes the Radon-Nikodym (RN) derivative of µ with respect to ?. 
 For the estimation problem the fidelity criterion adopted is the total variational distance. Let v and µ be two probability measures in P(X). The total variation of v and µ is given by 
 1A measure s is absolutely continuous with respect to a measure µ, denoted by  , if for any event A such that µ(A) = 0, then s(A) = 0. 
 Consequently   is well defined, which is the Radon-Nicodym derivative or density, and furthermore, ?A ?B(X), s(A) = RA ?s?µ?µ. 
 which is a bounded metric in P(X) and has been widely adopted in density estimation [6], [8]. For the case when, µ and v belong to AC(X), the Scheffe‘s identity´ [9] provides a connection between total variation and the L1-norm of the densities involved [6], [8], more precisely, 
 (µ,v) (with densities (f,g), respectively) by Aµ,v = {x ? X : f(x) > g(x)} ? B(X), then V (µ,v) = µ(Aµ,v) - v(Aµ,v) [6]. 
 Let F = {µ? : ? ? T} ? AC(X) be an indexed collection of densities of interest. T represents the index set of F, which can live, in general, in an infinite dimensional space (a nonparametric scenario). 
 Definition 1: A (n,2nR) learning rule of length n and rate R is a pair of functions (f,f), with f : Xn ? S and f : S ? T, where S is a finite set and 
 The composition of these two functions p = f ? f : Xn ? T defines the explicit learning rule taking values in the set {f(s) : s ? S} ? T, which is called the reproduction codebook of (f,f). For an arbitrary learning rule p, the operator R(p) returns log2(|S|)/n, which is the description complexity of the range of p, in bits per sample. 
 Definition 2: A finite description learning scheme ? with rate sequence (Rn)n=1 is a collection of learning rules for all possible finite lengths, i.e., ? = {(fn,fn) : n = 1} such that R(pn) = Rn, for all n = 1. 
 Let X1,X2 ... be independent and identically distributed (i.i.d.) realizations of a measure µ ? F. In this context,  denotes the product measure of the block  in (Xn,B(Xn)) and Pµ the entire process distribution of X1,X2 .... Hence, the problem is to study the existence of a universal learning scheme ? = {(fn,fn) : n = 1}, such that its finite description density estimate induced by the data µpn(X1n) ? F convergences to µ, in the following sense, 
 In other words, we are interested in characterizing a densityfree zero-distortion estimate for the family F, adopting a scheme ?, and consequently, in studying the necessary and sufficient conditions, if any, that this consistency assumption imposes on the intrinsic complexity of F. 
 Definition 3: Let F = {µ? : ? ? T} ? AC(X) be an indexed collection of densities in (X,B(X)). We say that the rate R = 0 is asymptotically achievable for F, if there exists a learning scheme ? = {(fn,fn) : n = 1}, with limsupn?8 R(pn) = R such that 
 In this case we say that ? is an R-rate uniformly consistent estimate for the class F. 
 Definition 3 considers estimating the density in F with zero-distortion. We are interested in the zero distortion (i.e., lossless) operational point, as it is the standard objective in density estimation, and because it is fundamentally related with the problem of universal source coding [5]. The focus of the next section, containing the main results of this paper, is to characterize the class of distributions that permits a zerorate scheme for lossless density estimation. 
 Definition 4: Let F ? AC(X) be a class of densities. We say that F is totally bounded if for every , there exists a finite covering   of elements in F such 
 is the L1 ball of radius  centered at µ. Let N denote the smallest positive integer that achieves (4). N is called the -covering number of F and   is the 
 Kolmogorov‘s -entropy of the class [6]. Finally, an -covering   such that   , is called an -Skeleton of F 
 THEOREM 1: Let F = {µ? : ? ? T} be an indexed collection of densities in AC(X) with index set T (that could be an infinite dimensional set in general). Then, there exists a zero-rate uniformly consistent scheme ? for the class F, if and only if, F is totally bounded. 
 Hence, the rate zero is achievable with zero distortion for the class F, if and only if, F is totally bounded. This offers a concrete correspondence between zero-rate density estimation and L1-totally bounded collections of densities. The proof has two parts which are presented in detail next. 
 For the achievability argument, we present a concrete learning scheme that achieves consistency in the sense of (3), under the desired zero asymptotic rate. The scheme is based on the Skeleton estimate [6, Chapter 7] proposed by Yatracos [1]. 
 Skeletons . In what follows, we use  as a short-hand for the densities in G, and we define   to represent the index set of G. The idea of Yatracos was connecting this collection of probability measures with a set of measurable events in B(X). More precisely, let us define the Yatracos class of G [6] by 
 Scheffe set of´   with respect to  [9], [6]. Then the idea is to partition T using as a codebook the Skeleton-index set T and to adopt a minimum distance principle [1], [6]. More precisely, given i.i.d. realizations X1,..,Xn with Xi ~ µ (µ ? F), the Skeleton estimator is given by [1], 
 where   is the standard empirical distribution [6]. Note that   is the minimum-distance approximation of µˆn with elements of G, adopting the similarity measure in (6), that is reminiscent of the total variational distance in (1). The following key theorem offers a performance bound with respect to the minimum-distance decision on the knowledge of the true distribution. THEOREM 2: (Yatracos [1]) For any µ ? F, 
 This bound consists of an approximation error and an estimation error, the first and second term on the right-hand-side of (7), respectively The approximation error is bounded by the definition of G, as F is totally bounded. On the other hand for the estimation error, Yatracos proposed the use of the Hoeffding‘s inequality [6]. 
 Note that for any fixed  , as n tends to infinity one can make the estimation error component in (9) arbitrarily small. The beauty of Theorem 3 is that (8) is distributionfree (in particular valid for any µ ? F) and, furthermore, given its finite-length nature (non-asymptotic), it is valid even if the approximation fidelity  (attributed to  ) is chosen as a function of the amount of data n [6]. Consequently, for any sequence   of non-increasing positive numbers, 
 for all n = 1. Here we can consider the sequence   that offers a balance between the estimation and the approximation error expressions, and by doing so, get a consistent estimate of µ in the sense of (3). A simpler idea was stated by Devroye and Lugosi [6, Chp. 7] . If the class F is totally bounded, we can consider the sequence  , which is well defined and clearly convergences to zero as	n	tends	to	infinity.	Consequently,	it	satisfies	that n	o 
 To conclude, for any skeleton learning rule in (6), let us characterize its encoder-decoder pair   by, 
 for any sequence   and for any  , where µˆn is the empirical distribution induced from the argument xn. Then the learning scheme  satisfies the uniform consistency re- 
 , which by construction is O(1/ n). Consequently the skeleton estimate offers a zero-rate lossless learning scheme for the family F, which concludes the achievability part. 
 Associated with the learning rule of length n, we have its reproduction codebook that we denote by Tn = 
 This means that   for all µ ? F. Rephrasing,  there exists  , such that for any arbitrary , where by construction |Tn¯| < 8. Then F is totally bounded, completing the proof of Theorem 1. 
 In this section we explore density collections with extra regularities (on top of the needed totally bounded assumption) 
 to achieve the critical O(p1/n) asymptotic rate of convergence in total variation2. On this, we follow the ideas proposed by Yatracos [2] who, in the context of the minimum distance estimate [6, Ch. 8], explored families of distributions with finite Vapnik and Chervonenkis (VC) dimension, also called VC classes [10], [11]. 
 The following results focus exclusively on the skeleton based learning scheme presented in Section III-A for the achievability part of Theorem 1, i.e.,  ˆ   indexed by a sequence of nonnegative precision numbers  . 
 Definition 5: (Yatracos [2]) Let F = {µ? : ? ? T} ? AC(X) be an indexed collection of densities. The Yatracos class for such collection is given by, 
 Definition 7 in Appendix VI-A) iii) and the Kolmogorov’s complexity of F associated with 
 Proof of Theorem 4: We consider the definitions and notations introduced in Section III-A. Let us first focus on the convergence rate of the skeleton estimate. First, from Theorem 
 with  the Yatracos class of the Skeleton  . It is clear that . Then by monotonocity 
 for all  and for any distribution µ ? P(X). Here is where we use the assumption that AT has finite VC dimension V , which implies (see the details in Theorems 3.2 and 4.3 in [6]) that 
 we can achieve the same rate O(1/ n) for the approximation error in (7) if condition iii) is satisfied. 
 Remark 1: From Definition 4,   is inversely proportional to . In fact, depending of how rich is  can go from being , passing from being polynomial in 1/, to being   (see a number of examples in [6, 
 Chp. 7] and references therein). In fact iii) provides a bound on how fast N should tend to infinity as  goes to zero, to guarantee zero-rate in the learning scheme. It is simple to show that N being   with q ? [0,2) is sufficient to get log2(N1/vn ) being o(n). This is a condition satisfied by a large collection of totally bounded classes in P(X) (see [6]). 
 The results presented so far are of theoretical interest, because they relay on the Skeleton partition of F, which is typically unknown. Moving on the direction to make the Skeleton learning scheme of practical interest, we revisit the scenario studied in [5], in which F = {µ? : ? ? T} ? AC(X) is indexed by T, with T being a compact set leaving in a finite dimension Euclidean space Rk, or what people in learning theory call parametric families3. Interestingly, in this context we can achieve optimal learning rates adopting a practical L1covering of F, induced by a uniform partition of T. Let us first start with some preliminaries. 
 Definition 6: (Raginsky [5]) Let F = {µ? : ? ? T} with T ? Rk. Let IF : T ? F be the index function of F, that maps ? ? T to µ? ? P(X). IF(·) is said to be locally uniformly Lipschitz, if there exists r > 0 and m > 0, such ?? ? T, ?f ? Br(?), 
 ,where Br(?) ? T denotes the ball of radius r (with respect to the Euclidean norm in Rk) centered at ?. 
 for some constant c > 0. Substituting this result in (15),	Under the assumptions of Proposition 1, let 
 The argument concludes by replacing, a of T that induces a sub-optimal -covering of F, denoted solution which achieves the intended rate of convergence by(see details of this construction in Appendix VI-C). in (14). Finally by construction, the rate of the learning rule Then by definition, 
 dlog2(N1/vn)e of length-n is	n	, which tends to zero by iii).this last part from Corollary 1. With this, let 
 Interpreting this result, by imposing extra combinatorialdenote our practical learning scheme regularity assumptions on F (conditions ii) and iii)), we 
 ) and the mapping IF : T ? F is locally uniformly Lipschitz, then F is totally bounded. 
 can achieve the optimal rate of convergence to estimate µ uniformly in F. More precisely, by imposing that the Yatracosv 
 class is a VC class, we can achieve O(1/ n) rate of convergence for the estimation error in (7) and, on the other hand, in a position to integrate the results presented in Section IV 
 3This parametric case is the setting considered by Raginsky [5] for the problem of fixed-rate lossy source coding and modeling. 
 (Theorem 4, Proposition 1, Corollary 1 and Remark 1) to state the following implication. 
 THEOREM 5: Under the assumptions of Proposition 1, let us in addition assume that the Yatracos collection AT = 
 Proof: Let be the -covering induced from the uniform partition of T presented in Appendix VI-C. From this we can construct the minimum-distance estimate in (6) adopting the Yatracos class of  (with index set T˜), i.e.,  from (5): 
 Using the same arguments presented in the proof of Theorem 4, we can obtain an equivalent version of (17), i.e., ?, 
 (from Corollary 1). To conclude note that the same result extends to the Skeleton estimate of Section III-A as. 
 The behavior of the distortion overhead of ?((1˜ / n)n=1) in (19), has a faster asymptotic rate than its counterpart obtained by Raginsky [5] (O(plogn/n)), under the same parametric setting and with the same bits-per-sample overheadv of O(logn/n). In addition, ?((1˜ / n)n=1) offers an implementable scheme, as its minimum distance decision is carried out on a finite number of candidates. 
 Let C ? B(X) be a collection of measurable events, and   be a sequence of n points in Xn. 
 Then we define by   the number of different sets in {{x1,x2,..,xn} n B : B ? C}, and the shatter coefficient of 
 C by   is an indicator of the richness of C to dichotomize a finite sequence of points in the space, where by definition Sn(C) = 2n. 
 Definition 7: The largest integer n where Sn(C) is strictly less than 2n is called the Vapnik and Chervonenkis (VC) dimension of C [12]. If Sn(C) = 2n for all n, then the class is said to have infinite VC-dimension. 
 First note that T is contained in a compact set Nk [-L,L] ? Rk, then, , there exists a finite coveri=1 
 ing	such that   . On the other hand, from the locally uniformly Lipschitz assumption on IF : T ? F, there exists r > 0 and m > 0 such that V (µ?,µf) = m||? - f||, ?? ? T, ?f ? Br(?). Then let us consider , then by construction 
 where BdV (µ) = {v ? P(X) : V (v,µ) < d} is the ball induced from the total variational distances, and the last inequality is from the Lipschitz condition. Hence from (22),  there 
 Let (m,r) be the uniform parameters that characterize the Lipschitz condition of IF(·) (Definition 6). Without loss of generality, let us assume the critical regime where  , hence from (22) N is upper bounded by , which is the covering number of T (see Appendix VI-B). As T ? 
 , we will work with a uniform partition of   to find a bound for . Let . Then inducing a product-type partition, where in each coordinate we have   uniform-length cells, we have the required ¯covering. The number of prototypes is , which as a function of . 
 The work of J. Silva is supported by funding from Fondecyt Grant 1110145, Conicyt-Chile.. The work of M. S. Derpich is supported by funding from post-doc Fondecyt project nr. 3100109, and the Conicyt Anillos project ACT-53. 
 ﻿Abstract— We prove achievability of the recently characterized quadratic Gaussian rate-distortion function (RDF) subject to the constraint that the distortion is uncorrelated to the source. This result is based on shaped dithered lattice quantization in the limit as the lattice dimension tends to infinity and holds for all positive distortions. It turns out that this uncorrelated distortion RDF can be realized causally. This feature, which stands in contrast to Shannon’s RDF, is illustrated by causal transform coding. Moreover, we prove that by using feedback noise shaping the uncorrelated distortion RDF can be achieved causally and with memoryless entropy coding. Whilst achievability relies upon infinite dimensional quantizers, we prove that the rate loss incurred in the finite dimensional case can be upper-bounded by the space filling loss of the quantizer and, thus, is at most 0.254 bit/dimension.
 I. INTRODUCTION
 Shannon’s rate-distortion function R(D) for a stationary zero-mean Gaussian source X with memory and under the MSE fidelity criterion can be written in a parametric form (the reverse water-filling solution) [1]
 (1a)(1b)where SX(?) denotes the power spectral density (PSD) of X and the distortion PSD SZ(?) is given bySZ(?) =?,	if SX(?) > ?	(1c)
 	SX(?),	otherwise. The water level ? is chosen such that the distortion constraint (1b) is satisfied.
 It is well known that in order to achieve Shannon’s RDF in the quadratic Gaussian case, the distortion must be independent of the output. This clearly implies that the distortion must be correlated to the source.
 Interestingly, many well known source coding schemes actually lead, by construction, to source-uncorrelated distortions. In particular, this is the case when the source coder satisfies the following two conditions: a) The linear processing stages (if any) achieve perfect reconstruction (PR) in the absence of quantization; b) the quantization error is uncorrelated to the source. The first condition is typically satisfied by PR filterbanks [2], transform coders [3] and feedback quantizers [4]. The second condition is met when subtractive (and often when non-subtractive) dither quantizers are employed [5]. Thus, any PR scheme using, for example, subtractively dithered quantization, leads to source-uncorrelated distortions.
 An important fundamental question, which was raised by the authors in a recent paper [6], is: “What is the impact on Shannon’s rate-distortion function, when we further impose the constraint that the end-to-end distortion must be uncorrelated to the input?”
 In [6], we formalized the notion of R?(D), which is the quadratic rate-distortion function subject to the constraint that the distortion is uncorrelated to the input. For a Gaussian source X ? RN, we defined R?(D) as [6]
 	R?(D) ,	min T	N1 I(X;Y ),	(2)
 Y :E[X(Y-X) ]=0,
 1
 N1 tr(KY-X)=D,N1 |KY-X|N >0 where the notation KX denotes the covariance matrix of X and |·| refers to the determinant. For zero mean Gaussian stationary sources, we showed in [6] that the above minimum (in the limit when N ? 8) satisfies the following equations:
 is the PSD of the optimal distortion, which needs to be Gaussian. Notice that here the parameter a (akin to ? in (1)) does not represent a “water level”. Indeed, unless X is white, the PSD of the optimal distortion for R?(D) is not white, for all D > 0. 1
 In the present paper we prove achievability of R?(D) by constructing coding schemes based on dithered lattice quantization, which, in the limit as the quantizer dimension approaches infinity, are able to achieve R?(D) for any positive D. We also show that R?(D) can be realized causally, i.e., that for all Gaussian sources and for all positive distortions one can build forward test channels that realize R?(D) without using non-causal filters. This is contrary to the case of Shannon’s rate distortion function R(D), where at least one of the filters
 1Other similarities and differences between R?(D) and Shannon’s R(D) are discussed in [6].
 of the forward test channel that realizes R(D) needs to be non-causal [1]. To further illustrate the causality of R?(D), we present a causal transform coding architecture that realizes it. We also show that the use of feedback noise-shaping allows one to achieve R?(D) with memoryless entropy coding. This parallels a recent result by Zamir, Kochman and Erez for R(D) [7]. We conclude the paper by showing that, in all the discussed architectures, the rate-loss (with respect to R?(D)) when using a finite-dimensional quantizer can be upper bounded by the space-filling loss of the quantizer. Thus, for any Gaussian source with memory, by using noiseshaping and scalar dithered quantization, the scalar entropy (conditioned to the dither) of the quantized output exceeds R?(D) by at most 0.254 bit/dimension.
 II. BACKGROUND ON DITHERED LATTICE QUANTIZATION
 A randomized lattice quantizer is a lattice quantizer with subtractive dither ?, followed by entropy encoding. The dither ? ~ U(V0) is uniformly distributed over a Voronoi cell V0 of the lattice quantizer.Due to the dither, the quantization error is truly independent of the input. Furthermore, it was shown in [8] that the coding rate of the quantizer, i.e.
 	RQN , N1 H(QN(X + ?)|?)	(4)
 can be written as the mutual information between the input and the output of an additive noise channel Y ' = X+E', where E' denotes the channel’s additive noise and is distributed as -?. More precisely, RQN = N1 I(X;Y ') = N1 I(X;X + E') and the quadratic distortion per dimension is given by N1 EkY ' - Xk2 = N1 EkE'k2.
 It has furthermore been shown that when ? is white there exists a sequence of lattice quantizers {QN} where the quantization error (and therefore also the dither) tends to be approximately Gaussian distributed (in the divergence sense) for large N. Specifically, let E' have a probability distribution (PDF) fE', and let be Gaussian distributed with the same mean and covariance as E'. Then limN?8 N1 D(fE'(e)kfEG' (e)) =
 0 with a convergence rate of log(NN) if the sequence {QN} is chosen appropriately [9].
 In the next section we will be interested in the case where the dither is not necessarily white. By shaping the Voronoi cells of a lattice quantizer whose dither ? is white, we also shape ?, obtaining a colored dither ?'. This situation was considered in detail in [9] from where we obtain the following lemma (which was proven in [9] but not put into a lemma).
 Lemma 1: Let E ~ U(V0) be white, i.e. E is uniformly distributed over the Voronoi cell V0 of the lattice quantizer
 QN and KE = oI. Furthermore, let , where
 denotes the shaped Voronoi cell and M is some invertible linear transformation. Denote the covariance of E' by KE' = MMTo. Similarly, let EG ~ N(0,KEG) having covariance matrix KEG = KE and let
 EG' ~ N(0,KEG' ) where KEG' = KE'. Then there exists a
 sequence of shaped lattice quantizers such that
 	N1 D(fE'(e)kfEG' (e)) = O(log(N)/N).	(5)
 Proof: The divergence is invariant to invertible transformations since h(E') = h(E) + log2(|M|).
 Thus, D(fE'(e)kfEG' (e)) = D(fME(e)kfMEG(e)) = D(fE(e)kfEG(e)) for any N. 
 III. ACHIEVABILITY OF R?(D)
 The simplest forward channel that realizes R?(D) is shown in Fig. 1. According to (3), all that is needed for the mutual information per dimension between X and Y to equal R?(D) is that Z be Gaussian with PSD equal to the right hand side (RHS) of (3b).
 Z
 X  Y
 Fig. 1: Forward test channel
 In view of the asymptotic properties of randomized lattice quantizers discussed in Section II, the achievability of R?(D) can be shown by replacing the test channel of Fig.1 by an adequately shaped N-dimensional randomized lattice quantizer  and then letting N ? 8. In order to establish this result,
 the following lemma is needed.
 Lemma 2: Let X, X', Z and Z' be mutually independent random vectors. Let X' and Z' be arbitrarily distributed, and let X and Z be Gaussian having the same mean and covariance as X' and Z', respectively. Then
 	I(X';X' + Z') = I(X;X + Z) + D(Z'kZ).	(6)
 Proof:
 I(X';X' + Z') = h(X' + Z') - h(Z')
 (=a) h(X + Z) - h(Z) + D(Z'kZ) - D(X' + Z'kX + Z)
 = I(X;X + Z) + D(Z'kZ),
 where (a) stems from the well known result D(X'kX) =
 h(X) - h(X'), see, e.g., [10, p. 254].	
 We can now prove the achievability of R?(D).
 Theorem 1: For a source X being an infinite length Gaussian random vector with zero mean, R?(D) is achievable.
 Proof: Let X(N) be the sub-vector containing the first N elements of X. For a fixed distortion D = tr(KZ(N))/N, the average mutual information per dimension N1 I(X(N);X(N)+ Z(N)) is minimized when X(N) and Z(N) are jointly Gaussian and
 	K,	(7)
 see [6]. Let the N-dimensional shaped randomized lattice quantizer Q'N be such that the dither is distributed as , with KE'(N) = KZ(N). It follows that the coding rate of the quantizer is given by RQN =
 N1 I(X(N);X(N) + E'(N)). The rate loss due to using QN to quantize X(N) is given by
 RQN(D) - R?(D) = N1 hI(X(N);X(N) + E'(N))
 - I(X(N);X(N) + E'(N)G)i
 (a)
 	= N1 D(fE'(N)(e)kfEG' (N)(e)),	(8)
 where fEG' (N) is the PDF of the Gaussian random vector EG' (N), independent of E'(N) and X(N), and having the same first and second order statistics as E'(N). In (8), inequality (a) follows directly from Lemma 2, since the use of subtractive dither yields the error E'(N) independent of X(N).
 To complete the proof, we invoke Lemma 1, which guarantees that the RHS of (8) vanishes as N ? 8. 
 Remark 1: 1) For zero mean stationary Gaussian random sources, R?(D) is achieved by taking X in Theorem 1 to be the complete input process. For this case, as shown in [6], the Fourier transform of the autocorrelation function of Z(N) tends to the RHS of (3b).
 For vector processes, the achievability of R?(D) follows by building X in Theorem 1 from the concatenation of infinitely many consecutive vectors.
 Note that if one has an infinite number of parallel scalar random processes, R?(D) can be achieved causally by forming X in Theorem 1 from the k-th sample of each of the processes and using entropy coding after Q.
 The fact that R?(D) can be realized causally is further illustrated in the following section.
 IV. REALIZATION OF R?(D) BY CAUSAL TRANSFORM CODING
 We will next show that for a Gaussian random vector X ? RN with positive definite covariance matrix KX, R?(D) can be realized by causal transform coding [11], [12]. A typical transform coding architecture is shown in Fig. 2. In this figure, T is an N×N matrix, and W is a Gaussian vector, independent of X, with covariance matrix KW = sW  I. The system clearly satisfies the perfect reconstruction condition Y = X + T-1W. The reconstruction error is the Gaussian random vector Z , Y - X, and the MSE is D = N1 tr{KZ},
 Fig. 2: Transform coder.
 By restricting T to be lower triangular, the transform coder in Fig. 2 becomes causal, in the sense that ?k ? {1,..,N}, the k-th elements of U and Uˆ can be determined using just the first k elements of X and the k-th element of W.
 To have N1 I(X;Y ) = R?(D), it is necessary and sufficient that
 	T-1T-T = KZ?/sW2 ,	(9)
 where the covariance matrix of the optimal distortion is [6]
 	K.	(10)
 Since T-1 is lower triangular, (9) is the Cholesky decomposition of KZ?/sW2 , which always exists.2 Thus, R?(D) can be realized by causal transform coding.
 In practice, transform coders are implemented by replacing the (vector) AWGN channel Uˆ = V + W by a quantizer
 (or several quantizers) followed by entropy coding. The latter process is simplified if the quantized outputs are independent. When using quantizers with subtractive dither, this can be shown to be equivalent to having 
 N1 I(U;Uˆ) in the transform coder when using the AWGN channel. Notice that, since T in (9) is invertible, the mutual information per dimension is also equal to R?(D). By the chain rule of mutual information we have
 
 with equality iff the elements of Uˆ are mutually independent. If Uˆ is Gaussian, this is equivalent to KUˆ being diagonal. Clearly, this cannot be obtained with the architecture shown in Fig. 2 using causal matrices (while at the same time satisfying (9)). However, it can be achieved by using error feedback, as we show next.
 Consider the scheme shown in Fig. 3, where A ? RN×N is lower triangular and F ? RN×N is strictly lower triangular. Again, a sufficient and necessary condition to have
 
 Fig. 3: A causal transform coding scheme with error feedback.
 N1 I(X;Y ) = R?(D) is that KZ = KZ?, see (10), i.e.,
 	-	-
 	?? (I - F)(I - F)T = AKZ?AT/sW2 .	(12)
 On the other hand, equality in (11) is achieved only if
 	KUˆ = AKXAT + sW2 (I - F)(I - F)T = D,	(13)
 for some diagonal matrix D with positive elements. If we substitute the Cholesky factorization KZ? = LLT into (12), we obtain (I - F)(I - F)T = ALLTAT/sW2 , and thus
 	A = sW(I - F)L-1.	(14)
 Substituting the above into (13) we obtain
 	D = sW2 (I - F)hL-1KXL-T + Ii(I - F)T	(15)
 Thus, there exist  A and F satisfying (12) and (13). Substitution of (14) into (15) yields D = A(KX + KZ?)AT, and log|D| = 2log|A| + log|Kx + KZ?|. From (12) and the fact that |I - F| = 1 it follows that |A|2 = sW2 /|KZ?|, and therefore 
 (16)
 thus achieving equality in (11).
 We have seen that the use of error feedback allows one to make the average scalar mutual information between the input and output of each AWGN channel in the transform domain equal to R?(D). In the following section we show how this result can be extended to stationary Gaussian processes.
 V. ACHIEVING R?(D) BY NOISE SHAPING
 In this section we show that, for any colored stationary Gaussian stationary source and for any positive distortion, R?(D) can be realized by noise shaping, and that R?(D) is achievable using memory-less entropy coding.
 A. Realization of R?(D) by Noise-Shaping
 The fact that R?(D) can be realized by the additive colored Gaussian noise test channel of Fig. 1 suggests that R?(D) could also be achieved by an additive white Gaussian noise (AWGN) channel embedded in a noise-shaping feedback loop, see Fig. 4. In this figure, {Xk} is a Gaussian stationary process with PSD Sx(ej?). The filters A(z) and F(z) are LTI. The AWGN channel is situated between V and Uˆ, where white Gaussian noise {Wk}, independent of {Xk}, is added. The reconstructed signal Y is obtained by passing Uˆ through the filter A(z)-1, yielding the reconstruction error Zk = Yk-Xk.
 
 Fig. 4: Test channel built by embedding the AWGN channel Uˆk = Vk + Wk in a noise feedback loop.
 The following theorem states that, for this scheme, the scalar mutual information across the AWGN channel can actually equal R?(D = sZ2 ).
 Theorem 2: Consider the scheme in Fig. 4. Let {Xk}, {Wk} be independent stationary Gaussian random processes. Suppose that the differential entropy rate of {Xk} is bounded, and that {Wk} is white. Then, for every D > 0, there exist causal and stable filters A(z), A(z)-1 and F(z) such that
 	I(Vk;Uˆk) = R?(D), where D , sZ2 .	(17)
 Proof: Consider all possible choices of the filters A(z) and F(z) such that the obtained sequence {Uˆk} is white, i.e., such that. From Fig. 4, this is
 achieved iff the filters A(z) and F(z) satisfy
 		.	(18)
 On the other hand, since is Gaussian, a necessary and sufficient condition in order to achieve is that
 ,
 This holds iff
 Substituting the latter and (21) into (18), and after some algebra, we obtain
 
 are bounded and positive for all ? ? [-p,p], and that a bounded differential entropy rate of {Xk} implies that
 . From the Paley-Wiener criterion [15] (see also, e.g., [16]), this implies that (1 - F(z)), A(z) and A(z)-1 can be chosen to be stable and causal. Furthermore, recall that for any fixed D > 0, the corresponding value of a is unique (see [6]), and thus fixed. Since the variance sW2 is also fixed, it follows that each frequency response magnitude  that satisfies (22a) can be associated to a unique value of . Since F(z) is strictly causal and stable, the minimum value of the variance  is achieved when
 1	p d? = 0,	(23)
 2
 i.e., if 1 - F(z) has no zeros outside the unit circle (equivalently, if 1 - F(z) is minimum phase), see, e.g., [17]. If we choose in (22a) a filter F(z) that satisfies (23), and then we take the logarithm and integrate both sides of (22a), we obtain
 
 21log ss2U2ˆ ! = 21p Zplog"pSX(ej?)+vaa- pSX(ej?) #d?
 W
 -p p
 = 1 Z log"pSX(ej?)+va + pSX(ej?) #d? = R?(D).
 	2p	a
 -p
 where (3a) has been used. We then have that
 
 where (a) follows from the Gaussianity of Wk and Uˆk, and (b) from the fact that Wk is independent of Vk (since F is strictly causal). This completes the proof. Alternatively,
 (a)
 R?(D) = I¯({Xk};{Yk})
 = h¯(A-1{Uˆk}) - h¯({Xk} + A-1(1 - F){Wk}|{Xk})
 = h¯(A-1{Uˆk}) - h¯(A-1(1 - F){Wk})
 (=b) h¯({Uˆk}) - ¯h((1 - F){Wk})
 	(c)	(d)
 = h(Uˆk|Uk-) - h(Wk) = h(Uˆk) - h(Wk)
 (=e) h(Uˆk) - h(VK + Wk|Vk) = I(Vk;Uˆk),
 In (a), equality is achieved iff the right hand side of (19) equals (22a), i.e., if Z has the optimal PSD. Equality (b) holds because  8, which follows from (22b). The fact that is stationary has been used in (c), wherein equality is achieved iff |1 - F| is minimum phase, i.e., if (23) holds. Equality in (d) holds if an only if the elements of {Uˆk} are independent, which, from the Gaussianity of {Uˆk}, is equivalent to (18). Finally, (e) stems from the fact that Wk is independent of Vk. Notice that the key to the proof of Theorem 2 relies on knowing a priori the PSD of the end to end distortion required to realize R?(D). Indeed, one could also use this fact to realize R?(D) by embedding the AWGN in a DPCM feedback loop, and then following a reasoning similar to that in [7].
 B. Achieving R?(D) Through Feedback Quantization
 In order to achieve R?(D) by using a quantizer instead of an AWGN channel, one would require the quantization errors to be Gaussian. This cannot be achieved with scalar quantizers. However, as we have seen in II, dithered lattice quantizers are able to yield quantization errors approximately Gaussian as the lattice dimension tends to infinity. The sequential (causal) nature of the feedback architecture does not immediately allow for the possibility of using vector quantizers. However, if several sources are to be processed simultaneously, we can overcome this difficulty by using an idea suggested in [7] where the sources are processed in parallel by separate feedback quantizers. The feedback quantizers are operating independently of each other except that their scalar quantizers are replaced by a single vector quantizer. If the number of parallel sources is large, then the vector quantizer guarantees that the marginal distributions of the individual components of the quantized vectors becomes approximately Gaussian distributed. Thus, due to the dithering within the vector quantizer, each feedback quantizer observes a sequence of i.i.d. Gaussian quantization noises. Furthermore, the effective coding rate (per source) is that of a high dimensional entropy constrained dithered quantizer (per dimension).
 The fact that the scalar mutual information between Vk and Uˆk equals the mutual information rate between {VK} and {Uˆk} in each of the parallel coders implies that R?(D) can be achieved by using a memoryless entropy coder.
 VI. RATE LOSS WITH DITHERED FEEDBACK QUANTIZATION
 The results presented in sections IV and V suggest that if a test channel embedding an AWGN channel realizes R?(D), then a source coder obtained by replacing the AWGN channel by a dithered, finite dimensional lattice quantizer, would exhibit a rate close to R?(D).
 The next theorem, whose proof follows the line of the results given in [7, sec. VII], provides an upper bound on the rate-loss incurred in this case.
 Theorem 3: Consider a source coder with a finite dimensional subtractively dithered lattice quantizer Q. If when replacing the quantizer by an AWGN channel the scalar mutual information across the channel equals R?(D), then the scalar entropy of the quantized output exceeds R?(D) by at most 0.254 bit/dimension.
 Proof: Let W be the noise of the AWGN channel, and V and Uˆ denote the channel input and output signals. From the conditions of the theorem, we have that
 	I(Vk;Uˆk) = R?(D).	(24)
 If we now replace the AWGN by a dithered quantizer with subtractive dither ?, such that the quantization noise W' is obtained with the same first and second order statistics as W, then the end to end MSE remains the same. The corresponding signals in the quantized case, namely V ' and Uˆ', will also have the same second order statistics as their Gaussian counterparts V and Uˆ. Thus, by using Lemma 2 we obtain
 	I(Vk';Uˆk') = R?(D) + D(Uˆk'kUˆk).	(25)
 Finally, from [8, Theorem 1], we have that H(Q(Vk + ?k)|?k) = I(Vk';Uˆk'). Substitution of (25) into this last equation yields the result.	
 VII. CONCLUSIONS
 We have proved the achievability of R?(D) by using lattice quantization with subtractive dither. We have shown that R?(D) can be realized causally, and that the use of feedback allows one to achieve R?(D) by using memoryless entropy coding. We also showed that the scalar entropy of the quantized output when using optimal finite-dimensional dithered lattice quantization exceeds R?(D) by at most 0.254 bits/dimension.
 .
 ﻿ This paper novel on scalar feedback quantization with uniform . We focus on general where reconstruction is via a linear combination of frame . a deterministic approach , we derive two necessary and sufficient for to be optimal , i . e ., to produce , for every input , a sequence that is a global minimizer of the norm of the reconstruction error . The first condition is related to the design of the feedback , and can always be . The second condition only on the reconstruction , and is given explicitly in of the Gram matrix of the reconstruction frame . As a by product , we also show that the the first condition alone scalar feedback that yield the , when one quantization noise as uncorrelated , identically distributed random . 
 In many signal , have to be by a series of , so that they can be , or in digital form . This paradigm sampling , quantization and reconstruction . 
 The quantization of the , namely the sequence ,, a sequence whose are constrained to belong to a discrete set of . We focus our attention on uniform quantization , and thus require that 
 The and most common paradigm to recover the signal from the is linear reconstruction . Here , one is able to recover the original signal , say a , via 
 In , is a set of a frame in the reconstruction space typically a subspace of or of L . Thus , the are the frame expansion of a . of linear reconstruction are the reconstruction formula , the reconstruction stage in filter , and the inverse wavelet transform . 
 Throughout this work , we will be concerned with the squared norm of the reconstruction error , i . e ., 
 for every . Unfortunately , minimization of subject to is a non convex optimization problem . Moreover , the complexity of this problem exponentially with the number of to be . In addition , unless an orthogonal set , one would need to preview the entire input sequence before being able to calculate any optimal value for . This is incompatible with delay sensitive . 
 For the above , in practice quantization is often accomplished via simpler sub optimal that operate sequentially . The of these correspond to scalar feedback . At the i th iteration , these A obtain the output sample by simple scalar quantization of an auxiliary sequence , which is a linear combination of input and output , i . e ., 
 In , the real ai ,, i , , ,..., are design , and is the nearest scalar quantization function 
 The above can be used to describe many scalar quantization and bit Sigma Delta . The latter have been well studied in the context of shift invariant reconstruction wherein reconstruction is done by , and recently also for frame see , e .., , . 
 Not surprisingly , for a given reconstruction frame , and in return for the above , optimal vector quantization generally . However , it is not known under what this performance gap . In this paper we derive those . More precisely , we state necessary and sufficient for to be optimal , i . e ., to yield , for any input , the output sequence that , in . Our extend the work in , to more general . 
 Notation We use bold , e .., to denote both the sequence and the column vector x , where the meaning is clear from the context . We also use bold to represent matrices and their corresponding column . For example , a matrix , we use to refer to the i th column of , and , to refer to the th element of . The null space and the pseudo inverse of a respectively via and †. The notation to the sub matrix by removing the first i and i from . Similarly , the its first . The symbol N an length column vector of . We use the short hand the quadratic form . We write as an abbreviation for if and only if . to the , and we use to denote the set of all length with integer . We say a matrix or vector is integral all its are . 
 Here we will first present some regarding that will be used in our subsequent analysis . 
 A finite frame for a an ordered set of such that , for every , 
 where the set of square summable . The Gram matrix of the frame is defined element wise via 
 It is easy to show from that an cannot yield for all unless ai , di ,, i ,, where di , is the delta function . If the latter , then can be written as : 
 where v , , is the feedback matrix the vector of quantization . In order for the above to be well defined , needs to be lower strictly triangular , i . e ., lower triangular with all main diagonal equal to zero . Notice also the only degree of freedom in the design of an . 
 In order to determine , u for , it is convenient to define the noise shaping matrix 
 where IN matrix . Clearly , is constrained to be lower unit triangular , i . e ., lower triangular with all its main diagonal equal to . 
 Substituting into u . this , and substituting and into , the distortion by can be written as 
 G , the distortion , u of an for all the following two hold : 
 Notice that i a matching condition between the feedback matrix and the reconstruction frame . Thus , i can always be satisfied by a proper choice of which is given explicitly by . On the other hand , condition only on the reconstruction frame , or more precisely , on its Gram matrix . 
 The proof of Theorem will be given in Section , based on preliminary given in and . The latter provide valuable insight into the problem , and stem from two alternative : lattice quantization and dynamic . 
 In this section we use the fact that minimization of subject to is equivalent to a lattice quantization problem . To show this , we first note that any symmetric positive semidefinite matrix can be decomposed as 
 where is lower triangular see ., e .., . It then directly from and that 
 . Thus , one can analyze the relationship between the of any group of by looking at their in through . In particular , 
 Since the quantization alphabet U is uniform see , the all the UN constitute the reconstruction lattice 
 Accordingly , we say that is the generating matrix for . Every lattice a basic cell , V , associated with it , i . e ., the region of closer to the origin than to any other point in the lattice . More precisely , 
 . Similarly , we define the quantization cell around of an converter as 
 where the hyper cube : , , is the set all possible quantization noise . Thus , is the set of all target for which an the sequence . 
 With the above , we can now prove the necessity of condition i of Theorem . 
 Lemma For a reconstruction frame with gram matrix , the distortion , u of an can equal for all only if condition i in Theorem . 
 is that it the minimum second moment among all the whose form a tessellation , see . Thus , an is a candidate to be optimal only if its second moment N . This second moment can be readily shown to be given by trace I I 
 f , lower triangular lower strictly triangular . The fact that each trace term only on its corresponding column the trace is each i i i . 
 where i is an arbitrary vector in Hi and , thus , in as well . Substitution of the identity A † † AT into , thus the proof . 
 Remark If a vector of uncorrelated , uniformly distributed u . u ., random , one trace trace I I . On the other hand , an whose feedback matrix to characterize one of the noise shaping for frame in . More precisely , condition i is satisfied by the variant in which the error associated with each coefficient is onto all the ahead of the current iteration coefficient . Thus , Lemma also that , an u . u . model for quantization , the latter scheme the minimum among all . 
 Sequential quantization , such as , decide upon the value of each output coefficient sequentially . Insight can be by them from a dynamic point of view . The key point is that each of the additively to the cost defined in , leaving , after each step , a sub problem similar in form to the original one . In turn , each of these sub is determined by the already made . The following result us to formalize these 
 Proof The result from direct algebraic manipulation , the identity A † AA † A † and from the fact that † , i ,..., which positive semidefinite . 
 Recursive application of Lemma to one to split the total cost , as : 
 The summation on the right hand side of the irreducible reconstruction error stemming from the first i . The cost to go after decision i is the last term in . It the same form as the original cost , but it the target vector . The latter can be as a state vector which the effect of , and of previous , on the go . 
 Joint Sufficiency of i and It is well known in lattice theory that any two L and L , with M and 
 M non singular , are equal there an integral such that M see , e .., . On the other hand , if i and hold , then there a lower matrix such that is integral . lower unit triangular , we have that , and thus . It then that . On the other hand , if condition i , then it directly from that the product an orthogonal , lower triangular matrix . This in turn a rectangular lattice . Moreover , it is easy to verify that the associated cell V is given by the hyper rectangle , which is precisely the quantization cell of the , N see . Therefore i and guarantee that the corresponding is optimal . 
 Necessity of i and The necessity of i was shown in Lemma . Thus , it to prove the necessity of assuming that i . If i , then the target given in can be written in of the feedback 
 Now let us consider a that the target vector , at iteration i , 
 for some UN i and some e ,. With the above target , an would choose ti , i , and thus . Then , from , the cost to go for the after i can be split as 
 the minimum difference between the cost to go achievable by and that of the choice is 
 that . As a consequence , the first term on the right hand side of is strictly positive . It then that , u is strictly than , for sufficiently small of e , the proof . 
 Lattice Quantization Interpretation It been shown in the proof of Theorem that is a sufficient condition be rectangular and have a hyper rectangular cell . It is important to note that this can happen for a non diagonal reconstruction Gram matrix , i . e ., reconstruction that are non orthogonal , and even linearly dependent , not to be non singular . It is also important to note that the converse does not necessarily hold , that is , a not ensure that condition is satisfied . More precisely , the fact that a lattice is rectangular the existence of an integral such that is orthogonal . It be also lower unit triangular , as by . On the other hand , i alone is orthogonal , and thus N is . For a uniformly distributed , the gap between such an and a lattice vector is given by the difference between the second of N and V . Although no closed from are known for the second moment of V of arbitrary , preliminary suggest that it is possible to derive lower for this gap from the non integer part of the mi defined in b . 
 Reconstruction by a Single Filter By and considering the distortion per sample , as the cost function , our can be applied to where reconstruction is a discrete time filter , say . Without loss of generality , we assume that . In this case , the reconstruction frame take the form , where is the impulse response of . This setup infinite dimensional matrices , the first column . In turn , f can be seen as the impulse response of a filter . It then that the orthogonality of the of stemming from i is equivalent to . This to a whitening , which minimum , in the alternative white quantization noise paradigm . Similarly , an satisfying i also the , see Remark . On the other hand , for this case , all the mi see b are equal to the impulse response first sample removed of . Thus , into the impulse response of being integer valued . Hence , the standard th order bit converter is optimal for . This the in , for U , . 
 We derived necessary and sufficient that make scalar feedback quantization optimal , in the sense of generating , for any input , the sequence that the norm of the reconstruction error . The first condition , which only on the design of the scalar feedback , to characterize the best of this class , when a stochastic framework is adopted . The second condition only on the Gram matrix of the reconstruction frame , and can be satisfied for non orthogonal , and even linearly dependent , reconstruction . 
  
 ﻿ This paper with the design of feedback to encode plant output in control with data rate constrained . Starting form a nominal design made under the assumption of transparent communication links , we show how to design a feedback so as to systematically reduce the impact of quantization on closed loop performance . To obtain our , we model quantization as additive white noise with a signal to noise ratio constraint . As a , we obtain a simple characterization of the minimal noise ratio that one to design a feedback that stability . This bound only upon the plant and controller unstable . If the plant is strongly , then the bound is consistent with the absolute minimal data rate for stabilization in previous work . 
 Introduction 
 Standard control theory with where the communication links between plant and controller can be as transparent see , e .., , . There exist , however , where the links in a control system are far from being transparent and may become in the achievable performance . Control where this are collectively to as Control see , e .., , , , and the many therein . Clearly , unless the channel are explicitly taken into account at the design stage , the performance of an may be far from optimal and sometimes completely unsatisfactory . The main that need to be considered when dealing with include data rate i . e ., quantization , data loss and random . A framework for the treatment of the general design problem does not exist . Nevertheless , there been significant progress in the study of specific that focus on . For example , data rate have been studied in , , , , and design to deal with quantization have been in , e .., , . The issue of data loss been studied in , , , among many , and have been considered in , e .., , , , . 
 In this paper we focus on linear time invariant plant , and concentrate on the effects of quantization on closed loop performance . Within this framework , a key result in the minimal data rate which is necessary and sufficient to achieve stabilization of an unstable plant , to its in very simple way . This bound been linked to information theoretic where it been given an interpretation akin to that of entropy see , e .., , , . Furthermore , , established that the minimal data rate for stabilization is sometimes consistent with minimal noise ratio in standard one degree of freedom control that employ . More precisely , , that , if the plant is defined in discrete time , relative degree one and is minimum phase , then a memoryless channel a signal to noise ratio equal to the lower bound derived in , would exhibit a channel capacity equal to the data rate bound in . 
 The above give absolute lower on the admissible channel data rate which cannot be by by any control law . It , however , quite difficult to obtain practical design from such as those in , , . This some to move towards a simplified treatment of quantization . For example , quantization as a sector bound uncertainty and standard robust control . On the other hand , a simple white noise model for quantization . The latter model for quantization close to the signal literature , where it been successfully used to design high performance quantization see , e .., , , , , . 
 In the present work we assume that a controller already been designed under the assumption of transparent communication links . However , we subsequently extend the set up by assuming that the control loop to be a bit rate limited channel in the plant to controller communication link . Thus , the plant output have to be prior to transmission . To that end , we borrow from the signal literature and employ a feedback to encode the plant output see , e .., , . a fixed signal to noise ratio additive noise model for quantization , we show how to design the feedback so as to systematically reduce the impact of quantization on closed loop performance , as measured by the error variance . We show via that our approach very good even for bit as low as one bit per sample . We also study stability for this linear model . As a , we obtain a simple characterization of the minimal signal to noise ratio that one to design a feedback system that stability . This result is expressed in of the plant and controller unstable only . For stable , and regardless of the plant or relative degree , our suggest a minimal data rate for stabilization that is consistent with the bound in . 
 The idea of designing to embellish given controller is not new . For example , our previous work in a scheme that turns out to be a special case of the one considered here . On the other hand , the same architecture as the one studied in this paper , but the design procedure in that quantization effects are relatively small . The methodology used in the current paper does not require this assumption . Also , the stability analysis included in the current paper goes beyond the of , . Another related line of work been in , , . The latter work a precise deterministic stability analysis when the system is constrained to be a modulator or thereof ; see , e .., , but does not address performance . Another recent publication closely related to the current paper is . In that work , the propose a architecture similar to the one in this paper , but restrict the to have infinitely many and a quantization step . The latter are not here . Interestingly , the optimal coder in which on a time domain functional turns out to have a structure that is a special case of the architecture considered here . 
 The remainder of this paper is organized as : Section the notation employed in the paper . Section the architecture of interest and a linear model that is suitable for analysis and synthesis linear system theoretical . Section stability of the linear model , while Section the design procedure . Section a simulation study . Concluding are included in Section . 
 Notation 
 We use standard vector space notation for , i . e ., N . We also both the argument of the transform and as the forward shift operator , where the meaning is clear from the context . Given any matrix , and denote conjugate transposition and transposition , respectively . Given any complex scalar , and magnitude and complex conjugation , respectively . 
 The set of all discrete time real rational transfer is by . We define six : all proper transfer , all strictly proper transfer , all stable and proper transfer , U all matrices in that have in , all stable and strictly proper transfer , all transfer that have only outside the unit circle and are either proper or improper . For any A we define A , A . We say that A is unitary if and only if A A I . We also define A , A A . 
 Every A with no on the unit circle to L in which case we define the norm of A via see , e .., 
 , trace . 
 For each such A , we can always find and A such that A A 
 A and , accordingly , see , e .., . 
 Any transfer matrix A an inner outer factorization of the form 
 A Ai , 
 where Ai is unitary i . e ., Ai is inner and is a scalar transfer function , that no in i . e ., is scalar and outer . Moreover , if A no on the unit circle , then U see , e .., . 
 Given any wide sense stationary process , we denote its power spectral density by , its variance by and its standard deviation by . We note that if , in addition , an always positive rational spectrum , then we can always find a spectral factor U such that , ,. We also recall the well known fact that see , e .., . 
 for Control 
 In this paper , we will consider the architecture in Figure . In that figure , is the plant model , is a controller , is the plant output , is the reference signal , do 
  
 Figure : Considered control architecture . 
 output and to measurement noise . Unlike standard non see , e ., , , the feedback path in Figure a communication channel and a source system and . The main focus of the current paper in designing this system , performance in mind . To that end , we utilize as the performance assessment quantity the stationary variance of the error e , defined via 
 e ,. 
 We next describe the that underly our subsequent analysis . 
 . The nominal design 
 Since our aim is to design , we will assume that the controller in Figure been already designed assuming transparent communication links . The control loop formed by and when transparent communication links are in place i . e ., when ym in Figure will be to as the nominal loop or nominal design . 
 For future reference we note that , in the nominal loop , 
 e , 
 £ ¤ T 
 where , do , 
 £ ¤ 
 , , 
 and and are defined via 
 . 
 The transfer function is the nominal loop sensitivity function and is the nominal loop complementary sensitivity function see . 
 In the sequel , we will assume the following : 
 Assumption Plant and nominal design The plant model to , whilst the controller ,, to , is non zero and is such that the nominal loop is stable and well in the standard sense ; see , e .., , . 
 The assumption that the nominal loop is stable and well defined is , of course , sensible in our context where the system is designed a . We assume that is strictly proper for simplicity . In principle , this can be removed at the expense of additional technical care . On the other hand , the assumption of being non zero non interesting , where the nominal loop is such that is left in open loop i . e ., uncontrolled . 
 We end this section with a description of the exogenous , do and . 
 Assumption The , do and are mutually independent scalar zero mean , each a rational power spectral density that , if not identically zero , a spectral factor in U . 
 We note that Assumption is standard see , e ., . 
 . The system 
 In this paper , we will focus on error free bit rate limited . As a consequence , the input to the channel , i . e ., see Figure , must be prior to transmission . To that end , we will consider a standard feedback as in Figure also known as a noise shaping ; see , e .., , . In that figure , A , and are in that need to be designed anda uniform see , e .., , , i . e ., 
 Q , sat , 
 the dynamic range , , V the number quantization . 
 We recall that a is said to be if and only if the absolute value of its input is greater than its dynamic range , i . e ., for some N . If the does not overload , then the quantization noise , defined via 
 q ,, 
 is such that for every . 
 As already in Section . , we are interested in designing for nominal . In this setting , it is natural to employ that , in the absence of channel , have unit transfer function . That is , we will utilize that achieve perfect reconstruction . In our case , the channel is assumed to be error free and hence . As a consequence , it is straightforward to see from Figure that 
 A ym , 
  
 Figure : Considered and system . 
 It from that perfect reconstruction is tantamount to A for every . On the other hand , in order to have a properly defined feedback loop around the it is necessary to have a strictly proper see , e .., Chapter in . We summarize the previous discussion as : 
 Constraint Structural on the feedback The feedback are such that A and . 
 Quantization is a deterministic non linear operation and hence , the exact analysis of is difficult see , e .., , , , . It thus become standard , particularly in the signal literature see , e .., , , , , , , to approximate quantization noise by an additive white noise source uncorrelated with the input of the . Here , we adopt this paradigm and assume the following : 
 Assumption Quantization noise model The quantization noise signal defined in is a sequence of i . i .. random uniformly distributed in , and uncorrelated with . 
 Note that we do not assume that the quantization noise is uncorrelated with , which is certainly not the case since the quantization noise is fed back to the input of the and , moreover , the system is inside the main feedback control loop . Instead , we adopt a milder assumption that only with the exogenous in . We stress that the previous model is valid only if is small enough , the does not overload anda smooth probability density see , e .., . These usually do not hold in the case of that are in feedback see , e .., the discussion regarding stand alone feedback in . Nevertheless , one can make use of see , e .., , to render the model in Assumption exact provided no overload . Despite the above , we will see in the simulation study included in Section , that , even if one a non uniform with as few as , the made the simple model in Assumption are surprisingly accurate see also simulation in , , . 
 In order to guarantee that the does not overload , in principle one needs to consider infinite quantization or assume that the input is bounded , which is seldom the case in a stochastic framework . In practice , it is standard to choose a dynamic range such that the probability of overload is negligible see , e ., . Indeed , and is any positive real , then one can always find a finite a such that choosing that the probability of overload is less than ; a is the loading factor . With such a choice for the factor , it is immediate to see that 
 , 
 where we have used the fact that , according to Assumption This the following additional assumption : 
 Assumption Fixed signal to noise ratio For a fixed number of quantization , the variance of the quantization noise is proportional to the variance of the signal being , i . e ., the a fixed signal to noise ratio defined via 
 . 
 Assumption is a key constraint . As before , it one to guarantee that the dynamic range is always properly scaled . In addition , it a effect on the optimization based design of the system . Indeed , if this constraint were not in place i . e ., assumed to have some statistics , then it would be optimal to choose and A with . This is , of course , not a sensible choice since A and grow unbounded when . 
 Remark We would like to stress that , in some , overload may become the dominant quantization effect in feedback . Indeed , overload may trigger limit cycle that are , of course , not by the linear model for quantization above see , e .., , , . As by and , we assume in this paper that overload is infrequent enough and , accordingly , that it no significative effect on overall closed loop performance . Careful design of the loading factor may act as a safeguard against overload . 
 Considering the model for quantization above , together with the nominal loop description in Section . , it is easy to derive the linear model shown in Figure for the considered . Note that we have made the perfect reconstruction constraint explicit . In Figure , and , and , do , satisfy Assumption . We will refer to this model as the linear model . It will be the basis of the remainder of this paper . 
 Mean Square Stability 
 In this section we study stability of the linear model for the considered derived in Section . In particular , we characterize all and A that lead to stable linear in an appropriate sense for a given signal to noise ratio . As a , we characterize the minimal signal to noise ratio that one to find and A such that the resulting linear model is stable . 
 We begin by that , a dimensional vector that the of ,, A , A and see Figure , then the evolution be by a linear state space model : 
 x Ax , a 
 v , b 
  
 Figure : Linear model for considered situation . 
 where A and are matrices of appropriate that depend on the particular of ,, A , A and . Next , since we are considering a stochastic system , we need an appropriate notion of stability : 
 Definition Mean Square Stability , , The linear system in is Mean Square Stable if and only if there exist a finite and a finite , , both not dependent on the initial state , such that 
 n o 
 lim , lim E , 
 where , E . 
 The next theorem necessary and sufficient for in our case : 
 Theorem for Mean Square Stability If hold , and is an independent random variable with finite mean and finite variance matrix , then the linear model in Figure is if and only if A U , and 
 . 
 Proof : Define as the variance matrix of . Since the spectral factor of , , to , we lose no generality if we restrict attention to the case where , for every i . e ., if we assume white noise . The general case the same , but an augmented description of the system that additional stable . 
 Consider the state space description of the system under study given by . Standard allow one to conclude see , e .., Chapter in that under our working 
 AkE 
 £ ¤ £ 
 , ARx , AH 
 £ ¤ T 
 where is the variance matrix of the vector and ¤, 
 n o 
 H 
 , , E 
 Moreover , we also have that . 
  
 , 
 where and , are defined as and ,, but of . 
 • If the is , then both and are finite and unique . Therefore , that A must be stable . On the other hand , we also see from that ,, i . e ., the stationary variance of , say , must be positive semi definite , finite and unique . 
 Since the nominal loop is stable , a simple calculation that A being stable that both A and A must be stable , and moreover , that is stable . Of course , both A and A must be proper and , on the other hand , is constrained to be strictly proper recall Constraint . Therefore , it that A U and . 
 If A is stable , then it is easy to see that the stationary variance of see also Section 
 . 
 , 
 where is defined in , and where we have used the fact uncorrelated is such that . the definition of in 
 . 
 Therefore , we conclude that , provided A is stable , being positive semi definite , finite and unique is equivalent to . 
 • Since the nominal loop is stable , and A U , we have that A is stable . Therefore , it from that is finite , unique and well defined . 
 If , then the when proving the sufficiency part of this theorem imply that is positive semi definite , unique and finite . the definition of , it then that is positive semi definite , finite and unique . Therefore , is positive semi definite , unique and finite and , since A is to be stable see above , then we have that the equation that the limiting value of , in a finite , unique and positive semi definite solution see , e .., Section . in . Therefore , we have proven that is as . This the proof . 
 ¤¤¤ 
 The condition for given in Theorem is deceivingly simple . This is due to the fact that the nominal loop is assumed stable and we are on that achieve perfect reconstruction recall Section . . It is relevant to note that does not depend on A . Therefore , one can easily characterize the lower bound on that one to guarantee : 
 Theorem Minimal signal to noise ratio for If hold , and is an independent random variable with finite mean and finite variance matrix , then there exist A and that allow one to guarantee if and only if 
 , 
 where pi i ,, the set of unstable of . 
 Proof : It to compute see Theorem . To that end , we employ the in detail in , e .., , , . We first note that , . Define 
 , 
 where pi i ,, the set of non minimum phase of that lie strictly outside the unit circle i . e ., the unstable of outside the unit circle . It is clear that , is unitary , and is such that the transfer function to , is and as non minimum phase the on the unit circle of i . e ., the on the unit circle of 
 G . It thus that 
  
 Q 
 Q 
  
  
 , 
 where we have used orthogonal in L , the fact that both unitary , the fact that Assumption , and basic of the norm . By construction , and is invertible in except for on the unit circle . Elementary see , e .., Chapter in allow one to conclude from that 
 . 
 Use of the Residue Theorem and some simple algebra the desired result . ¤¤¤ 
 Theorem a precise condition that the signal to noise ratio to satisfy in order to be able to find a system that , when inserted in the feedback path of a stable nominal loop , the of the resulting linear model . The bound on only on the unstable of , i . e ., on the unstable of the plant and controller . If the plant model is strongly i . e ., can be a stable controller ; see , e .., , then a stable controller in the nominal loop one to find a feedback coder capable of the resulting linear model if and only if 
 , 
 where i ,, the set of unstable of . We note that the same conclusion if the controller is stable except for on the unit circle e .., with integral action . 
 If we fix , then must satisfy , which is a fixed constraint in our framework . If it were possible to redesign the controller under the constraint , then one can use the in to establish that the admissible signal to noise ratio must satisfy 
 , 
 where is non negative and on the non minimum phase and on the relative degree of the plant model if and only if is minimum phase and relative degree equal to one . We thus conclude that the inclusion of the system one to reduce the on the signal to noise ratio , at least for strong regardless of the plant or relative degree . This reduction may be very significative if , e .., the plant high relative degree . This is an important indication of the that to control . A question that remains open , however , is whether or not there exist different that allow one to recover for any plant . 
 Remark Relationship to prior work In it is proved that is the minimal signal to noise ratio that one to find one degree of freedom that stabilize a given plant model over an additive noise channel with a power constraint . In a second step , the show that a memoryless channel , with a signal to noise ratio that , would have a capacity Cap see , e .., that 
 , 
 where is the minimal data rate which is necessary and sufficient to stabilize an system over an error free bit rate limited channel . Equality in is if and only if the plant is minimum phase and a relative degree equal to one . These suggest that signal to noise ratio in one degree of freedom control are , for a restricted class of , consistent with the minimal data rate of . If the plant non minimum phase , or a relative degree than one , then see . It thus that , in these , data rate by signal to noise ratio may be more demanding than those in . 
 Our can be applied to the channel model in as well , provided error free feedback with a unit delay is available from the channel output to the channel input . When doing so , it turns out that is consistent in the sense above with the minimal data rate derived in . Our even if the plant model arbitrary relative degree and arbitrary , as long as is strongly . We thus conclude that , within the framework , the use of feedback is key to achieve and , accordingly , key to make signal to noise ratio consistent with the in . We stress that the issue of existence of feedback from the channel output to the channel input is inconsequential to the set up used in because the channel is error free , as in our case . Note that the assumption of channel feedback been explicitly made for with stochastic see , e .., , , again the in . If channel feedback is removed from the analysis of , then the minimal data for stabilization do not necessarily coincide with those in see Section in . 
 Design for Performance 
 In this section we go beyond stability and focus on how to actually design a feedback system that the impact that the communication channel on closed loop performance , as measured by the steady state variance of the error . 
 . Problem definition 
 The purpose of this section is to define the performance of interest in a precise way . To that end , we consider the linear model in Figure . Straightforward analysis that the error 
 e A . 
 Therefore , if the linear model is and and hold , then the stationary variance of e and is given by 
 , 
 where is a spectral factor of the power spectral density of . Since Assumption , is not a given constant ; indeed , it on the variance of . Proceeding as above and the same , it from Figure that 
 v A , 
 where 
 £ ¤ 
 , , 
 and , accordingly , 
 . 
 and in , it that 
  
 . 
 We note that of the linear model that and , consequently , 
 , as . 
 We note that , since is assumed to be given , the choice of the i . e ., A and only the second term in , which we denote as 
 . 
 Accordingly , we can state the problem of interest as : 
 Problem Main problem Given a fixed , , a controller and a plant that satisfy Assumption , and exogenous satisfying Assumption , find defined via 
 , A , 
 A U 
 F 
  
 and A and that achieve or approximate arbitrarily well . 
 We note that all in the formulation of Problem stem from , as in and . We will use the term admissible A resp . admissible to refer to a filter A resp . that the in Problem . 
 Problem is non trivial . Indeed , the much simpler problem of designing A and so as to minimize the steady state variance of ym , when and been only recently exactly see . This is quite surprising given the fact that feedback have been studied extensively see , e .., , , . Unfortunately , the technique employed in does not seem to yield an explicit characterization of the solution in the present situation . Instead of that line of reasoning here , we will derive an iterative approach that is to yield performance that is arbitrarily close to optimum . 
 Before the design procedure , we note that the following : 
 Fact Asymptotic behavior of Assume that the of Problem hold . Then : 
 . If , then unless all exogenous have zero spectral density , in which case A for every admissible A and . 
 . If , then . 
 Proof : 
 . By definition of , we have that . Thus unless either . Since A U and 
 Assumption , the result upon that 
 . Fix A U and . In these , and hence , . 
 ¤¤¤ 
 As a consequence of Fact , we will omit from our subsequent presentation an explicit analysis of the or . The reader can easily verify that the below are consistent with Fact by or . 
 . Choosing A 
 We begin by showing how to choose A , when an admissible is given . To that end we define , for any given admissible , 
 , A ,, 
 A U 
 , A ,. 
 A U 
 The next theorem both and 
 Theorem Optimal A for a given Assume that the of Problem hold and consider a fixed admissible . If is not identically zero , then : 
 . The minimal value given by 
  
 . The corresponding optimal A 
 , 
 where a is any arbitrary positive real . 
 Proof : The definition of the norm one to conclude that , for , the following hold : 
 . 
 Both and follow and the inequality in note that is always well defined if Assumption , and is not identically zero . To complete the proof we note that is a condition on the magnitude of the filter A . Thus , can always be , to any desired degree of accuracy , by a rational filter in U as . ¤¤¤ 
 Remark Of course , assuming that is not identically zero does not hinder the generality of Theorem see Part in Fact . 
 The characterization of given by Theorem , although explicit , is usually not satisfied by any transfer function in U . This is due to the fact that , except in very special , the th root of the right hand side in is irrational . Nevertheless , as in the proof of Theorem , it is always possible to find a filter in U that a performance that is as close as desired to 
 . In practice , it is usually enough to consider reasonably low order to approximate see also . 
 . Choosing 
 In this section we address the problem of choosing when an admissible A is given . Consistent with the notation before , 
 A , A , 
 F 
  
 the minimal value A U is fixed . We also define 
 , A ,. 
 F 
  
 We begin by that A can be written in a simpler form as : 
 Fact Equivalent formulation for A Assume that the of Problem hold and consider a fixed A U . Then , 
 , 
 where 
 . 
 Proof : the definition the fact that A is fixed , it is immediate to see that 
 . 
 Define a new real variable ,, constrained to belong to ,. With this definition , elementary optimization see , e .., Section . . in allow one to write as 
 , 
 where we have used the fact that , by definition of , J for any . The result is now immediate . ¤¤¤ 
 Fact is key to derive the main result in this section . Namely , a one parameter characterization for A and the corresponding optimal . Towards that goal , we begin by considering an auxiliary problem . Define the functional 
 L , J J , 
 where , , and 
 F ,. 
 F We have the following characterization of : 
 Lemma Solution to auxiliary problem in and suppose that Assumption . 
 . If , , then the in is achievable in and 
 F , o , o , 
 where , o U is an outer factor of 
  
 and 
 , 
 the relative degree of , i ,, resp . pi i ,, is the set of non minimum phase resp . unstable of that lie strictly outside the unit circle . 
 . If , then 
 F 
 and , if , then 
 . 
 . If resp . , then the in is achievable in , if and only if no resp . on the unit circle . 
 Proof : 
 . We will proceed as in the proof of Theorem see also . As before , we define via , Q . It is easy to see from that 
 ´ 
 L 
 A A z Q 
  
 Moreover , the same procedure as in the proof , it is also clear that 
 A A z Q A A Q 
  
 A 
 T 
 ¡ A A A Q , where we have used the fact that the relative degree and non minimum phase of are the relative degree and non minimum phase of , that unitary , and that , since A U , is such that A to , is and as non minimum phase the on the unit circle of i . e ., the on the unit circle of . From and it that 
 , 
 where 
 , 
 P defined in to , is , and 
 . 
 Define the unitary matrix 
 , 
 where , i is an inner factor of and , o is the corresponding outer factor . We note that , since Assumption , no on the unit circle for , . Thus , for those of ,, o U . 
 multiplying the argument of in by it is immediate to see that 
 . 
 A straightforward calculation that 
 P , i , o , i . 
 Therefore , orthogonal as those employed before allow one to write 
  
 . 
 Since , o U the result . 
 . If , , then and yield immediately the . 
 . The result upon that , by definition of and , resp . A to if and only if no on the unit circle resp . on the unit circle . 
 ¤¤¤ 
 The characterization of given in Lemma an essential role in our subsequent discussion . It is worth that the only critical step when calculating is the inner outer factorization of . Since no at infinity i . e ., is , this factorization can be made with the aid of standard see , e .., , . 
 The next theorem a characterization of the optimal in of . 
 Theorem Optimal for a fixed A Assume that the of Problem hold and consider a fixed A U . Then , 
  
 , 
 where 
 , min . 
 In , is defined as : If there does not exist , such that J , then . Otherwise , , where is the unique real in , such that J . 
 Proof : We will use the alternative formulation Fact . 
 . We first show how to solve an auxiliary problem related to the inner optimization problem in 
 . Consider the problem : 
 J . 
 F 
 J M 
 The well known for this problem see , e .., , allow one to conclude that the optimal , say , if it is a critical point of J J , where , , and , moreover , J . It is immediate to see that this is equivalent to saying that is a critical point of see , with , and J . 
 L is a strictly convex functional and so are J and J . Hence , it an unique critical point given by see . Moreover , the set of in the J versus J plane defined by , when from zero to one , is the set of optimal of the objective problem of simultaneously J and J see , e .., , . This set is a strictly convex and decreasing function when J is seen as function of J . Clearly , the optimal point corresponding to resp . is such that J is minimum resp . J is minimum . Thus , by definition of optimal point , the minimum of J , when J is when J , provided J F . If J F , then the minimum J is when J J F . As a consequence , the optimal solution of the auxiliary problem is given by , where , provided J F , to , and is such that J note that convexity that , in this case , is unique . On the other hand , if J F , then . 
 . We next show how to exploit the above reasoning to prove the result . We first note that , since F J , it is of no use to consider that J F note also that is optimal for the first optimization problem in and , accordingly , constraining J F to be greater than or equal not impede the minimization of . Thus , 
 , 
 Part it that with such that 
 M , 
 M J F 
 to exist in , and to be unique . A key feature of this problem is that the optimal of the auxiliary problem considered in Part do not depend on . Thus , in , min , J F is equivalent to , min , if defined in the body of this Theorem does not exist , then pick . It should be clear that the structure of the problem is such that , min , J F . Thus , it to consider , min , . As a consequence , the result . 
 ¤¤¤ 
 Theorem a one parameter characterization of the optimal and the corresponding minimal cost A , for any admissible A . The scalar parameter can be found any standard line search procedure and , as such , its calculation no additional . This is by the fact that the search for is made over , and that actually in , which is precisely the range of of for which is always defined in see Lemma . 
 . Design procedure and final 
 In this section we show how to use the in . and . to design a feedback system in an iterative fashion . Of course , one can always choose to fix one of the coder trivial are A or and then use Theorem or to design the free parameter . Obviously , this choice will limit the achievable performance . To exploit the full potential of a feedback system we suggest that one an iterative algorithm such as the following : 
 Algorithm Iterative design procedure For a given plant and controller satisfying Assumption , and a given , proceed as : 
 • : 
 Pick a tolerance , a transfer function A U and a transfer function F that is admissible . 
 Set A A , F . Set A ,, fix A or , alternatively , fix and set . 
 • Repeat th iteration : 
 Set . 
 If at the th iteration A was fixed , then use Theorem to obtain . Set and A ,. Fix . 
 If at the th iteration was fixed , then use Theorem to obtain . Set and A ,. Fix A . 
 • Until : . 
 It should be clear that it is not certain that Algorithm will converge to the global minimum of . Nevertheless , it is easy to see that , by definition of and , the algorithm the value each iteration . Therefore , Algorithm , necessarily , to a local minimum . Thus , we suggest to use multiple starting so as to find the global minimum . A procedure for getting a good starting point is below . 
 In general , and . Thus , fixing A or and choosing the other filter , will obviously provide a system that closed loop performance when with a non situation . It is also clear that the use of Algorithm one to design that will always outperform that have been designed the in our work in . This is a consequence of the fact that to be identically zero . 
 A more interesting discussion if one the in this paper with the in . 
 In the latter work , it is assumed that is sufficiently high so as to be able to by 
 . 
 In order to minimize J it to choose A so as to , in 
  
 a second stage , to choose as the minimizer of . A problem with the above approach is that , a , which are high enough to be impossible . In particular , since the procedure in does not take the constraint explicitly into account , the choice for may be not admissible or may be such that A , . Needless to say , this drawback is explicitly in the current paper . It is also clear that choosing A as in and , then , Theorem to choose will always lead to a feedback coder that a error variance that is lower than the one by the in . Of course , if the in are feasible , then they may provide a good starting point for Algorithm . 
 Design Example 
 This section a design study that the in this paper . We consider a very simple case that , nevertheless , will allow us to present the main of our proposal . 
 We consider a nominal loop with plant and controller given by 
 . 
 The measurement noise and output disturbance are assumed zero , whilst the reference is considered to have a power spectral density with spectral factor 
 . 
 The loading factor is fixed at in all , and the number of quantization ,, b , between and . Since we do not consider the use of channel e .., entropy ; see , , to the rate at which data is sent through the channel in 
 bit sample . 
 Figure the steady state error variance se see as a function of the number of in Algorithm for two representative of the signal to noise ratio : . and . , which correspond to and , respectively . and refer to that start with A and F . In Case we initially fixed A , whereas in Case we start fixing . Case to that start with the in . We note that to be greater than . in order for the proposal in to be admissible . Accordingly , we 
  
 Figure : error as function of the number of in Algorithm see text for . 
 Case in Figure when . . It can be seen that rapid convergence of Algorithm and , more interestingly , that the limiting performance does not depend on the order in which the are calculated or on the initial condition . Thus , local minima related do not seem to play a role in this example . 
 In Figure we have three . The first of these point to the performance without and A . The second point to the performance when the optimal system in . The third point to the performance the approximately optimal in . 
 The show that is , indeed , necessary to achieve the best possible loop performance . Compare point with , e .., the value of se for . It is also possible to see that use of Algorithm that perform better than our previous in , , which is consistent with the discussion at the end of Section . . Compare and with the limiting value for se . It is also interesting to mention that , for , the performance provided by the in is substantially closer to the limiting value of se than the case shown in Figure . This suggest , as before , that the in , when feasible , provide good starting for the iterative procedure here . 
 We end this section by the behavior of the error variance as a function of the channel bit rate . The are in Figure , where Nominal performance to the performance by the nominal loop without quantization , No empirical to when no is employed i . e ., when A and , Opt . empirical to with the by Algorithm after , and Opt . analytical to the corresponding made the simplified noise model for quantization . One can see that , as , the effects of quantization vanish as . Interestingly , the made our model turn out to be very accurate for every bit rate : indeed , for the relative are of less than and , for , , the relative are around . We note that turns out to be non admissible for . Accordingly , 
  
 Figure : error as function of the channel bit rate . 
 we have the non for . 
  
 This paper a methodology to design feedback that encode plant output in a control situation data rate limited . a fixed signal to noise ratio additive noise model for quantization , we have shown how to iteratively design the of a feedback system so as to minimize the impact of quantization on the closed loop error . Our show that feedback quantization are beneficial when to simpler in the literature . An interesting by product of our in the characterization of the signal to noise ratio compatible with stabilization . We have shown that , for a given signal to noise ratio , the class of that are when feedback is employed is significatively than the class of that are when no is used . This result the door to investigating other control and feedback and the associated signal to noise ratio . 
 A very interesting extension of the present work in multiple input multiple output . In that case , it is worth exploring how may help the well known performance that arise when constraining the structure of the controller see , e .., , . A second immediate extension in the problem of joint controller and coder design . The study of how to apply similar to the case of prone to data loss is also interesting see preliminary work in . 
 A Appendix 
 Consider a a on and extensible to . If X and X is achievable in , i . e ., if such that X , then , X . On the contrary , if such that X , then defined as above should be understood as limn , where is a sequence in whose limit to such that limn X . Therefore , if we write and , it is implicit that one can find a sequence as above . In these , it is clear that one can always pick that is as close to X as desired . 
  
 ﻿ We obtain the maximum average data achievable over block fading when the receiver perfect channel state information , and only an entropy constrained approximation of this is available at the transmitter . We assume channel gains in consecutive are independent and identically distributed and consider a short term power constraint . Our analysis is valid for a wide variety of channel fading statistics , and fading . For this situation , the problem into designing an optimal entropy constrained to convey to the transmitter and to define a rate adaptation policy for the latter so as to maximize average data rate . A numerical procedure is which the and reconstruction of the optimal , together with the associated maximum average , by finding the of a small set of scalar of two scalar . this procedure , it is found that the maximum average capacity , in some , time between two . In addition , it is found that , for an entropy constraint log , a with more a small capacity increase , especially at high . 
 Index Channel state information feedback , Information , fading , quantization , radio communication . 
 T is well known that the achievable data for reliable communication over a fading wireless channel depend on the availability of channel state information at the transmitter and end , . For single input flat fading , the of channel gain and phase . If perfect is available at the transmitter perfect and at the receiver perfect , the channel is slowly fading and the transmission is subject to a long term average power constraint , then the average capacity is by rate and power to the channel gain in a time fashion , . By contrast , if an instantaneous per block maximum power constraint is , the are ergodic and the transmission are long enough so that the fade statistics over each block converge to their ensemble statistics , then the ergodic channel capacity is achievable without , . Else , if the fading is so slow that channel gain can be as constant within each block which to a block fading scenario then is beneficial . In this case , with perfect and per block power constraint , the capacity is by at maximum power , with only the data rate being to the channel gain in each transmission block . 
 If perfect is available and the receiver back this via an with limited information throughput , then only imperfect will be available at the transmitter . In a block fading situation , the uncertainty at the transmitter about the true channel gain in each block a trade off between throughput and reliability : the the data rate chosen by the transmitter , the higher the probability of exceeding the channel capacity during the transmission block . This the problem of the at the receiver and it at the transmitter i . e ., choosing rate and power in a rate distortion optimal fashion , where the distortion is some measure of the decrease in throughput , as in , or the increase in error probability , as in . 
 The capacity of memory less block fading with long term power constrained transmission and fixed rate constrained feedback was studied in . A similar situation was considered in , assuming a scheme in which data are perfectly or totally lost if transmission data rate is , respectively , below or above the channel capacity during the block . The idea in was to design a with a fixed number of quantization so as to maximize the rate , i . e ., the number or long term average of successfully . Also for a constraint in the number of quantization , studied the maximization of throughput considering a noisy feedback channel . There exist also numerous related to throughput maximization for multiple output wireless see , e .. , and the therein . Although not directly related to the problem which is the focus of this work , it is worth that , in all the in , and the therein , the only constraint on the where there is a is its . In , the maximum average throughput under a long term power constraint and for a fixed number of quantization is . The performance of to as MASA was against that of average reliable throughput to as ART , which allow for to occur . It is shown in that , in some , when the additional feedback load of the ART associated with the transmitter of a previous outage is in , MASA outperform ART . In that context , the feedback load to the entropy of the plus and that are sent to the transmitter . However , in this entropy is a , i . e ., after the have been without considering entropy as a constraint . 
 Thus , in all these , the design of optimal been only considering a constraint on the number of quantization or . However , if one the question what is the maximum throughput that can be if there is a constraint on the amount of information that can be sent to the transmitter for the , then it is more appropriate to consider an entropy constraint instead of a constraint for the . On the other hand , the entropy of the output , say , is a lower bound to the average number of to represent this output . At the same time , by , it is possible to find prefix free for each outcome with an average length not greater than per realization . Moreover , in a situation in . i .. are at a time which would happen , for example , in an system fading , joint entropy would yield with an average length , at most , bit . Since , in general , information to feed back for each realization less average power , or time , the latter can be directly associated with a low entropy . This a practical motivation for considering entropy , instead of , as a constraint for the . However , to the best of the knowledge , there are no available on average throughput maximization in which the to encode for the transmitter is to be designed subject to a constraint on the entropy of its output . 
 With the stated in the previous paragraph , in this paper we study the problem of finding entropy constrained with any given number of quantization , for block channel gains for the transmitter , that yield the average data rate . In our setup , the channel is assumed to experience i . i .. block fading , with associated gains and phases perfectly known to the receiver . We consider a wide family of fading statistics , general enough to include and fading with one or more of freedom . As in , the over which is fed back is an , zero delay channel . To solve this problem , we propose a numerical method which the optimal quantization and reconstruction for any given number of quantization and average channel signal to noise ratio . The optimization problem is partly similar to the design in because of the common entropy constraint . However , as we shall see , since the distortion measure in this case is the decrease in average rate not mean squared error , the resulting situation is vastly different from the one in standard entropy constrained quantization . The problem turns out to be non convex , and our analysis that it , in general , several local . Its formulation , for quantization , to a system of N non linear in N , each of which taking over the non negative real . Since each of these must be numerically , and due to the high dimensionality of the search space , direct solution of this system of a high numerical complexity task . The numerical procedure in this paper greatly this complexity by turning the problem into finding the of a small set of scalar of two scalar , only one of which unbounded support . The evaluation of each of search with respect to monotonic . By this procedure , it is found that , in general , the maximum average a given entropy is a non concave function . Since in our formulation time between two an average capacity and entropy equal to the weighted of the capacity entropy of each regime , the region of all achievable , is given by the convex hull of curve . On the other hand , it is found that if is log of the number of available quantization , then the so as to obtain is nearly optimal . Our also allow one to find the gain in average throughput of an optimal entropy constrained instead of a constrained optimal . For instance , when the average is , then an entropy with and an average rate of bit per realization an increase in average throughput over an optimal fixed rate with two i . e ., the same average rate . The performance of the latter fixed rate with the one found in . It is also found that for any given maximum entropy constraint log , the increase in maximum capacity by a with more relatively small . Moreover , our analysis also that , for any given , the maximum average capacity is a with a finite number of . This with what is also for an exponentially distributed source but with as the distortion measure , wherein the optimal turns out to be uniform with infinitely many . 
 In the following section we present a precise model description , introduce some notation , and formally state the problem of interest . To illustrate some of the of this problem and its , we first analyze the case two quantization , which can be explicitly , in Section . Then we extend the analysis to the case in Section , where we introduce the numerical procedure to solve the problem in its generality . the with this procedure for the case and under fading . Finally , Section . 
 We consider a block fading additive white noise channel , a transmitter , a receiver and an error free , zero delay channel , as in Fig . . In the transmitter , the binary message into consecutive of . During each block , a real valued sequence is over the channel . The random block channel gain magnitude for the th block is assumed constant within each block . Channel gains in consecutive are i . i .. according to a probability density function satisfying the following : 
 Assumption : The of the the channel gain squared magnitude the form 
 for appropriate K , K , where the differentiable function is such that the ratio u u is non increasing with respect to u over , . 
 The structure of the is fairly general . For example , if channel gain magnitude is distributed , then the form 
 where I is the function of the first kind of order zero . From direct comparison with , we obtain , for this case ,, K s and u . It can be numerically that the latter form of the by Assumption . Likewise , if channel gain are by a distribution , then the form 
 and we have K , K and u um . If , it is easy to verify that u also the 
 to Fig . , the real valued random process , ,...,, is with sample variance N . Thus , if were the , taken at frequency , of continuous time band limited to , then the 
 The necessity of the condition upon in Assumption will become evident in Lemma Section , in which it us to prove the convexity of a function a key role in the problem under study . 
 two sided of the latter would be N . On the other hand , the information bearing signal is subject to a per block power constraint of the form 
 where . With this constraint , if the block large , then the maximum achievable data rate during any given be well by capacity formula as , where 
 is the mean at the receiver for a channel power unit mean value . 
 At the other end of the channel , the receiver is assumed to acquire a perfect estimation of prior to or at the beginning of the th transmission block . This channel power gain is instantaneously and entropy , with the resulting being sent over a zero delay , error free channel . These about the feedback channel have been considered before in , . The zero delay condition can be to be a good approximation when the time spent to feed the back to the transmitter is much shorter than the duration of a frame . In turn , it is possible to have an almost error free feedback channel if the feedback is sufficiently large and or strong forward error correction is employed for the . And naturally , if in a given situation these latter are not present , then our would provide upper to achievable performance . 
 As in the Introduction , it is possible to translate a small entropy of the into less average power , or time to convey this to the transmitter . At this point , it is perhaps worth that if only a single realization is and fed back at the beginning of each block , then these may require one to match the channel and modulation scheme in the feedback link to the variable coming out of the entropy coder . For instance , an off the shelf channel coder and modulator in the feedback channel would yield an that only of fixed length data . Such choice which would entail significant when variable length , in comparison to sending . However , in this scenario wherein a single realization is and fed back at a time , the 
 feedback channel and modulation can be chosen so as to handle variable length bit or the associated unequal probability of the as efficiently as it is possible for fixed rate . This can be done , e .., by variable length error correcting or joint source channel see , e .., and the therein . Although the design of such and is beyond the scope of this work , we illustrate this fact with an example a simple scheme similar in spirit to , which can be found in Section A in the Appendix . 
 Upon the , the transmitter a transmission data rate from a discrete set of data . To define the and its reconstruction , let 
 be the number of quantization or , and let denote the set , where 
 Define also the quantization , , i ,...,. As in , whenever the channel power gain within cell , the transmitter a satisfying , belonging to the i th amongst , one for each cell . This is capacity for some nominal channel power gain associated with the cell , i . e ., 
 Thus , the power gain can be seen as the set of reconstruction or of the , as in Fig . . 
 Since in each block the transmitter information over the a capacity code for a nominal channel gain , all the are correctly if . Else , if , then is not by the channel , and the receiver an outage , all the information received during the th block . From this , it is clear that a necessary condition for a set of reconstruction to be optimal is 
 Let the random variable , taking in with , denote the output of the for the th block . As already in Section I , we focus on that satisfy an entropy constraint , which we now formally state as 
 with the maximum entropy for the output . 
 We are interested on finding the i . e ., the and reconstruction satisfying the entropy constraint and the average in the channel , defined as the average number of correctly . The average number of correctly sometimes to as average or average reliable throughput is also the the objective function in , , . It is a reasonable figure of merit if one forward error correction by been applied to the data being sent over the , so that , with high probability , lost due to outage do not cause irrecoverable . Otherwise , and if all data is to be correctly , and would have to be sent back over the to request retransmission of lost data . As we shall see from the in Section , at least for fading and for equal and , the optimal entropy constrained are such that only the first cell V for outage . The latter that if sending and is necessary , then it would mean at most V per realization to the . The extra bit rate is upper bounded by V block because only when V it becomes necessary to send an or during block , which at most extra bit every time V . 
 Since in consecutive are i . i .. and ergodic , over a large number of converge to ensemble . Thus , for notation simplicity , in the following we drop the frame and channel . With this , the design problem can be stated as finding the and satisfying and , that maximize the average data rate in the channel without exceeding the entropy constraint in the . More precisely , combining , , and , we state the optimization problem in canonical form as minimize : 
 with and , and where is the cumulative distribution function of . 
 This optimization problem is difficult to solve primarily because the entropy constraint c is non convex . As we shall see , this to the existence of several local , which , in principle , one to run an optimization program several times with a potentially large number of different starting . In the following we solve this optimization problem , first explicitly for the case , and then numerically by of optimization and a novel procedure which greatly the overall complexity of the task . 
 We now address the optimization problem stated in for the case , corresponding to two quantization . In this case , to : minimize : , i 
 This problem can be explicitly without by that the entropy associated with the two only on the threshold . Supposing is given , the optimal value of u is found by the objective respect to it and to zero : 
 We see from this equation that for every u there a unique u for which u . On the other hand , in order to determine the optimal value of u given , we notice that this value to minimize the term u u in a . Although , in general , such value cannot be found explicitly , the following lemma that it is unique and that it can easily be found numerically : Lemma : a satisfying Assumption . Define u 
 The proof of this lemma , which will play a key role later in Section , can be found in the Appendix , at the end of this document . 
 It turns out that the value of u which u , u u with . More precisely , define the function U 
 for any , with the inequality being a consequence of the fact that is non decreasing . from Lemma that u , is convex in u , we conclude that becomes zero at a single value of u greater than or equal to . This that for all , . 
 The latter result that the optimal value for u must belong to the interval ,, where . 
 Also , by Lemma with , it is readily found that the unique value of u a also . The convexity by Lemma that the latter function can be easily numerically by line search . Moreover , Lemma that u u , which to the conclusion that the optimal value of u given is 
 It then that , if u is part of an optimal for some entropy constraint , then the optimal can be explicitly from u by , and then the optimal u can be directly derived from . In this manner , by increasing u from to and and u with the latter , one a family of the optimal for every value of . 
 Fig . top the curve of capacity versus entropy by the method in the 
 paragraph , for two quantization , under an average , left and , right . More precisely , for every , the corresponding was calculated . Then , for this value of , the optimal u was determined . In this way , for each value of u , a different was . The pair capacity , output entropy associated with each a single point in the top two in Fig . . In this example , channel gain distribute , so exponential , chosen to yield , i . e ., u e u , u , . Notice that , for every value of , there exist two to and , corresponding to different local constrained . There is one associated with each of these two . One of these the upper section of the curve in each of the shown in top , and the other one the lower section . Of course , the optimal are those responsible for the upper part of their respective , i . e ., those which yield the maximum capacity for a given entropy constraint . As , in general , capacity when the entropy of the available to the transmitter entropy is . 
 Fig . . to and two quantization for fading with unit mean channel power gain . Top : under an average , left and , right . Bottom : and code for the optimal solution as a function of entropy under an average , left and , right . 
 Note that the maximum capacity for , . , at an entropy of . block , not with maximum entropy , which , for a two cell is bit block . This is expectable for a with a fixed number of , since there is no reason why all being equally likely the only situation in which the entropy is should yield the capacity . Also , the maximum for a two cell at and coincide with what was in , where average capacity was without an entropy constraint on the output . At an average of , Fig . top right that the maximum capacity closer to maximum entropy , and that , corresponding to this maximum entropy , are near optimal . Interestingly , the maximum capacity curve at this a at an entropy of about . block where the curve itself in Fig . top right , which it non concave . For this case , this that better performance for below block can be by doing time between two : one with a single cell and zero entropy , and another with two and an entropy of about . block . By choosing one regime more frequently than the other , it is possible to achieve a capacity and an entropy equal , respectively , to the weighted of the and of both . In this manner , all capacity entropy within the convex hull of the can be . 
 Fig . bottom the evolution of and for the optimal solution , as the entropy of the output . For , on the left , u at all . We see also that higher are by and code closer together . For the case , shown in Fig . bottom right , the in with a change in the arrangement of and code in the . Except in a neighborhood to the right of this , we find that the u with its left boundary threshold . 
 The straightforward approach in the previous section cannot be extended directly to the case in which there are more than two quantization . optimization can be instead , which , as we shall see , to a system of non linear that must be numerically . The non convexity of the optimization problem and the existence of several local satisfying the the need to solve this system of non linear possibly many times with different initial . However , we will introduce an algorithm , in the same spirit as the strategy in the previous section , that one to simplify the optimization problem to a sequence of simple line search , each with a single solution . 
 Before the associated with , we note from a that , at the optimum , the inequality stated in e are not active . Similarly , constraint d for the case i is not active since increasing u above would raise the average data rate without increasing the entropy of the output . 
 Taking the above into account , the associated with the following form 
 . with respect to u and to zero 
 Notice that a is identical to , which that u is a solution to a only if 
 L with respect to the other and to zero 
 On the other hand , the with respect to the we obtain 
 Finally , the Tucker , provide another set of , 
 Although it is possible to solve this system of N non linear by standard numerical , the existence of numerous local minima one to apply these repeatedly , each time with different initial . This shortcoming is by the fact that the vector of initial plus threshold and code point in a N dimensional space , which a large number of initial is to obtain a reasonably good coverage of the search space . In the following section we will show how these can be by an approach similar to the one in Section . More precisely , we derive a method which , for this problem , one to find all local minima in a systematic , sequential manner , greatly reducing the number of . 
 In this section we exploit the recursive nature of to reduce its induced system of non linear into a sequence of line search over bounded , in a spirit similar to the one behind the approach in Section . 
 To begin with , recall that the imply that , for every constrained local minimizer of a , the multiplier only if i . e ., only if the associated constraint is active . The next corollary of Lemma an verify condition for to hold in such a minimizer : 
 Suppose are a solution to optimization problem . Then for some ,..., if and only if 
 Proof : The result directly from Lemma , since it the convexity of the function u u , and from a , upon that the entropy of the output does not depend on the choice of . 
 Corollary will allow us to find and from , , and in a simple manner . For this purpose , define , for ,..., where 
 is the complementary . With these , the combined c , d , g and i can be written in the following equivalent form 
 , , ,..., a , ,...,. b 
 Fig . . of , and defined in , as of . Left : a case in which . Right : a case in which 
 Figure a qualitative description of , and as of . It can be seen that both are monotonically increasing , the first one being affine , the second one convex . 
 A look at Fig . immediately that , for any given , and depending on the of the , and , there will be , in general , more than one pair of of and satisfying . Let us find out which actually by first considering the under which the constraint is active or inactive : 
 • Inactive Constraint : In this case which see b . In view of , this is equivalent to 
 The first equality of is satisfied by a unique value of the argument of , say , shown in Fig . . 
 From the definition of , this quantity must be . On the other hand , Corollary that if and only if 
 situation and in Fig . right . In addition , Lemma that , if this inequality is satisfied , then there a unique satisfying the second equality of . Thus , there a solution to for which the constraint is inactive if and only if and . In this case , we say solution for . 
 • Active Constraint : In this case , , and can be positive . By looking at , a solution satisfying this condition if and only if there is for which 
 which correspond to of the of , and on the first quadrant in Fig . . Since , with respect to , the function , is affine and increasing , and the function is convex and monotonically increasing , it that is satisfied for either none , one or two of . Indeed , these imply that two to equality a in will exist if and only if 
 is the unique value which , , see Fig . . It is also easy to show that if , these two , say and , will lie at opposite sides of . Also , it is straightforward to verify that both are not than . Therefore , 
 problem , each solution to equality a in will also be a solution to if and only if it is non negative and it a non negative value for . This one to discard solution or if 
 . On the converse , if these two do not hold , solution will be non negative and yield 
 , i . e ., it will be a valid solution to . In this case , it is easy to verify that 
 , with i , , , be the threshold value associated with , we can devise the following procedure to find the to for a single , given : 
 Procedure : Suppose , and that , and are given , with . Then , in order to find the to for , 
 a Find by equality a in with respect to by line search over , 
 , find equality a in by line search over unless , in which case . Set , and 
 The last step , where yielding are whenever , to the fact that is a complementary value . This requirement is only if one is calculating the last threshold i . e ., when , to allow a higher level routine to iteratively adjust so that . Such a routine is by Procedure below . Of course , unless , solution can be before doing the corresponding line search if . The same for solution if . 
 In each of the line in Procedure , there a single solution over the corresponding search interval , since , in all , the involved function is monotonic within it . This each step straightforward to execute . Notice also that for every , and depending on the of , and , there are between zero and three of for , , namely , and , which satisfy for that . 
 The above procedure can be applied sequentially to find all , , for , ,...,, that satisfy . More precisely , one can first choose for u , and , with which one can calculate explicitly from a . Then , setting , Procedure can be carried out to find at most three of for u , satisfying for . Each solution can be considered a branch in a tree structure . one and the procedure for each branch , until , the complete tree of valid , each of which is associated with a path in the tree . Thus , for each choice of u and , there can be at most N different , each associated with a sequence of and satisfying for all , ,...,. However , we shall see in the following that the number of valid in practice is much smaller than N . 
 Following our notation for adopted in Procedure , we label each solution path in the tree the of the solution associated with its , thus to a sequence . For a given choice 
 It is important to note that there is a one to one relationship between every solution satisfying for a given choice of u , and every path in O u ,. Indeed , the path associated with any such solution can be easily determined by each of its code point threshold the the reasoning that led to Procedure . 
 Now , suppose one to know whether a given path is associated with a valid solution to and then find this solution . Instead of Procedure to find the entire tree of valid and then if is one of them , one can apply the following algorithm , derived directly from Procedure , for this purpose : 
 Procedure : Let u ,, and the corresponding be given by a . Let be a path . 
 Then the following can be taken to determine whether and find its associated and code 
 With the above procedure , the resulting of all and are a function of . For convenience , we denote this function by , defined 
 where we have chosen † as a special symbol to indicate that the path does not yield a valid solution . For future use , we also define 
 Although being a solution to is a necessary condition for code and to be a solution to , two additional must be satisfied for sufficiency . The first one is the entropy constraint , expressed in the equation f . The second is the construction condition or , equivalently , . For a given path , u and , this condition can be expressed as . 
 is the set of all , for the first u and multiplier associated with to for some entropy constraint , the set of all 
 , respectively , as the entropy and capacity associated with , the original optimization problem can be stated as 
 Thus , we have reduced the problem from a set of N non linear , over a N dimensional space , into a moderate number of one per valid path , over two , the evaluation of a scalar function to compute . 
 Define a grid of of u over ,, say U , and a grid of for say , for some . 
 Detect of consecutive of between which a sign change of for some valid path . In each of the formed by such , find the value of for which by line search , running Procedure for the corresponding path . 
 Calculate and for each of the found in the previous step . Select the combination that the capacity with an entropy not greater than . 
 In the following section we present an example in which Procedure was to find the solution to for . 
 In this section we apply Procedure to find the set see , for the case , i . e ., for four , assuming is fading . The latter set the , for u and that characterize a solution to , i . e ., and code that yield a local maximum or minimum capacity for some fixed maximum entropy constraint . The are in Fig . , for , on the left , and for , on the right . 
 The two top graphics in this figure correspond to for all to . It can be seen that , although for each there exist several such , for each entropy constraint the number of these is significantly smaller than N . For the case , the absolute maximum capacity is . , with an entropy of . block , by a solution with associated path . The curve that this maximum is ended at that point and , to the eye , it as if there was a missing segment which would connect it to the curve that the right boundary of the plot , at an entropy of block . The absence of this segment can be to the fact that in the formulation of the problem , the entropy is an inequality and not an equality constraint . 
 The solution yielding the maximum capacity for a given entropy is given by the highest curve in each of the . Interestingly , for somewhat below log and log block , the curve with the optimal solution with and quantization , respectively . This can be seen by from the bottom in Fig . that a few block below these entropy , the optimal solution is such that one , two or three , respectively , tend to infinity , effectively leaving three , two and then one cell , as the entropy is . Such behaviour that for a finite entropy constraint , the maximum capacity over all is with a a finite number of . 
 As already for the same and two , the region of achievable average is given by the convex hull formed by all the in the . Unlike what is for , since the composite maximum capacity curve for Fig . top right is not concave , the maximum capacity for some entropy constraint between two . 
 The point of maximum capacity for each number of quantization to the solution when a with that number of is for maximum average throughput without an entropy constraint . Therefore , those peak are the found in for single layer , where the was under a constraint only . From this fact , we can conclude from Fig . top left that at , and for the same average rate of an optimal fixed rate from with two that is , bit per realization , which . , an optimal entropy with quantization approximately . . This an increase of roughly in average throughput for the same average rate . The corresponding increase with respect to a fixed rate with goes from . at a fixed 
 Fig . . entropy for the to , for fading with unit mean channel power gain , up to quantization . Left : Average . Right : Average . 
 . an optimal entropy with . For an of , Fig . top right that an optimal entropy constrained smaller gains over fixed rate optimal . Notice also that can only operate at a limited set of given by log realization , Thus , entropy quantization is the only scheme which one to send other average for example , below bit realization . 
 We have a numerical procedure to find the maximum average capacity over block fading , under a fixed per block power constraint , when the receiver perfect and an error less , delay free , channel is available to convey to the transmitter . This procedure , which a smaller numerical complexity than trying to directly solve the associated with the problem , also the and that achieve the optimal solution . Our are valid for a broad class of channel fade , and fading . We have applied the procedure here to find optimal and quantization . The revealed that , for a given number of quantization , say , maximum capacity is at an entropy slightly below log block . Furthermore , our show that for any entropy below log block , there is little to be in average capacity by more or . This that for any finite entropy , the optimal a finite number of quantization . Our analysis also revealed that for high average , the maximum average capacity time between two with different and associated . 
 As a final remark , we would like to mention that , after several , the have found that the and here for a short term power constraint do not seem to be applicable for the long term power constrained version of the problem . Indeed , the latter problem to be significantly harder to solve than both the one in this paper and the long term problem without the entropy constraint . 
 Here we provide an example to illustrate how a discrete random source with small entropy which can be associated with the variable length coming out of an entropy coder can be efficiently a channel coder . The latter coder is able to transmit the low entropy source less power and with a smaller message error probability than what is when modulation and maximum likelihood . For this purpose , suppose we have two , each with four quantization . The first is not entropy , and each of its , two , equal probability . For simplicity , suppose that this is by a rate error correcting channel coder and that is . Assume each symbol in the constellation unit energy and that there is a memoryless channel in the , with complex circularly symmetric white noise with variance . Therefore , each outcome or message is into of length two that is , two consecutive are sent for each message , which an average energy of . At the other end , the is done by by the most likely symbol sequence given the received signal . For this scheme , it can be found either analytically or via that at an of , the message error probability is approximately . . 
 For the entropy , suppose that its four possible , say m , m , m , m , have , , and , respectively . An entropy coder for this for example , a coder would output , , and , respectively , for each of its . In order to send these four or over the feedback channel , consider a time digital modulator generating from the shown in Fig top . Each of these except symbol o unit energy . 
 An outcome from the entropy is fed back to the transmitter by sending a sequence of three channel , each coming from the first , second and third constellation , as in the table of Fig . Notice that with higher probability are to symbol with smaller total energy , the latter being proportional to the length of the by a entropy coder i . e ., proportional to log , where is the probability of the i th message or outcome . This to the sequence length or energy distribution that average energy , the latter energy being in this case equal to . Therefore , the average energy by the channel scheme for the entropy is just of the mean energy associated with the fixed rate . On top of this power reduction gain , if this variable rate scheme to the entropy is combined with a maximum likelihood sequence at an of , then each message is with a message error probability not greater than . . This that if the of the have uneven which to a smaller entropy than with probable , then it is possible to transmit the less power and with a smaller probability of error than when the of a fixed rate . 
 where we a short hand notation for . For every u such that u , it readily from the structure of see that u and therefore immediately da u . The same for u . Thus , it is only left to consider of u and such that u . If da u , then , from , 
 Since we are only considering the in which u , u . This one to 
 Since we are considering of u such that u , we can substitute into , 
 It then that also if da u . We therefore conclude that , irrespective of the sign of da u , 
 Fig . . Top : Three consecutive of a digital modulator for the of an entropy with quantization . a ,,, have unit energy . Bottom : A between quantization m to m and channel symbol . The 
 Since is a non increasing function , it that the of is positive . Therefore , we obtain from that a u is also convex for all u , such that u . This the proof . 
  
 ﻿ This paper novel on perfect reconstruction feedback , i . e ., noise shaping , predictive and sigma delta A whose signal transfer function is unity . Our analysis of this class of is based upon an additive white noise model of quantization . Our key result is a formula that the minimum achievable of such to the signal to noise ratio of the scalar in the feedback loop . This result us to obtain analytical that characterize the corresponding optimal . We also show that , for a fixed of the scalar , the end to end of an optimal which the optimal which for this case turn out to be increasing ratio . Key from work include the fact that fed back quantization noise is explicitly taken into account and that the order of the converter is not apriori restricted . 
 Index Differential pulse code modulation , optimization , quantization , sigma delta modulation , source . 
 HE term feedback to a class of to digital converter wherein a scalar is within a linear feedback loop . Well known of include , and sigma delta . The latter have been very successfully applied in a number of , audio compression , , A conversion , , subband , digital image half , power conversion , and control over . 
 Fig . a general configuration . In this scheme , may take the form of a nonuniform or a uniform , the latter being either or . 
 The in an system allow one to exploit the predictability of the input signal so as to reduce the variance of . When with simple 
 smaller quantization step . The error feedback filter the possibility of spectrally shaping the effect of quantization noise in the frequency where it is less harmful from a user point of view . Accordingly , it is convenient to use a frequency weighted error criterion , via an error frequency weighting filter , and to focus on the frequency weighted see discussion in and . 
 For the sake of generality , we consider the possible use of a clipper before . This device the value of the input signal so that if , and if 
 , where is the saturation threshold of the clipper which is helpful in reducing limit cycle idle in an with high order , as in . On the other hand , if we chose to be sufficiently large , then , and the clipper no effect on the system . 
 If the of and the spectral of the input signal are known , then the design of an converter that the variance of to choosing the 
 It is often desirable that a converter is transparent to the system in which it is inserted . This to the widespread paradigm in which the scheme to the application that it , without need to modify the latter . A transparent converter is one whose signal transfer function i . e ., the transfer function from input to output is unity at the of interest . The design of such perfect reconstruction feedback the main topic of the present work . are by the property that , in the absence of quantization effects , there is no frequency weighted reconstruction error , i . e .,. If we denote the power spectral density of , then it can be seen from Fig . that the latter if and only 
 Thus , in the design of an optimal converter , only two of freedom are available : the or , alternatively 
 To the best of our knowledge , on optimal filter design for either consider finite order , , , assume or require that the variance of the signal is much smaller than that of , , 
 , , or have a heuristic component in the optimization , , , . available for the optimal performance and corresponding filter frequency of a converter are those given in . However , the assumption of negligible fed back quantization in these suboptimal . Indeed , as we will show in the sequel , there exist where the in yield large fed back quantization error , even when a fine step scalar is used . In these , not only is the main assumption in , but also an much than can result due to excessive overload see , e .., and . 
 In the present paper , we will show how to design optimal . For this purpose , as in , , and , we model the scalar as a linear device that additive white noise whose variance is proportional to that of the signal being . A key departure from , however , is that we explicitly take into account fed back quantization noise in the feedback loop . Our main are : 
 i We derive one parameter that relate the minimum achievable frequency weighted to the signal to noise ratio of ; We show , within our model , that the frequency weighted in an optimal where the of is fixed exponentially with ratio ; and We derive that characterize the optimal for a . Our can be applied to any given number of quantization , and to almost arbitrary input spectra and frequency weighting criteria . 
 The remainder of this paper is organized as : In Section , we present our analysis model for . In Section , we formulate the associated optimization problem . Section a one parameter characterization of the solution . In discuss the main of an . The case of is in Section . Section the relationship to previous and the importance of taking account of fed back quantization noise . Section simulation . Section . For ease of exposition , all of our are included in the Appendix . 
 We write as a short hand expression for if and only if . The of all complex valued square integrable and absolutely integrable on are by and , respectively . Given we adopt the standard inner product , where complex conjugation . We denote the corresponding 
 transform . If is a transfer function , then we use the short hand notation to refer to the associated frequency response 
 . If is a set , then we write a . e . on almost everywhere on for everywhere on , except on a zero measure subset of . We use to denote the variance of a given wide sense stationary ... random process We recall that if zero mean , then 
 where is any given function and any arbitrary and positive bounded value . For later use , we also recall the following definition . 
 In this section , we discuss some of the main of feedback quantization . We also describe the analysis model and the to be considered later in the search for the optimal . 
 We begin by the that describe the behavior of the shown in Fig . . 
 Quantization and Clipping : From Fig . , the quantization error is given by 
 such that , if , then is said to be . When the is not , then is only granular quantization error , namely , which can be bounded as for some 
 see , e .., . For example , if is a symmetric , uniform , with and quantization interval , then one needs in order to obtain . 
 As outlined in the introduction , the clipper in Fig . can be used to keep from . For simplicity , we will only consider here two , namely , that , or else 
 . The former choice that does not overload , since clipping error , defined as 
 clipping is that , unlike overload , clipping are not fed back into through . This to avoid large limit cycle from the overload of , see . Since such are not part of the analysis model we will use , their occurrence could increase the significantly above the value by the model . 
 which that from by the sum of the quantization and clipping . 
 Notice are require no on the involved . From b one can see that to the signal transfer function , from to , of the converter . Similarly , the product is the transfer function for quantization , usually to as the noise transfer function of the converter . The term will play a crucial role in the derivation of the optimal 
 Output stable for any input sequence satisfying . 
 , and , thus , all the other in the converter are bounded . On the other hand , if , then can be written as 
 If the a finite number of quantization , then is bounded . If is stable and is minimum phase , then it from that is bounded . This , in turn , that and all the other in the converter are bounded see and if all the in Fig . are stable , and if no on or outside the unit circle , then the resulting is stable . 
 In addition , if and are stable , then the norm of their impulse , namely and , are bounded . 
 Therefore , for a uniform with quantization interval , it to have or more quantization in order to avoid clipping or overload . 
 Input Spectrum and Frequency Weighting : The error weighting filter in Fig . the impact that reconstruction have at each frequency . This performance assessment filter is application dependent , and is assumed to be stable and given . The input signal is a zero mean ... stochastic process with known and finite power , i . e . In 
 order to simplify our subsequent analysis , we shall further restrict and to satisfy the following : 
 Assumption : The product is a piece wise differentiable function at most a finite number of and satisfying In addition , is such that one of the following . 
 such that . Furthermore , if the set of noncontiguous and nonoverlapping in such that 
 We note that the above is a rather weak constraint , since i and include almost any product of practical or theoretical interest . In particular , condition i all the where the product no on the unit circle . In turn , condition is satisfied if is zero over any interval on nonzero measure , or if is rational and on the unit circle . 
 The : We shall focus our analysis on the effect that granular quantization have on the . For this effect to closely represent the actual , we need to assume the following : 
 Assumption : The of overload and clipping are negligible , i . e . 
 In addition , and as stated in the introduction , we will adopt an additive white noise model for . This model is widely used for the analysis and design of data see , e .., , , , and , being usually as . 
 Assumption : The sequence of quantization noise is a zero mean ... random process , 
 The above additive white noise model , although not exact , is , in general a good approximation when a signal with a smooth probability density function is with many and negligible overload in the sense of Assumption , see , e .., . The model can be made exact , even for few quantization , by a uniform scalar with either subtractive or dither , provided overload does not occur , see . As before , one way to achieve this is to use a with a sufficiently large number of quantization , so as to satisfy . In this case , if the quantization interval is and the dither sequence 
 , uncorrelated to when is not and is bounded as , then any number of greater than or equal to will make Assumption hold exactly . If a smaller number of quantization are employed so that , then the use of dither with the same as before , together with clipping i . e ., setting , will also make satisfy Assumption exactly . 
 . . on through the feedback path . However , if the scalar a finite and fixed number of quantization , then another link between these two needs to be considered . In order to model this relationship , we will use the fixed model employed in , e .., , , , , and . 
 Assumption : For a fixed number of quantization , the variance of quantization is proportional to the variance of the signal being , i . e ., there such that 
 If no clipping is used i . e ., if , then exactly to the of . If , then is a good a approximation of the of when b in Assumption . In our model , is assumed fixed and given . Strictly speaking , on the of , on the number of quantization of , and on how quantization and are distributed along the dynamic range of . In practice , for a given number of quantization , should be chosen such that the dynamic range of is used efficiently , whilst en 
 Here and in the sequel , we assume the dither is such white and uncorrelated not . 
 a low probability of overload or clipping . For example , for the often uniform with loading factor equal to we obtain assuming that a uniform and overload . We note that for large , and provided overload are negligible , a quadratic relationship between and for most of scalar see , e .., . This is indeed the well known rule of reduction of quantization noise variance per additional bit of resolution . 
 In the sequel , we refer to the model of determined by , , and as The Linear Model the Linear Model is exact if the a enough quantization to avoid overload . If not enough quantization are available and dither is used jointly with clipping , then the model is exact in the effects of granular quantization , and is a good approximation in the total if Assumption also . If the scalar is , a small quantization interval relative to and enough quantization to avoid overload , then the Linear Model can be to yield a good approximation of the total . Perhaps surprisingly , the Linear Model turns out to predict with remarkable accuracy the of an optimal when few quantization and clipping are used with a loading factor big enough to satisfy Assumption , even without dither , and even for a bit . This can be from the simulation in Section . 
 We shall restrict the search for the optimal to those satisfying the following constraint . 
 As in Section I , the first constraint perfect reconstruction . As in Section A , the stability on are a necessary condition for the converter to be stable . The additional requirement on , namely strict causality , is for the feedback loop in Fig . to be well defined see , e .., . Notice that we will not a require to have only inside the open unit disk . Instead , we will show that the latter property naturally from the solution of the design optimization problem . 
 An additional constraint on from the value of , as next . The ratio between the of and 
 One can see from the above that if , then any filter or scaling of the quantization of will yield , thus , making large overload or clipping inevitable . This would and , if no clipping is used , may lead to large limit cycle . We , thus , conclude that the use of feedback the following constraint . Constraint : 
 If the above constraint is met , then can be found by substituting into . This 
 Given the model in the previous section , we can now evaluate the quantity that we aim to minimize , namely , the frequency weighted mean squared error . From c , and and , it that the is given by 
 of the in the Linear Model can be stated as . Optimization Problem : For given , and for given and satisfying Assumption , find the frequency , and satisfying and that minimize 
 The following proposition us to further reduce the number of in by the optimal 
 the following change of : 
 proof of Proposition in the Appendix , Constraint is satisfied . In addition , a stable and strictly causal 
 i . e ., one satisfying Constraint always to a function , see , which 
 This result directly from formula see also the Bode Integral Theorem in , e .., . 
 On the other hand , as we shall see in Section , if Assumption , then the optimal within the set of by and the requirement turns out to be piece wise differentiable on , at most a finite number of discontinuity , and 
 Under these , it is always possible to find a stable and strictly causal filter such that arbitrarily well on , as stated in the following lemma . 
 , that it at most a finite number of discontinuity and that it . Then , for every , there 
 Optimization Problem : For given and known and for satisfying Assumption , find 
 the optimal feedback filter , say , via see also Lemma . In the following section , we will show how to solve this optimization problem . 
 It would be desirable to provide an explicit analytical solution to Optimization Problem . Unfortunately , and as will become apparent in the discussion later , a closed form solution , for arbitrary , infeasible . Nevertheless , we can provide a one parameter characterization of the optimal function in as . 
 Theorem : For any given satisfying Assumption , and for any , the function in to the one parameter family of , where 
 Here is the lower bound of feasible , and , if it , is the unique scalar such that 
 Note that the above result an explicit analytic expression for , once the optimal , defined as 
 Theorem can be used to develop an efficient algorithm to solve Optimization Problem . The key point is that substitution of a into the search space from the infinite dimensional set to the real interval . More precisely , Optimization Problem is turned into the simpler problem of finding the minimizer of the single variable scalar function 
 , and hence the solution of Optimization Problem is unique . Furthermore , can be by finding the root of a scalar , convex , and monotonically decreasing function . 
 Moreover , it from and that , for any satisfying Assumption , and for any , the global minimizer of and is unique . In addition , these guarantee that can be easily found by , via , for example , the bisection algorithm , or any other convex optimization method . 
 We can now express and the minimum achievable , namely , in of , and . Indeed , combining and a with after some algebraic simplification that 
 It can be seen from a that is a monotonically increasing function of . In view of Theorem , this that , as , is monotonically decreasing with increasing . As a consequence , the converse of Optimization Problem , namely , finding the optimal and minimum of for a given target distortion , can be by and . Moreover , since the of a is a concave , monotonically increasing function of , this parameter can be easily found by standard iterative , as in the original optimization problem . 
 It is also interesting to note that and a , which relate and via the parameter , have a structure akin to the well known reverse water filling see , e .., , and . The latter characterize the rate distortion function for . 
 To summarize , we have given an explicit analytic expression for the optimal and , once been determined . Furthermore , we have shown that the parameter always , is unique , and can be easily found simple numerical . 
 In the following , we will provide additional insight into the of , as well as into some of optimal , 
 In the sequel , we say that a is optimal or if its , satisfy for negligibly small of and , and is such that , a . e . on , with as defined by . 
 It from and that , for any given satisfying Assumption , in a the family of all noise shaping that are optimal for some . 
 As we will show , from to equivalently , from to one to undergo a smooth progression from full noise shaping to no noise shaping , in an optimal manner . An example of this progression is shown in Fig . . Note in this figure how solid a unit transfer function as the for which in the figure , becomes smaller and . It can also be that the inverse of is . 
 Such asymptotic convergence does indeed take place in general , as the following theorem : 
 Theorem : For any satisfying Assumption , the defined in a converge uniformly to 
 as . Similarly , for any function satisfying condition i in Assumption , the defined in a converge uniformly to 
 , which the to a converter . In view of , this no noise shaping scenario is asymptotically optimal as . In turn , defined in to the full whitening feedback in , , . From and , is optimal . See also the discussion in Section . 
 The Output of the : By looking at Fig . and Assumption , we find that the of in an is given by 
 and , we conclude that the variance of the quantization noise in an is given by 
 a been used . Substitution of a and into this expression to 
 , the output of the in an is white . This that near optimal of the output can be with a memory less entropy coder . 
 The Frequency Weighted Reconstruction Error : The of the frequency weighted reconstruction error is given by of into the above . 
 Thus , we conclude that the frequency weighted quantization error in an is not white . This fact in stark contrast to the when the are without the perfect reconstruction constraint , see , e .., . It also from the result when the feedback filter is fed back quantization error , as in and . Note that , as is made , not only becomes smaller , but its asymptotically a constant function over the 
 It is well known that i . e ., sampling a continuous time signal at a frequency above its rate one to smaller error for a given , fixed number of quantization . For instance , the of simple scalar quantization without feedback is known to decrease as , see , where is the ratio , given by the order of the feedback filter see also recent work in . From a rate distortion viewpoint , the inversely polynomial error decay of this error estimate is too slow to compensate for the increase in the overall bit rate due to which is proportional to . To be more precise , let us consider a scalar with quantization , where the quantization resolution in per sample . If the additional by was instead to increase , then the would decay as , i . e ., exponentially . 
 A faster decay of the of with can be by a different feedback filter with possibly different order for each ratio . An example of such a family of bit was given in . Here , the continuous time reconstruction error can be uniformly bounded by is independent of . This bound an that with as , which is faster than any inverse polynomial , but still far from 
 Strictly speaking , this only for whose have finite support . Indeed , it been shown that for several infinite support , the of uniform quantization asymptotically faster than , where a is a constant independent of , see . 
 exponential . Based on this result , the family of bit in achieve an that is , i . e ., increasing . Notably , the in and were an exact , deterministic model of quantization . 
 We will next show that , within the Linear Model , if the optimal infinite order in Section are used for each value of , then one can achieve an exponential decay of with the ratio , provided is kept constant . If the input sequence is from sampling a band limited signal , would cause defined in to vary with . To capture this effect , we replace 
 In , the square root of the of the frequency weighted input without , and . Notice that , that is , the total power of in of variance per sample , remains constant for all . This a uniform comparison basis for the distortion . 
 to the output of . Interestingly , it is possible to establish a precise exchange formula for and . Indeed , in of minimal achievable distortion , the effect of increasing equivalent to an exponential increase in the output of . This is shown in the next theorem : 
 Theorem : Under the Linear Model in Section , for any function , and for any , the minimum achievable : 
 If we assume that exponentially on the number of per sample , then Theorem an that exponentially with , provided the Linear Model and that optimal , and by , a and are employed for each . The following simple example this idea : 
 is constant , without . For this setup , the optimal for our model of is 
 , i . e ., a converter . From , the minimum without i . e ., with becomes 
 where . To analyze behavior of in this case , we apply Theorem to the above expression . 
 for all . Note that , to achieve , needs to be according to b and . Therefore , for this example , the of an with fixed an exponential decay with the ratio since , by definition 
 being a uniform with many and operating with a loading factor of , then becomes 
 posing that and hold , we obtain from that is lower and upper bounded by proportional to 
 . For loading factor of , , and , the exponent in the latter expression to , respectively . 
 The next theorem that the exponential decay of the in the example above can be extended to arbitrary band limited input and frequency weighting criteria . 
 Thus , under the Linear Model , we have that the of an exponentially with . 
 Remark : Model in Section . Here it is convenient to present some further regarding the validity of that model when the ratio to infinity , for different of a . 
 As already in Section , if is bounded and a sufficiently large number of quantization to avoid overload is used together with dither , then the Linear Model is exact . Nevertheless , there is no guarantee that the number of necessary quantization to avoid overload remains constant as . If such number with , then can only be kept constant by increasing the number of quantization in the . 
 If the number of quantization is insufficient to avoid clipping overload , and if dither and clipping are used with a fixed loading factor , then there a certain finite value of beyond which Assumption is . This from the fact that , for any fixed loading factor , the effect of clipping in the output does not decay with , thus , becoming the dominant component in the for sufficiently high . Further reduction of the would then require one to balance clipping and granular quantization by increasing the loading factor . If the number of quantization is fixed , this would necessarily reduce the value of , clearly increasing the component of the due to granular quantization . Nevertheless , if clipping and dither are used with , then the Linear Model and Theorem is exact in the due to granular quantization . 
 If one tried to optimize the of a fed back quantization noise , i . e ., by trying to minimize 
 Theorem . This to the result in 
 , the noise transfer function magnitude is also equivalent to that derived in . The latter is optimal in the sense of the ratio , but not in the sense of for a fixed . 
 As shown in Theorem in general , does approach as . One can then expect to be near optimal in where , see . The latter is often satisfied at high bit i . e ., when many quantization are available . However , for any given number of quantization , it is easy to find practical where is such that is comparable to or greater than . More precisely , from , and that see Appendix , one can show that , if over a set of in with measure , where is some positive 
 whose magnitude becomes significantly small in relative over certain frequency . An example is included in Section . A direct consequence is that , for these , and in view of , trying to match to will yield a performance far from optimal , also increasing the risk of large limit cycle if no clipping is employed see , e .., and . 
 was already in . Several heuristic have been since then see , e .., , , , , , and . In contrast to these , the method derived in the present paper one to characterize the true optimal , by explicitly taking into account in the cost functional to be see . Our method not only that , but also the actual optimal . Our proposal also the advantage of being applicable to arbitrary input spectra and frequency weighting , regardless of how small the 
 To illustrate our , we have designed the of a at digitally audio in a as well as the of both the and the numerical are given later . 
 The of audio was as unit variance zero mean white noise through 
 of the frequency response of is in Fig . solid line . The frequency weighting filter considered had a frequency response magnitude which the curve derived in , Table , thus , modeling the sensitivity of human hearing to noise . The corresponding frequency response is plotted with dotted line in Fig . the sampling frequency is . . The resulting 
 for these is also shown in the same figure dashed line . For this choice of , and in view of , one could expect the norm of a full whitening feedback filter to be very large . This is indeed the case : . Thus , the suboptimal feedback filter by the use of a scalar with at least in order to become feasible see Constraint . 
 In the , was chosen to be a uniform mid rise with quantization interval . Several were considered for the , calculated as 
 the loading factor . Two different loading were considered : and . The latter choice a slightly lower than the usual loading factor of . However , this regime the benefit of making overload smaller and more infrequent . As the simulation will show , for our of and , this more conservative loading factor lower 
 Fig . . Frequency response for solid line , dotted line and e e dashed line . 
 For each and corresponding two for , one for each loading factor , the of the converter were designed according to the following : 
 These were then with rational transfer , of order and 
 An appropriate value for the parameter in was chosen via , see , assuming 
 For each combination of and , the resulting converter was two different . 
 , with virtually infinitely many . Thus , for all neither clipping nor overload er 
 and Clipped : Here which a scalar with a finite input dynamic range . As a consequence , any value would overload if or produce clipping error if . To avoid large limit cycle , this variant was clipping i . e ., 
 Each simulation with the comprised , . For the converter , five , were for each combination of 
 The of the numerical and the are next . 
 Comparison Between and the Rate Distortion Function : The information theoretic lower bound see for the associated with the given source and filter is plotted in Fig . solid line . This to quadratic frequency weighted Distortion Rate function when . As the bit rate is , the gap between and this absolute lower bound to approximately . for and for 
 , at . This difference can be to the rate distortion inefficiency of the uniform scalar . On the other hand , the performance gap at lower bit can be to the perfect reconstruction constraint . Recall that , at low bit , the achievement of rate distortion function the suppression of relatively less significant of the of the input signal see , e .., and . This linear distortion , which a cannot achieve , is more severe at lower bit . Thus , the performance gap as is reduced . 
 : The of this converter variant is in four of the in Fig . , with beginning with opt . These differ in the loading factor , and in the meaning of in each case . For the whose do not have the ending E .. entropy , is simply the number to generate the value for which the were . The whose end in E .. correspond to the same , but for each point the value of is the scalar entropy of the output of the converter . It can be seen in Fig . that the for the without entropy is remarkably close to the theoretical value by a . More importantly , even for bit as small as , each ratio from its nominal value of by less than . For the extreme situation , the was slightly lower than , while was higher than due to the highly nonuniform of the resulting sequence . It can also be seen that the scalar entropy of the output of the in these is very close to function for a given distortion . This with the observation that the output of in an is white , see the comment at the end of Section . The difference between these is bigger for lower of , for the same reason in Section . 
 : For the an of , the along with the corresponding 
 that range of bit . This performance degradation can be to clipping . The fact that overload become noticeable only for high bit many quantization might seem , at first , surprising . However , this phenomenon can be easily by that the size of the of the of that fall outside the dynamic range of remains approximately constant in relation to for all . This is a direct consequence of the loading factor rule . In contrast , granular quantization error is proportional to 
 which is constant in the . Therefore , the ratio between clipping and granular quantization approximately as and clipping become dominant for sufficiently high bit . 
 Because of the reduced occurrence and magnitude of clipping , the with 
 and an smaller than that of its counterpart with . Furthermore , this more conservative loading factor the converter to perform almost exactly as by our analytical expression for 
 . For the chosen input and frequency weighting filter , and calculating as , the value of with as shown in Fig . dotted line . As seen in this figure , the gap between and , for each value of , smaller as the bit rate . This with the fact that the optimal a converter as , see Section A . It can also be seen in Fig . that the with and an improvement of over at . Equivalently , in order to obtain the same as that of at , the converter with less than . At lower bit , the improvement of the optimal is also significant . For example , the with a lower than the converter with , thus , a data rate compression of see Fig . . 
 This paper studied perfect reconstruction feedback based on an additive white noise model for quantization . We have derived that relate the minimum frequency weighted and the of the scalar in the converter . We have also provided closed form for the optimal frequency of the in the converter and have derived several of optimal . In particular , we have shown that the optimal frequency response of the are unique , that the frequency weighted of an optimal are nonwhite , and that consecutive of the output sequence of the scalar are uncorrelated . We have also shown that , within our model , exponentially with ratio . 
 The following preliminary are necessary to prove the stated in the previous . We begin by the following definition . 
 We say that two are similarly functionally related there a monotonically increasing function such that , for all , and write . Similarly , if there a monotonically decreasing function such that , for all 
 If and are oppositely functionally related , then the inequality in is reversed . In either case , equality is and therefore is almost constant . 
 Proof : We will examine the difference between the and in . We obtain 
 We now proceed to upper bound the last term in the above inequality . From and , we have that 
 where the last inequality from and . Substitution of into 
 Since is bounded , and from b , it from that for any , one can always choose sufficiently large 
 Denote the squared norm of see via , and define the set of all the the same norm as 
 It is easy to show that must belong to . From this , and since , it that 
 The problem by within the category of isoperimetrical , well known in variational calculus see , e .., and . The standard solution of these is based upon the fact that any that see needs to satisfy 
 We note that for the trivial case in which is almost constant see Definition , is also almost constant . this to constraint i in that , for this case , is such that 
 . Thus , the remainder of the proof only the in which is not almost constant . 
 In order to find , we will next discard the possible of which do not correspond to global of in . The unique function , which is with and in , will characterize the solution of Optimization Problem . 
 The Case : Fore this case , substitution of into that needs to satisfy 
 so that can be explicitly from . Note that cannot be zero in the above expression , otherwise would be undefined . From this , the feasible sign for , the sign before the square root , and in are 
 Option a : We show next that any solution by option a in , say , a greater 
 by Theorem to the numerator of , together with and the fact that . Both are strict since is not almost constant see Theorem and Definition . 
 On the other hand . From the above , it that for all non 
 Option : The candidate are now by and only . a to and , these take the form 
 Combining this result with , and considering to be not almost constant , we obtain 
 response magnitude in the absence of fed back quantization noise recall . This is not surprising , since taking to removing constraint i which the 
 Since the , are continuously differentiable , so is . We , therefore , have that if 
 , then we obtain . This would imply for all such that . Thus , belong to , the integral of over the needs to be infinite . Since ; x , this that infeasible and . 
 We will first elaborate upon to derive . Then we will prove that . 
 where and are as defined in . Application of the identity , which from and a to the numerator on the of 
 The Sign of : Since , this limit needs to be for two possible , depending on whether or not is positive . 
 must necessarily hold in order to obtain . Thus , and its first are continuous . Therefore , in view of , we get 
 , it is clear from that there a value for greater than under which is small enough to render negative . Therefore 
 : In order to show that the and in Theorem hold , we write as 
 We will first prove the validity of . Clearly , if for all condition i of Assumption , then the of the above equation to as 
 . If this the case , then the second condition of Assumption must be satisfied , and therefore the of 
 In order to show that i . e ., , we first note from that for all . On the 
 H . Proof of Theorem c to one can write Since is monotonically decreasing see Theorem 
 to the minimum for a constant , by virtue of we have that . Substitution of this into the last inequality . 
  
 ﻿ We improve the achievable rate for causal and for zero delay source of stationary under an average mean squared error distortion measure . To begin with , we find a closed form expression for the information theoretic causal rate distortion function under such distortion measure , by , for first order Gauss . is a lower bound to the optimal performance theoretically attainable by any causal source code , namely . We show that , for , the latter can also be upper bounded as sample . In order to 
 analyze for arbitrary zero mean stationary , we introduce , the information theoretic causal when the reconstruction error is jointly stationary with the source . Based upon , we derive three closed form upper to the additive rate loss defined as , where . Two of these are strictly smaller than . sample at all . These differ from one another in their tightness and ease of evaluation ; the the bound , the more involved its evaluation . We then show that , for any source spectral density and any positive distortion , can be by an additive white noise channel surrounded by a unique set of causal , post , and feedback . We show that finding such a convex optimization problem . In order to solve the latter , we propose an iterative optimization procedure that the optimal and is to converge to . Finally , by a connection to feedback quantization , we design a causal and a zero delay scheme which , for , an 
 sample , respectively . This that the among all zero delay source , by , is upper bounded as sample . 
 Causality , convex optimization , differential modulation , entropy quantization , noise shaping , rate distortion theory , sequential . 
 N zero delay source , the reconstruction of each input sample must take place at the same time instant the corresponding input sample been . Zero delay source is desirable in many , e .., in real time where one cannot afford to have large , or in feedback , in which the current input on the previous . A notion closely related to the principle behind zero delay is that of causal source , wherein the reproduction of the present source sample only on the present and past source but not on the future source , . This notion does not preclude the use of entropy , and thus , it does not guarantee zero delay reconstruction . Nevertheless , any zero delay source code must also be causal . 
 It is known that , in general , causal cannot achieve the rate distortion function of the source , which is the optimal performance theoretically attainable in the absence of causality . However , it is in general not known how close to one can get when attention to the class of causal or zero delay source , except , for causal , when dealing with memory less , stationary at high resolution , or first order Gauss under a per sample mean squared error distortion metric . 
 For the case of memory less , it was shown by and Gilbert that the optimum rate distortion performance of causal source , say , is by time at most two memory less scalar by entropy . In this case , the rate loss due to causality was shown to be given by the space filling loss of the , i . e ., the loss is at most sample . For the case of stationary with memory and distortion , and that the information theoretic causal , here by 
 to be defined formally in Section and which , to as the distortion goes to zero , . The possible gap between the of causal source and this information theoretic causal was not assessed . Since operational data are lower bounded by the mutual information between the source and its reconstruction , we also have that . 
 On the other hand , for arbitrary stationary with finite differential entropy and under high resolution , it was shown in that the rate loss of causal i . e ., the difference between their and is at most the space filling loss of a uniform scalar . With the exception of memory less and first order Gauss , the price of causality at general rate for other stationary remains an open problem . However , it is known that for any source , the mutual information across an additive white noise channel and across a scalar entropy quantization channel do not exceed by more than . and . sample , respectively , . This immediately the and . 
 In causal source , it is generally difficult to provide a constructive proof of since random construction , which upon jointly long of source , is not directly applicable even in the case of memory less . Thus , even if one could obtain an outer bound for the achievable region based on an information theoretic , finding the inner bound , i . e ., the , would still remain being a challenge . 
 There exist other related to the information theoretic causal , in which is not . The minimum sum rate necessary to sequentially block encode and block decode two scalar correlated random under a coupled fidelity criterion was studied in . A closed form expression for this minimum rate is given in , Th . for the special case of a squared error distortion measure and a per variable as opposed to a sum or average distortion constraint . In , the minimum rate for causally and source under either a per sample or average distortion was given the name sequential rate distortion function . Under a per sample distortion constraint , it was also shown in ,. that for a first order Gauss source , a zero mean white process with variance , the information theoretic the form 
 for all . No are known for for higher order Gauss . Also , with the exception of memory less with its average distortion constraint than a per sample constraint , not been . 
 In this paper , we improve the inner and outer rate distortion for causal and for zero delay source of zero mean stationary and average distortion . We start by showing that , for any zero mean source with bounded differential entropy rate , the causal by less than approximately . sample . Then , we revisit the problem for first order Gauss under a per sample distortion constraint schedule and find the explicit expression for the corresponding by of an alternative , constructive derivation . This expression , which turns out to differ from the one found in , bottom of . , us to show that for first order 
 Gauss , the information theoretic causal for an average as opposed to per sample distortion 
 measure with . In order to upper bound for general stationary , we introduce the information theoretic causal when the distortion is jointly stationary with the source and denote it by . We then derive three closed form upper bounding to the rate loss 
 , which can be applied to any stationary random process . Two of these are , at all , strictly than the best previously known general bound of . sample . Since , by definition we have that 
 . As we shall see , equality would hold in if could be by a test channel with distortion jointly stationary with the source , which a reasonable conjecture for stationary . 
 We do not provide a closed form expression for except for first order Gauss , and thus the upper bound on the right hand side of the bound in this paper is not analytically for the general case . However , we propose an iterative procedure that can be numerically and which one to evaluate , for any source power spectral density and 
 , with any desired accuracy . This procedure is based upon the iterative optimization of causal , post , and feedback around an channel . A key result in this paper and its second main contribution is showing that such filter optimization problem is convex in the frequency of all the . This that the mutual information rate between source and reconstruction by our iterative procedure monotonically to as the number of and the order of the tend to infinity . This equivalence between the solution to a convex filter design optimization problem and the troublesome minimization over mutual , thus making it possible to actually compute in practice , for general stationary . We then make the link between and the of causal and zero delay . More precisely , when the channel is by a uniform scalar by memory less entropy , the with the iterative procedure yield a causal source system whose operational rate is below sample . If the entropy coder in this system is restricted to encode individually as opposed to long of them , then this system zero delay operation with an operational rate sample . This directly into an upper bound to the of zero delay source , namely . To illustrate our , we present an example for a zero mean AR and a zero mean AR source , for which we evaluate the closed form and obtain an approximation of numerically by the iterative procedure herein . 
 This paper is organized as . In Section , we review some preliminary . We prove in Section that the for does not exceed the information theoretic by more than approximately . sample . Section the derivation of a closed form expression for for first order Gauss . In formally introduce and derive the three closed form upper bounding for the information theoretic rate loss of causality . Section the iterative procedure to calculate , after the proof of convexity that its convergence . The two are provided in Section . Finally , Section . Most of the of our are given in . 
 denote , respectively , the set of real and the set of real . and denote , respectively , the of and positive . We use lower case , such as , to denote scalar random , and and to denote and matrices , respectively . We use and to denote the , the column span , and the null space of the matrix , respectively . The expectation operator is by . The notation to the variance of . The notation a one sided random process , which may also be written simply as . We write to refer to the sequence . The of a wide sense stationary process is by 
 . Notice that . For any two we write the standard squared norm and inner product as and , 
 respectively , where complex conjugation . For one sided random and , the term the 
 mutual information rate between and , provided the limit . Similarly , for a stationary random process 
 A source pair a source into binary , from which a reconstruction is . The end to end effect 
 of any pair can be by a series of reproduction , such that , for every 
 where we write as a short notation for . Following , we say that an pair is causal if and only if it the following definition . 
 Definition Causal Source Coder : An pair is said to be causal if and only if its reproduction are such that 
 It also from Definition that an pair is causal if and only if the following chain for every possible random input process : 
 It is worth that if the are random , then this equivalent causality constraint must require that is satisfied for each realization of the 
 be the total number of that the received when it the output subsequence . Define as the random binary sequence that the that the received when is . Notice that is , in general , a function of all source , since the binary may be , i . e ., may be only after the received enough to reproduce 
 , with . We highlight the fact that even though may contain which depend on with , the random may still satisfy , i . e ., the pair can still be causal . Notice also a random variable , which on , the , and on the manner in which the source is into the binary sequence sent to the . 
 For further analysis , we define the average operational rate of an pair as 
 In the sequel , we focus only on the as the distortion measure . Accordingly , we define the average distortion associated with an pair as 
 The allow us to define the operational causal as : 
 We note that the operational causal defined previously to the of all causal . 
 where the last inequality turns into equality for a causal pair , since in that case . Thus , combining , , and 
 This lower bound the study of an information theoretic causal , as defined in the following . 
 Definition : The information theoretic causal for a source , with respect to the average distortion measure , is defined as 
 The definition is a special case of the nonanticipative epsilon entropy by and , which was shown to converge to , for stationary and in the limit as the rate goes to infinity , 
 In the case , it is known that for any source and for any single letter distortion measure , the the information theoretic . Unfortunately , such a strong equivalence between the and the information theoretic 
 . One exception is if one is to jointly and causally encode an asymptotically large number of parallel , of causal . Nevertheless , as outlined in Section I , it is possible to obtain lower and upper to the of causal from . Indeed , and to begin with , since , it directly from and that 
 The previous inequality in is strict , in general , and becomes equality when the source is white or when the rate to infinity . Also , as it will be shown in Section , for , does not exceed by more than 
 For completeness , and for future reference , we recall that for any distortion , the for a stationary source with is equal to the associated , given by the reverse water filling a 
 Although , in general , it is not known by how much , for stationary one can readily 
 More generally , it is known that , for any source , the mutual information across an channel which noise with variance , 
 Until now it been an open question whether a bound than can be for with memory and at general rate . In , we show that for , this is indeed the case . But before on upper for , its operational importance will be established by showing in the following section that , for , the does not exceed by more than approximately . sample . 
 and , an upper bound to can be readily from by approximately . per sample to . This result is first formally stated and proved for finite of any source . Then , it is extended to stationary . We start with two . 
 Definition : The causal information theoretic for a zero mean random vector of length is defined as 
 where the is taken over all output satisfying the causality constraint 
 Definition : The operational causal for a zero mean random vector of length is defined as 
 Lemma : Let be two random with zero mean and the same covariance matrix , i . e . and the same cross covariance matrix with respect to , that is If 
 If furthermore , then equality is in if and only if with and being jointly . 
 Notice that if one Lemma to a reconstruction error with which the output sequence the causality constraint , then the version of the same reconstruction error will also produce an output causally related with the input . To see this , let 
 be the factorization of the covariance matrix of the random vector where is a lower triangular matrix . This one to write as 
 where satisfy . Then , there a set of reproduction satisfying the of Definition which generate each partial vector . Specifically , for any given , there a function , such that . From and given that 
 and thus , for some function . From this and the fact that is independent of , we have that 
 where probabilistic independence . On the other hand , for each let be the minimum mean square error linear estimator of 
 given . Then , the notation for the left corner of a matrix , we have that 
 where from and all the subsequent stem from and from the fact that is lower triangular . Therefore , since the residual is uncorrelated to , it that 
 The result stated in Lemma for random vector is extended to stationary in the following theorem the second main result of this section . 
 The fact that for one to find upper to the of causal by explicitly finding or upper bounding . This is accomplished in the following . 
 In this section , we will find when the source is a Gauss process . More precisely , we will show that the information theoretic causal , which is associated with an average distortion constraint , with the expression for the on the of in for a per sample distortion constraint . To do so , and to provide also a constructive method of realizing the as well as , we will start by an alternative derivation of the for scalar source of length . In this case , from its definition in . . ,. , the the following form : 
 where the is over all conditional of given satisfying the causality constraint and the distortion schedule 
 Before proceeding , it will be convenient to introduce some . , to denote the random column vector and adopt the shorter notation . For any two random , 
 It was already stated in Lemma that the reconstruction vector which mutual information between a source vector and for any given distortion constraint , must be jointly with the source . This , in particular , for a realization of the with distortion schedule . In the next theorem , we will obtain an explicit expression for this and prove that in its realization , the sample 
 Fig . . Recursive Procedure at its th iteration . Starting from known covariance matrices , their next partial and are found . The indicate the step in the algorithm which the corresponding part of the matrix . 
 step is responsible of revealing the partial and by number in the figure . 
 The are formally stated in the following theorem , which also an exact expression for the of first order Gauss . 
 the . Under the latter interpretation , nothing one from choosing an arbitrarily large value for , say , yielding an arbitrarily large value for the second term in the summation on the of , which is , of course , inadequate . 
 We are now in a position to find the expression for for first order Gauss . This is done in the following theorem , whose proof is in Section . 
 The technique applied to prove and does not seem to be extensible to Gauss of order greater than . In the sequel , we will find upper to for arbitrary any order stationary . 
 In order to upper bound the difference between and for arbitrary stationary , we will start this section by an upper bounding function for , by . then derive three closed form upper bounding to the rate loss , applicable to any stationary process . Two of these are 
 Definition Causal Stationary : For a stationary , the information theoretic causal 
 Next , we derive three closed form upper bounding to that are applicable to arbitrary zero mean stationary with finite differential entropy rate . This result is stated in the following theorem , proved in Section : 
 Theorem : Let be a zero mean stationary source with with bounded differential entropy rate and variance . Let denote for given by , and let denote the quadratic for source uncorrelated for the source defined in . Let denote the information theoretic causal see Definition . Then , for all 
 Notice that is independent of , being therefore numerically simpler to evaluate than the other bounding in Theorem . However , as is away from and , becomes very loose . In fact , it can be seen from a that for , the gap between and is actually upper bounded by , which is of course than , but one to evaluate . 
 It is easy to see that time between two causal an output process which causality with a rate distortion pair corresponding to the linear combination of , 
 . Thus , in some , one could get a bound than by considering the boundary of the convex hull of the region above and then . However , such bound would be much more involved to compute , since it to evaluate not only , but also the already convex hull . 
 It is also worth that the first term within the on the of becomes smaller when is reduced . This difference , which from inequality is 
 Fig . . channel within a perfect reconstruction system by the causal filter . 
 always , could be taken as a measure of the of the of especially when . Indeed , as a white process , to zero . 
 It can be seen from that the upper bound for the information theoretic among all so far . Although it does not seem to be feasible to obtain a closed form expression for , we show in the next section how to get arbitrarily close to it . 
 In this section , we present an iterative procedure that one to calculate with arbitrary accuracy , for any . 
 In addition , we will see that this procedure a characterization of the in a feedback that which sample . 
 To derive the previously , we will work on a scheme of an channel and a set of causal , as in Fig . . In this scheme , the source is and stationary , with , and is assumed to 
 is a zero mean process with i . i . independent of . Thus , between and the channel . The filter is stable and strictly causal , i . e ., it at least a one sample delay . The are causal and stable . The idea , to be in the remainder of this section , is to first show that with the that minimize the variance of the reconstruction error for a fixed ratio , the system of Fig . a mutual information rate between source and reconstruction equal to , with a reconstruction equal to . We will then show that finding such is a convex optimization problem , which naturally an iterative procedure to solve it . 
 In order to analyze the system in Fig . , and for notational convenience , we define 
 The perfect reconstruction condition a division , convenient of the optimization problem associated with it . On the one hand , because of , the net effect of the channel and the and is to introduce 
 colored stationary additive noise , namely , independent of the source . The of this noise is given by 
 The diagram in Fig . how the signal transfer function and the noise transfer function act upon and to yield the output process . 
 On the other hand , by looking at Fig . , one can see that also the role of a filter , which can be to reduce additive noise at the expense of linear upon the stationary corrupted by additive stationary noise 
 On the of , the first term is the variance of the additive , source independent , noise . The second term to the error due to linear distortion , that is , from the deviation of from a unit gain . 
 Since we will be interested in , for any given and , the and in Fig . are chosen so as to minimize in , while still satisfying . From the viewpoint of the subsystem comprised of the and and the channel , as an error frequency weighting filter , see . Thus , for any and , the that minimize are those in , Prop . , by setting in b equal to . With the minimizer in , the variance of the source independent error term is given by 
 On the other hand , the filter needs to be strictly causal and stable . As a consequence , it that 
 which from formula see also the Bode Integral Theorem in . 
 Thus , from and , if one to minimize the reconstruction by choosing appropriate causal in the 
 where the space of all frequency that can be with causal . 
 From the lemma , whose proof can be found in Section , one can find either by the minimization in Definition or by Optimization Problem . In the following , we will pursue the latter approach . As we shall see , our formulation of Optimization Problem a convenient of its decision . In fact , it defined in a with respect to the set of all causal frequency involved . That result can be directly from the following key lemma , proved in Section : 
 Proof : With the change of in , we obtain , see . With this , Optimization Problem to finding the and that 
 Clearly , the space of frequency associated with causal transfer is a convex set . This that is a convex set . In addition , is also a convex set , and from Lemma , is a convex functional . Therefore , the optimization problem stated in , and thus 
 Lemma and the in Optimization Problem allow one to define an iterative algorithm that , as will be shown later , the information theoretic causal . Such algorithm is in iterative Procedure . 
 Notice that after Step in the first iteration of Procedure , the is comprised of only additive noise independent of the source . Step then the by source independent noise at the expense of linear distortion . Each step the until a local or global minimum of the is . Based upon the Problem , the following theorem , which is the main technical result in this section , convergence to the global minimum of the , say , for a given end to end mutual information . Since all the in Optimization Problem are causal , the mutual information at this global minimum is equal to . 
 Theorem Convergence of Iterative Procedure : Iterative Procedure monotonically to the unique and that realize . More precisely , denote the 
 Indeed , after Step for the first time , the resulting rate is the quadratic for source uncorrelated in see also . 
 Fig . . Uniform scalar and dither forming an , the channel of the system from Fig . . 
 Fig . . in sample and several upper bounding for for zero mean unit variance white noise through . The resulting source variance is . . 
 after the th iteration of Iterative Procedure at a target rate , we have that 
 Proof : The result directly from the fact that Optimization Problem is strictly convex in and , which was shown in Lemma , and from Lemma . 
 The theorem that the stationary information theoretic causal can be by Iterative Procedure . In practice , this that an approximation arbitrarily for a given can be if sufficient of the procedure are carried out . 
 The feasibility of running Iterative Procedure on being able to solve each of the minimization sub involved in and . We next show how these can be . 
 If is given , the minimization problem in Step of Iterative Procedure is equivalent to a feedback design problem with the constraint and with error weighting filter . Therefore , the solution to Step is given in closed form by , , and b , where in b is by . The latter 
 Fig . . in sample and several upper bounding for for zero mean unit variance white noise through . The resulting source variance is . . 
 in characterize the frequency response of the optimal , and given . The existence of rational transfer and arbitrarily close in an sense to such frequency response is also shown in . 
 Finding the causal frequency response that for a given is equivalent to 
 for a given , where is as defined in . Since are convex , is a convex optimization problem . As such , its global solution can always be found iteratively . In particular , if is constrained to be an th order finite impulse response FIR filter with impulse response , such that the discrete time 
 is a convex functional . The latter directly from the convexity of and the linearity of . As a consequence , one can solve the minimization problem in Step , to any degree of accuracy , by over the of the impulse response of , standard convex optimization see , e .., . This approach also the benefit of being amenable to numerical computation . 
 It is interesting to note that if the order of the filter were not a restricted , then , after Iterative Procedure 
 Wiener filter i . e ., the causal estimator for the noisy signal that comes out of the perfect reconstruction system that . Notice also that one can get the system in Fig . to yield a realization of Iterative Procedure by simply to be . This would yield a system equivalent to the one that was analytically in . An important observation is that one could not obtain a realization such a system in one step by simply a Wiener filter by the causal estimator that is , a causal Wiener filter . To see , and would no longer be optimal for . One would then have to change , and then again , and so on , thus to carry out infinitely many recursive optimization . However , a causally truncated version of the non causal Wiener filter that could be used as an alternative starting guess in Step of the iterative procedure . 
 If the channel in the system of Fig . is by an , as shown in Fig . , then instead of the noise 
 , we will have an i . i .. process independent of , whose are uniformly distributed over the quantization interval . The dither signal , by , is an i . i .. sequence of uniformly distributed random , independent of the source . Let be the output of the . Denote the resulting input and the output to the , before and after the dither , respectively , as and , and let be the quantization noise by the . Notice that the of are independent , both mutually and from the source . However , unlike and , the and are not , since they contain of the uniformly distributed process . We then have the following . 
 Theorem : If the scheme shown in Fig . the by Iterative Procedure , and if long of the output of this system are entropy conditioned to the dither in a memoryless fashion , then an operational rate satisfying 
 , and linear time invariant a reconstruction error jointly stationary with the source , it that the operational rate distortion performance of the feedback thus is within 
 Remark : When the rate goes to infinity , so does . In that limiting case , the transfer function to unity , and it from that the optimal asymptotically satisfy 
 Moreover , when , the system of Fig . which , in this asymptotic regime , with 
 If the requirement of zero delay , which is than that of causality , was to be satisfied , then it would not be possible to apply entropy to long of . This would entail an excess bit rate not greater than bit per sample , see , e .., , Sec . . . Consequently , we have the following result . 
 Theorem : The of zero delay , say , can be upper bounded by the operational rate of the scheme of Fig . when each output value is entropy independently , conditioned to the current dither value . Thus 
 The . sample in , commonly to as the space filling loss of scalar quantization , can be reduced by vector quantization , . Vector quantization could be applied while causality and without delay if the of the source were dimensional . This would also allow for the use of entropy over 
 dimensional of , which the extra bit sample at the end of to sample see , Th . . . . 
 It is worth that Lemma and the an interesting fact : the rate loss due to causality for with memory , i . e ., the difference between the of causal and , is upper bounded by the sum of two . The first term is . sample , and from the space filling loss associated with scalar quantization , as was also pointed out in for the high resolution situation . This term is associated only with the . For a scalar stationary source , such excess rate can only be by jointly of consecutive source vector quantization , i . e ., by for or by several parallel . The second term can be to the reduced of causal , to those of or smoothing . The contribution of the causal filtering aspect to the total rate loss is indeed . This latter gap can also be associated with the performance loss of causal . 
 As a final remark , we note that the architecture of Fig . , which us to pose the search of as a convex optimization problem , is by no the only scheme capable of the upper and . For instance , it can be shown that the same performance can be removing either or in the system of Fig . , provided an entropy coder with infinite memory is used . Indeed , the theoretical among causal of the differential pulse code , with estimation at the end , been shown in a different setting . 
 To illustrate the upper in the previous , we here evaluate and , and calculate an approximation of via Iterative Procedure , for two zero mean AR and AR . These were by the recursion 
 where the of the process are i . i .. zero mean unit variance random . 
 Iterative Procedure was carried out by to be an eight tap FIR filter . For each of the target considered , the procedure was stopped after four complete . 
 The first order source Source was chosen by setting the of the in to be . This to zero mean , unit variance white noise through the coloring transfer function . The second order source Source of zero mean , unit variance white noise through the coloring transfer function . The resulting upper for Source and Source are shown in . and , respectively . As by and , all the upper for derived in to 
 in the limit of both large and small i . e ., when and , respectively . 
 For both , the gap between and is significantly smaller than . sample , for all at which was . Indeed , this gap is smaller than . 
 For the first order source , the magnitude of the of the FIR filter rapidly with coefficient index . For example , when running five of Iterative Procedure , a tenth order FIR filter for , for Source at sample , the was 
 Such fast decay of the impulse response of that , at least for AR , there is little to be by be an FIR filter of order . It is worth that , in the iterative procedure , the initial guess for is a unit scalar gain . The frequency response magnitude of is plotted in Fig . , together with and the resulting frequency after for a target rate of . 
 Notice that for Source , after four of Iterative Procedure , the for are almost identical to 
 , according to . This that Iterative Procedure fast convergence . For example , when four of Iterative Procedure to Source with a target rate of . sample , the after each iteration were . , . , . , and . , respectively . For the same source with a target rate of . sample , the distortion took the . , . , . , and . as the . A similar behavior is for other target , and for other of in as well . Thus , at least for AR , one close to the global optimum after just three . 
 In this paper , we have and upper to the causal and zero delay rate distortion function for stationary and as the distortion measure . We first that for with bounded differential entropy rate , the causal does not exceed the information theoretic by more than approximately . sample . After that , we derived an explicit expression for the information theoretic under per sample distortion a constructive method . This result was then for a closed form formula for the causal information theoretic of first order Gauss under an average distortion constraint . 
 We then derived three closed form upper bounding to the difference between and . Two of these bounding are than the previously best known bound of . sample , at all . We also provided a fourth upper bound to that is constructive . More precisely , we provide a practical scheme that this bound , based on a noise shaped predictive coder of an channel surrounded by , post , and feedback . For a given source spectral density and desired distortion , the design of the is convex in their frequency . We an iterative algorithm , which is to converge to the optimal set of unique . Moreover , the mutual information across the channel , monotonically to . Thus , one to solve the more complicated minimization of the mutual information over all possible conditional satisfying the distortion constraint . To achieve the upper on the operational , one may simply replace the channel by a scalar and memoryless entropy conditioned to the dither . 
 We will first show that can be by a vector channel between two square matrices . It was already established in Lemma that an output to a realization of only if it is jointly with the source 
 where the inverse of from the fact that bounded differential entropy . It is clear from and the joint between and that the causality condition is satisfied if and only if the matrix 
 We will now describe a simple scheme which is capable of the joint statistics between and any given jointly with satisfying . 
 Suppose is first by a matrix yielding the random vector . Then a vector with i . i .. with unit variance , independent from , say , is added to , to yield the random vector . Finally , this result is by a matrix to yield the output 
 On the other hand , the joint second order statistics between and are fully by the matrices 
 It can be seen from these that all that is for the system previously to reproduce any given pair of covariance matrices is that the matrices and 
 Thus , can be chosen , for example , as the lower triangular matrix in a factorization of . With this , a tentative solution for could be as , which would satisfy if and only if . The latter if and only if recall that is nonsingular since bounded differential entropy . We will now show that this condition actually by a contradiction argument . Suppose 
 . Since , the former supposition is equivalent to . If this were the case , then there would exist such that and . The latter , combined with , would imply 
 . One could then construct the scalar random variable , which would have nonzero variance . The of from is given by 
 From this , and in view of the fact that is with nonzero variance , we conclude that would be unbounded . However , by construction , the chain , and therefore by the Data Inequality we would have that 
 , that is unbounded too . This the assumption that is a realization of , leading to the conclusion that . There 
 is to satisfy , and thus for every , there exist matrices and which yield an output vector satisfying . 
 The first equality from the data inequality and the fact that is from . To prove that the second equality in , we will prove that 
 . We first have , from , that , which combined with the identity immediately that 
 where the orthogonal projection operator onto a given subspace . Since and is orthogonal to the other two on the of , we have that 
 where the last equality from the fact that is i . i .., which that is independent of the other two in the expression . On the other hand , from 
 Thus , we have , shown at the bottom of the page , where comes from the data inequality , and 
 from the fact that and from . To complete the proof of the second equality in , we note that the data inequality also . 
 Finally , and and replace the noise by the vector of noise with unit variance by independently operating , with their being jointly conditioned to the dither , then the operational data rate would be upper bounded by 
 where is the output of the channel . Since the distortion by the is the same as that with the original channel , we conclude that 
 First , following exactly the same proof as in Lemma in the Appendix , it is straightforward to show that 
 Now , consider the following family of . For some positive integer , the entire source sequence is in of contiguous . and of each block is independent of the and of any other block . As in the scheme in the second part of the proof of Lemma , each source block is by the optimal matrix , the resulting block being and parallel and independent , with their jointly entropy conditioned to the dither . When , the result is then by the optimal post matrix in the proof of Lemma . 
 For such an pair , and from , the operational rate after have been reconstructed is 
 where rounding to the nearest integer since the th sample is reconstructed only after of length are . On the other hand , since the variance of each reconstruction error sample cannot be than the variance source , we with the first is upper bounded as 
 where rounding to the nearest smaller integer . Therefore , for any finite , the average distortion of this scheme when i . e ., when we consider the entire source process . Also , from and we conclude that 
 for every finite . Our aim is to use this result to show that . Since is valid only for 
 finite of , we must resort to the convergence of as . First of all , since is bounded , 
 From Lemma , for any given reconstruction error covariance matrix , the mutual information is if and only if the output is jointly with the source . In addition , for any information between and a jointly 
 , the variance of every reconstruction error sample is if and only if is the estimation error resulting from from , that is , if and only if 
 Thus , hereafter we restrict the analysis to output jointly with and causally related also satisfy . For any such output process , say the following : 
 and thus equality in if and only if the following chain is satisfied : 
 is lower bounded by the of , which in turn only on the error associated with . We shall now see that this lower bound is by a unique set of error , and then show that the resulting bound is achievable while these error . , we have that 
 With this , and since the of when any error variance , the minimum value of the of subject to the 
 see . Therefore , for all causally related to and jointly with satisfying the distortion con 
 Now , we will show that for any distortion schedule , the output by the recursive algorithm of Procedure is such that the lower bound , thus being a realization of . 
 and the , and Source Past Independence which are necessary and sufficient to attain equality in . 
 pose causality . Then , since , it from that the top left square is lower triangular , being 
 This that the top in the th column of depend only on the of above its th row . that , we conclude that is also lower triangular , and thus also causality . Notice that for any given causality up to sample , the by Step is the only vector consistent with satisfying causality up to the th sample . 
 : for . , and mean all . Therefore , the reconstruction vector by the above algorithm for all . 
 Source Past Independence : Since all are jointly , condition is equivalent to 
 Since the above algorithm an output which , , and , for all , this output equality in , thus being a realization of . Notice that once the are given , each step in the recursive algorithm the only and that satisfy , and . Therefore , for any given distortion schedule , the latter algorithm the unique output that . This the proof . 
 Consider the first of input and output . The average distortion constraint here the form 
 Then , we have , shown at the bottom of the page , where the last inequality from inequality and the fact that is a convex function of . Equality is if and 
 . Given that the of is when constraint is active i . e ., by making , we can attain equality in and minimize its by 
 The first inequality in directly from and . For a plain channel with noise variance , the mutual information between source and reconstruction is 
 In both the end to end distortion can be reduced by a scalar gain after the test channel . The optimal minimum gain is . The mutual information from the source to the signal before the scalar gain is the same as that between the source an the signal after it . However , now the resulting end to end distortion is . Therefore , for a given end to end distortion , the distortion between the source and the signal before the optimal scalar gain is 
 where from , , and and by that , from , and from inequality . Notice that the of the first term on the of . 
 The middle term on the of directly from . Finally , for close to , a bound than can be from a as : 
 which is precisely the third term on the of . In the above , a trivially since , and 
 b from inequality . Therefore , equality in b if and only if is white . The validity of the chain of in directly from and . This the proof . 
 Immediately afterward we prove that , despite the distortion and causality , the scheme in Fig . enough of freedom to turn all the above into . That that if we are able to globally over the of the system while satisfying the distortion and causality , then that , say , must satisfy 
 We now proceed to demonstrate the validity of and to state the under which are . The first equality in from the fact that is a i . i .. process . Inequality from the following : 
 where is the signal at the output of , see Fig . . In the above , from the fact that and are independent and from the fact that is strictly causal . As a consequence , is independent of , for all . Inequality from the property , with equality if and only if and are independent , i . e ., if and only if is white . Similarly , since the of are independent . By that is a linear combination of and , it immediately that is independent from upon knowledge of , which to . On the other hand , from the fact that 
 . Equality in from the fact that , if is known , then can be from 
 , and vice , see Fig . . Equality from the fact that there no feedback from to , and thus the chain . On the other hand with equality if and only if is invertible for all for which . Finally , directly from the 
 Since is by definition an , it that , for every , there an output process jointly with , satisfying the causality and distortion and such that . 
 Such output can be by its noise , say , and its signal transfer function , say , by the model in Fig . . 
 chosen in a for simplicity and because , as we shall see next , we have enough of freedom to do so without compromising rate distortion performance . the system of formed by a , c , and b , we obtain 
 that their squared equal their in . To do so , we will make use of the Wiener theorem Theorem in the Appendix . 
 Substitution of the of the second equation of c into the above , together with the Wiener theorem , that there a causal , stable and minimum phase transfer 
 Since can be chosen to be arbitrarily small , it can always be chosen so that , which . Therefore 
 from Theorem that if we construct an output process by the recursive algorithm of that theorem , with the choice , for all , then this output process is such that . 
 Proposition Column Correspondence : Let be a random vector source with covariance matrix . A reconstruction random vector 
 , with , be a random source vector with covariance matrix . A reconstruction random vector 
 Proof : Let us first introduce the notation , the top left of any given square matrix 
 Lemma that , if the reconstruction is the output of a causal Wiener filter applied to the noisy source for some noise vector a condition equivalent to , then and have identical on and above their main . 
 Theorem see ,. : Let be a function defined on . There a unique stable , causal and minimum phase transfer function such that if and only if 
 In ,. , it is stated that is a sufficient condition for such a to exist . However , from , Note ,. and the discrete continuous equivalence in ,. , it that is also necessary . 
  
 import 
 from . corpus import 
 . 
 import os 
 os . 
 ,,,,,,, ,,, ,,,, , 
 , , , ,, , , , , 
 , , , , , , , , , , , , , 
 , , , , , , , , , , 
 ⟨, , ,, , , ,,,,,, 
 , , , ,,,,,, , ,,∤ 
 ⊥, ,, , ,,, , , , , , , , , , , , , , 
 , , , , , ,,,,,,,,,,,,, 
 ,,,,,,,,,,,,,,,,,, 
 ,,,,,,,,, ,, ,,,,,,,,,, 
 ,,,,,,,,,,,,, ,,,, , 
 , , ,,,,,,,,, ,, , 
  
 set . corpus 
 for i in range : 
 if i de para . and i . and i . : 
 i 
 print i 
 open , 
 . read 
 . join . 
 if . lower in or not . 
 for i in : 
 . replace i , 
 for i in : 
 . replace i , 
  
 . join . 
 if . lower in or not . 
  
 open , 
 . write 
 . close 
  
  
 We study the increase in per sample differential entropy rate of random and after being through a non minimum phase discrete time , linear time invariant filter . For discrete time and random , it long been established that this entropy gain ,, the integral of . It is also known that , if the first sample of the impulse response magnitude , then the latter integral the sum of the logarithm of the of the non minimum phase of i . e ., its outside the unit circle , say . These have been derived in the frequency domain as well as in the time domain . In this note , we begin by showing that time domain , which consider finite length and then to infinity , have significant mathematical and , therefore , are inaccurate . We discuss some of the of this oversight when considering random . We then present a rigorous time domain analysis of the entropy gain of for random . In particular , we show that the entropy gain between equal length input and output is upper bounded by and if and only if there an output additive disturbance with finite differential entropy no matter how small or a random initial state . Unlike what with linear , the entropy gain in this case on the distribution of all the involved . Instead , when the input differential entropy to that of the entire longer output of , the entropy gain irrespective of the and without the need for additional exogenous random . We illustrate some of the of these by their in three different . Specifically : a simple derivation of the rate distortion function for non stationary , for 
 In his seminal paper , gave a formula for the increase in differential entropy per degree of freedom that a continuous time , band limited random process u after passing through a linear time invariant continuous time filter . In this formula , if the input process is to a frequency range ,, differential entropy rate per degree of freedom u , and the filter frequency response , then the resulting differential entropy rate of the output process is given by , Theorem 
 The last term on the right hand side of can be understood as the entropy gain entropy amplification or entropy boost by the filter . proved this result by that an filter can be seen as a linear operator that selectively scales its input signal along infinitely many , each of them an orthogonal component of the source . The result is then by writing down the determinant of the of this operator as the product of the frequency response of the filter overfrequency , logarithm and then taking the limit as the number of frequency to infinity . 
 An analogous result can be for discrete time input u and output , and an discrete time filter by them to their continuous time , which 
 is the differential entropy rate of the process u . Of course the same formula can also be by the frequency domain proof technique that in his derivation of . 
 The rightmost term in , which to the entropy gain of , can be related to the structure of this filter . It is well known that causal with a rational transfer function such that i . e ., such that the first sample of its impulse response unit magnitude , then 
 where i are the of and , : is the open unit disk on the complex 
 plane . This a straightforward way to evaluate the entropy gain of a given filter with rational transfer function . In addition , that , if , then such gain is greater than one if and only if outside . A filter with the latter property is said to be non minimum phase ; conversely , a filter with all its said to be minimum phase . 
 appear naturally in various . For instance , any unstable system via linear feedback control will yield transfer which are , . Additionally , also appear when a discrete time with zero order hold equivalent system is from a plant whose number of its number of by at least , as the sampling rate , Lemma . . On the other hand , all linear phase , which are specially for audio and , are , . The same is true for any all pass filter , which is an important building block in signal , . 
 An alternative approach for the entropy gain of is to work in the time do 
 where yn , y y yn and the random vector un is defined likewise . From this , it is clear that 
 regardless of whether i . e ., the polynomial g with magnitude greater than one , which clearly and . Perhaps surprisingly , the above contradiction not only been in previous works such as , , but the time domain formulation in the form of been as a to prove or disprove see , for example , the reasoning in ,. . 
 A reason for why the contradiction between , and can be from the analysis in for an a noisy feedback loop , as the one in Fig . . In 
 Figure . Left : a noisy feedback loop . Right : equivalent system when the feedback channel is noiseless and unit gain . 
 this scheme , a causal feedback channel which the output an exogenous noise random process c to generate its output . The process c is assumed independent of the initial state of , by the random vector x , which finite differential entropy . For this system , it is shown in , Theorem . that 
 with equality a deterministic function of . Furthermore , it is shown in , Lemma . that if 
 x and the steady state variance of asymptotically bounded as , then 
 where pi are the of . Thus , for the case in which , the output y is the result of filtering u by a filter as shown in Fig . right , and the resulting entropy rate of will exceed that of u only if there is a random initial state with bounded differential entropy see a . Moreover , under the latter , , Lemma . that if is stable and x , then this entropy gain will be lower bounded by the right hand side of , which is greater than zero if and only . However , the result in b does not provide under which the equality in the latter equation . 
 Additional and intuition related to this problem can be from in . There it is shown that if is a two sided stationary random process by a state space recursion of the form 
 for some A , , , with unit variance i . i .. u , then its entropy rate will be exactly i . e ., the differential entropy rate of u plus the of with i now being the of A outside the unit circle . However , as noted in , if the same system with zero or deterministic initial state is excited by a one sided infinite 
 i . i .. process u with unit sample variance , then the asymptotic entropy rate of the output process y is just i . e ., there is no entropy gain . Moreover , it is also shown that if is a random sequence with positive definite covariance matrix and , then the entropy rate that of u by the of . This that for an system which a representation of the form , the entropy gain for a single sided i . i .. input is zero , and that the entropy gain from the input to the output plus disturbance is , for any disturbance of positive definite covariance matrix no matter how small this covariance matrix may 
 The previous analysis that it is the absence of a random initial state or a random additive output disturbance that the time domain formulation yield a zero entropy gain . But , how would the addition of such finite energy exogenous random to actually produce an increase in the differential entropy rate which asymptotically the of In a sense , it is not clear from the above what the necessary and sufficient are under which an entropy gain equal to the of the analysis in only a set of sufficient and on second order statistics and to derive the previously . Another important observation to be made is the following : it is well known that the entropy gain by a linear is independent of the input statistics . However , there is no reason to assume such independence when this entropy gain as the result of a random signal to the input of the , i . e ., when the by itself does not produce the entropy gain . Hence , it remains to characterize the set of input statistics which yield an entropy gain , and the magnitude of this gain . 
 The first part of this paper to these . In particular , in Section explain how and when the entropy gain in the above , starting with input and output of finite length , in a time domain analysis similar to , and then taking the limit as the length to infinity . In Section it is shown that , in the output plus disturbance scenario , the entropy gain is at most the of . We show that , for a broad class of input not necessarily or stationary , this maximum entropy gain is only when the disturbance bounded differential entropy and its length is at least equal to the number of non minimum phase of the filter . We provide upper and lower on the entropy gain if the latter condition is not met . A similar result is shown to hold when there is a random initial state in the system with finite differential entropy . In addition , in Section we study the entropy gain between the entire output sequence that a filter as response to a shorter input sequence in Section . In this case , however , it is necessary to consider a new definition for differential entropy , effective differential entropy . Here we show that an effective entropy gain equal to the of is provided the input finite differential entropy rate , even when there is no random initial state or output disturbance . 
 In the second part of this paper we apply the in the first part to three , namely , control , the rate distortion function for non stationary , and the channel capacity with feedback . In particular , we show that equality in b for the feedback system in Fig . left under very general even when the noisy . For the problem of finding the quadratic rate distortion function for non stationary auto regressive , previously in , we provide a simpler proof based upon the we derive in the first part . This proof the result stated in , to a class of non stationary . For the feedback capacity problem , we show that capacity based on a short random sequence as channel input and on a feedback filter which the entropy rate of the end to end channel noise such as the one in , crucially depend upon the complete absence of any additional disturbance anywhere in the system . Specifically , we show that the information rate of such capacity to zero in the presence of any such additional disturbance . As a consequence , the relevance of the robust i . e ., in the presence of feedback capacity of , which to be a fairly unexplored problem , becomes evident . 
 For any system , the transfer function to the transform of the impulse response g , g ,..., i . e . For a transfer function , we denote by n 
 the lower triangular matrix g as its first column . We write as a shorthand for the sequence x ,..., and , when convenient , we write in vector form as , x x , where transposition . Random are non , such as non and , such as . For matrices we use upper case , such as A . We write i A to the note the i th magnitude eigenvalue of A . If An , then 
 Figure . Linear , causal , stable and time invariant input and output , initial state and output disturbance . 
 Ai , the entry in the intersection between the i th row and the th column . We write , with i i , to refer to the matrix formed by the i to i of A . The expression m A m to the square sub matrix along the main diagonal of A , with its top left and bottom right on Am , m and Am , m , respectively . A diagonal matrix whose are the as 
 Consider the discrete time system in Fig . . In this setup , the input u is a random process and the a causal , linear and time invariant system with random initial state vector x and random output disturbance z . In vector notation , 
 where n is the natural response the initial state x . We make the following further the around it : 
 Assumption . is a causal , stable and rational transfer function of finite order , whose impulse 
 It is worth that there is no loss of generality in considering g , since otherwise one can write as g g , and thus the entropy gain by would be plus the entropy gain due to g , which an impulse response where the first sample . 
 Assumption . The disturbance z is independent of u and to a dimensional linear subspace , for some finite . This subspace is by the of a matrix 
 where for the countably infinite size of , such that z . Equivalently , z 
 , where the random vector s , z finite differential entropy and is independent of u . 
 As in the Introduction , we are interested in the entropy the presence or absence of the random u , by 
 In the next section we provide geometrical insight into the behaviour of for the situation where there is a random output disturbance and no random initial state . A formal and precise treatment of this scenario is then in Section . The other are considered in the subsequent 
 In this section we provide an intuitive geometric interpretation of how and when the entropy gain defined in . This understanding will justify the introduction of the notion of an random process in Definition below , which will be shown to play a key role in this and in related . 
 Suppose for the moment Fig . is an FIR filter with impulse response g , g , , i . Notice that this choice , and thus one non minimum phase zero , at . The associated matrix for is 
 whose determinant is clearly one indeed , all its are . Hence , as in the introduction , u , and thus G and in general does not introduce an entropy gain by itself . However , an interesting phenomenon becomes evident by looking at the singular value decomposition 
 of G , given by , where Q and R are unitary matrices and D , d , d , d . In this case , D . , . , . , and thus one of the singular of G is much smaller than the although the product of all singular , as . As will be shown in Section , for a stable such uneven distribution of singular only when non minimum phase . The effect of this can be by looking at the image of the cube 
 , through G shown in Fig . . If the input u were uniformly distributed over this cube of unit 
 Figure . Image of the cube , through the square matrix with , and . 
 volume , then would distribute uniformly over the unit volume parallelepiped in Fig . , and hence u . 
 Now , if we add to a disturbance z , with distributed over . , . independent of u , and with R , the effect would be to thicken the support over which the resulting random vector y z is distributed , along the direction pointed by . with the direction along which the support of is given by q , , the first row of Q , then the resulting support would have its volume significantly , which can be associated with a large increase in the differential entropy of y with respect to u . Indeed , a relatively small variance an still produce a significant entropy gain . 
 The above example that the entropy gain from un to yn as a combination of two . The first of these is the uneven way in which the random vector is distributed over . The second factor is the alignment of the disturbance vector with respect to the span of the subset , i i of of , associated with singular of , indexed by the in the set . As we shall discuss in the next section , non minimum phase , then , as , there will of going to zero exponentially . Since the product of the singular of for all , it that , i must grow exponentially with , where , i is the i th diagonal entry of . This that the span of , i i , compensating its shrinkage along the span of , i i , thus keeping un for all . Thus , as , any small disturbance distributed over the span of , i i , added to , will keep the support of the resulting distribution from shrinking along this subspace . Consequently , the expansion of the span of , i i is no longer , yielding an entropy increase proportional to log , i . 
 The above analysis one to anticipate a situation in which no entropy gain would take place even when some singular of tend to zero as . Since the increase in entropy is made possible by the fact that , as , the support of the distribution of along the span of , i i , no such entropy gain should arise if the support of the distribution of the input un accordingly along the pointed by the , i i of . 
 An example of such situation can be easily as : Let in Fig . have phase and suppose that u is as , where u is an i . i .. random process with bounded entropy rate . Since the determinant of n for all , we have that un u n , for all . On the other hand , yn nu n u n . Since for some finite 
 The preceding discussion that the entropy gain produced the situation shown in Fig . on the distribution of the input and on the support and distribution of the disturbance . This in stark contrast with the well known fact that the increase in differential entropy produced by an invertible linear operator only on its , and not on the statistics of the input . We have also seen that the distribution of a random process along the different within the space which it a key role as well . This the need to specify a class of random which distribute more or less evenly over all . The following section a rigorous definition of this class and a large family of belonging to it . 
 We begin by formally the notion of an entropy balanced process u , being one in which , for every finite , the differential entropy rate of the orthogonal projection of un into any subspace of dimension the entropy rate of u . This idea is precisely in the following 
 Definition . A random process is said to be entropy balanced if , for every , 
 for every sequence of matrices , with . Equivalently , a random process is entropy balanced if every unitary transformation on 
 sequence yn that one cannot predict its last with arbitrary accuracy by its previous , even to infinity . 
 We now characterize a large family of entropy balanced random and establish some of their . Although intuition may suggest that most random such as i . i .. or stationary should be entropy balanced , that statement rather difficult to prove . In the following , we show that the entropy balanced condition is met by i . i .. with per sample probability density function being uniform , piece wise constant or . It is also shown that to an entropy balanced process an independent random independent of the former another entropy balanced process , and that filtering an entropy balanced process by a stable and minimum phase filter an entropy balanced process as well . 
 Proposition . Let u be a i . i .. random process with positive and bounded per sample 
 Lemma . Let u be an i . i .. process with finite differential entropy rate , in which each is distributed according to a piece wise constant in which each interval where this is constant measure greater than o , for some bounded away from zero constant o . Then u is entropy balanced . N 
 Lemma . Let u and v be mutually independent random . If u is entropy balanced , then 
 The working behind this lemma can be intuitively by that to a random process another independent random process can only increase the spread of the distribution of the former , which to balance the entropy of the resulting process along all in space . In addition , it from Lemma that all i . i .. a per sample which can be by uniform , piece wise constant or as many times as are entropy balanced . It also that one can have non stationary which are entropy balanced , since Lemma no for the process v . 
 Our last lemma related to the of entropy balanced that filtering by a stable and minimum phase filter the entropy balanced condition of its input . 
 Lemma . Let u be an entropy balanced process stable and minimum phase filter . Then the also an entropy balanced process . N 
 This result that any stable moving average auto regressive process from is also entropy balanced , provided the of the and regression correspond to a stable filter . 
 We finish this section by pointing out two of which are non entropy balanced , namely , the output of a filter to an entropy balanced input and the output of an unstable filter to an entropy balanced input . The first of these a central role in the next section . 
 In this section we formalize the which were qualitatively outlined in the previous section . Specifically , for the system shown in Fig . we will characterize the entropy gain defined in for the case in which the initial state x is zero or deterministic and there an output random disturbance of possibly infinite length z which Assumption . The following will be instrumental for that purpose . 
 Lemma . Let A be a causal , finite order , stable and minimum phase rational transfer function with 
 Lemma . Consider the system in Fig . , and suppose z Assumption , and that the input process u is entropy balanced . Let the of , where , ,... are the singular of , with , , ,, such that . the number of these singular which tend to zero exponentially as . Then 
 The previous lemma precisely the geometric idea outlined in Section . To see this , notice that no entropy gain is if the output disturbance vector is orthogonal to the space by the . If this were the case , then the disturbance would not be able fill the subspace along which is shrinking exponentially . Indeed , if for all , then 
 , and the latter sum out the one on the of , while limn n nun since u is entropy balanced . On the contrary and loosely speaking , if the projection of the support of onto the subspace by the is of dimension , then remains bounded for all 
 n , and the entropy limit of the sum on the of the possible entropy gain . Notice that because , and thus 
 this entropy gain from the uncompensated expansion of along the space by the 
 Lemma also the following corollary , which that only a filter with outside the unit circle i . e ., an transfer function can introduce entropy gain . 
 Corollary Minimum Phase do not Introduce Entropy Gain . Consider the system shown in Fig . and let u be an entropy balanced random process with bounded entropy rate . Besides Assumption , suppose that is minimum phase . Then 
 Proof : Since is minimum phase and stable , it from Lemma that the number of singular of which go to zero exponentially , as , is zero . Indeed , all the singular vary with . Thus and Lemma directly that the entropy gain is zero since the of is zero . 
 In this section we show that random satisfying Assumption , when added to the input u i . e ., before , do not introduce entropy gain . This result can be from Lemma , as stated in the following theorem : 
 Theorem Input do not Introduce Entropy Gain . Assumption . Suppose that u is entropy balanced and consider the output 
 where b a , with a being a random vector satisfying a , and where . Then , 
 Proof : In this case , the effect of the input disturbance in the output is the forced response it . This response can be as an output disturbance . Thus , the argument of the differential entropy on the of is 
 The proof is by substituting this result into the of and that 
 Remark . An alternative proof for this result can be given based upon the of an sequence , as . Since , , we have that un un . 
 Let and be a matrices with which satisfy and such that is a unitary matrix . Then 
 which is upper bounded for an and , the latter due to u being entropy balanced . On the other hand , since is independent of un , it that un un , 
 We show here that the entropy gain of a transfer function with outside the unit circle is at most the sum of the logarithm of the magnitude of these . To be more precise , the following assumption is . 
 Assumption . The and its transfer , of which are . the number of distinct , given by , i . e ., such that , with li being the multiplicity of the i th distinct zero . We denote by i , where : ,.. ,...,, the distinct zero of associated with the i th non distinct zero of , i . e ., 
 As can be from the previous in this section , we will need to characterize the asymptotic behaviour of the singular of . This is accomplished in the following lemma , which these singular to the of . This result is a generalization of the unnumbered lemma in the proof of , Theorem in the appendix as Lemma , which for FIR 
 transfer , to the case of infinite impulse response transfer i . e ., transfer . 
 where the in the sequence an , are positive and increase or decrease at most 
 Theorem . In the system of Fig . , suppose that u is entropy balanced and that and z satisfy and , respectively . Then 
 where , min , and is as defined in Assumption . Both are tight . The upper bound is if limn n n , where the unitary matrices the 
 Theorem . In the system of Fig . , suppose that u is entropy balanced and that 
 Assumption . Let z be a random output disturbance , such that i , i , and that . Then 
 Here we analyze the case in which there a random initial state x independent of the input u , and zero or deterministic output disturbance . 
 The effect of a random initial state in the output as the natural response it , namely the sequence n . Thus , yn can be written in vector form as 
 This that the effect of a random initial state can be as a random output disturbance , which us to apply the from the previous . 
 Recall from Assumption that is a stable and rational transfer function with . As such , it can be as 
 where is a filter only all the of , and is a FIR filter , all the of . 
 We have already established recall Theorem that the entropy gain by the minimum phase system is zero . It then that the entropy gain can be only by the of and an appropriate output disturbance . Notice that , in this case , the input process w to i . e ., the output sequence to a random input u is independent of since we have the natural response after , hose initial state is now zero . This condition us to directly use Lemma in order to analyze the entropy gain that u after being 
 Theorem . Consider a stable th order filter , and with a random initial state x , such that x . Then , the entropy gain due to the existence of a random initial 
 Proof : Being a and stable rational transfer function , can be as 
 where is a stable transfer function only all the of and with all its at the origin , while is stable and FIR filter , all the of . Let and be the natural of their common random initial state x , respectively , where , . Then we can write 
 Since is stable and , it from Corollary that un for all , and therefore 
 Therefore , we only need to consider the entropy gain by the possibly non minimum to a random output disturbance n , which is independent of the input . Thus , the of Lemma are met considering , where 
 the for , and , , ,. Consequently , it to consider the differential entropy on the of , whose argument is 
 where , un bounded entropy rate and is entropy balanced since is the natural response of a stable system and because of Lemma . We remark that , in , is not independent of x , which one from the proof of Theorem directly . 
 On the other hand , since is FIR of order at most , we have that , where 
 is a non singular upper triangular matrix independent of . Hence , can be written as 
 , where and , . According to , the entropy gain in as long as is lower bounded by a finite constant or if it sub linearly as . Then , we need m n to be a full row ranked matrix in the limit as . However , 
 where m the the . We will now show that these 
 do not go to zero as . Define the matrix such that m . Then , it that , 
 Hence , the minimum singular value of m is lower bounded by the singular value of , for all . But it was shown in the proof of Theorem see page that limn min . this result in and taking the limit , we arrive to 
 is upper and lower bounded by a constant independent v is entropy balanced , m , and , which that the entropy rate in the of to zero . The proof is finished by Lemma . 
 Theorem us to formalize the effect that the presence or absence of a random initial state on the entropy gain similar to those in Section . Indeed , if the random initial state x finite differential entropy , then the entropy gain , since the alignment between x and the is . This us to characterize the behavior of the entropy gain due only to a random initial state , when the initial state x can be written as pst , with , which that x an undefined or differential entropy . 
 Corollary . Consider an FIR , order filter , such that its random initial state can be written as x , where and . Then , 
 where , min ,. The upper bound in is when is a non singular matrix , with defined by n as in Theorem . 
 Proof : The effect of the random initial state to the output sequence y can be written as yn , 
 remains bounded , for , if and only if limn . 
 Define the rank of as ,... If m , then the lower bound is by in . Otherwise , enough such that , 
 We then proceed as the proof of Theorem , by considering a unitary matrix , and a matrix An such that 
 that the lower limit in the latter sum when is a full row rank matrix . the latter into the proof . 
 Remark . If the random initial state x is with , then the entropy gain by an FIR minimum phase at least log . Otherwise , the entropy gain could be identically zero , as long as the of fill only the orthogonal space to the span of the row in m , where En , and m are defined as in the proof of Theorem . 
 Both , Theorem and Corollary , reveal that the entropy gain as long as the effect of the random initial state with the first of , just as in the of the previous section . 
 If there are no and the initial state is zero , then the to an input un is given by . Therefore , the entropy gain in this case , as defined in , is zero , regardless of whether 
 Despite the above , there is an interesting question which , to the best of the knowledge , not been before : Since in any filter the entire output is longer than the input , what would happen if one the differential of the complete output sequence to that of the shorter input sequence As we show next , a proper definition of this question recasting the problem in of a new definition of differential entropy . After providing a geometrical interpretation of this problem , we prove that the new entropy gain in this case is exactly . 
 Suppose u is uniformly distributed over , , . the conventional definition of differential entropy of a random sequence , we would have that 
 In other , the problem in that although the output is a three dimensional vector , it only two of freedom , i . e ., it is restricted to a dimensional subspace of R . This is in Fig . , where the set , , is shown with the u plane , together with its image through as defined in . 
 As can be seen in this figure , the image of the square , through is a dimensional rhombus over which y , y , y uniformly . Since the intuitive notion of differential entropy of an ensemble of random such as how difficult it is to compress it in a fashion to the size of the region by the associated random vector , one could argue that the differential entropy of y , y , y , far from being , should be somewhat than that of u , u since the rhombus , a area than , . So , what does it mean that and why should y , y , y Simply put , the differential entropy to the volume by the support of the probability density function . our example , the latter three dimensional volume is clearly zero . 
 Figure . Support of u laying in the u plane to that of u the rhombus in R . 
 From the above discussion , the comparison between the differential of R and u R of our previous example should take into account in a two dimensional subspace of R . Indeed , since the multiplication by a unitary matrix does not alter differential , we could consider the differential entropy of 
 the matrix with in the singular value decomposition of 
 and is a unit norm vector orthogonal to the of and thus orthogonal well . We are now able to compute the differential entropy in R for , corresponding to the rotated version that its support is now with R . 
 The preceding discussion the use of a version of the notion of differential entropy for a random vector which the number of actually 
 Definition The Effective Differential Entropy . Let be a random vector . be written as a linear transformation , for some u , , then the effective differential entropy defined as 
 It is worth that differential entropy of a vector , whose support is greater than zero , from considering it as the difference between its absolute entropy and that of a random variable uniformly distributed over an dimensional , unit volume region of . More precisely , if in this case the probability density function of y y is integrable , then . . , 
 where is the discrete valued random vector resulting an dimensional uniform with cubic quantization with volume . However , if we consider a support to an dimensional subspace of , i . e ., AT , as in Definition , then the entropy of its version in , say , is distinct from Ay , the entropy of Ay in . Moreover , it turns out that , in general , 
 despite the fact that A . Thus , the definition given by does not yield consistent for the case wherein a random vector a support dimension i . e ., its number of of freedom smaller that its length If this were not the case , then we could redefine by , in a spirit similar to the one behind dimensional entropy . To see this , consider the case in which u uniformly over , and . Clearly , uniformly over the unit length segment the origin with the point . Then 
 The latter example further why the notion of effective entropy is appropriate in the setup considered in this section , where the effective dimension of the random does not coincide with their length it is easy to verify that the effective entropy not change if . Indeed , we will need to consider only which can be by multiplying some random vector u , with bounded differential entropy , by a tall matrix , with as in , which are precisely the by Definition . 
 Theorem . Let the entropy balanced random sequence u be the input of an filter , and let y be its output . Assume that is the transform of the length sequence . Then 
 Theorem that , when considering the full length output of a filter , the effective entropy gain is by the filter itself , without the presence of external random or initial . This may seem a surprising result , in view of the made in the previous , where the entropy gain only when such random exogenous were present . In other , when observing the full length output and the input , the maximum entropy gain of a filter can be in of the volume expansion by the filter as a linear operator , provided we measure effective differential instead of differential entropy . 
 Proof of Theorem : The total length of the output , will grow with the the input , FIR , and will be infinite , . Thus , we define the output length function 
 It is also convenient to define the sequence of matrices , with 
 G ni , i , ni , i . This one to write the entire output of a causal 
 Let the , where , is 
 where the first equality from the fact that un can be written as , which that un un . But 
 G . 
 The product , is a symmetric matrix , with its first column , h h , given by 
 Thus , the sequence to the to of those resulting from the complete convolution , even when the , where the time reversed perhaps infinitely large response . Consequently , the and ¨ theorem , it that 
 In order to finish the proof , we divide by , take the limit as , and replace in the 
 In this section we obtain a simpler proof of a result by Gray , and , which the rate distortion function of a non stationary auto regressive process x of 
 Figure . Block diagram representation of how the non stationary source x is built and then reconstructed as u . 
 a certain class to that of a corresponding stationary version , under distortion . Our proof is based upon the in the previous , and the class of non stationary for which the in are valid . 
 To be more precise , let and be the impulse of two linear time invariant A and A with rational transfer 
 where pi , i ,...,. From these it is clear that A is unstable , A is stable , and 
 A A , ,. Notice also that lim A and lim A pi , and thus 
 Consider the non stationary random source x and the asymptotically stationary source by passing a stationary process w through A and A , respectively , which can be written as 
 A block diagram associated with the construction in Fig . . Define the rate distortion for these two as 
 where , for each , the are taken over all the conditional probability density 
 The above rate distortion have been in for the case in which w is an i . i .. process . In particular , it is explicitly stated in , that , for that case , 
 We will next provide an alternative and simpler proof of this result , and extend its validity for general not necessarily stationary w , the entropy gain of non minimum phase established in Section . Indeed , the approach in is based upon asymptotically equivalent matrices in of the covariance matrices . This w to be and i . i .. and A to be an all pole unstable transfer function , and then , the only non stationary is that from unstable . For instance , a innovation by an unstable filter A would yield a source which cannot be Gray and approach . By contrast , the reasoning behind our proof w be any process , and then let the source be Aw , with A unstable and possibly and stable as well . 
 Theorem . Let w be any stationary process with bounded differential entropy rate , and let 
 Thanks to the in the previous , it is possible to give an intuitive outline of the proof of this theorem given in the appendix , page by a sequence of block . More precisely , consider the shown in Fig . . In the top diagram in this figure , suppose the for the non stationary source . The sequence u is independent of , and the linear filter is such that the error a necessary condition for minimum . The filter is the product of A see in the appendix a stable , filter with unit frequency response magnitude such that . 
 If one now the filter towards the source , then the middle diagram in Fig . is . By doing this , the stationary source with an additive error signal u that the same asymptotic variance as u , reconstructed as u . From the invertibility of , it also that the mutual information rate between and that . Thus , the channel u the same rate and distortion as the . 
 However , if one now a short the error signal u as in the bottom diagram 
 Figure . Block diagram representation of the of in the proof of Theorem . 
 of Fig . , then the resulting additive error term u u will be independent of and will have the same asymptotic variance as u . However , the differential entropy rate of u will exceed that of u by the of . This will make the mutual information rate between and to be less than that between and by the same amount . Hence , be at most . A similar reasoning can 
 Here we revisit the setup shown in Fig . and in Section I . Recall from b that , for this general class of control , it was shown in , Lemma . that 
 By the in show next that equality in b provided the feedback channel the following assumption : 
 Figure . Top : The class of feedback by Assumption . Bottom : an equivalent form . 
 A stable rational transfer such that is , the same unstable as , and the feedback the plant . 
 F is any possibly non linear operator such that , , for all , and 
 An illustration of the class of feedback satisfying this assumption is on top of Fig . . Trivial of satisfying Assumption are a additive channel and by linear . Indeed , an system with a strictly causal transfer function , the feedback channel that Assumption is widely known as a noise shaper with input and post filter , used in , e .. . 
 Theorem . In the control system of Fig . , suppose that the feedback channel Assumption and that the input u is entropy balanced . If the random initial state of the plant , with , x , then 
 Proof : Let and , A . Then , from Lemma in the appendix , the output yn can be written as 
 where the initial state s to yn , the initial state x to the output of , and the initial state x of to yn . Since u is entropy balanced and c finite entropy rate , it from Lemma that u is entropy balanced as well . Thus , we can proceed as in the proof of Theorem to conclude that 
 The feedback information capacity of this channel is by a input , and is given by 
 Figure . Block diagram representation a non white the scheme considered in . 
 where is the covariance matrix of and , for every , the input is to depend upon the channel since there a causal , noise less feedback channel with one step delay . 
 In , it was shown that an auto regressive moving average process of th order , then can be by the scheme shown in Fig . . In this system , is a strictly causal and stable finite order filter and v is with for all such that is with a positive definite covariance matrix . 
 Here we use the in Section to show that the information rate by the capacity scheme in to zero if there any additive disturbance of length at finite differential entropy affecting the output , no matter how small . To see this , notice that , in this case , and for all n , 
 since In . From Theorem , this gap between differential is precisely the entropy gain by In to an input when the output is affected by the disturbance . Thus , from 
 Theorem , the capacity of this scheme will correspond to , where are the of , which is precisely the result stated in , Theorem . . 
 However , if the output is now affected by an additive disturbance d not passing through such that , , with , then we will have 
 But limn n In In , which directly from Theorem to each of the differential . Notice that this result irrespective of how small the power of the disturbance may be . 
 Thus , the capacity scheme in and further studied in , although of theoretical importance , would yield zero rate in any practical situation , since every real signal is unavoidably affected by some amount of noise . 
 This paper provided a geometrical insight and rigorous for the increase in differential entropy rate to as entropy gain by passing an input random sequence through a discrete time linear time invariant filter such that the first sample of its impulse response unit magnitude . Our time domain analysis us to explain and establish under what the entropy gain with what was by , who a approach to a related problem in his seminal paper . In particular , we that the entropy gain only if outside the unit circle i . e ., it is non minimum phase , . 
 This is not sufficient , nonetheless , since the input and output be u and , the difference 
 is zero for all , yielding no entropy gain . However , if the distribution of the input process 
 u a certain regularity condition defined as being entropy balanced and the output the form , an output disturbance with bounded differential entropy , we have shown that the entropy gain can range from zero to the sum of the logarithm of the of the of , depending on distributed . A similar result is if , instead of an output disturbance , we let have a random initial state . We also considered the difference between the differential entropy rate of the entire and longer output of and that of its input , i . e .,, where is the length of the impulse response of . For this purpose , we the notion of effective differential entropy , which can be applied to a random sequence whose support dimensionality smaller than its dimension . Interestingly , the effective differential entropy gain in this case , which is intrinsic to , is also the sum of the logarithm of the of the of , without the need to add or a random initial state . We have some of the of these in three . Specifically , we used the fundamental here to provide a simpler and more general proof to characterize the rate distortion function for non stationary and distortion . Then , we applied our to provide sufficient for equality in an information inequality of significant importance in control . Finally , we that the information rate of the capacity scheme in for the channel with feedback to zero in the presence of any additive disturbance in the channel input or output of sufficient finite length , no matter how small it may be . 
 yn , . Then , where In is the identity matrix . 
 Proof of Lemma : Let be the the sample is constant . Let be the of these . Define the discrete random process c , where i if and 
 where the inequality is due to the fact that un and yn are deterministic of un , and hence un yn . un from we obtain 
 where the last equality from Lemma see Appendix whose are met because , given , the sequence un independent each of them distributed uniformly over a possibly different interval with bounded and positive measure . The opposite inequality is by following the same as in the proof of Lemma , from onwards , which the proof . 
 Proof of Lemma : Let yn , , where is a unitary matrix and where and have . Then 
 Substituting this result into , dividing taking the limit as , and that , since 
 where n is a jointly sequence with the same second order moment as . Therefore , 
 that a bounded second moment at each entry i , and the latter inequality in , 
 Proof of Lemma : Let yn , where is a unitary matrix and where and have . Since , we have that 
 Let be the of , where An is an orthogonal matrix , and is a diagonal matrix with the singular of . Hence 
 It is straightforward to show that the diagonal in are lower and upper bounded by the and singular of , say and , respectively , which 
 where the last equality is due to the fact that u is entropy balanced . This the proof . 
 Proof of Lemma : The fact that limn is upper bounded directly from 
 the fact that A is a stable transfer function . On the other hand , An is positive definite with all its equal to , and so is positive definite as well , with limn . Suppose that limn . If this were true , then it would hold that limn A nA . But A n is the lower triangular matrix associated with A , which is stable since A is minimum phase , that limn A nA , thus leading to a contradiction . This the proof . 
 Notice that . Thus , it only remains to determine the limit of as . We will do this by a lower and an upper bound for this differential entropy and show that these converge to the same expression as . 
 where a from as well to the set , while and stem from the independence between u and z . Inequality is a consequence of , and e from to the set in the second term , and that is not reduced upon the knowledge of . 
 then , by and in , dividing by , and taking the limit , we obtain 
 n un Xi , i m un 
 where the last equality is a consequence of the fact that u is entropy balanced . 
 Notice that by Assumption and thus is restricted to the span of of dimension , for all . Then , for , one can construct a unitary matrix , such that the of An span the space by the of and such that B 
 . Therefore , from , z 
 where and KAn z are the covariance matrices of A and A , 
 respectively , and where the last inequality from . The fact that and are bounded and remain bounded away from zero for all , and the fact that min either sub exponentially since singular decay exponentially to zero , with , imply in that 
 Proof of Lemma : The transfer function can be as , where is stable and minimum phase and is stable with all the non minimum phase of , both being rational . From Lemma , in the limit as , the of are lower and upper bounded by min and T , respectively , where min 
 . Let and the , respectively , with , , , and , , , being the diagonal of the diagonal matrices respectively . Then 
 the i th row of by , i be , we have that , from the Courant theorem that 
 Notice that the of the matrix m n span a space of dimension , ,.., which that one can have m n if . In this case i . e ., if limn m n then the lower bound is by the latter expression into and Lemma . 
 We now consider the case in which limn m n . This condition that there large such that for all . Then , for exist unitary matrices 
 The first differential entropy on the of the latter expression is uniformly upper bounded because u is entropy balanced , m , and . For the last differential entropy , 
 notice that m . Consider the An m , being unitary , being diagonal , . We can then conclude that 
 that A and that is unitary , it is easy to show by the 
 with equality if and only if A . Substituting this into and then the latter into we arrive to 
 Substituting this into , the fact that u is entropy balanced and Lemma the upper bound in . Clearly , this upper bound is if , for example , n n is non singular for large , since , in that case , and we can choose An I 
 Proof of Theorem : As in , the transfer function can be as , where is stable and minimum phase and is a stable FIR transfer function with all the phase of in total . u n , nun , we have that yn nu n , u n un , and that is entropy balanced from Lemma . Thus , 
 This that the entropy gain of due to the output disturbance z to the entropy gain due to the same output disturbance . One can then evaluate the entropy gain of by Theorem to the filter instead of , which we do next . 
 Since only the z are non zero , it that in this case see Assumption . Therefore , m n m n and the sufficient condition given in Theorem will be satisfied for if limn , where now is the left unitary matrix in the . We will prove that this is the case by a 
 Then , there a sequence of unit norm , with for all , such that 
 such that an and . Then , from this definition and from , we have that 
 where the last equality from the fact that , by construction , is in the span of the , together with the fact that is unitary which that . Since the top m 
 where we have applied and the fact that m is bounded and does not depend on . Now , notice that is a matrix with the convolution the impulse response its time reversed version , respectively on its first row and column . It then from , Lemma . that 
 the inequality is strict because all the of are strictly outside the unit disk . Substituting this into we conclude that 
 which . Therefore , to a contradiction , the proof . 
 where b is the first sample in the impulse response of . Notice that that limn n limn n kunk for every sequence of random u with uniformly bounded variance . Since only stable and its coincide exactly with the of A , it that A is a stable transfer function . Thus , the asymptotically stationary process defined in can be as 
 where is a lower triangular matrix with its main diagonal equal to b . 
 The fact that is with b as in that for any un with finite differential entropy 
 For any given , suppose that is chosen and and un are distributed so as to minimize I ; un subject to the constraint E E I E kunk i . e ., , un is a realization of ,, yielding the reconstruction 
 Since we are considering mean squared error distortion , it that , for rate distortion , un must be jointly with . From these , define 
 y n , x n u n , n , n n u n . 
 where is a zero mean vector independent of u n , n with finite differential entropy such 
 that , k . Then , we have that , I ; yn a I ; I n ; n 
 where a from being invertible , is due to the fact that n n u n , because un . The equality from u n un see . Equality in e because n u n , and in because of . The last inequality because n n and n . But from Theorem , limn n u n un , and thus , limn n n ; n . 
 At the same time , the distortion for the source n when reconstructed as n is 
 where a because is bounded , and is due to the fact that , in the limit , is a unitary operator . the of and , we conclude that limn n n ; n ,, and therefore 
 purpose , consider now the asymptotically stationary source n , and suppose that n un ,. Again , n and un will be jointly , satisfying un the latter condition is for minimum . From this , one can propose an alternative realization in which the error The change of and the in this chain of is by the block shown in Fig . . sequence is u , , yielding an output n n u n with n u n . Then 
 where a by that n un and because un , from , is a consequence of n u n , from the fact that n n u n . Finally , e because is invertible for all . Since , asymptotically as , the distortion by yn for the non stationary source is the same which is when n is reconstructed as recall , we conclude that 
 Lemma . Let u be a random process with independent , and where each element is uniformly distributed over possible different , such that ai amin , i , 
 Proof : Without loss of generality , we can assume that ai , for all i otherwise , we could scale the input by amin , which would scale the output by the same proportion , increasing the input entropy by amin and the output entropy by log amin , without the result . The input 
 vector un is confined to an box Un the support of un of volume and entropy 
 these is determined by un to ai , and freely over . Thus , the volume of each box is the product of sizes ai of the associated selected free sweeping . But that ai for all i , the volume of each box can be upper bounded by . With this , the added volume of all the in the original box can be upper bounded as 
 have . From this definition , will distribute over a finite region 
 , corresponding to the projection onto the dimensional span of the of . Hence , is upper bounded by the entropy of a uniformly distributed vector over the same support , i . e ., by , where is the dimensional volume of this support . In turn , 
 is upper bounded by the sum of the volume of all dimensional in 
 the box in which un is confined , which we already by , and which is upper bounded 
 where a because is an orthogonal matrix . correspond to the jointly sequence with the same second order as , and that the distribution differential entropy for a given covariance , we obtain the upper bound 
 where a since the are independent , and from the fact that and from the Courant theorem . Since is bounded for all , 
 we obtain by substituting into that . The combination of this with , the proof . 
 We re state here for completeness and convenience the unnumbered lemma in the proof of , Theorem as : 
 Lemma . Let the function be as defined in but for a transfer function with no and only a finite number of , of which lie outside the unit circle . Then , 
 where the in the sequence an , are positive and increase or decrease at most 
 Lemma . Let be rational transfer function of relative degree , with initial a rational transfer function of initial state s . Let 
 where the initial state of is x and the initial state of can be taken to be x s . 
 Combining the above , it is found related to the input u by the following recursion : 
  
