{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model paths\n",
    "MODEL_TYPE = \"gpt2\" \n",
    "OUTPUT_DIR = f\"../../weights/{MODEL_TYPE}/papers_milan/\"\n",
    "TRAIN_PATH = f\"../../data/papers_milan/train_papers.txt\"\n",
    "TEST_PATH = f\"../../data/papers_milan/test_papers.txt\"\n",
    "VAL_PATH = f\"../../data/papers_milan/val_papers.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params_modeling(output_dir, model_type=\"gpt2\", model_name_or_path=None, train_path=None, eval_path=None, \n",
    "                             do_train=False, do_eval=False, evaluate_during_training=False, line_by_line=False, block_size=-1):\n",
    "    return {\n",
    "    \"output_dir\": output_dir,\n",
    "    \"model_type\": model_type,\n",
    "    \"model_name_or_path\": model_name_or_path,\n",
    "    \"do_train\": \"--do_train\" if do_train else \"\",\n",
    "    \"train_data_file\": train_path if do_train else None,\n",
    "    \"do_eval\": \"--do_eval\" if do_eval else \"\",\n",
    "    \"eval_data_file\": eval_path if do_eval else None,\n",
    "    \"evaluate_during_training\": \"--evaluate_during_training\" if evaluate_during_training else \"\",\n",
    "    \"block_size\": block_size,\n",
    "    \"line_by_line\": \"--line_by_line\" if line_by_line else \"\",\n",
    "    \"fp16\": \"--fp16\",\n",
    "    \"fp16_opt_level\": \"O1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_finetuning = \"\"\"../../transformers/examples/language-modeling/run_language_modeling.py \\\n",
    "    --output_dir={output_dir} \\\n",
    "    --model_type={model_type} \\\n",
    "    --model_name_or_path={model_name_or_path} \\\n",
    "    {do_train} \\\n",
    "    --train_data_file={train_data_file} \\\n",
    "    {do_eval} \\\n",
    "    --eval_data_file={eval_data_file} \\\n",
    "    {evaluate_during_training} \\\n",
    "    --per_device_train_batch_size=1 \\\n",
    "    --per_device_eval_batch_size=1 \\\n",
    "    --block_size={block_size}\n",
    "    --overwrite_output_dir \\\n",
    "    --save_steps 5000 \\\n",
    "    --save_total_limit 5 \\\n",
    "    {line_by_line} \\\n",
    "    {fp16} \\\n",
    "    --fp16_opt_level={fp16_opt_level} \\\n",
    "    --logging_steps 2 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for training from scratch. I turn off evaluate_during_training,\n",
    "#   line_by_line, should_continue, and model_name_or_path.\n",
    "train_params = create_params_modeling(output_dir=OUTPUT_DIR, \n",
    "                                        model_type=MODEL_TYPE,\n",
    "                                        model_name_or_path=MODEL_TYPE,\n",
    "                                        train_path=TRAIN_PATH, \n",
    "                                        eval_path=TEST_PATH, \n",
    "                                        do_train=True, \n",
    "                                        do_eval=True, \n",
    "                                        evaluate_during_training=False,\n",
    "                                        line_by_line=True\n",
    "                                        )\n",
    "\n",
    "val_finetuning_params = create_params_modeling(output_dir=OUTPUT_DIR,\n",
    "                                    model_name_or_path=OUTPUT_DIR,\n",
    "                                    train_path=None, \n",
    "                                    eval_path=VAL_PATH,                                      \n",
    "                                    do_train=False, \n",
    "                                    do_eval=True,\n",
    "                                    line_by_line=True\n",
    "                                    )\n",
    "\n",
    "val_params = create_params_modeling(output_dir=OUTPUT_DIR,\n",
    "                                    model_name_or_path=MODEL_TYPE,\n",
    "                                    model_type=MODEL_TYPE,\n",
    "                                    train_path=None, \n",
    "                                    eval_path=VAL_PATH,\n",
    "                                    do_train=False, \n",
    "                                    do_eval=True,\n",
    "                                    line_by_line=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:42:10 - INFO - transformers.training_args -   PyTorch: setting up devices\n",
      "06/30/2020 16:42:10 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "06/30/2020 16:42:10 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='../../weights/gpt2/papers_milan/', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jun30_16-42-10_Camilo-UbuntuPC', logging_first_step=False, logging_steps=2, save_steps=5000, save_total_limit=5, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, dataloader_drop_last=False)\n",
      "06/30/2020 16:42:10 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/camilojd/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "06/30/2020 16:42:10 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "06/30/2020 16:42:11 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/camilojd/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "06/30/2020 16:42:11 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "06/30/2020 16:42:12 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/camilojd/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "06/30/2020 16:42:12 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/camilojd/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "06/30/2020 16:42:23 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/camilojd/.cache/torch/transformers/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "06/30/2020 16:42:26 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "06/30/2020 16:42:26 - WARNING - transformers.modeling_utils -   Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "06/30/2020 16:42:26 - INFO - transformers.data.datasets.language_modeling -   Creating features from dataset file at ../../data/papers_milan/train_papers.txt\n",
      "06/30/2020 16:42:26 - WARNING - transformers.tokenization_utils_base -   Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'only_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you may want to check this is the right behavior.\n",
      "06/30/2020 16:42:26 - INFO - transformers.data.datasets.language_modeling -   Creating features from dataset file at ../../data/papers_milan/test_papers.txt\n",
      "06/30/2020 16:42:26 - WARNING - transformers.tokenization_utils_base -   Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'only_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you may want to check this is the right behavior.\n",
      "06/30/2020 16:42:26 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n",
      "06/30/2020 16:42:26 - INFO - transformers.trainer -   ***** Running training *****\n",
      "06/30/2020 16:42:26 - INFO - transformers.trainer -     Num examples = 3583\n",
      "06/30/2020 16:42:26 - INFO - transformers.trainer -     Num Epochs = 3\n",
      "06/30/2020 16:42:26 - INFO - transformers.trainer -     Instantaneous batch size per device = 1\n",
      "06/30/2020 16:42:26 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "06/30/2020 16:42:26 - INFO - transformers.trainer -     Gradient Accumulation steps = 1\n",
      "06/30/2020 16:42:26 - INFO - transformers.trainer -     Total optimization steps = 10749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c43104246994e95a87110ad1d6cfb2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c641d1c017144469bb33160d94384f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=3583.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:42:27 - INFO - transformers.trainer -   {'loss': 5.954214572906494, 'learning_rate': 4.9990696809005496e-05, 'epoch': 0.0005581914596706671, 'step': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:42:27 - INFO - transformers.trainer -   {'loss': 5.598135232925415, 'learning_rate': 4.998139361801098e-05, 'epoch': 0.0011163829193413341, 'step': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:42:27 - INFO - transformers.trainer -   {'loss': 4.98131251335144, 'learning_rate': 4.997209042701647e-05, 'epoch': 0.0016745743790120011, 'step': 6}\n",
      "06/30/2020 16:42:27 - INFO - transformers.trainer -   {'loss': 5.079455852508545, 'learning_rate': 4.9962787236021956e-05, 'epoch': 0.0022327658386826683, 'step': 8}\n",
      "06/30/2020 16:42:27 - INFO - transformers.trainer -   {'loss': 4.626350164413452, 'learning_rate': 4.995348404502745e-05, 'epoch': 0.0027909572983533353, 'step': 10}\n",
      "06/30/2020 16:42:27 - INFO - transformers.trainer -   {'loss': 4.750042676925659, 'learning_rate': 4.9944180854032937e-05, 'epoch': 0.0033491487580240022, 'step': 12}\n",
      "06/30/2020 16:42:27 - INFO - transformers.trainer -   {'loss': 5.311662912368774, 'learning_rate': 4.993487766303842e-05, 'epoch': 0.003907340217694669, 'step': 14}\n",
      "06/30/2020 16:42:28 - INFO - transformers.trainer -   {'loss': 4.626871347427368, 'learning_rate': 4.992557447204391e-05, 'epoch': 0.004465531677365337, 'step': 16}\n",
      "06/30/2020 16:42:28 - INFO - transformers.trainer -   {'loss': 4.633468151092529, 'learning_rate': 4.9916271281049404e-05, 'epoch': 0.005023723137036003, 'step': 18}\n",
      "06/30/2020 16:42:28 - INFO - transformers.trainer -   {'loss': 4.4036478996276855, 'learning_rate': 4.990696809005489e-05, 'epoch': 0.0055819145967066705, 'step': 20}\n",
      "06/30/2020 16:42:28 - INFO - transformers.trainer -   {'loss': 4.834054708480835, 'learning_rate': 4.9897664899060384e-05, 'epoch': 0.006140106056377337, 'step': 22}\n",
      "06/30/2020 16:42:28 - INFO - transformers.trainer -   {'loss': 4.626383304595947, 'learning_rate': 4.9888361708065864e-05, 'epoch': 0.0066982975160480044, 'step': 24}\n",
      "06/30/2020 16:42:28 - INFO - transformers.trainer -   {'loss': 5.90561056137085, 'learning_rate': 4.987905851707136e-05, 'epoch': 0.007256488975718672, 'step': 26}\n",
      "06/30/2020 16:42:29 - INFO - transformers.trainer -   {'loss': 5.029845714569092, 'learning_rate': 4.9869755326076844e-05, 'epoch': 0.007814680435389338, 'step': 28}\n",
      "06/30/2020 16:42:29 - INFO - transformers.trainer -   {'loss': 5.589216709136963, 'learning_rate': 4.986045213508234e-05, 'epoch': 0.008372871895060006, 'step': 30}\n",
      "06/30/2020 16:42:29 - INFO - transformers.trainer -   {'loss': 4.731669187545776, 'learning_rate': 4.9851148944087825e-05, 'epoch': 0.008931063354730673, 'step': 32}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:42:29 - INFO - transformers.trainer -   {'loss': 4.611403703689575, 'learning_rate': 4.984184575309331e-05, 'epoch': 0.009489254814401339, 'step': 34}\n",
      "06/30/2020 16:42:29 - INFO - transformers.trainer -   {'loss': 4.471472501754761, 'learning_rate': 4.98325425620988e-05, 'epoch': 0.010047446274072006, 'step': 36}\n",
      "06/30/2020 16:42:29 - INFO - transformers.trainer -   {'loss': 4.545317888259888, 'learning_rate': 4.982323937110429e-05, 'epoch': 0.010605637733742674, 'step': 38}\n",
      "06/30/2020 16:42:29 - INFO - transformers.trainer -   {'loss': 5.127191543579102, 'learning_rate': 4.9813936180109785e-05, 'epoch': 0.011163829193413341, 'step': 40}\n",
      "06/30/2020 16:42:30 - INFO - transformers.trainer -   {'loss': 4.553024649620056, 'learning_rate': 4.9804632989115265e-05, 'epoch': 0.011722020653084008, 'step': 42}\n",
      "06/30/2020 16:42:30 - INFO - transformers.trainer -   {'loss': 4.434962749481201, 'learning_rate': 4.979532979812076e-05, 'epoch': 0.012280212112754674, 'step': 44}\n",
      "06/30/2020 16:42:30 - INFO - transformers.trainer -   {'loss': 4.991727828979492, 'learning_rate': 4.9786026607126246e-05, 'epoch': 0.012838403572425341, 'step': 46}\n",
      "06/30/2020 16:42:30 - INFO - transformers.trainer -   {'loss': 4.672907829284668, 'learning_rate': 4.977672341613174e-05, 'epoch': 0.013396595032096009, 'step': 48}\n",
      "06/30/2020 16:42:30 - INFO - transformers.trainer -   {'loss': 4.512429237365723, 'learning_rate': 4.9767420225137226e-05, 'epoch': 0.013954786491766676, 'step': 50}\n",
      "06/30/2020 16:42:30 - INFO - transformers.trainer -   {'loss': 5.042616367340088, 'learning_rate': 4.975811703414271e-05, 'epoch': 0.014512977951437344, 'step': 52}\n",
      "06/30/2020 16:42:30 - INFO - transformers.trainer -   {'loss': 5.0770275592803955, 'learning_rate': 4.97488138431482e-05, 'epoch': 0.01507116941110801, 'step': 54}\n",
      "06/30/2020 16:42:31 - INFO - transformers.trainer -   {'loss': 4.784116744995117, 'learning_rate': 4.973951065215369e-05, 'epoch': 0.015629360870778677, 'step': 56}\n",
      "06/30/2020 16:42:31 - INFO - transformers.trainer -   {'loss': 4.146842360496521, 'learning_rate': 4.973020746115918e-05, 'epoch': 0.016187552330449346, 'step': 58}\n",
      "06/30/2020 16:42:31 - INFO - transformers.trainer -   {'loss': 4.419312953948975, 'learning_rate': 4.972090427016467e-05, 'epoch': 0.01674574379012001, 'step': 60}\n",
      "06/30/2020 16:42:31 - INFO - transformers.trainer -   {'loss': 4.69534969329834, 'learning_rate': 4.971160107917015e-05, 'epoch': 0.017303935249790677, 'step': 62}\n",
      "06/30/2020 16:42:31 - INFO - transformers.trainer -   {'loss': 4.3406455516815186, 'learning_rate': 4.970229788817565e-05, 'epoch': 0.017862126709461346, 'step': 64}\n",
      "06/30/2020 16:42:31 - INFO - transformers.trainer -   {'loss': 4.365892648696899, 'learning_rate': 4.9692994697181134e-05, 'epoch': 0.018420318169132012, 'step': 66}\n",
      "06/30/2020 16:42:31 - INFO - transformers.trainer -   {'loss': 4.614649772644043, 'learning_rate': 4.968369150618663e-05, 'epoch': 0.018978509628802678, 'step': 68}\n",
      "06/30/2020 16:42:32 - INFO - transformers.trainer -   {'loss': 4.359646797180176, 'learning_rate': 4.9674388315192114e-05, 'epoch': 0.019536701088473347, 'step': 70}\n",
      "06/30/2020 16:42:32 - INFO - transformers.trainer -   {'loss': 4.602043151855469, 'learning_rate': 4.96650851241976e-05, 'epoch': 0.020094892548144012, 'step': 72}\n",
      "06/30/2020 16:42:32 - INFO - transformers.trainer -   {'loss': 4.135887861251831, 'learning_rate': 4.9655781933203094e-05, 'epoch': 0.02065308400781468, 'step': 74}\n",
      "06/30/2020 16:42:32 - INFO - transformers.trainer -   {'loss': 4.983617782592773, 'learning_rate': 4.964647874220858e-05, 'epoch': 0.021211275467485347, 'step': 76}\n",
      "06/30/2020 16:42:32 - INFO - transformers.trainer -   {'loss': 3.8064013719558716, 'learning_rate': 4.9637175551214075e-05, 'epoch': 0.021769466927156013, 'step': 78}\n",
      "06/30/2020 16:42:32 - INFO - transformers.trainer -   {'loss': 4.55860710144043, 'learning_rate': 4.9627872360219555e-05, 'epoch': 0.022327658386826682, 'step': 80}\n",
      "06/30/2020 16:42:32 - INFO - transformers.trainer -   {'loss': 5.030249118804932, 'learning_rate': 4.961856916922505e-05, 'epoch': 0.022885849846497348, 'step': 82}\n",
      "06/30/2020 16:42:33 - INFO - transformers.trainer -   {'loss': 4.766526460647583, 'learning_rate': 4.9609265978230535e-05, 'epoch': 0.023444041306168017, 'step': 84}\n",
      "06/30/2020 16:42:33 - INFO - transformers.trainer -   {'loss': 4.76186728477478, 'learning_rate': 4.959996278723603e-05, 'epoch': 0.024002232765838682, 'step': 86}\n",
      "06/30/2020 16:42:33 - INFO - transformers.trainer -   {'loss': 4.455097675323486, 'learning_rate': 4.9590659596241515e-05, 'epoch': 0.024560424225509348, 'step': 88}\n",
      "06/30/2020 16:42:33 - INFO - transformers.trainer -   {'loss': 4.875946044921875, 'learning_rate': 4.9581356405247e-05, 'epoch': 0.025118615685180017, 'step': 90}\n",
      "06/30/2020 16:42:33 - INFO - transformers.trainer -   {'loss': 4.486190557479858, 'learning_rate': 4.957205321425249e-05, 'epoch': 0.025676807144850683, 'step': 92}\n",
      "06/30/2020 16:42:33 - INFO - transformers.trainer -   {'loss': 4.13785982131958, 'learning_rate': 4.956275002325798e-05, 'epoch': 0.026234998604521352, 'step': 94}\n",
      "06/30/2020 16:42:33 - INFO - transformers.trainer -   {'loss': 4.359389662742615, 'learning_rate': 4.955344683226347e-05, 'epoch': 0.026793190064192018, 'step': 96}\n",
      "06/30/2020 16:42:34 - INFO - transformers.trainer -   {'loss': 4.460237503051758, 'learning_rate': 4.9544143641268956e-05, 'epoch': 0.027351381523862683, 'step': 98}\n",
      "06/30/2020 16:42:34 - INFO - transformers.trainer -   {'loss': 3.9390554428100586, 'learning_rate': 4.953484045027444e-05, 'epoch': 0.027909572983533353, 'step': 100}\n",
      "06/30/2020 16:42:34 - INFO - transformers.trainer -   {'loss': 3.9770612716674805, 'learning_rate': 4.9525537259279936e-05, 'epoch': 0.028467764443204018, 'step': 102}\n",
      "06/30/2020 16:42:34 - INFO - transformers.trainer -   {'loss': 4.906947374343872, 'learning_rate': 4.951623406828542e-05, 'epoch': 0.029025955902874687, 'step': 104}\n",
      "06/30/2020 16:42:34 - INFO - transformers.trainer -   {'loss': 4.177755832672119, 'learning_rate': 4.9506930877290916e-05, 'epoch': 0.029584147362545353, 'step': 106}\n",
      "06/30/2020 16:42:34 - INFO - transformers.trainer -   {'loss': 3.983149766921997, 'learning_rate': 4.9497627686296396e-05, 'epoch': 0.03014233882221602, 'step': 108}\n",
      "06/30/2020 16:42:34 - INFO - transformers.trainer -   {'loss': 3.7263071537017822, 'learning_rate': 4.948832449530189e-05, 'epoch': 0.030700530281886688, 'step': 110}\n",
      "06/30/2020 16:42:35 - INFO - transformers.trainer -   {'loss': 4.826260805130005, 'learning_rate': 4.9479021304307383e-05, 'epoch': 0.03125872174155735, 'step': 112}\n",
      "06/30/2020 16:42:35 - INFO - transformers.trainer -   {'loss': 5.057158708572388, 'learning_rate': 4.946971811331287e-05, 'epoch': 0.03181691320122802, 'step': 114}\n",
      "06/30/2020 16:42:35 - INFO - transformers.trainer -   {'loss': 4.0948100090026855, 'learning_rate': 4.946041492231836e-05, 'epoch': 0.03237510466089869, 'step': 116}\n",
      "06/30/2020 16:42:35 - INFO - transformers.trainer -   {'loss': 3.612423300743103, 'learning_rate': 4.9451111731323844e-05, 'epoch': 0.032933296120569354, 'step': 118}\n",
      "06/30/2020 16:42:35 - INFO - transformers.trainer -   {'loss': 4.407186031341553, 'learning_rate': 4.944180854032934e-05, 'epoch': 0.03349148758024002, 'step': 120}\n",
      "06/30/2020 16:42:35 - INFO - transformers.trainer -   {'loss': 4.446979999542236, 'learning_rate': 4.9432505349334824e-05, 'epoch': 0.03404967903991069, 'step': 122}\n",
      "06/30/2020 16:42:35 - INFO - transformers.trainer -   {'loss': 4.853465795516968, 'learning_rate': 4.942320215834032e-05, 'epoch': 0.034607870499581354, 'step': 124}\n",
      "06/30/2020 16:42:36 - INFO - transformers.trainer -   {'loss': 4.022480607032776, 'learning_rate': 4.94138989673458e-05, 'epoch': 0.035166061959252023, 'step': 126}\n",
      "06/30/2020 16:42:36 - INFO - transformers.trainer -   {'loss': 4.003551244735718, 'learning_rate': 4.940459577635129e-05, 'epoch': 0.03572425341892269, 'step': 128}\n",
      "06/30/2020 16:42:36 - INFO - transformers.trainer -   {'loss': 4.625049591064453, 'learning_rate': 4.939529258535678e-05, 'epoch': 0.036282444878593355, 'step': 130}\n",
      "06/30/2020 16:42:36 - INFO - transformers.trainer -   {'loss': 4.9656243324279785, 'learning_rate': 4.938598939436227e-05, 'epoch': 0.036840636338264024, 'step': 132}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:42:36 - INFO - transformers.trainer -   {'loss': 4.794435977935791, 'learning_rate': 4.937668620336776e-05, 'epoch': 0.03739882779793469, 'step': 134}\n",
      "06/30/2020 16:42:36 - INFO - transformers.trainer -   {'loss': 3.6300346851348877, 'learning_rate': 4.9367383012373245e-05, 'epoch': 0.037957019257605355, 'step': 136}\n",
      "06/30/2020 16:42:36 - INFO - transformers.trainer -   {'loss': 4.864150047302246, 'learning_rate': 4.935807982137873e-05, 'epoch': 0.038515210717276024, 'step': 138}\n",
      "06/30/2020 16:42:36 - INFO - transformers.trainer -   {'loss': 4.246760010719299, 'learning_rate': 4.9348776630384225e-05, 'epoch': 0.039073402176946694, 'step': 140}\n",
      "06/30/2020 16:42:37 - INFO - transformers.trainer -   {'loss': 4.197904586791992, 'learning_rate': 4.933947343938971e-05, 'epoch': 0.03963159363661736, 'step': 142}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:42:37 - INFO - transformers.trainer -   {'loss': 4.079368591308594, 'learning_rate': 4.93301702483952e-05, 'epoch': 0.040189785096288025, 'step': 144}\n",
      "06/30/2020 16:42:37 - INFO - transformers.trainer -   {'loss': 4.257288694381714, 'learning_rate': 4.9320867057400686e-05, 'epoch': 0.040747976555958694, 'step': 146}\n",
      "06/30/2020 16:42:37 - INFO - transformers.trainer -   {'loss': 4.607589244842529, 'learning_rate': 4.931156386640618e-05, 'epoch': 0.04130616801562936, 'step': 148}\n",
      "06/30/2020 16:42:37 - INFO - transformers.trainer -   {'loss': 4.624755382537842, 'learning_rate': 4.930226067541167e-05, 'epoch': 0.041864359475300025, 'step': 150}\n",
      "06/30/2020 16:42:37 - INFO - transformers.trainer -   {'loss': 4.862242698669434, 'learning_rate': 4.929295748441716e-05, 'epoch': 0.042422550934970694, 'step': 152}\n",
      "06/30/2020 16:42:37 - INFO - transformers.trainer -   {'loss': 5.036818027496338, 'learning_rate': 4.9283654293422646e-05, 'epoch': 0.042980742394641364, 'step': 154}\n",
      "06/30/2020 16:42:38 - INFO - transformers.trainer -   {'loss': 4.063532114028931, 'learning_rate': 4.927435110242813e-05, 'epoch': 0.043538933854312026, 'step': 156}\n",
      "06/30/2020 16:42:38 - INFO - transformers.trainer -   {'loss': 3.7065635919570923, 'learning_rate': 4.926504791143363e-05, 'epoch': 0.044097125313982695, 'step': 158}\n",
      "06/30/2020 16:42:38 - INFO - transformers.trainer -   {'loss': 4.807370662689209, 'learning_rate': 4.925574472043911e-05, 'epoch': 0.044655316773653364, 'step': 160}\n",
      "06/30/2020 16:42:38 - INFO - transformers.trainer -   {'loss': 3.6711236238479614, 'learning_rate': 4.924644152944461e-05, 'epoch': 0.04521350823332403, 'step': 162}\n",
      "06/30/2020 16:42:38 - INFO - transformers.trainer -   {'loss': 4.4270899295806885, 'learning_rate': 4.923713833845009e-05, 'epoch': 0.045771699692994695, 'step': 164}\n",
      "06/30/2020 16:42:38 - INFO - transformers.trainer -   {'loss': 4.443131446838379, 'learning_rate': 4.922783514745558e-05, 'epoch': 0.046329891152665365, 'step': 166}\n",
      "06/30/2020 16:42:38 - INFO - transformers.trainer -   {'loss': 4.2753989696502686, 'learning_rate': 4.921853195646107e-05, 'epoch': 0.046888082612336034, 'step': 168}\n",
      "06/30/2020 16:42:39 - INFO - transformers.trainer -   {'loss': 3.6941243410110474, 'learning_rate': 4.920922876546656e-05, 'epoch': 0.047446274072006696, 'step': 170}\n",
      "06/30/2020 16:42:39 - INFO - transformers.trainer -   {'loss': 3.691367030143738, 'learning_rate': 4.919992557447205e-05, 'epoch': 0.048004465531677365, 'step': 172}\n",
      "06/30/2020 16:42:39 - INFO - transformers.trainer -   {'loss': 4.591900825500488, 'learning_rate': 4.9190622383477534e-05, 'epoch': 0.048562656991348034, 'step': 174}\n",
      "06/30/2020 16:42:39 - INFO - transformers.trainer -   {'loss': 4.1139713525772095, 'learning_rate': 4.918131919248302e-05, 'epoch': 0.049120848451018696, 'step': 176}\n",
      "06/30/2020 16:42:39 - INFO - transformers.trainer -   {'loss': 4.775711536407471, 'learning_rate': 4.9172016001488515e-05, 'epoch': 0.049679039910689365, 'step': 178}\n",
      "06/30/2020 16:42:39 - INFO - transformers.trainer -   {'loss': 3.947701334953308, 'learning_rate': 4.9162712810494e-05, 'epoch': 0.050237231370360035, 'step': 180}\n",
      "06/30/2020 16:42:40 - INFO - transformers.trainer -   {'loss': 3.89215886592865, 'learning_rate': 4.915340961949949e-05, 'epoch': 0.050795422830030704, 'step': 182}\n",
      "06/30/2020 16:42:40 - INFO - transformers.trainer -   {'loss': 3.7481465339660645, 'learning_rate': 4.9144106428504975e-05, 'epoch': 0.051353614289701366, 'step': 184}\n",
      "06/30/2020 16:42:40 - INFO - transformers.trainer -   {'loss': 5.010171890258789, 'learning_rate': 4.913480323751047e-05, 'epoch': 0.051911805749372035, 'step': 186}\n",
      "06/30/2020 16:42:40 - INFO - transformers.trainer -   {'loss': 5.001028060913086, 'learning_rate': 4.912550004651596e-05, 'epoch': 0.052469997209042704, 'step': 188}\n",
      "06/30/2020 16:42:40 - INFO - transformers.trainer -   {'loss': 4.598485708236694, 'learning_rate': 4.911619685552145e-05, 'epoch': 0.053028188668713366, 'step': 190}\n",
      "06/30/2020 16:42:40 - INFO - transformers.trainer -   {'loss': 4.305927276611328, 'learning_rate': 4.9106893664526936e-05, 'epoch': 0.053586380128384035, 'step': 192}\n",
      "06/30/2020 16:42:40 - INFO - transformers.trainer -   {'loss': 5.925792455673218, 'learning_rate': 4.909759047353242e-05, 'epoch': 0.054144571588054705, 'step': 194}\n",
      "06/30/2020 16:42:41 - INFO - transformers.trainer -   {'loss': 4.090641617774963, 'learning_rate': 4.9088287282537916e-05, 'epoch': 0.05470276304772537, 'step': 196}\n",
      "06/30/2020 16:42:41 - INFO - transformers.trainer -   {'loss': 3.7911919355392456, 'learning_rate': 4.90789840915434e-05, 'epoch': 0.055260954507396036, 'step': 198}\n",
      "06/30/2020 16:42:41 - INFO - transformers.trainer -   {'loss': 4.061520338058472, 'learning_rate': 4.906968090054889e-05, 'epoch': 0.055819145967066705, 'step': 200}\n",
      "06/30/2020 16:42:41 - INFO - transformers.trainer -   {'loss': 4.880811452865601, 'learning_rate': 4.9060377709554376e-05, 'epoch': 0.056377337426737374, 'step': 202}\n",
      "06/30/2020 16:42:41 - INFO - transformers.trainer -   {'loss': 3.7124441862106323, 'learning_rate': 4.905107451855987e-05, 'epoch': 0.056935528886408036, 'step': 204}\n",
      "06/30/2020 16:42:41 - INFO - transformers.trainer -   {'loss': 4.338734745979309, 'learning_rate': 4.9041771327565357e-05, 'epoch': 0.057493720346078706, 'step': 206}\n",
      "06/30/2020 16:42:41 - INFO - transformers.trainer -   {'loss': 4.2949440479278564, 'learning_rate': 4.903246813657085e-05, 'epoch': 0.058051911805749375, 'step': 208}\n",
      "06/30/2020 16:42:42 - INFO - transformers.trainer -   {'loss': 5.508741617202759, 'learning_rate': 4.902316494557633e-05, 'epoch': 0.05861010326542004, 'step': 210}\n",
      "06/30/2020 16:42:42 - INFO - transformers.trainer -   {'loss': 4.071216702461243, 'learning_rate': 4.9013861754581824e-05, 'epoch': 0.059168294725090706, 'step': 212}\n",
      "06/30/2020 16:42:42 - INFO - transformers.trainer -   {'loss': 4.5925374031066895, 'learning_rate': 4.900455856358731e-05, 'epoch': 0.059726486184761375, 'step': 214}\n",
      "06/30/2020 16:42:42 - INFO - transformers.trainer -   {'loss': 3.975721597671509, 'learning_rate': 4.8995255372592804e-05, 'epoch': 0.06028467764443204, 'step': 216}\n",
      "06/30/2020 16:42:42 - INFO - transformers.trainer -   {'loss': 3.9878408908843994, 'learning_rate': 4.898595218159829e-05, 'epoch': 0.060842869104102706, 'step': 218}\n",
      "06/30/2020 16:42:42 - INFO - transformers.trainer -   {'loss': 3.9668736457824707, 'learning_rate': 4.897664899060378e-05, 'epoch': 0.061401060563773376, 'step': 220}\n",
      "06/30/2020 16:42:42 - INFO - transformers.trainer -   {'loss': 3.7043133974075317, 'learning_rate': 4.896734579960927e-05, 'epoch': 0.061959252023444045, 'step': 222}\n",
      "06/30/2020 16:42:43 - INFO - transformers.trainer -   {'loss': 4.633538722991943, 'learning_rate': 4.895804260861476e-05, 'epoch': 0.0625174434831147, 'step': 224}\n",
      "06/30/2020 16:42:43 - INFO - transformers.trainer -   {'loss': 4.758166790008545, 'learning_rate': 4.894873941762025e-05, 'epoch': 0.06307563494278537, 'step': 226}\n",
      "06/30/2020 16:42:43 - INFO - transformers.trainer -   {'loss': 4.435040712356567, 'learning_rate': 4.893943622662573e-05, 'epoch': 0.06363382640245605, 'step': 228}\n",
      "06/30/2020 16:42:43 - INFO - transformers.trainer -   {'loss': 4.380676031112671, 'learning_rate': 4.8930133035631225e-05, 'epoch': 0.06419201786212671, 'step': 230}\n",
      "06/30/2020 16:42:43 - INFO - transformers.trainer -   {'loss': 3.23842716217041, 'learning_rate': 4.892082984463671e-05, 'epoch': 0.06475020932179738, 'step': 232}\n",
      "06/30/2020 16:42:43 - INFO - transformers.trainer -   {'loss': 3.9362993240356445, 'learning_rate': 4.8911526653642205e-05, 'epoch': 0.06530840078146805, 'step': 234}\n",
      "06/30/2020 16:42:43 - INFO - transformers.trainer -   {'loss': 4.141249418258667, 'learning_rate': 4.890222346264769e-05, 'epoch': 0.06586659224113871, 'step': 236}\n",
      "06/30/2020 16:42:44 - INFO - transformers.trainer -   {'loss': 4.3534674644470215, 'learning_rate': 4.889292027165318e-05, 'epoch': 0.06642478370080938, 'step': 238}\n",
      "06/30/2020 16:42:44 - INFO - transformers.trainer -   {'loss': 4.406991362571716, 'learning_rate': 4.8883617080658665e-05, 'epoch': 0.06698297516048005, 'step': 240}\n",
      "06/30/2020 16:42:44 - INFO - transformers.trainer -   {'loss': 3.984511613845825, 'learning_rate': 4.887431388966416e-05, 'epoch': 0.06754116662015071, 'step': 242}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:42:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8865010698669646e-05, 'epoch': 0.06809935807982138, 'step': 244}\n",
      "06/30/2020 16:42:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.885570750767513e-05, 'epoch': 0.06865754953949205, 'step': 246}\n",
      "06/30/2020 16:42:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.884640431668062e-05, 'epoch': 0.06921574099916271, 'step': 248}\n",
      "06/30/2020 16:42:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.883710112568611e-05, 'epoch': 0.06977393245883338, 'step': 250}\n",
      "06/30/2020 16:42:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.88277979346916e-05, 'epoch': 0.07033212391850405, 'step': 252}\n",
      "06/30/2020 16:42:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.881849474369709e-05, 'epoch': 0.07089031537817471, 'step': 254}\n",
      "06/30/2020 16:42:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.880919155270258e-05, 'epoch': 0.07144850683784539, 'step': 256}\n",
      "06/30/2020 16:42:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.879988836170807e-05, 'epoch': 0.07200669829751605, 'step': 258}\n",
      "06/30/2020 16:42:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.879058517071356e-05, 'epoch': 0.07256488975718671, 'step': 260}\n",
      "06/30/2020 16:42:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.878128197971905e-05, 'epoch': 0.07312308121685739, 'step': 262}\n",
      "06/30/2020 16:42:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8771978788724534e-05, 'epoch': 0.07368127267652805, 'step': 264}\n",
      "06/30/2020 16:42:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.876267559773002e-05, 'epoch': 0.07423946413619871, 'step': 266}\n",
      "06/30/2020 16:42:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8753372406735514e-05, 'epoch': 0.07479765559586939, 'step': 268}\n",
      "06/30/2020 16:42:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8744069215741e-05, 'epoch': 0.07535584705554005, 'step': 270}\n",
      "06/30/2020 16:42:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8734766024746494e-05, 'epoch': 0.07591403851521071, 'step': 272}\n",
      "06/30/2020 16:42:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.872546283375198e-05, 'epoch': 0.07647222997488139, 'step': 274}\n",
      "06/30/2020 16:42:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.871615964275747e-05, 'epoch': 0.07703042143455205, 'step': 276}\n",
      "06/30/2020 16:42:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8706856451762955e-05, 'epoch': 0.07758861289422272, 'step': 278}\n",
      "06/30/2020 16:42:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.869755326076845e-05, 'epoch': 0.07814680435389339, 'step': 280}\n",
      "06/30/2020 16:42:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8688250069773935e-05, 'epoch': 0.07870499581356405, 'step': 282}\n",
      "06/30/2020 16:42:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.867894687877942e-05, 'epoch': 0.07926318727323473, 'step': 284}\n",
      "06/30/2020 16:42:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.866964368778491e-05, 'epoch': 0.07982137873290539, 'step': 286}\n",
      "06/30/2020 16:42:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.86603404967904e-05, 'epoch': 0.08037957019257605, 'step': 288}\n",
      "06/30/2020 16:42:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.865103730579589e-05, 'epoch': 0.08093776165224673, 'step': 290}\n",
      "06/30/2020 16:42:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.864173411480138e-05, 'epoch': 0.08149595311191739, 'step': 292}\n",
      "06/30/2020 16:42:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.863243092380686e-05, 'epoch': 0.08205414457158805, 'step': 294}\n",
      "06/30/2020 16:42:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8623127732812356e-05, 'epoch': 0.08261233603125873, 'step': 296}\n",
      "06/30/2020 16:42:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.861382454181785e-05, 'epoch': 0.08317052749092939, 'step': 298}\n",
      "06/30/2020 16:42:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8604521350823336e-05, 'epoch': 0.08372871895060005, 'step': 300}\n",
      "06/30/2020 16:42:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.859521815982882e-05, 'epoch': 0.08428691041027073, 'step': 302}\n",
      "06/30/2020 16:42:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.858591496883431e-05, 'epoch': 0.08484510186994139, 'step': 304}\n",
      "06/30/2020 16:42:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8576611777839803e-05, 'epoch': 0.08540329332961205, 'step': 306}\n",
      "06/30/2020 16:42:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.856730858684529e-05, 'epoch': 0.08596148478928273, 'step': 308}\n",
      "06/30/2020 16:42:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8558005395850784e-05, 'epoch': 0.08651967624895339, 'step': 310}\n",
      "06/30/2020 16:42:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8548702204856264e-05, 'epoch': 0.08707786770862405, 'step': 312}\n",
      "06/30/2020 16:42:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.853939901386176e-05, 'epoch': 0.08763605916829473, 'step': 314}\n",
      "06/30/2020 16:42:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8530095822867244e-05, 'epoch': 0.08819425062796539, 'step': 316}\n",
      "06/30/2020 16:42:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.852079263187274e-05, 'epoch': 0.08875244208763607, 'step': 318}\n",
      "06/30/2020 16:42:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8511489440878224e-05, 'epoch': 0.08931063354730673, 'step': 320}\n",
      "06/30/2020 16:42:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.850218624988371e-05, 'epoch': 0.08986882500697739, 'step': 322}\n",
      "06/30/2020 16:42:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.84928830588892e-05, 'epoch': 0.09042701646664807, 'step': 324}\n",
      "06/30/2020 16:42:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.848357986789469e-05, 'epoch': 0.09098520792631873, 'step': 326}\n",
      "06/30/2020 16:42:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.847427667690018e-05, 'epoch': 0.09154339938598939, 'step': 328}\n",
      "06/30/2020 16:42:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8464973485905665e-05, 'epoch': 0.09210159084566007, 'step': 330}\n",
      "06/30/2020 16:42:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.845567029491116e-05, 'epoch': 0.09265978230533073, 'step': 332}\n",
      "06/30/2020 16:42:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8446367103916645e-05, 'epoch': 0.09321797376500139, 'step': 334}\n",
      "06/30/2020 16:42:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.843706391292214e-05, 'epoch': 0.09377616522467207, 'step': 336}\n",
      "06/30/2020 16:42:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8427760721927626e-05, 'epoch': 0.09433435668434273, 'step': 338}\n",
      "06/30/2020 16:42:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.841845753093311e-05, 'epoch': 0.09489254814401339, 'step': 340}\n",
      "06/30/2020 16:42:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.84091543399386e-05, 'epoch': 0.09545073960368407, 'step': 342}\n",
      "06/30/2020 16:42:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.839985114894409e-05, 'epoch': 0.09600893106335473, 'step': 344}\n",
      "06/30/2020 16:42:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.839054795794958e-05, 'epoch': 0.09656712252302539, 'step': 346}\n",
      "06/30/2020 16:42:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8381244766955066e-05, 'epoch': 0.09712531398269607, 'step': 348}\n",
      "06/30/2020 16:42:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.837194157596055e-05, 'epoch': 0.09768350544236673, 'step': 350}\n",
      "06/30/2020 16:42:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8362638384966047e-05, 'epoch': 0.09824169690203739, 'step': 352}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:42:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.835333519397153e-05, 'epoch': 0.09879988836170807, 'step': 354}\n",
      "06/30/2020 16:42:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.834403200297703e-05, 'epoch': 0.09935807982137873, 'step': 356}\n",
      "06/30/2020 16:42:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8334728811982514e-05, 'epoch': 0.09991627128104939, 'step': 358}\n",
      "06/30/2020 16:42:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8325425620988e-05, 'epoch': 0.10047446274072007, 'step': 360}\n",
      "06/30/2020 16:42:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.831612242999349e-05, 'epoch': 0.10103265420039073, 'step': 362}\n",
      "06/30/2020 16:42:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.830681923899898e-05, 'epoch': 0.10159084566006141, 'step': 364}\n",
      "06/30/2020 16:42:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.829751604800447e-05, 'epoch': 0.10214903711973207, 'step': 366}\n",
      "06/30/2020 16:42:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8288212857009954e-05, 'epoch': 0.10270722857940273, 'step': 368}\n",
      "06/30/2020 16:42:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.827890966601545e-05, 'epoch': 0.10326542003907341, 'step': 370}\n",
      "06/30/2020 16:42:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8269606475020935e-05, 'epoch': 0.10382361149874407, 'step': 372}\n",
      "06/30/2020 16:42:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.826030328402643e-05, 'epoch': 0.10438180295841473, 'step': 374}\n",
      "06/30/2020 16:42:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8251000093031915e-05, 'epoch': 0.10493999441808541, 'step': 376}\n",
      "06/30/2020 16:42:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.82416969020374e-05, 'epoch': 0.10549818587775607, 'step': 378}\n",
      "06/30/2020 16:42:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.823239371104289e-05, 'epoch': 0.10605637733742673, 'step': 380}\n",
      "06/30/2020 16:42:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.822309052004838e-05, 'epoch': 0.10661456879709741, 'step': 382}\n",
      "06/30/2020 16:42:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.821378732905387e-05, 'epoch': 0.10717276025676807, 'step': 384}\n",
      "06/30/2020 16:42:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8204484138059356e-05, 'epoch': 0.10773095171643873, 'step': 386}\n",
      "06/30/2020 16:42:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.819518094706484e-05, 'epoch': 0.10828914317610941, 'step': 388}\n",
      "06/30/2020 16:42:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8185877756070336e-05, 'epoch': 0.10884733463578007, 'step': 390}\n",
      "06/30/2020 16:42:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.817657456507582e-05, 'epoch': 0.10940552609545073, 'step': 392}\n",
      "06/30/2020 16:42:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8167271374081316e-05, 'epoch': 0.10996371755512141, 'step': 394}\n",
      "06/30/2020 16:42:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8157968183086796e-05, 'epoch': 0.11052190901479207, 'step': 396}\n",
      "06/30/2020 16:42:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.814866499209229e-05, 'epoch': 0.11108010047446273, 'step': 398}\n",
      "06/30/2020 16:42:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8139361801097776e-05, 'epoch': 0.11163829193413341, 'step': 400}\n",
      "06/30/2020 16:42:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.813005861010327e-05, 'epoch': 0.11219648339380407, 'step': 402}\n",
      "06/30/2020 16:42:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.812075541910876e-05, 'epoch': 0.11275467485347475, 'step': 404}\n",
      "06/30/2020 16:42:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8111452228114244e-05, 'epoch': 0.11331286631314541, 'step': 406}\n",
      "06/30/2020 16:42:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.810214903711974e-05, 'epoch': 0.11387105777281607, 'step': 408}\n",
      "06/30/2020 16:42:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8092845846125224e-05, 'epoch': 0.11442924923248675, 'step': 410}\n",
      "06/30/2020 16:42:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.808354265513072e-05, 'epoch': 0.11498744069215741, 'step': 412}\n",
      "06/30/2020 16:42:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.80742394641362e-05, 'epoch': 0.11554563215182807, 'step': 414}\n",
      "06/30/2020 16:42:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.806493627314169e-05, 'epoch': 0.11610382361149875, 'step': 416}\n",
      "06/30/2020 16:42:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.805563308214718e-05, 'epoch': 0.11666201507116941, 'step': 418}\n",
      "06/30/2020 16:42:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.804632989115267e-05, 'epoch': 0.11722020653084007, 'step': 420}\n",
      "06/30/2020 16:42:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.803702670015816e-05, 'epoch': 0.11777839799051075, 'step': 422}\n",
      "06/30/2020 16:42:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8027723509163645e-05, 'epoch': 0.11833658945018141, 'step': 424}\n",
      "06/30/2020 16:42:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.801842031816913e-05, 'epoch': 0.11889478090985207, 'step': 426}\n",
      "06/30/2020 16:42:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8009117127174625e-05, 'epoch': 0.11945297236952275, 'step': 428}\n",
      "06/30/2020 16:42:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.799981393618011e-05, 'epoch': 0.12001116382919341, 'step': 430}\n",
      "06/30/2020 16:42:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.79905107451856e-05, 'epoch': 0.12056935528886407, 'step': 432}\n",
      "06/30/2020 16:42:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7981207554191085e-05, 'epoch': 0.12112754674853475, 'step': 434}\n",
      "06/30/2020 16:42:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.797190436319658e-05, 'epoch': 0.12168573820820541, 'step': 436}\n",
      "06/30/2020 16:42:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7962601172202066e-05, 'epoch': 0.12224392966787608, 'step': 438}\n",
      "06/30/2020 16:42:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.795329798120756e-05, 'epoch': 0.12280212112754675, 'step': 440}\n",
      "06/30/2020 16:42:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.794399479021304e-05, 'epoch': 0.12336031258721741, 'step': 442}\n",
      "06/30/2020 16:42:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.793469159921853e-05, 'epoch': 0.12391850404688809, 'step': 444}\n",
      "06/30/2020 16:42:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7925388408224026e-05, 'epoch': 0.12447669550655875, 'step': 446}\n",
      "06/30/2020 16:42:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.791608521722951e-05, 'epoch': 0.1250348869662294, 'step': 448}\n",
      "06/30/2020 16:42:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7906782026235e-05, 'epoch': 0.1255930784259001, 'step': 450}\n",
      "06/30/2020 16:42:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.789747883524049e-05, 'epoch': 0.12615126988557074, 'step': 452}\n",
      "06/30/2020 16:42:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.788817564424598e-05, 'epoch': 0.12670946134524141, 'step': 454}\n",
      "06/30/2020 16:42:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.787887245325147e-05, 'epoch': 0.1272676528049121, 'step': 456}\n",
      "06/30/2020 16:42:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.786956926225696e-05, 'epoch': 0.12782584426458274, 'step': 458}\n",
      "06/30/2020 16:43:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.786026607126245e-05, 'epoch': 0.12838403572425341, 'step': 460}\n",
      "06/30/2020 16:43:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7850962880267934e-05, 'epoch': 0.1289422271839241, 'step': 462}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:43:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.784165968927342e-05, 'epoch': 0.12950041864359477, 'step': 464}\n",
      "06/30/2020 16:43:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7832356498278914e-05, 'epoch': 0.13005861010326542, 'step': 466}\n",
      "06/30/2020 16:43:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.78230533072844e-05, 'epoch': 0.1306168015629361, 'step': 468}\n",
      "06/30/2020 16:43:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.781375011628989e-05, 'epoch': 0.13117499302260677, 'step': 470}\n",
      "06/30/2020 16:43:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7804446925295375e-05, 'epoch': 0.13173318448227742, 'step': 472}\n",
      "06/30/2020 16:43:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.779514373430087e-05, 'epoch': 0.1322913759419481, 'step': 474}\n",
      "06/30/2020 16:43:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7785840543306355e-05, 'epoch': 0.13284956740161877, 'step': 476}\n",
      "06/30/2020 16:43:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.777653735231185e-05, 'epoch': 0.13340775886128942, 'step': 478}\n",
      "06/30/2020 16:43:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7767234161317335e-05, 'epoch': 0.1339659503209601, 'step': 480}\n",
      "06/30/2020 16:43:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.775793097032282e-05, 'epoch': 0.13452414178063077, 'step': 482}\n",
      "06/30/2020 16:43:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7748627779328316e-05, 'epoch': 0.13508233324030142, 'step': 484}\n",
      "06/30/2020 16:43:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.77393245883338e-05, 'epoch': 0.1356405246999721, 'step': 486}\n",
      "06/30/2020 16:43:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.773002139733929e-05, 'epoch': 0.13619871615964277, 'step': 488}\n",
      "06/30/2020 16:43:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7720718206344776e-05, 'epoch': 0.13675690761931342, 'step': 490}\n",
      "06/30/2020 16:43:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.771141501535027e-05, 'epoch': 0.1373150990789841, 'step': 492}\n",
      "06/30/2020 16:43:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7702111824355756e-05, 'epoch': 0.13787329053865477, 'step': 494}\n",
      "06/30/2020 16:43:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.769280863336125e-05, 'epoch': 0.13843148199832542, 'step': 496}\n",
      "06/30/2020 16:43:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.768350544236673e-05, 'epoch': 0.1389896734579961, 'step': 498}\n",
      "06/30/2020 16:43:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.767420225137222e-05, 'epoch': 0.13954786491766677, 'step': 500}\n",
      "06/30/2020 16:43:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.766489906037771e-05, 'epoch': 0.14010605637733742, 'step': 502}\n",
      "06/30/2020 16:43:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7655595869383204e-05, 'epoch': 0.1406642478370081, 'step': 504}\n",
      "06/30/2020 16:43:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.764629267838869e-05, 'epoch': 0.14122243929667877, 'step': 506}\n",
      "06/30/2020 16:43:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.763698948739418e-05, 'epoch': 0.14178063075634942, 'step': 508}\n",
      "06/30/2020 16:43:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7627686296399664e-05, 'epoch': 0.1423388222160201, 'step': 510}\n",
      "06/30/2020 16:43:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.761838310540516e-05, 'epoch': 0.14289701367569077, 'step': 512}\n",
      "06/30/2020 16:43:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7609079914410644e-05, 'epoch': 0.14345520513536142, 'step': 514}\n",
      "06/30/2020 16:43:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.759977672341613e-05, 'epoch': 0.1440133965950321, 'step': 516}\n",
      "06/30/2020 16:43:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7590473532421625e-05, 'epoch': 0.14457158805470277, 'step': 518}\n",
      "06/30/2020 16:43:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.758117034142711e-05, 'epoch': 0.14512977951437342, 'step': 520}\n",
      "06/30/2020 16:43:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7571867150432605e-05, 'epoch': 0.1456879709740441, 'step': 522}\n",
      "06/30/2020 16:43:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.756256395943809e-05, 'epoch': 0.14624616243371477, 'step': 524}\n",
      "06/30/2020 16:43:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.755326076844358e-05, 'epoch': 0.14680435389338542, 'step': 526}\n",
      "06/30/2020 16:43:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7543957577449065e-05, 'epoch': 0.1473625453530561, 'step': 528}\n",
      "06/30/2020 16:43:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.753465438645456e-05, 'epoch': 0.14792073681272677, 'step': 530}\n",
      "06/30/2020 16:43:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7525351195460046e-05, 'epoch': 0.14847892827239742, 'step': 532}\n",
      "06/30/2020 16:43:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.751604800446553e-05, 'epoch': 0.1490371197320681, 'step': 534}\n",
      "06/30/2020 16:43:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.750674481347102e-05, 'epoch': 0.14959531119173877, 'step': 536}\n",
      "06/30/2020 16:43:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.749744162247651e-05, 'epoch': 0.15015350265140942, 'step': 538}\n",
      "06/30/2020 16:43:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7488138431482e-05, 'epoch': 0.1507116941110801, 'step': 540}\n",
      "06/30/2020 16:43:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.747883524048749e-05, 'epoch': 0.15126988557075077, 'step': 542}\n",
      "06/30/2020 16:43:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.746953204949297e-05, 'epoch': 0.15182807703042142, 'step': 544}\n",
      "06/30/2020 16:43:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7460228858498467e-05, 'epoch': 0.1523862684900921, 'step': 546}\n",
      "06/30/2020 16:43:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.745092566750395e-05, 'epoch': 0.15294445994976277, 'step': 548}\n",
      "06/30/2020 16:43:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.744162247650945e-05, 'epoch': 0.15350265140943345, 'step': 550}\n",
      "06/30/2020 16:43:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7432319285514934e-05, 'epoch': 0.1540608428691041, 'step': 552}\n",
      "06/30/2020 16:43:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.742301609452042e-05, 'epoch': 0.15461903432877477, 'step': 554}\n",
      "06/30/2020 16:43:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7413712903525914e-05, 'epoch': 0.15517722578844545, 'step': 556}\n",
      "06/30/2020 16:43:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.74044097125314e-05, 'epoch': 0.1557354172481161, 'step': 558}\n",
      "06/30/2020 16:43:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7395106521536894e-05, 'epoch': 0.15629360870778677, 'step': 560}\n",
      "06/30/2020 16:43:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.738580333054238e-05, 'epoch': 0.15685180016745745, 'step': 562}\n",
      "06/30/2020 16:43:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.737650013954787e-05, 'epoch': 0.1574099916271281, 'step': 564}\n",
      "06/30/2020 16:43:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7367196948553355e-05, 'epoch': 0.15796818308679877, 'step': 566}\n",
      "06/30/2020 16:43:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.735789375755885e-05, 'epoch': 0.15852637454646945, 'step': 568}\n",
      "06/30/2020 16:43:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7348590566564335e-05, 'epoch': 0.1590845660061401, 'step': 570}\n",
      "06/30/2020 16:43:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.733928737556982e-05, 'epoch': 0.15964275746581078, 'step': 572}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:43:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.732998418457531e-05, 'epoch': 0.16020094892548145, 'step': 574}\n",
      "06/30/2020 16:43:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.73206809935808e-05, 'epoch': 0.1607591403851521, 'step': 576}\n",
      "06/30/2020 16:43:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.731137780258629e-05, 'epoch': 0.16131733184482278, 'step': 578}\n",
      "06/30/2020 16:43:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.730207461159178e-05, 'epoch': 0.16187552330449345, 'step': 580}\n",
      "06/30/2020 16:43:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.729277142059726e-05, 'epoch': 0.1624337147641641, 'step': 582}\n",
      "06/30/2020 16:43:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7283468229602756e-05, 'epoch': 0.16299190622383478, 'step': 584}\n",
      "06/30/2020 16:43:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.727416503860824e-05, 'epoch': 0.16355009768350545, 'step': 586}\n",
      "06/30/2020 16:43:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7264861847613736e-05, 'epoch': 0.1641082891431761, 'step': 588}\n",
      "06/30/2020 16:43:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.725555865661922e-05, 'epoch': 0.16466648060284678, 'step': 590}\n",
      "06/30/2020 16:43:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.724625546562471e-05, 'epoch': 0.16522467206251745, 'step': 592}\n",
      "06/30/2020 16:43:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.72369522746302e-05, 'epoch': 0.1657828635221881, 'step': 594}\n",
      "06/30/2020 16:43:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.722764908363569e-05, 'epoch': 0.16634105498185878, 'step': 596}\n",
      "06/30/2020 16:43:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7218345892641184e-05, 'epoch': 0.16689924644152945, 'step': 598}\n",
      "06/30/2020 16:43:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7209042701646664e-05, 'epoch': 0.1674574379012001, 'step': 600}\n",
      "06/30/2020 16:43:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.719973951065216e-05, 'epoch': 0.16801562936087078, 'step': 602}\n",
      "06/30/2020 16:43:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7190436319657644e-05, 'epoch': 0.16857382082054145, 'step': 604}\n",
      "06/30/2020 16:43:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.718113312866314e-05, 'epoch': 0.1691320122802121, 'step': 606}\n",
      "06/30/2020 16:43:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7171829937668624e-05, 'epoch': 0.16969020373988278, 'step': 608}\n",
      "06/30/2020 16:43:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.716252674667411e-05, 'epoch': 0.17024839519955345, 'step': 610}\n",
      "06/30/2020 16:43:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.71532235556796e-05, 'epoch': 0.1708065866592241, 'step': 612}\n",
      "06/30/2020 16:43:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.714392036468509e-05, 'epoch': 0.17136477811889478, 'step': 614}\n",
      "06/30/2020 16:43:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.713461717369058e-05, 'epoch': 0.17192296957856545, 'step': 616}\n",
      "06/30/2020 16:43:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7125313982696065e-05, 'epoch': 0.1724811610382361, 'step': 618}\n",
      "06/30/2020 16:43:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.711601079170155e-05, 'epoch': 0.17303935249790678, 'step': 620}\n",
      "06/30/2020 16:43:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7106707600707045e-05, 'epoch': 0.17359754395757745, 'step': 622}\n",
      "06/30/2020 16:43:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.709740440971253e-05, 'epoch': 0.1741557354172481, 'step': 624}\n",
      "06/30/2020 16:43:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7088101218718025e-05, 'epoch': 0.17471392687691878, 'step': 626}\n",
      "06/30/2020 16:43:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.707879802772351e-05, 'epoch': 0.17527211833658946, 'step': 628}\n",
      "06/30/2020 16:43:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7069494836729e-05, 'epoch': 0.1758303097962601, 'step': 630}\n",
      "06/30/2020 16:43:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.706019164573449e-05, 'epoch': 0.17638850125593078, 'step': 632}\n",
      "06/30/2020 16:43:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.705088845473998e-05, 'epoch': 0.17694669271560146, 'step': 634}\n",
      "06/30/2020 16:43:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7041585263745466e-05, 'epoch': 0.17750488417527213, 'step': 636}\n",
      "06/30/2020 16:43:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.703228207275095e-05, 'epoch': 0.17806307563494278, 'step': 638}\n",
      "06/30/2020 16:43:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7022978881756446e-05, 'epoch': 0.17862126709461346, 'step': 640}\n",
      "06/30/2020 16:43:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.701367569076193e-05, 'epoch': 0.17917945855428413, 'step': 642}\n",
      "06/30/2020 16:43:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.700437249976743e-05, 'epoch': 0.17973765001395478, 'step': 644}\n",
      "06/30/2020 16:43:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.699506930877291e-05, 'epoch': 0.18029584147362546, 'step': 646}\n",
      "06/30/2020 16:43:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.69857661177784e-05, 'epoch': 0.18085403293329613, 'step': 648}\n",
      "06/30/2020 16:43:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.697646292678389e-05, 'epoch': 0.18141222439296678, 'step': 650}\n",
      "06/30/2020 16:43:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.696715973578938e-05, 'epoch': 0.18197041585263746, 'step': 652}\n",
      "06/30/2020 16:43:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.695785654479487e-05, 'epoch': 0.18252860731230813, 'step': 654}\n",
      "06/30/2020 16:43:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6948553353800354e-05, 'epoch': 0.18308679877197878, 'step': 656}\n",
      "06/30/2020 16:43:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.693925016280584e-05, 'epoch': 0.18364499023164946, 'step': 658}\n",
      "06/30/2020 16:43:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6929946971811334e-05, 'epoch': 0.18420318169132013, 'step': 660}\n",
      "06/30/2020 16:43:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.692064378081682e-05, 'epoch': 0.18476137315099078, 'step': 662}\n",
      "06/30/2020 16:43:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.691134058982231e-05, 'epoch': 0.18531956461066146, 'step': 664}\n",
      "06/30/2020 16:43:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.69020373988278e-05, 'epoch': 0.18587775607033213, 'step': 666}\n",
      "06/30/2020 16:43:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.689273420783329e-05, 'epoch': 0.18643594753000278, 'step': 668}\n",
      "06/30/2020 16:43:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.688343101683878e-05, 'epoch': 0.18699413898967346, 'step': 670}\n",
      "06/30/2020 16:43:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.687412782584427e-05, 'epoch': 0.18755233044934413, 'step': 672}\n",
      "06/30/2020 16:43:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6864824634849755e-05, 'epoch': 0.18811052190901478, 'step': 674}\n",
      "06/30/2020 16:43:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.685552144385524e-05, 'epoch': 0.18866871336868546, 'step': 676}\n",
      "06/30/2020 16:43:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6846218252860736e-05, 'epoch': 0.18922690482835614, 'step': 678}\n",
      "06/30/2020 16:43:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.683691506186622e-05, 'epoch': 0.18978509628802678, 'step': 680}\n",
      "06/30/2020 16:43:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6827611870871716e-05, 'epoch': 0.19034328774769746, 'step': 682}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:43:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6818308679877196e-05, 'epoch': 0.19090147920736814, 'step': 684}\n",
      "06/30/2020 16:43:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.680900548888269e-05, 'epoch': 0.19145967066703878, 'step': 686}\n",
      "06/30/2020 16:43:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6799702297888176e-05, 'epoch': 0.19201786212670946, 'step': 688}\n",
      "06/30/2020 16:43:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.679039910689367e-05, 'epoch': 0.19257605358638014, 'step': 690}\n",
      "06/30/2020 16:43:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6781095915899157e-05, 'epoch': 0.19313424504605078, 'step': 692}\n",
      "06/30/2020 16:43:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.677179272490464e-05, 'epoch': 0.19369243650572146, 'step': 694}\n",
      "06/30/2020 16:43:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.676248953391013e-05, 'epoch': 0.19425062796539214, 'step': 696}\n",
      "06/30/2020 16:43:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6753186342915624e-05, 'epoch': 0.19480881942506278, 'step': 698}\n",
      "06/30/2020 16:43:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.674388315192111e-05, 'epoch': 0.19536701088473346, 'step': 700}\n",
      "06/30/2020 16:43:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.67345799609266e-05, 'epoch': 0.19592520234440414, 'step': 702}\n",
      "06/30/2020 16:43:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.672527676993209e-05, 'epoch': 0.19648339380407479, 'step': 704}\n",
      "06/30/2020 16:43:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.671597357893758e-05, 'epoch': 0.19704158526374546, 'step': 706}\n",
      "06/30/2020 16:43:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.670667038794307e-05, 'epoch': 0.19759977672341614, 'step': 708}\n",
      "06/30/2020 16:43:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.669736719694856e-05, 'epoch': 0.19815796818308679, 'step': 710}\n",
      "06/30/2020 16:43:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6688064005954045e-05, 'epoch': 0.19871615964275746, 'step': 712}\n",
      "06/30/2020 16:43:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.667876081495953e-05, 'epoch': 0.19927435110242814, 'step': 714}\n",
      "06/30/2020 16:43:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6669457623965025e-05, 'epoch': 0.19983254256209879, 'step': 716}\n",
      "06/30/2020 16:43:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.666015443297051e-05, 'epoch': 0.20039073402176946, 'step': 718}\n",
      "06/30/2020 16:43:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6650851241976e-05, 'epoch': 0.20094892548144014, 'step': 720}\n",
      "06/30/2020 16:43:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6641548050981485e-05, 'epoch': 0.20150711694111081, 'step': 722}\n",
      "06/30/2020 16:43:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.663224485998698e-05, 'epoch': 0.20206530840078146, 'step': 724}\n",
      "06/30/2020 16:43:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6622941668992466e-05, 'epoch': 0.20262349986045214, 'step': 726}\n",
      "06/30/2020 16:43:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.661363847799796e-05, 'epoch': 0.20318169132012281, 'step': 728}\n",
      "06/30/2020 16:43:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.660433528700344e-05, 'epoch': 0.20373988277979346, 'step': 730}\n",
      "06/30/2020 16:43:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.659503209600893e-05, 'epoch': 0.20429807423946414, 'step': 732}\n",
      "06/30/2020 16:43:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.658572890501442e-05, 'epoch': 0.20485626569913482, 'step': 734}\n",
      "06/30/2020 16:43:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.657642571401991e-05, 'epoch': 0.20541445715880546, 'step': 736}\n",
      "06/30/2020 16:43:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.65671225230254e-05, 'epoch': 0.20597264861847614, 'step': 738}\n",
      "06/30/2020 16:43:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6557819332030886e-05, 'epoch': 0.20653084007814682, 'step': 740}\n",
      "06/30/2020 16:43:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.654851614103638e-05, 'epoch': 0.20708903153781746, 'step': 742}\n",
      "06/30/2020 16:43:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.653921295004187e-05, 'epoch': 0.20764722299748814, 'step': 744}\n",
      "06/30/2020 16:43:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.652990975904736e-05, 'epoch': 0.20820541445715882, 'step': 746}\n",
      "06/30/2020 16:43:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.652060656805284e-05, 'epoch': 0.20876360591682946, 'step': 748}\n",
      "06/30/2020 16:43:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6511303377058334e-05, 'epoch': 0.20932179737650014, 'step': 750}\n",
      "06/30/2020 16:43:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.650200018606382e-05, 'epoch': 0.20987998883617082, 'step': 752}\n",
      "06/30/2020 16:43:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6492696995069314e-05, 'epoch': 0.21043818029584146, 'step': 754}\n",
      "06/30/2020 16:43:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.64833938040748e-05, 'epoch': 0.21099637175551214, 'step': 756}\n",
      "06/30/2020 16:43:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.647409061308029e-05, 'epoch': 0.21155456321518282, 'step': 758}\n",
      "06/30/2020 16:43:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6464787422085774e-05, 'epoch': 0.21211275467485347, 'step': 760}\n",
      "06/30/2020 16:43:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.645548423109127e-05, 'epoch': 0.21267094613452414, 'step': 762}\n",
      "06/30/2020 16:43:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6446181040096755e-05, 'epoch': 0.21322913759419482, 'step': 764}\n",
      "06/30/2020 16:43:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.643687784910224e-05, 'epoch': 0.21378732905386547, 'step': 766}\n",
      "06/30/2020 16:43:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.642757465810773e-05, 'epoch': 0.21434552051353614, 'step': 768}\n",
      "06/30/2020 16:43:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.641827146711322e-05, 'epoch': 0.21490371197320682, 'step': 770}\n",
      "06/30/2020 16:43:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.640896827611871e-05, 'epoch': 0.21546190343287747, 'step': 772}\n",
      "06/30/2020 16:43:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.63996650851242e-05, 'epoch': 0.21602009489254814, 'step': 774}\n",
      "06/30/2020 16:43:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.639036189412969e-05, 'epoch': 0.21657828635221882, 'step': 776}\n",
      "06/30/2020 16:43:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6381058703135176e-05, 'epoch': 0.21713647781188947, 'step': 778}\n",
      "06/30/2020 16:43:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.637175551214067e-05, 'epoch': 0.21769466927156014, 'step': 780}\n",
      "06/30/2020 16:43:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6362452321146156e-05, 'epoch': 0.21825286073123082, 'step': 782}\n",
      "06/30/2020 16:43:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.635314913015165e-05, 'epoch': 0.21881105219090147, 'step': 784}\n",
      "06/30/2020 16:43:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.634384593915713e-05, 'epoch': 0.21936924365057214, 'step': 786}\n",
      "06/30/2020 16:43:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.633454274816262e-05, 'epoch': 0.21992743511024282, 'step': 788}\n",
      "06/30/2020 16:43:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.632523955716811e-05, 'epoch': 0.22048562656991347, 'step': 790}\n",
      "06/30/2020 16:43:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6315936366173603e-05, 'epoch': 0.22104381802958414, 'step': 792}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:43:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.630663317517909e-05, 'epoch': 0.22160200948925482, 'step': 794}\n",
      "06/30/2020 16:43:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.629732998418458e-05, 'epoch': 0.22216020094892547, 'step': 796}\n",
      "06/30/2020 16:43:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6288026793190064e-05, 'epoch': 0.22271839240859614, 'step': 798}\n",
      "06/30/2020 16:43:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.627872360219556e-05, 'epoch': 0.22327658386826682, 'step': 800}\n",
      "06/30/2020 16:43:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6269420411201044e-05, 'epoch': 0.2238347753279375, 'step': 802}\n",
      "06/30/2020 16:43:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.626011722020653e-05, 'epoch': 0.22439296678760814, 'step': 804}\n",
      "06/30/2020 16:43:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.625081402921202e-05, 'epoch': 0.22495115824727882, 'step': 806}\n",
      "06/30/2020 16:43:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.624151083821751e-05, 'epoch': 0.2255093497069495, 'step': 808}\n",
      "06/30/2020 16:43:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6232207647223e-05, 'epoch': 0.22606754116662015, 'step': 810}\n",
      "06/30/2020 16:43:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.622290445622849e-05, 'epoch': 0.22662573262629082, 'step': 812}\n",
      "06/30/2020 16:43:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.621360126523398e-05, 'epoch': 0.2271839240859615, 'step': 814}\n",
      "06/30/2020 16:43:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6204298074239465e-05, 'epoch': 0.22774211554563215, 'step': 816}\n",
      "06/30/2020 16:43:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.619499488324496e-05, 'epoch': 0.22830030700530282, 'step': 818}\n",
      "06/30/2020 16:43:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6185691692250445e-05, 'epoch': 0.2288584984649735, 'step': 820}\n",
      "06/30/2020 16:43:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.617638850125593e-05, 'epoch': 0.22941668992464415, 'step': 822}\n",
      "06/30/2020 16:43:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.616708531026142e-05, 'epoch': 0.22997488138431482, 'step': 824}\n",
      "06/30/2020 16:43:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.615778211926691e-05, 'epoch': 0.2305330728439855, 'step': 826}\n",
      "06/30/2020 16:43:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.61484789282724e-05, 'epoch': 0.23109126430365615, 'step': 828}\n",
      "06/30/2020 16:43:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.613917573727789e-05, 'epoch': 0.23164945576332682, 'step': 830}\n",
      "06/30/2020 16:43:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.612987254628337e-05, 'epoch': 0.2322076472229975, 'step': 832}\n",
      "06/30/2020 16:43:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6120569355288866e-05, 'epoch': 0.23276583868266815, 'step': 834}\n",
      "06/30/2020 16:43:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.611126616429435e-05, 'epoch': 0.23332403014233882, 'step': 836}\n",
      "06/30/2020 16:43:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6101962973299847e-05, 'epoch': 0.2338822216020095, 'step': 838}\n",
      "06/30/2020 16:43:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.609265978230533e-05, 'epoch': 0.23444041306168015, 'step': 840}\n",
      "06/30/2020 16:43:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.608335659131082e-05, 'epoch': 0.23499860452135082, 'step': 842}\n",
      "06/30/2020 16:43:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.607405340031631e-05, 'epoch': 0.2355567959810215, 'step': 844}\n",
      "06/30/2020 16:43:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.60647502093218e-05, 'epoch': 0.23611498744069215, 'step': 846}\n",
      "06/30/2020 16:43:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.605544701832729e-05, 'epoch': 0.23667317890036282, 'step': 848}\n",
      "06/30/2020 16:43:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6046143827332774e-05, 'epoch': 0.2372313703600335, 'step': 850}\n",
      "06/30/2020 16:43:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.603684063633827e-05, 'epoch': 0.23778956181970415, 'step': 852}\n",
      "06/30/2020 16:43:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6027537445343754e-05, 'epoch': 0.23834775327937482, 'step': 854}\n",
      "06/30/2020 16:43:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.601823425434925e-05, 'epoch': 0.2389059447390455, 'step': 856}\n",
      "06/30/2020 16:43:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6008931063354735e-05, 'epoch': 0.23946413619871615, 'step': 858}\n",
      "06/30/2020 16:43:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.599962787236022e-05, 'epoch': 0.24002232765838682, 'step': 860}\n",
      "06/30/2020 16:43:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.599032468136571e-05, 'epoch': 0.2405805191180575, 'step': 862}\n",
      "06/30/2020 16:43:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.59810214903712e-05, 'epoch': 0.24113871057772815, 'step': 864}\n",
      "06/30/2020 16:43:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.597171829937669e-05, 'epoch': 0.24169690203739883, 'step': 866}\n",
      "06/30/2020 16:43:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5962415108382175e-05, 'epoch': 0.2422550934970695, 'step': 868}\n",
      "06/30/2020 16:43:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.595311191738766e-05, 'epoch': 0.24281328495674015, 'step': 870}\n",
      "06/30/2020 16:43:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5943808726393156e-05, 'epoch': 0.24337147641641083, 'step': 872}\n",
      "06/30/2020 16:43:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.593450553539864e-05, 'epoch': 0.2439296678760815, 'step': 874}\n",
      "06/30/2020 16:43:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5925202344404136e-05, 'epoch': 0.24448785933575215, 'step': 876}\n",
      "06/30/2020 16:43:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.591589915340962e-05, 'epoch': 0.24504605079542283, 'step': 878}\n",
      "06/30/2020 16:43:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.590659596241511e-05, 'epoch': 0.2456042422550935, 'step': 880}\n",
      "06/30/2020 16:43:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5897292771420596e-05, 'epoch': 0.24616243371476415, 'step': 882}\n",
      "06/30/2020 16:43:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.588798958042609e-05, 'epoch': 0.24672062517443483, 'step': 884}\n",
      "06/30/2020 16:43:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.587868638943158e-05, 'epoch': 0.2472788166341055, 'step': 886}\n",
      "06/30/2020 16:43:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.586938319843706e-05, 'epoch': 0.24783700809377618, 'step': 888}\n",
      "06/30/2020 16:43:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.586008000744256e-05, 'epoch': 0.24839519955344683, 'step': 890}\n",
      "06/30/2020 16:43:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5850776816448044e-05, 'epoch': 0.2489533910131175, 'step': 892}\n",
      "06/30/2020 16:43:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.584147362545354e-05, 'epoch': 0.24951158247278818, 'step': 894}\n",
      "06/30/2020 16:43:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5832170434459024e-05, 'epoch': 0.2500697739324588, 'step': 896}\n",
      "06/30/2020 16:43:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.582286724346451e-05, 'epoch': 0.2506279653921295, 'step': 898}\n",
      "06/30/2020 16:43:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.581356405247e-05, 'epoch': 0.2511861568518002, 'step': 900}\n",
      "06/30/2020 16:43:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.580426086147549e-05, 'epoch': 0.25174434831147086, 'step': 902}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:43:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.579495767048098e-05, 'epoch': 0.2523025397711415, 'step': 904}\n",
      "06/30/2020 16:43:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5785654479486465e-05, 'epoch': 0.25286073123081215, 'step': 906}\n",
      "06/30/2020 16:43:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.577635128849195e-05, 'epoch': 0.25341892269048283, 'step': 908}\n",
      "06/30/2020 16:43:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5767048097497445e-05, 'epoch': 0.2539771141501535, 'step': 910}\n",
      "06/30/2020 16:43:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.575774490650293e-05, 'epoch': 0.2545353056098242, 'step': 912}\n",
      "06/30/2020 16:43:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5748441715508425e-05, 'epoch': 0.25509349706949486, 'step': 914}\n",
      "06/30/2020 16:43:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5739138524513905e-05, 'epoch': 0.2556516885291655, 'step': 916}\n",
      "06/30/2020 16:43:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.57298353335194e-05, 'epoch': 0.25620987998883615, 'step': 918}\n",
      "06/30/2020 16:43:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5720532142524885e-05, 'epoch': 0.25676807144850683, 'step': 920}\n",
      "06/30/2020 16:43:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.571122895153038e-05, 'epoch': 0.2573262629081775, 'step': 922}\n",
      "06/30/2020 16:43:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5701925760535866e-05, 'epoch': 0.2578844543678482, 'step': 924}\n",
      "06/30/2020 16:43:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.569262256954135e-05, 'epoch': 0.25844264582751886, 'step': 926}\n",
      "06/30/2020 16:43:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5683319378546846e-05, 'epoch': 0.25900083728718953, 'step': 928}\n",
      "06/30/2020 16:43:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.567401618755233e-05, 'epoch': 0.25955902874686015, 'step': 930}\n",
      "06/30/2020 16:43:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5664712996557826e-05, 'epoch': 0.26011722020653083, 'step': 932}\n",
      "06/30/2020 16:43:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5655409805563306e-05, 'epoch': 0.2606754116662015, 'step': 934}\n",
      "06/30/2020 16:43:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.56461066145688e-05, 'epoch': 0.2612336031258722, 'step': 936}\n",
      "06/30/2020 16:43:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.563680342357429e-05, 'epoch': 0.26179179458554286, 'step': 938}\n",
      "06/30/2020 16:43:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.562750023257978e-05, 'epoch': 0.26234998604521353, 'step': 940}\n",
      "06/30/2020 16:43:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.561819704158527e-05, 'epoch': 0.26290817750488416, 'step': 942}\n",
      "06/30/2020 16:43:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5608893850590754e-05, 'epoch': 0.26346636896455483, 'step': 944}\n",
      "06/30/2020 16:43:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.559959065959624e-05, 'epoch': 0.2640245604242255, 'step': 946}\n",
      "06/30/2020 16:43:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5590287468601734e-05, 'epoch': 0.2645827518838962, 'step': 948}\n",
      "06/30/2020 16:43:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.558098427760722e-05, 'epoch': 0.26514094334356686, 'step': 950}\n",
      "06/30/2020 16:43:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.557168108661271e-05, 'epoch': 0.26569913480323754, 'step': 952}\n",
      "06/30/2020 16:43:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5562377895618194e-05, 'epoch': 0.26625732626290816, 'step': 954}\n",
      "06/30/2020 16:43:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.555307470462369e-05, 'epoch': 0.26681551772257883, 'step': 956}\n",
      "06/30/2020 16:43:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5543771513629175e-05, 'epoch': 0.2673737091822495, 'step': 958}\n",
      "06/30/2020 16:43:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.553446832263467e-05, 'epoch': 0.2679319006419202, 'step': 960}\n",
      "06/30/2020 16:43:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5525165131640155e-05, 'epoch': 0.26849009210159086, 'step': 962}\n",
      "06/30/2020 16:43:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.551586194064564e-05, 'epoch': 0.26904828356126154, 'step': 964}\n",
      "06/30/2020 16:43:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5506558749651135e-05, 'epoch': 0.26960647502093216, 'step': 966}\n",
      "06/30/2020 16:43:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.549725555865662e-05, 'epoch': 0.27016466648060283, 'step': 968}\n",
      "06/30/2020 16:43:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.548795236766211e-05, 'epoch': 0.2707228579402735, 'step': 970}\n",
      "06/30/2020 16:43:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5478649176667596e-05, 'epoch': 0.2712810493999442, 'step': 972}\n",
      "06/30/2020 16:43:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.546934598567309e-05, 'epoch': 0.27183924085961486, 'step': 974}\n",
      "06/30/2020 16:43:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5460042794678576e-05, 'epoch': 0.27239743231928554, 'step': 976}\n",
      "06/30/2020 16:43:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.545073960368407e-05, 'epoch': 0.27295562377895616, 'step': 978}\n",
      "06/30/2020 16:43:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5441436412689556e-05, 'epoch': 0.27351381523862683, 'step': 980}\n",
      "06/30/2020 16:43:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.543213322169504e-05, 'epoch': 0.2740720066982975, 'step': 982}\n",
      "06/30/2020 16:43:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.542283003070053e-05, 'epoch': 0.2746301981579682, 'step': 984}\n",
      "06/30/2020 16:43:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5413526839706023e-05, 'epoch': 0.27518838961763886, 'step': 986}\n",
      "06/30/2020 16:43:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.540422364871151e-05, 'epoch': 0.27574658107730954, 'step': 988}\n",
      "06/30/2020 16:43:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5394920457717e-05, 'epoch': 0.27630477253698016, 'step': 990}\n",
      "06/30/2020 16:43:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5385617266722484e-05, 'epoch': 0.27686296399665083, 'step': 992}\n",
      "06/30/2020 16:43:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.537631407572798e-05, 'epoch': 0.2774211554563215, 'step': 994}\n",
      "06/30/2020 16:43:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.536701088473347e-05, 'epoch': 0.2779793469159922, 'step': 996}\n",
      "06/30/2020 16:43:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.535770769373896e-05, 'epoch': 0.27853753837566286, 'step': 998}\n",
      "06/30/2020 16:43:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5348404502744444e-05, 'epoch': 0.27909572983533354, 'step': 1000}\n",
      "06/30/2020 16:43:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.533910131174993e-05, 'epoch': 0.27965392129500416, 'step': 1002}\n",
      "06/30/2020 16:43:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5329798120755425e-05, 'epoch': 0.28021211275467484, 'step': 1004}\n",
      "06/30/2020 16:43:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.532049492976091e-05, 'epoch': 0.2807703042143455, 'step': 1006}\n",
      "06/30/2020 16:43:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.53111917387664e-05, 'epoch': 0.2813284956740162, 'step': 1008}\n",
      "06/30/2020 16:43:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5301888547771885e-05, 'epoch': 0.28188668713368686, 'step': 1010}\n",
      "06/30/2020 16:43:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.529258535677738e-05, 'epoch': 0.28244487859335754, 'step': 1012}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:43:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5283282165782865e-05, 'epoch': 0.2830030700530282, 'step': 1014}\n",
      "06/30/2020 16:43:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.527397897478836e-05, 'epoch': 0.28356126151269884, 'step': 1016}\n",
      "06/30/2020 16:43:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.526467578379384e-05, 'epoch': 0.2841194529723695, 'step': 1018}\n",
      "06/30/2020 16:43:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.525537259279933e-05, 'epoch': 0.2846776444320402, 'step': 1020}\n",
      "06/30/2020 16:43:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.524606940180482e-05, 'epoch': 0.28523583589171086, 'step': 1022}\n",
      "06/30/2020 16:43:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.523676621081031e-05, 'epoch': 0.28579402735138154, 'step': 1024}\n",
      "06/30/2020 16:43:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.52274630198158e-05, 'epoch': 0.2863522188110522, 'step': 1026}\n",
      "06/30/2020 16:43:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5218159828821286e-05, 'epoch': 0.28691041027072284, 'step': 1028}\n",
      "06/30/2020 16:43:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.520885663782677e-05, 'epoch': 0.2874686017303935, 'step': 1030}\n",
      "06/30/2020 16:43:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5199553446832267e-05, 'epoch': 0.2880267931900642, 'step': 1032}\n",
      "06/30/2020 16:43:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.519025025583776e-05, 'epoch': 0.28858498464973487, 'step': 1034}\n",
      "06/30/2020 16:43:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.518094706484324e-05, 'epoch': 0.28914317610940554, 'step': 1036}\n",
      "06/30/2020 16:43:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5171643873848734e-05, 'epoch': 0.2897013675690762, 'step': 1038}\n",
      "06/30/2020 16:43:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.516234068285422e-05, 'epoch': 0.29025955902874684, 'step': 1040}\n",
      "06/30/2020 16:43:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5153037491859714e-05, 'epoch': 0.2908177504884175, 'step': 1042}\n",
      "06/30/2020 16:43:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.51437343008652e-05, 'epoch': 0.2913759419480882, 'step': 1044}\n",
      "06/30/2020 16:43:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.513443110987069e-05, 'epoch': 0.29193413340775887, 'step': 1046}\n",
      "06/30/2020 16:43:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5125127918876174e-05, 'epoch': 0.29249232486742954, 'step': 1048}\n",
      "06/30/2020 16:43:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.511582472788167e-05, 'epoch': 0.2930505163271002, 'step': 1050}\n",
      "06/30/2020 16:43:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5106521536887155e-05, 'epoch': 0.29360870778677084, 'step': 1052}\n",
      "06/30/2020 16:43:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.509721834589264e-05, 'epoch': 0.2941668992464415, 'step': 1054}\n",
      "06/30/2020 16:43:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.508791515489813e-05, 'epoch': 0.2947250907061122, 'step': 1056}\n",
      "06/30/2020 16:43:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.507861196390362e-05, 'epoch': 0.29528328216578287, 'step': 1058}\n",
      "06/30/2020 16:43:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.506930877290911e-05, 'epoch': 0.29584147362545354, 'step': 1060}\n",
      "06/30/2020 16:43:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.50600055819146e-05, 'epoch': 0.2963996650851242, 'step': 1062}\n",
      "06/30/2020 16:43:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.505070239092009e-05, 'epoch': 0.29695785654479484, 'step': 1064}\n",
      "06/30/2020 16:43:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5041399199925576e-05, 'epoch': 0.2975160480044655, 'step': 1066}\n",
      "06/30/2020 16:43:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.503209600893106e-05, 'epoch': 0.2980742394641362, 'step': 1068}\n",
      "06/30/2020 16:43:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5022792817936556e-05, 'epoch': 0.29863243092380687, 'step': 1070}\n",
      "06/30/2020 16:43:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.501348962694204e-05, 'epoch': 0.29919062238347754, 'step': 1072}\n",
      "06/30/2020 16:43:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.500418643594753e-05, 'epoch': 0.2997488138431482, 'step': 1074}\n",
      "06/30/2020 16:43:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.499488324495302e-05, 'epoch': 0.30030700530281884, 'step': 1076}\n",
      "06/30/2020 16:43:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.498558005395851e-05, 'epoch': 0.3008651967624895, 'step': 1078}\n",
      "06/30/2020 16:43:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4976276862964e-05, 'epoch': 0.3014233882221602, 'step': 1080}\n",
      "06/30/2020 16:43:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.496697367196949e-05, 'epoch': 0.30198157968183087, 'step': 1082}\n",
      "06/30/2020 16:43:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.495767048097498e-05, 'epoch': 0.30253977114150155, 'step': 1084}\n",
      "06/30/2020 16:43:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4948367289980464e-05, 'epoch': 0.3030979626011722, 'step': 1086}\n",
      "06/30/2020 16:43:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.493906409898596e-05, 'epoch': 0.30365615406084284, 'step': 1088}\n",
      "06/30/2020 16:43:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4929760907991444e-05, 'epoch': 0.3042143455205135, 'step': 1090}\n",
      "06/30/2020 16:43:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.492045771699693e-05, 'epoch': 0.3047725369801842, 'step': 1092}\n",
      "06/30/2020 16:43:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.491115452600242e-05, 'epoch': 0.30533072843985487, 'step': 1094}\n",
      "06/30/2020 16:43:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.490185133500791e-05, 'epoch': 0.30588891989952555, 'step': 1096}\n",
      "06/30/2020 16:43:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.48925481440134e-05, 'epoch': 0.3064471113591962, 'step': 1098}\n",
      "06/30/2020 16:43:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.488324495301889e-05, 'epoch': 0.3070053028188669, 'step': 1100}\n",
      "06/30/2020 16:43:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.487394176202437e-05, 'epoch': 0.3075634942785375, 'step': 1102}\n",
      "06/30/2020 16:43:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4864638571029865e-05, 'epoch': 0.3081216857382082, 'step': 1104}\n",
      "06/30/2020 16:43:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.485533538003535e-05, 'epoch': 0.30867987719787887, 'step': 1106}\n",
      "06/30/2020 16:43:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4846032189040845e-05, 'epoch': 0.30923806865754955, 'step': 1108}\n",
      "06/30/2020 16:43:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.483672899804633e-05, 'epoch': 0.3097962601172202, 'step': 1110}\n",
      "06/30/2020 16:43:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.482742580705182e-05, 'epoch': 0.3103544515768909, 'step': 1112}\n",
      "06/30/2020 16:43:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.481812261605731e-05, 'epoch': 0.3109126430365615, 'step': 1114}\n",
      "06/30/2020 16:43:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.48088194250628e-05, 'epoch': 0.3114708344962322, 'step': 1116}\n",
      "06/30/2020 16:43:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.479951623406829e-05, 'epoch': 0.3120290259559029, 'step': 1118}\n",
      "06/30/2020 16:43:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.479021304307377e-05, 'epoch': 0.31258721741557355, 'step': 1120}\n",
      "06/30/2020 16:43:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4780909852079266e-05, 'epoch': 0.3131454088752442, 'step': 1122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:43:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.477160666108475e-05, 'epoch': 0.3137036003349149, 'step': 1124}\n",
      "06/30/2020 16:43:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4762303470090246e-05, 'epoch': 0.3142617917945855, 'step': 1126}\n",
      "06/30/2020 16:43:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.475300027909573e-05, 'epoch': 0.3148199832542562, 'step': 1128}\n",
      "06/30/2020 16:43:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.474369708810122e-05, 'epoch': 0.3153781747139269, 'step': 1130}\n",
      "06/30/2020 16:43:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.473439389710671e-05, 'epoch': 0.31593636617359755, 'step': 1132}\n",
      "06/30/2020 16:43:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.47250907061122e-05, 'epoch': 0.3164945576332682, 'step': 1134}\n",
      "06/30/2020 16:43:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.471578751511769e-05, 'epoch': 0.3170527490929389, 'step': 1136}\n",
      "06/30/2020 16:43:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4706484324123174e-05, 'epoch': 0.3176109405526095, 'step': 1138}\n",
      "06/30/2020 16:43:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.469718113312866e-05, 'epoch': 0.3181691320122802, 'step': 1140}\n",
      "06/30/2020 16:43:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4687877942134154e-05, 'epoch': 0.3187273234719509, 'step': 1142}\n",
      "06/30/2020 16:43:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.467857475113965e-05, 'epoch': 0.31928551493162155, 'step': 1144}\n",
      "06/30/2020 16:43:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4669271560145134e-05, 'epoch': 0.3198437063912922, 'step': 1146}\n",
      "06/30/2020 16:43:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.465996836915062e-05, 'epoch': 0.3204018978509629, 'step': 1148}\n",
      "06/30/2020 16:43:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.465066517815611e-05, 'epoch': 0.3209600893106335, 'step': 1150}\n",
      "06/30/2020 16:43:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.46413619871616e-05, 'epoch': 0.3215182807703042, 'step': 1152}\n",
      "06/30/2020 16:43:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.463205879616709e-05, 'epoch': 0.3220764722299749, 'step': 1154}\n",
      "06/30/2020 16:43:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4622755605172575e-05, 'epoch': 0.32263466368964555, 'step': 1156}\n",
      "06/30/2020 16:43:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.461345241417806e-05, 'epoch': 0.3231928551493162, 'step': 1158}\n",
      "06/30/2020 16:43:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4604149223183555e-05, 'epoch': 0.3237510466089869, 'step': 1160}\n",
      "06/30/2020 16:43:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.459484603218904e-05, 'epoch': 0.3243092380686575, 'step': 1162}\n",
      "06/30/2020 16:43:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4585542841194536e-05, 'epoch': 0.3248674295283282, 'step': 1164}\n",
      "06/30/2020 16:43:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4576239650200016e-05, 'epoch': 0.3254256209879989, 'step': 1166}\n",
      "06/30/2020 16:43:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.456693645920551e-05, 'epoch': 0.32598381244766955, 'step': 1168}\n",
      "06/30/2020 16:43:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4557633268210996e-05, 'epoch': 0.32654200390734023, 'step': 1170}\n",
      "06/30/2020 16:43:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.454833007721649e-05, 'epoch': 0.3271001953670109, 'step': 1172}\n",
      "06/30/2020 16:43:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4539026886221976e-05, 'epoch': 0.3276583868266815, 'step': 1174}\n",
      "06/30/2020 16:43:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.452972369522746e-05, 'epoch': 0.3282165782863522, 'step': 1176}\n",
      "06/30/2020 16:43:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.452042050423295e-05, 'epoch': 0.3287747697460229, 'step': 1178}\n",
      "06/30/2020 16:43:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.451111731323844e-05, 'epoch': 0.32933296120569355, 'step': 1180}\n",
      "06/30/2020 16:43:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.450181412224394e-05, 'epoch': 0.32989115266536423, 'step': 1182}\n",
      "06/30/2020 16:43:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4492510931249424e-05, 'epoch': 0.3304493441250349, 'step': 1184}\n",
      "06/30/2020 16:43:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.448320774025491e-05, 'epoch': 0.3310075355847056, 'step': 1186}\n",
      "06/30/2020 16:43:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.44739045492604e-05, 'epoch': 0.3315657270443762, 'step': 1188}\n",
      "06/30/2020 16:43:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.446460135826589e-05, 'epoch': 0.3321239185040469, 'step': 1190}\n",
      "06/30/2020 16:43:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.445529816727138e-05, 'epoch': 0.33268210996371755, 'step': 1192}\n",
      "06/30/2020 16:43:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4445994976276864e-05, 'epoch': 0.33324030142338823, 'step': 1194}\n",
      "06/30/2020 16:43:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.443669178528235e-05, 'epoch': 0.3337984928830589, 'step': 1196}\n",
      "06/30/2020 16:43:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4427388594287845e-05, 'epoch': 0.3343566843427296, 'step': 1198}\n",
      "06/30/2020 16:43:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.441808540329333e-05, 'epoch': 0.3349148758024002, 'step': 1200}\n",
      "06/30/2020 16:43:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4408782212298825e-05, 'epoch': 0.3354730672620709, 'step': 1202}\n",
      "06/30/2020 16:43:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4399479021304305e-05, 'epoch': 0.33603125872174155, 'step': 1204}\n",
      "06/30/2020 16:43:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.43901758303098e-05, 'epoch': 0.33658945018141223, 'step': 1206}\n",
      "06/30/2020 16:43:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4380872639315285e-05, 'epoch': 0.3371476416410829, 'step': 1208}\n",
      "06/30/2020 16:43:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.437156944832078e-05, 'epoch': 0.3377058331007536, 'step': 1210}\n",
      "06/30/2020 16:43:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4362266257326266e-05, 'epoch': 0.3382640245604242, 'step': 1212}\n",
      "06/30/2020 16:43:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.435296306633175e-05, 'epoch': 0.3388222160200949, 'step': 1214}\n",
      "06/30/2020 16:43:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.434365987533724e-05, 'epoch': 0.33938040747976556, 'step': 1216}\n",
      "06/30/2020 16:43:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.433435668434273e-05, 'epoch': 0.33993859893943623, 'step': 1218}\n",
      "06/30/2020 16:43:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4325053493348226e-05, 'epoch': 0.3404967903991069, 'step': 1220}\n",
      "06/30/2020 16:43:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4315750302353706e-05, 'epoch': 0.3410549818587776, 'step': 1222}\n",
      "06/30/2020 16:43:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.43064471113592e-05, 'epoch': 0.3416131733184482, 'step': 1224}\n",
      "06/30/2020 16:43:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4297143920364687e-05, 'epoch': 0.3421713647781189, 'step': 1226}\n",
      "06/30/2020 16:43:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.428784072937018e-05, 'epoch': 0.34272955623778956, 'step': 1228}\n",
      "06/30/2020 16:43:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.427853753837567e-05, 'epoch': 0.34328774769746023, 'step': 1230}\n",
      "06/30/2020 16:43:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4269234347381154e-05, 'epoch': 0.3438459391571309, 'step': 1232}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:43:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.425993115638664e-05, 'epoch': 0.3444041306168016, 'step': 1234}\n",
      "06/30/2020 16:43:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4250627965392134e-05, 'epoch': 0.3449623220764722, 'step': 1236}\n",
      "06/30/2020 16:43:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.424132477439762e-05, 'epoch': 0.3455205135361429, 'step': 1238}\n",
      "06/30/2020 16:43:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.423202158340311e-05, 'epoch': 0.34607870499581356, 'step': 1240}\n",
      "06/30/2020 16:43:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4222718392408594e-05, 'epoch': 0.34663689645548423, 'step': 1242}\n",
      "06/30/2020 16:43:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.421341520141409e-05, 'epoch': 0.3471950879151549, 'step': 1244}\n",
      "06/30/2020 16:43:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4204112010419575e-05, 'epoch': 0.3477532793748256, 'step': 1246}\n",
      "06/30/2020 16:43:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.419480881942507e-05, 'epoch': 0.3483114708344962, 'step': 1248}\n",
      "06/30/2020 16:43:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.418550562843055e-05, 'epoch': 0.3488696622941669, 'step': 1250}\n",
      "06/30/2020 16:43:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.417620243743604e-05, 'epoch': 0.34942785375383756, 'step': 1252}\n",
      "06/30/2020 16:43:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4166899246441535e-05, 'epoch': 0.34998604521350823, 'step': 1254}\n",
      "06/30/2020 16:43:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.415759605544702e-05, 'epoch': 0.3505442366731789, 'step': 1256}\n",
      "06/30/2020 16:43:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.414829286445251e-05, 'epoch': 0.3511024281328496, 'step': 1258}\n",
      "06/30/2020 16:43:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4138989673457995e-05, 'epoch': 0.3516606195925202, 'step': 1260}\n",
      "06/30/2020 16:43:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.412968648246349e-05, 'epoch': 0.3522188110521909, 'step': 1262}\n",
      "06/30/2020 16:43:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4120383291468976e-05, 'epoch': 0.35277700251186156, 'step': 1264}\n",
      "06/30/2020 16:43:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.411108010047447e-05, 'epoch': 0.35333519397153224, 'step': 1266}\n",
      "06/30/2020 16:43:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.410177690947995e-05, 'epoch': 0.3538933854312029, 'step': 1268}\n",
      "06/30/2020 16:43:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.409247371848544e-05, 'epoch': 0.3544515768908736, 'step': 1270}\n",
      "06/30/2020 16:43:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.408317052749093e-05, 'epoch': 0.35500976835054426, 'step': 1272}\n",
      "06/30/2020 16:43:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.407386733649642e-05, 'epoch': 0.3555679598102149, 'step': 1274}\n",
      "06/30/2020 16:43:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.406456414550191e-05, 'epoch': 0.35612615126988556, 'step': 1276}\n",
      "06/30/2020 16:43:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.40552609545074e-05, 'epoch': 0.35668434272955624, 'step': 1278}\n",
      "06/30/2020 16:43:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4045957763512884e-05, 'epoch': 0.3572425341892269, 'step': 1280}\n",
      "06/30/2020 16:43:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.403665457251838e-05, 'epoch': 0.3578007256488976, 'step': 1282}\n",
      "06/30/2020 16:43:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.4027351381523864e-05, 'epoch': 0.35835891710856826, 'step': 1284}\n",
      "06/30/2020 16:43:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.401804819052936e-05, 'epoch': 0.3589171085682389, 'step': 1286}\n",
      "06/30/2020 16:43:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.400874499953484e-05, 'epoch': 0.35947530002790956, 'step': 1288}\n",
      "06/30/2020 16:43:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.399944180854033e-05, 'epoch': 0.36003349148758024, 'step': 1290}\n",
      "06/30/2020 16:43:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3990138617545824e-05, 'epoch': 0.3605916829472509, 'step': 1292}\n",
      "06/30/2020 16:43:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.398083542655131e-05, 'epoch': 0.3611498744069216, 'step': 1294}\n",
      "06/30/2020 16:43:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.39715322355568e-05, 'epoch': 0.36170806586659227, 'step': 1296}\n",
      "06/30/2020 16:43:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3962229044562285e-05, 'epoch': 0.3622662573262629, 'step': 1298}\n",
      "06/30/2020 16:43:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.395292585356778e-05, 'epoch': 0.36282444878593356, 'step': 1300}\n",
      "06/30/2020 16:43:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3943622662573265e-05, 'epoch': 0.36338264024560424, 'step': 1302}\n",
      "06/30/2020 16:44:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.393431947157876e-05, 'epoch': 0.3639408317052749, 'step': 1304}\n",
      "06/30/2020 16:44:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.392501628058424e-05, 'epoch': 0.3644990231649456, 'step': 1306}\n",
      "06/30/2020 16:44:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.391571308958973e-05, 'epoch': 0.36505721462461627, 'step': 1308}\n",
      "06/30/2020 16:44:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.390640989859522e-05, 'epoch': 0.3656154060842869, 'step': 1310}\n",
      "06/30/2020 16:44:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.389710670760071e-05, 'epoch': 0.36617359754395756, 'step': 1312}\n",
      "06/30/2020 16:44:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.38878035166062e-05, 'epoch': 0.36673178900362824, 'step': 1314}\n",
      "06/30/2020 16:44:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3878500325611686e-05, 'epoch': 0.3672899804632989, 'step': 1316}\n",
      "06/30/2020 16:44:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.386919713461717e-05, 'epoch': 0.3678481719229696, 'step': 1318}\n",
      "06/30/2020 16:44:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3859893943622666e-05, 'epoch': 0.36840636338264027, 'step': 1320}\n",
      "06/30/2020 16:44:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.385059075262815e-05, 'epoch': 0.3689645548423109, 'step': 1322}\n",
      "06/30/2020 16:44:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.384128756163364e-05, 'epoch': 0.36952274630198156, 'step': 1324}\n",
      "06/30/2020 16:44:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.383198437063913e-05, 'epoch': 0.37008093776165224, 'step': 1326}\n",
      "06/30/2020 16:44:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.382268117964462e-05, 'epoch': 0.3706391292213229, 'step': 1328}\n",
      "06/30/2020 16:44:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3813377988650114e-05, 'epoch': 0.3711973206809936, 'step': 1330}\n",
      "06/30/2020 16:44:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.38040747976556e-05, 'epoch': 0.37175551214066427, 'step': 1332}\n",
      "06/30/2020 16:44:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.379477160666109e-05, 'epoch': 0.3723137036003349, 'step': 1334}\n",
      "06/30/2020 16:44:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3785468415666574e-05, 'epoch': 0.37287189506000556, 'step': 1336}\n",
      "06/30/2020 16:44:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.377616522467207e-05, 'epoch': 0.37343008651967624, 'step': 1338}\n",
      "06/30/2020 16:44:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3766862033677554e-05, 'epoch': 0.3739882779793469, 'step': 1340}\n",
      "06/30/2020 16:44:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.375755884268304e-05, 'epoch': 0.3745464694390176, 'step': 1342}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:44:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.374825565168853e-05, 'epoch': 0.37510466089868827, 'step': 1344}\n",
      "06/30/2020 16:44:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.373895246069402e-05, 'epoch': 0.3756628523583589, 'step': 1346}\n",
      "06/30/2020 16:44:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.372964926969951e-05, 'epoch': 0.37622104381802957, 'step': 1348}\n",
      "06/30/2020 16:44:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3720346078705e-05, 'epoch': 0.37677923527770024, 'step': 1350}\n",
      "06/30/2020 16:44:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.371104288771048e-05, 'epoch': 0.3773374267373709, 'step': 1352}\n",
      "06/30/2020 16:44:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3701739696715975e-05, 'epoch': 0.3778956181970416, 'step': 1354}\n",
      "06/30/2020 16:44:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.369243650572146e-05, 'epoch': 0.37845380965671227, 'step': 1356}\n",
      "06/30/2020 16:44:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3683133314726956e-05, 'epoch': 0.37901200111638295, 'step': 1358}\n",
      "06/30/2020 16:44:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.367383012373244e-05, 'epoch': 0.37957019257605357, 'step': 1360}\n",
      "06/30/2020 16:44:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.366452693273793e-05, 'epoch': 0.38012838403572424, 'step': 1362}\n",
      "06/30/2020 16:44:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3655223741743416e-05, 'epoch': 0.3806865754953949, 'step': 1364}\n",
      "06/30/2020 16:44:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.364592055074891e-05, 'epoch': 0.3812447669550656, 'step': 1366}\n",
      "06/30/2020 16:44:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.36366173597544e-05, 'epoch': 0.38180295841473627, 'step': 1368}\n",
      "06/30/2020 16:44:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.362731416875988e-05, 'epoch': 0.38236114987440695, 'step': 1370}\n",
      "06/30/2020 16:44:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3618010977765377e-05, 'epoch': 0.38291934133407757, 'step': 1372}\n",
      "06/30/2020 16:44:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.360870778677086e-05, 'epoch': 0.38347753279374824, 'step': 1374}\n",
      "06/30/2020 16:44:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.359940459577636e-05, 'epoch': 0.3840357242534189, 'step': 1376}\n",
      "06/30/2020 16:44:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3590101404781844e-05, 'epoch': 0.3845939157130896, 'step': 1378}\n",
      "06/30/2020 16:44:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.358079821378733e-05, 'epoch': 0.38515210717276027, 'step': 1380}\n",
      "06/30/2020 16:44:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.357149502279282e-05, 'epoch': 0.38571029863243095, 'step': 1382}\n",
      "06/30/2020 16:44:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.356219183179831e-05, 'epoch': 0.38626849009210157, 'step': 1384}\n",
      "06/30/2020 16:44:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.35528886408038e-05, 'epoch': 0.38682668155177224, 'step': 1386}\n",
      "06/30/2020 16:44:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.354358544980929e-05, 'epoch': 0.3873848730114429, 'step': 1388}\n",
      "06/30/2020 16:44:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.353428225881477e-05, 'epoch': 0.3879430644711136, 'step': 1390}\n",
      "06/30/2020 16:44:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3524979067820265e-05, 'epoch': 0.3885012559307843, 'step': 1392}\n",
      "06/30/2020 16:44:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.351567587682575e-05, 'epoch': 0.38905944739045495, 'step': 1394}\n",
      "06/30/2020 16:44:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3506372685831245e-05, 'epoch': 0.38961763885012557, 'step': 1396}\n",
      "06/30/2020 16:44:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.349706949483673e-05, 'epoch': 0.39017583030979625, 'step': 1398}\n",
      "06/30/2020 16:44:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.348776630384222e-05, 'epoch': 0.3907340217694669, 'step': 1400}\n",
      "06/30/2020 16:44:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.347846311284771e-05, 'epoch': 0.3912922132291376, 'step': 1402}\n",
      "06/30/2020 16:44:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.34691599218532e-05, 'epoch': 0.3918504046888083, 'step': 1404}\n",
      "06/30/2020 16:44:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.345985673085869e-05, 'epoch': 0.39240859614847895, 'step': 1406}\n",
      "06/30/2020 16:44:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.345055353986417e-05, 'epoch': 0.39296678760814957, 'step': 1408}\n",
      "06/30/2020 16:44:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3441250348869666e-05, 'epoch': 0.39352497906782025, 'step': 1410}\n",
      "06/30/2020 16:44:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.343194715787515e-05, 'epoch': 0.3940831705274909, 'step': 1412}\n",
      "06/30/2020 16:44:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3422643966880646e-05, 'epoch': 0.3946413619871616, 'step': 1414}\n",
      "06/30/2020 16:44:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.341334077588613e-05, 'epoch': 0.3951995534468323, 'step': 1416}\n",
      "06/30/2020 16:44:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.340403758489162e-05, 'epoch': 0.39575774490650295, 'step': 1418}\n",
      "06/30/2020 16:44:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3394734393897106e-05, 'epoch': 0.39631593636617357, 'step': 1420}\n",
      "06/30/2020 16:44:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.33854312029026e-05, 'epoch': 0.39687412782584425, 'step': 1422}\n",
      "06/30/2020 16:44:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.337612801190809e-05, 'epoch': 0.3974323192855149, 'step': 1424}\n",
      "06/30/2020 16:44:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3366824820913574e-05, 'epoch': 0.3979905107451856, 'step': 1426}\n",
      "06/30/2020 16:44:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.335752162991906e-05, 'epoch': 0.3985487022048563, 'step': 1428}\n",
      "06/30/2020 16:44:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3348218438924554e-05, 'epoch': 0.39910689366452695, 'step': 1430}\n",
      "06/30/2020 16:44:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.333891524793004e-05, 'epoch': 0.39966508512419757, 'step': 1432}\n",
      "06/30/2020 16:44:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3329612056935534e-05, 'epoch': 0.40022327658386825, 'step': 1434}\n",
      "06/30/2020 16:44:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3320308865941014e-05, 'epoch': 0.4007814680435389, 'step': 1436}\n",
      "06/30/2020 16:44:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.331100567494651e-05, 'epoch': 0.4013396595032096, 'step': 1438}\n",
      "06/30/2020 16:44:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3301702483952e-05, 'epoch': 0.4018978509628803, 'step': 1440}\n",
      "06/30/2020 16:44:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.329239929295749e-05, 'epoch': 0.40245604242255095, 'step': 1442}\n",
      "06/30/2020 16:44:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3283096101962975e-05, 'epoch': 0.40301423388222163, 'step': 1444}\n",
      "06/30/2020 16:44:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.327379291096846e-05, 'epoch': 0.40357242534189225, 'step': 1446}\n",
      "06/30/2020 16:44:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3264489719973955e-05, 'epoch': 0.4041306168015629, 'step': 1448}\n",
      "06/30/2020 16:44:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.325518652897944e-05, 'epoch': 0.4046888082612336, 'step': 1450}\n",
      "06/30/2020 16:44:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3245883337984935e-05, 'epoch': 0.4052469997209043, 'step': 1452}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:44:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3236580146990415e-05, 'epoch': 0.40580519118057495, 'step': 1454}\n",
      "06/30/2020 16:44:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.322727695599591e-05, 'epoch': 0.40636338264024563, 'step': 1456}\n",
      "06/30/2020 16:44:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3217973765001396e-05, 'epoch': 0.40692157409991625, 'step': 1458}\n",
      "06/30/2020 16:44:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.320867057400689e-05, 'epoch': 0.4074797655595869, 'step': 1460}\n",
      "06/30/2020 16:44:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3199367383012376e-05, 'epoch': 0.4080379570192576, 'step': 1462}\n",
      "06/30/2020 16:44:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.319006419201786e-05, 'epoch': 0.4085961484789283, 'step': 1464}\n",
      "06/30/2020 16:44:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.318076100102335e-05, 'epoch': 0.40915433993859895, 'step': 1466}\n",
      "06/30/2020 16:44:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.317145781002884e-05, 'epoch': 0.40971253139826963, 'step': 1468}\n",
      "06/30/2020 16:44:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.316215461903433e-05, 'epoch': 0.41027072285794025, 'step': 1470}\n",
      "06/30/2020 16:44:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.315285142803982e-05, 'epoch': 0.4108289143176109, 'step': 1472}\n",
      "06/30/2020 16:44:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3143548237045303e-05, 'epoch': 0.4113871057772816, 'step': 1474}\n",
      "06/30/2020 16:44:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.31342450460508e-05, 'epoch': 0.4119452972369523, 'step': 1476}\n",
      "06/30/2020 16:44:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.312494185505629e-05, 'epoch': 0.41250348869662296, 'step': 1478}\n",
      "06/30/2020 16:44:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.311563866406178e-05, 'epoch': 0.41306168015629363, 'step': 1480}\n",
      "06/30/2020 16:44:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3106335473067264e-05, 'epoch': 0.41361987161596425, 'step': 1482}\n",
      "06/30/2020 16:44:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.309703228207275e-05, 'epoch': 0.41417806307563493, 'step': 1484}\n",
      "06/30/2020 16:44:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3087729091078244e-05, 'epoch': 0.4147362545353056, 'step': 1486}\n",
      "06/30/2020 16:44:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.307842590008373e-05, 'epoch': 0.4152944459949763, 'step': 1488}\n",
      "06/30/2020 16:44:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.306912270908922e-05, 'epoch': 0.41585263745464696, 'step': 1490}\n",
      "06/30/2020 16:44:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3059819518094705e-05, 'epoch': 0.41641082891431763, 'step': 1492}\n",
      "06/30/2020 16:44:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.30505163271002e-05, 'epoch': 0.41696902037398825, 'step': 1494}\n",
      "06/30/2020 16:44:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3041213136105685e-05, 'epoch': 0.41752721183365893, 'step': 1496}\n",
      "06/30/2020 16:44:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.303190994511118e-05, 'epoch': 0.4180854032933296, 'step': 1498}\n",
      "06/30/2020 16:44:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3022606754116665e-05, 'epoch': 0.4186435947530003, 'step': 1500}\n",
      "06/30/2020 16:44:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.301330356312215e-05, 'epoch': 0.41920178621267096, 'step': 1502}\n",
      "06/30/2020 16:44:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.300400037212764e-05, 'epoch': 0.41975997767234163, 'step': 1504}\n",
      "06/30/2020 16:44:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.299469718113313e-05, 'epoch': 0.42031816913201225, 'step': 1506}\n",
      "06/30/2020 16:44:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.298539399013862e-05, 'epoch': 0.42087636059168293, 'step': 1508}\n",
      "06/30/2020 16:44:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2976090799144106e-05, 'epoch': 0.4214345520513536, 'step': 1510}\n",
      "06/30/2020 16:44:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.29667876081496e-05, 'epoch': 0.4219927435110243, 'step': 1512}\n",
      "06/30/2020 16:44:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2957484417155086e-05, 'epoch': 0.42255093497069496, 'step': 1514}\n",
      "06/30/2020 16:44:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.294818122616058e-05, 'epoch': 0.42310912643036563, 'step': 1516}\n",
      "06/30/2020 16:44:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2938878035166067e-05, 'epoch': 0.4236673178900363, 'step': 1518}\n",
      "06/30/2020 16:44:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.292957484417155e-05, 'epoch': 0.42422550934970693, 'step': 1520}\n",
      "06/30/2020 16:44:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.292027165317704e-05, 'epoch': 0.4247837008093776, 'step': 1522}\n",
      "06/30/2020 16:44:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2910968462182534e-05, 'epoch': 0.4253418922690483, 'step': 1524}\n",
      "06/30/2020 16:44:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.290166527118802e-05, 'epoch': 0.42590008372871896, 'step': 1526}\n",
      "06/30/2020 16:44:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.289236208019351e-05, 'epoch': 0.42645827518838963, 'step': 1528}\n",
      "06/30/2020 16:44:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2883058889198994e-05, 'epoch': 0.4270164666480603, 'step': 1530}\n",
      "06/30/2020 16:44:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.287375569820449e-05, 'epoch': 0.42757465810773093, 'step': 1532}\n",
      "06/30/2020 16:44:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2864452507209974e-05, 'epoch': 0.4281328495674016, 'step': 1534}\n",
      "06/30/2020 16:44:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.285514931621547e-05, 'epoch': 0.4286910410270723, 'step': 1536}\n",
      "06/30/2020 16:44:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.284584612522095e-05, 'epoch': 0.42924923248674296, 'step': 1538}\n",
      "06/30/2020 16:44:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.283654293422644e-05, 'epoch': 0.42980742394641364, 'step': 1540}\n",
      "06/30/2020 16:44:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.282723974323193e-05, 'epoch': 0.4303656154060843, 'step': 1542}\n",
      "06/30/2020 16:44:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.281793655223742e-05, 'epoch': 0.43092380686575493, 'step': 1544}\n",
      "06/30/2020 16:44:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.280863336124291e-05, 'epoch': 0.4314819983254256, 'step': 1546}\n",
      "06/30/2020 16:44:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2799330170248395e-05, 'epoch': 0.4320401897850963, 'step': 1548}\n",
      "06/30/2020 16:44:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.279002697925389e-05, 'epoch': 0.43259838124476696, 'step': 1550}\n",
      "06/30/2020 16:44:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2780723788259376e-05, 'epoch': 0.43315657270443764, 'step': 1552}\n",
      "06/30/2020 16:44:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.277142059726487e-05, 'epoch': 0.4337147641641083, 'step': 1554}\n",
      "06/30/2020 16:44:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.276211740627035e-05, 'epoch': 0.43427295562377893, 'step': 1556}\n",
      "06/30/2020 16:44:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.275281421527584e-05, 'epoch': 0.4348311470834496, 'step': 1558}\n",
      "06/30/2020 16:44:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.274351102428133e-05, 'epoch': 0.4353893385431203, 'step': 1560}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:44:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.273420783328682e-05, 'epoch': 0.43594753000279096, 'step': 1562}\n",
      "06/30/2020 16:44:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.272490464229231e-05, 'epoch': 0.43650572146246164, 'step': 1564}\n",
      "06/30/2020 16:44:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2715601451297797e-05, 'epoch': 0.4370639129221323, 'step': 1566}\n",
      "06/30/2020 16:44:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.270629826030328e-05, 'epoch': 0.43762210438180293, 'step': 1568}\n",
      "06/30/2020 16:44:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.269699506930878e-05, 'epoch': 0.4381802958414736, 'step': 1570}\n",
      "06/30/2020 16:44:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2687691878314264e-05, 'epoch': 0.4387384873011443, 'step': 1572}\n",
      "06/30/2020 16:44:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.267838868731975e-05, 'epoch': 0.43929667876081496, 'step': 1574}\n",
      "06/30/2020 16:44:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.266908549632524e-05, 'epoch': 0.43985487022048564, 'step': 1576}\n",
      "06/30/2020 16:44:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.265978230533073e-05, 'epoch': 0.4404130616801563, 'step': 1578}\n",
      "06/30/2020 16:44:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.265047911433622e-05, 'epoch': 0.44097125313982694, 'step': 1580}\n",
      "06/30/2020 16:44:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.264117592334171e-05, 'epoch': 0.4415294445994976, 'step': 1582}\n",
      "06/30/2020 16:44:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.26318727323472e-05, 'epoch': 0.4420876360591683, 'step': 1584}\n",
      "06/30/2020 16:44:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2622569541352685e-05, 'epoch': 0.44264582751883896, 'step': 1586}\n",
      "06/30/2020 16:44:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.261326635035818e-05, 'epoch': 0.44320401897850964, 'step': 1588}\n",
      "06/30/2020 16:44:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2603963159363665e-05, 'epoch': 0.4437622104381803, 'step': 1590}\n",
      "06/30/2020 16:44:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.259465996836915e-05, 'epoch': 0.44432040189785094, 'step': 1592}\n",
      "06/30/2020 16:44:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.258535677737464e-05, 'epoch': 0.4448785933575216, 'step': 1594}\n",
      "06/30/2020 16:44:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.257605358638013e-05, 'epoch': 0.4454367848171923, 'step': 1596}\n",
      "06/30/2020 16:44:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.256675039538562e-05, 'epoch': 0.44599497627686296, 'step': 1598}\n",
      "06/30/2020 16:44:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.255744720439111e-05, 'epoch': 0.44655316773653364, 'step': 1600}\n",
      "06/30/2020 16:44:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.25481440133966e-05, 'epoch': 0.4471113591962043, 'step': 1602}\n",
      "06/30/2020 16:44:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2538840822402086e-05, 'epoch': 0.447669550655875, 'step': 1604}\n",
      "06/30/2020 16:44:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.252953763140757e-05, 'epoch': 0.4482277421155456, 'step': 1606}\n",
      "06/30/2020 16:44:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2520234440413066e-05, 'epoch': 0.4487859335752163, 'step': 1608}\n",
      "06/30/2020 16:44:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.251093124941855e-05, 'epoch': 0.44934412503488697, 'step': 1610}\n",
      "06/30/2020 16:44:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.250162805842404e-05, 'epoch': 0.44990231649455764, 'step': 1612}\n",
      "06/30/2020 16:44:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2492324867429526e-05, 'epoch': 0.4504605079542283, 'step': 1614}\n",
      "06/30/2020 16:44:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.248302167643502e-05, 'epoch': 0.451018699413899, 'step': 1616}\n",
      "06/30/2020 16:44:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.247371848544051e-05, 'epoch': 0.4515768908735696, 'step': 1618}\n",
      "06/30/2020 16:44:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2464415294446e-05, 'epoch': 0.4521350823332403, 'step': 1620}\n",
      "06/30/2020 16:44:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.245511210345148e-05, 'epoch': 0.45269327379291097, 'step': 1622}\n",
      "06/30/2020 16:44:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2445808912456974e-05, 'epoch': 0.45325146525258164, 'step': 1624}\n",
      "06/30/2020 16:44:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.243650572146247e-05, 'epoch': 0.4538096567122523, 'step': 1626}\n",
      "06/30/2020 16:44:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2427202530467954e-05, 'epoch': 0.454367848171923, 'step': 1628}\n",
      "06/30/2020 16:44:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.241789933947344e-05, 'epoch': 0.4549260396315936, 'step': 1630}\n",
      "06/30/2020 16:44:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.240859614847893e-05, 'epoch': 0.4554842310912643, 'step': 1632}\n",
      "06/30/2020 16:44:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.239929295748442e-05, 'epoch': 0.45604242255093497, 'step': 1634}\n",
      "06/30/2020 16:44:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.238998976648991e-05, 'epoch': 0.45660061401060564, 'step': 1636}\n",
      "06/30/2020 16:44:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.23806865754954e-05, 'epoch': 0.4571588054702763, 'step': 1638}\n",
      "06/30/2020 16:44:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.237138338450088e-05, 'epoch': 0.457716996929947, 'step': 1640}\n",
      "06/30/2020 16:44:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2362080193506375e-05, 'epoch': 0.4582751883896176, 'step': 1642}\n",
      "06/30/2020 16:44:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.235277700251186e-05, 'epoch': 0.4588333798492883, 'step': 1644}\n",
      "06/30/2020 16:44:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2343473811517355e-05, 'epoch': 0.45939157130895897, 'step': 1646}\n",
      "06/30/2020 16:44:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.233417062052284e-05, 'epoch': 0.45994976276862964, 'step': 1648}\n",
      "06/30/2020 16:44:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.232486742952833e-05, 'epoch': 0.4605079542283003, 'step': 1650}\n",
      "06/30/2020 16:44:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2315564238533816e-05, 'epoch': 0.461066145687971, 'step': 1652}\n",
      "06/30/2020 16:44:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.230626104753931e-05, 'epoch': 0.4616243371476416, 'step': 1654}\n",
      "06/30/2020 16:44:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2296957856544796e-05, 'epoch': 0.4621825286073123, 'step': 1656}\n",
      "06/30/2020 16:44:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.228765466555028e-05, 'epoch': 0.46274072006698297, 'step': 1658}\n",
      "06/30/2020 16:44:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2278351474555776e-05, 'epoch': 0.46329891152665365, 'step': 1660}\n",
      "06/30/2020 16:44:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.226904828356126e-05, 'epoch': 0.4638571029863243, 'step': 1662}\n",
      "06/30/2020 16:44:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.225974509256676e-05, 'epoch': 0.464415294445995, 'step': 1664}\n",
      "06/30/2020 16:44:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2250441901572243e-05, 'epoch': 0.4649734859056656, 'step': 1666}\n",
      "06/30/2020 16:44:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.224113871057773e-05, 'epoch': 0.4655316773653363, 'step': 1668}\n",
      "06/30/2020 16:44:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.223183551958322e-05, 'epoch': 0.46608986882500697, 'step': 1670}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:44:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.222253232858871e-05, 'epoch': 0.46664806028467765, 'step': 1672}\n",
      "06/30/2020 16:44:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.22132291375942e-05, 'epoch': 0.4672062517443483, 'step': 1674}\n",
      "06/30/2020 16:44:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2203925946599684e-05, 'epoch': 0.467764443204019, 'step': 1676}\n",
      "06/30/2020 16:44:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.219462275560517e-05, 'epoch': 0.4683226346636896, 'step': 1678}\n",
      "06/30/2020 16:44:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2185319564610664e-05, 'epoch': 0.4688808261233603, 'step': 1680}\n",
      "06/30/2020 16:44:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.217601637361615e-05, 'epoch': 0.46943901758303097, 'step': 1682}\n",
      "06/30/2020 16:44:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2166713182621645e-05, 'epoch': 0.46999720904270165, 'step': 1684}\n",
      "06/30/2020 16:44:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.215740999162713e-05, 'epoch': 0.4705554005023723, 'step': 1686}\n",
      "06/30/2020 16:44:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.214810680063262e-05, 'epoch': 0.471113591962043, 'step': 1688}\n",
      "06/30/2020 16:44:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2138803609638105e-05, 'epoch': 0.4716717834217137, 'step': 1690}\n",
      "06/30/2020 16:44:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.21295004186436e-05, 'epoch': 0.4722299748813843, 'step': 1692}\n",
      "06/30/2020 16:44:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2120197227649085e-05, 'epoch': 0.47278816634105497, 'step': 1694}\n",
      "06/30/2020 16:44:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.211089403665457e-05, 'epoch': 0.47334635780072565, 'step': 1696}\n",
      "06/30/2020 16:44:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2101590845660066e-05, 'epoch': 0.4739045492603963, 'step': 1698}\n",
      "06/30/2020 16:44:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.209228765466555e-05, 'epoch': 0.474462740720067, 'step': 1700}\n",
      "06/30/2020 16:44:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2082984463671046e-05, 'epoch': 0.4750209321797377, 'step': 1702}\n",
      "06/30/2020 16:44:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.207368127267653e-05, 'epoch': 0.4755791236394083, 'step': 1704}\n",
      "06/30/2020 16:44:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.206437808168202e-05, 'epoch': 0.476137315099079, 'step': 1706}\n",
      "06/30/2020 16:44:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2055074890687506e-05, 'epoch': 0.47669550655874965, 'step': 1708}\n",
      "06/30/2020 16:44:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2045771699693e-05, 'epoch': 0.4772536980184203, 'step': 1710}\n",
      "06/30/2020 16:44:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2036468508698487e-05, 'epoch': 0.477811889478091, 'step': 1712}\n",
      "06/30/2020 16:44:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.202716531770397e-05, 'epoch': 0.4783700809377617, 'step': 1714}\n",
      "06/30/2020 16:44:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.201786212670946e-05, 'epoch': 0.4789282723974323, 'step': 1716}\n",
      "06/30/2020 16:44:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2008558935714954e-05, 'epoch': 0.479486463857103, 'step': 1718}\n",
      "06/30/2020 16:44:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.199925574472044e-05, 'epoch': 0.48004465531677365, 'step': 1720}\n",
      "06/30/2020 16:44:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1989952553725934e-05, 'epoch': 0.4806028467764443, 'step': 1722}\n",
      "06/30/2020 16:44:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1980649362731414e-05, 'epoch': 0.481161038236115, 'step': 1724}\n",
      "06/30/2020 16:44:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.197134617173691e-05, 'epoch': 0.4817192296957857, 'step': 1726}\n",
      "06/30/2020 16:44:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1962042980742394e-05, 'epoch': 0.4822774211554563, 'step': 1728}\n",
      "06/30/2020 16:44:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.195273978974789e-05, 'epoch': 0.482835612615127, 'step': 1730}\n",
      "06/30/2020 16:44:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1943436598753375e-05, 'epoch': 0.48339380407479765, 'step': 1732}\n",
      "06/30/2020 16:44:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.193413340775886e-05, 'epoch': 0.4839519955344683, 'step': 1734}\n",
      "06/30/2020 16:44:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1924830216764355e-05, 'epoch': 0.484510186994139, 'step': 1736}\n",
      "06/30/2020 16:44:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.191552702576984e-05, 'epoch': 0.4850683784538097, 'step': 1738}\n",
      "06/30/2020 16:44:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1906223834775335e-05, 'epoch': 0.4856265699134803, 'step': 1740}\n",
      "06/30/2020 16:44:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1896920643780815e-05, 'epoch': 0.486184761373151, 'step': 1742}\n",
      "06/30/2020 16:44:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.188761745278631e-05, 'epoch': 0.48674295283282165, 'step': 1744}\n",
      "06/30/2020 16:44:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1878314261791796e-05, 'epoch': 0.4873011442924923, 'step': 1746}\n",
      "06/30/2020 16:44:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.186901107079729e-05, 'epoch': 0.487859335752163, 'step': 1748}\n",
      "06/30/2020 16:44:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1859707879802776e-05, 'epoch': 0.4884175272118337, 'step': 1750}\n",
      "06/30/2020 16:44:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.185040468880826e-05, 'epoch': 0.4889757186715043, 'step': 1752}\n",
      "06/30/2020 16:44:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.184110149781375e-05, 'epoch': 0.489533910131175, 'step': 1754}\n",
      "06/30/2020 16:44:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.183179830681924e-05, 'epoch': 0.49009210159084565, 'step': 1756}\n",
      "06/30/2020 16:44:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.182249511582473e-05, 'epoch': 0.49065029305051633, 'step': 1758}\n",
      "06/30/2020 16:44:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1813191924830216e-05, 'epoch': 0.491208484510187, 'step': 1760}\n",
      "06/30/2020 16:44:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.18038887338357e-05, 'epoch': 0.4917666759698577, 'step': 1762}\n",
      "06/30/2020 16:44:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.17945855428412e-05, 'epoch': 0.4923248674295283, 'step': 1764}\n",
      "06/30/2020 16:44:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1785282351846684e-05, 'epoch': 0.492883058889199, 'step': 1766}\n",
      "06/30/2020 16:44:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.177597916085218e-05, 'epoch': 0.49344125034886965, 'step': 1768}\n",
      "06/30/2020 16:44:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1766675969857664e-05, 'epoch': 0.49399944180854033, 'step': 1770}\n",
      "06/30/2020 16:44:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.175737277886315e-05, 'epoch': 0.494557633268211, 'step': 1772}\n",
      "06/30/2020 16:44:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1748069587868644e-05, 'epoch': 0.4951158247278817, 'step': 1774}\n",
      "06/30/2020 16:44:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.173876639687413e-05, 'epoch': 0.49567401618755236, 'step': 1776}\n",
      "06/30/2020 16:44:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.172946320587962e-05, 'epoch': 0.496232207647223, 'step': 1778}\n",
      "06/30/2020 16:44:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1720160014885104e-05, 'epoch': 0.49679039910689365, 'step': 1780}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:44:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.17108568238906e-05, 'epoch': 0.49734859056656433, 'step': 1782}\n",
      "06/30/2020 16:44:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1701553632896085e-05, 'epoch': 0.497906782026235, 'step': 1784}\n",
      "06/30/2020 16:44:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.169225044190158e-05, 'epoch': 0.4984649734859057, 'step': 1786}\n",
      "06/30/2020 16:44:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1682947250907065e-05, 'epoch': 0.49902316494557636, 'step': 1788}\n",
      "06/30/2020 16:44:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.167364405991255e-05, 'epoch': 0.499581356405247, 'step': 1790}\n",
      "06/30/2020 16:44:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.166434086891804e-05, 'epoch': 0.5001395478649177, 'step': 1792}\n",
      "06/30/2020 16:44:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.165503767792353e-05, 'epoch': 0.5006977393245884, 'step': 1794}\n",
      "06/30/2020 16:44:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.164573448692902e-05, 'epoch': 0.501255930784259, 'step': 1796}\n",
      "06/30/2020 16:44:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1636431295934506e-05, 'epoch': 0.5018141222439296, 'step': 1798}\n",
      "06/30/2020 16:44:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.162712810493999e-05, 'epoch': 0.5023723137036004, 'step': 1800}\n",
      "06/30/2020 16:44:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1617824913945486e-05, 'epoch': 0.502930505163271, 'step': 1802}\n",
      "06/30/2020 16:44:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.160852172295097e-05, 'epoch': 0.5034886966229417, 'step': 1804}\n",
      "06/30/2020 16:44:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1599218531956466e-05, 'epoch': 0.5040468880826123, 'step': 1806}\n",
      "06/30/2020 16:44:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.158991534096195e-05, 'epoch': 0.504605079542283, 'step': 1808}\n",
      "06/30/2020 16:44:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.158061214996744e-05, 'epoch': 0.5051632710019537, 'step': 1810}\n",
      "06/30/2020 16:44:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1571308958972933e-05, 'epoch': 0.5057214624616243, 'step': 1812}\n",
      "06/30/2020 16:44:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.156200576797842e-05, 'epoch': 0.506279653921295, 'step': 1814}\n",
      "06/30/2020 16:44:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.155270257698391e-05, 'epoch': 0.5068378453809657, 'step': 1816}\n",
      "06/30/2020 16:44:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1543399385989394e-05, 'epoch': 0.5073960368406364, 'step': 1818}\n",
      "06/30/2020 16:44:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.153409619499489e-05, 'epoch': 0.507954228300307, 'step': 1820}\n",
      "06/30/2020 16:44:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1524793004000374e-05, 'epoch': 0.5085124197599776, 'step': 1822}\n",
      "06/30/2020 16:44:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.151548981300587e-05, 'epoch': 0.5090706112196484, 'step': 1824}\n",
      "06/30/2020 16:44:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.150618662201135e-05, 'epoch': 0.509628802679319, 'step': 1826}\n",
      "06/30/2020 16:44:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.149688343101684e-05, 'epoch': 0.5101869941389897, 'step': 1828}\n",
      "06/30/2020 16:44:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.148758024002233e-05, 'epoch': 0.5107451855986603, 'step': 1830}\n",
      "06/30/2020 16:44:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.147827704902782e-05, 'epoch': 0.511303377058331, 'step': 1832}\n",
      "06/30/2020 16:44:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.146897385803331e-05, 'epoch': 0.5118615685180017, 'step': 1834}\n",
      "06/30/2020 16:44:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1459670667038795e-05, 'epoch': 0.5124197599776723, 'step': 1836}\n",
      "06/30/2020 16:44:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.145036747604428e-05, 'epoch': 0.512977951437343, 'step': 1838}\n",
      "06/30/2020 16:44:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1441064285049775e-05, 'epoch': 0.5135361428970137, 'step': 1840}\n",
      "06/30/2020 16:44:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.143176109405526e-05, 'epoch': 0.5140943343566844, 'step': 1842}\n",
      "06/30/2020 16:44:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.142245790306075e-05, 'epoch': 0.514652525816355, 'step': 1844}\n",
      "06/30/2020 16:44:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.141315471206624e-05, 'epoch': 0.5152107172760256, 'step': 1846}\n",
      "06/30/2020 16:44:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.140385152107173e-05, 'epoch': 0.5157689087356964, 'step': 1848}\n",
      "06/30/2020 16:44:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.139454833007722e-05, 'epoch': 0.516327100195367, 'step': 1850}\n",
      "06/30/2020 16:44:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.138524513908271e-05, 'epoch': 0.5168852916550377, 'step': 1852}\n",
      "06/30/2020 16:44:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1375941948088196e-05, 'epoch': 0.5174434831147083, 'step': 1854}\n",
      "06/30/2020 16:44:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.136663875709368e-05, 'epoch': 0.5180016745743791, 'step': 1856}\n",
      "06/30/2020 16:44:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1357335566099177e-05, 'epoch': 0.5185598660340497, 'step': 1858}\n",
      "06/30/2020 16:44:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.134803237510466e-05, 'epoch': 0.5191180574937203, 'step': 1860}\n",
      "06/30/2020 16:44:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.133872918411015e-05, 'epoch': 0.519676248953391, 'step': 1862}\n",
      "06/30/2020 16:44:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.132942599311564e-05, 'epoch': 0.5202344404130617, 'step': 1864}\n",
      "06/30/2020 16:44:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.132012280212113e-05, 'epoch': 0.5207926318727324, 'step': 1866}\n",
      "06/30/2020 16:44:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.131081961112662e-05, 'epoch': 0.521350823332403, 'step': 1868}\n",
      "06/30/2020 16:44:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.130151642013211e-05, 'epoch': 0.5219090147920736, 'step': 1870}\n",
      "06/30/2020 16:44:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.129221322913759e-05, 'epoch': 0.5224672062517444, 'step': 1872}\n",
      "06/30/2020 16:44:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1282910038143084e-05, 'epoch': 0.523025397711415, 'step': 1874}\n",
      "06/30/2020 16:44:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.127360684714857e-05, 'epoch': 0.5235835891710857, 'step': 1876}\n",
      "06/30/2020 16:44:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1264303656154065e-05, 'epoch': 0.5241417806307563, 'step': 1878}\n",
      "06/30/2020 16:44:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.125500046515955e-05, 'epoch': 0.5246999720904271, 'step': 1880}\n",
      "06/30/2020 16:44:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.124569727416504e-05, 'epoch': 0.5252581635500977, 'step': 1882}\n",
      "06/30/2020 16:44:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.123639408317053e-05, 'epoch': 0.5258163550097683, 'step': 1884}\n",
      "06/30/2020 16:44:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.122709089217602e-05, 'epoch': 0.526374546469439, 'step': 1886}\n",
      "06/30/2020 16:44:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.121778770118151e-05, 'epoch': 0.5269327379291097, 'step': 1888}\n",
      "06/30/2020 16:44:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.120848451018699e-05, 'epoch': 0.5274909293887804, 'step': 1890}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:44:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1199181319192486e-05, 'epoch': 0.528049120848451, 'step': 1892}\n",
      "06/30/2020 16:44:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.118987812819797e-05, 'epoch': 0.5286073123081216, 'step': 1894}\n",
      "06/30/2020 16:44:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1180574937203466e-05, 'epoch': 0.5291655037677924, 'step': 1896}\n",
      "06/30/2020 16:44:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.117127174620895e-05, 'epoch': 0.529723695227463, 'step': 1898}\n",
      "06/30/2020 16:44:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.116196855521444e-05, 'epoch': 0.5302818866871337, 'step': 1900}\n",
      "06/30/2020 16:44:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1152665364219926e-05, 'epoch': 0.5308400781468043, 'step': 1902}\n",
      "06/30/2020 16:44:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.114336217322542e-05, 'epoch': 0.5313982696064751, 'step': 1904}\n",
      "06/30/2020 16:44:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1134058982230907e-05, 'epoch': 0.5319564610661457, 'step': 1906}\n",
      "06/30/2020 16:44:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.11247557912364e-05, 'epoch': 0.5325146525258163, 'step': 1908}\n",
      "06/30/2020 16:44:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.111545260024188e-05, 'epoch': 0.533072843985487, 'step': 1910}\n",
      "06/30/2020 16:44:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1106149409247374e-05, 'epoch': 0.5336310354451577, 'step': 1912}\n",
      "06/30/2020 16:44:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.109684621825286e-05, 'epoch': 0.5341892269048284, 'step': 1914}\n",
      "06/30/2020 16:44:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1087543027258354e-05, 'epoch': 0.534747418364499, 'step': 1916}\n",
      "06/30/2020 16:44:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.107823983626384e-05, 'epoch': 0.5353056098241696, 'step': 1918}\n",
      "06/30/2020 16:44:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.106893664526933e-05, 'epoch': 0.5358638012838404, 'step': 1920}\n",
      "06/30/2020 16:44:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.105963345427482e-05, 'epoch': 0.536421992743511, 'step': 1922}\n",
      "06/30/2020 16:44:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.105033026328031e-05, 'epoch': 0.5369801842031817, 'step': 1924}\n",
      "06/30/2020 16:44:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.10410270722858e-05, 'epoch': 0.5375383756628523, 'step': 1926}\n",
      "06/30/2020 16:44:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.103172388129128e-05, 'epoch': 0.5380965671225231, 'step': 1928}\n",
      "06/30/2020 16:44:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1022420690296775e-05, 'epoch': 0.5386547585821937, 'step': 1930}\n",
      "06/30/2020 16:44:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.101311749930226e-05, 'epoch': 0.5392129500418643, 'step': 1932}\n",
      "06/30/2020 16:44:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1003814308307755e-05, 'epoch': 0.539771141501535, 'step': 1934}\n",
      "06/30/2020 16:44:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.099451111731324e-05, 'epoch': 0.5403293329612057, 'step': 1936}\n",
      "06/30/2020 16:44:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.098520792631873e-05, 'epoch': 0.5408875244208764, 'step': 1938}\n",
      "06/30/2020 16:44:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0975904735324215e-05, 'epoch': 0.541445715880547, 'step': 1940}\n",
      "06/30/2020 16:44:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.096660154432971e-05, 'epoch': 0.5420039073402177, 'step': 1942}\n",
      "06/30/2020 16:44:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0957298353335196e-05, 'epoch': 0.5425620987998884, 'step': 1944}\n",
      "06/30/2020 16:44:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.094799516234068e-05, 'epoch': 0.543120290259559, 'step': 1946}\n",
      "06/30/2020 16:44:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.093869197134617e-05, 'epoch': 0.5436784817192297, 'step': 1948}\n",
      "06/30/2020 16:44:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.092938878035166e-05, 'epoch': 0.5442366731789003, 'step': 1950}\n",
      "06/30/2020 16:44:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.092008558935715e-05, 'epoch': 0.5447948646385711, 'step': 1952}\n",
      "06/30/2020 16:44:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.091078239836264e-05, 'epoch': 0.5453530560982417, 'step': 1954}\n",
      "06/30/2020 16:44:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.090147920736813e-05, 'epoch': 0.5459112475579123, 'step': 1956}\n",
      "06/30/2020 16:44:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.089217601637362e-05, 'epoch': 0.546469439017583, 'step': 1958}\n",
      "06/30/2020 16:44:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.088287282537911e-05, 'epoch': 0.5470276304772537, 'step': 1960}\n",
      "06/30/2020 16:44:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.08735696343846e-05, 'epoch': 0.5475858219369244, 'step': 1962}\n",
      "06/30/2020 16:44:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0864266443390084e-05, 'epoch': 0.548144013396595, 'step': 1964}\n",
      "06/30/2020 16:44:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.085496325239557e-05, 'epoch': 0.5487022048562658, 'step': 1966}\n",
      "06/30/2020 16:44:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0845660061401064e-05, 'epoch': 0.5492603963159364, 'step': 1968}\n",
      "06/30/2020 16:44:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.083635687040655e-05, 'epoch': 0.549818587775607, 'step': 1970}\n",
      "06/30/2020 16:44:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0827053679412044e-05, 'epoch': 0.5503767792352777, 'step': 1972}\n",
      "06/30/2020 16:44:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0817750488417524e-05, 'epoch': 0.5509349706949483, 'step': 1974}\n",
      "06/30/2020 16:44:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.080844729742302e-05, 'epoch': 0.5514931621546191, 'step': 1976}\n",
      "06/30/2020 16:44:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0799144106428505e-05, 'epoch': 0.5520513536142897, 'step': 1978}\n",
      "06/30/2020 16:44:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0789840915434e-05, 'epoch': 0.5526095450739603, 'step': 1980}\n",
      "06/30/2020 16:44:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0780537724439485e-05, 'epoch': 0.553167736533631, 'step': 1982}\n",
      "06/30/2020 16:44:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.077123453344497e-05, 'epoch': 0.5537259279933017, 'step': 1984}\n",
      "06/30/2020 16:44:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.076193134245046e-05, 'epoch': 0.5542841194529724, 'step': 1986}\n",
      "06/30/2020 16:44:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.075262815145595e-05, 'epoch': 0.554842310912643, 'step': 1988}\n",
      "06/30/2020 16:44:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.074332496046144e-05, 'epoch': 0.5554005023723138, 'step': 1990}\n",
      "06/30/2020 16:44:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0734021769466926e-05, 'epoch': 0.5559586938319844, 'step': 1992}\n",
      "06/30/2020 16:44:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.072471857847242e-05, 'epoch': 0.556516885291655, 'step': 1994}\n",
      "06/30/2020 16:44:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0715415387477906e-05, 'epoch': 0.5570750767513257, 'step': 1996}\n",
      "06/30/2020 16:44:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.07061121964834e-05, 'epoch': 0.5576332682109963, 'step': 1998}\n",
      "06/30/2020 16:44:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0696809005488886e-05, 'epoch': 0.5581914596706671, 'step': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:44:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.068750581449437e-05, 'epoch': 0.5587496511303377, 'step': 2002}\n",
      "06/30/2020 16:44:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.067820262349986e-05, 'epoch': 0.5593078425900083, 'step': 2004}\n",
      "06/30/2020 16:44:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0668899432505353e-05, 'epoch': 0.559866034049679, 'step': 2006}\n",
      "06/30/2020 16:44:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.065959624151084e-05, 'epoch': 0.5604242255093497, 'step': 2008}\n",
      "06/30/2020 16:44:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0650293050516334e-05, 'epoch': 0.5609824169690204, 'step': 2010}\n",
      "06/30/2020 16:44:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0640989859521814e-05, 'epoch': 0.561540608428691, 'step': 2012}\n",
      "06/30/2020 16:44:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.063168666852731e-05, 'epoch': 0.5620987998883618, 'step': 2014}\n",
      "06/30/2020 16:44:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0622383477532794e-05, 'epoch': 0.5626569913480324, 'step': 2016}\n",
      "06/30/2020 16:44:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.061308028653829e-05, 'epoch': 0.563215182807703, 'step': 2018}\n",
      "06/30/2020 16:44:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0603777095543774e-05, 'epoch': 0.5637733742673737, 'step': 2020}\n",
      "06/30/2020 16:44:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.059447390454926e-05, 'epoch': 0.5643315657270443, 'step': 2022}\n",
      "06/30/2020 16:44:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.058517071355475e-05, 'epoch': 0.5648897571867151, 'step': 2024}\n",
      "06/30/2020 16:44:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.057586752256024e-05, 'epoch': 0.5654479486463857, 'step': 2026}\n",
      "06/30/2020 16:44:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.056656433156573e-05, 'epoch': 0.5660061401060564, 'step': 2028}\n",
      "06/30/2020 16:44:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0557261140571215e-05, 'epoch': 0.566564331565727, 'step': 2030}\n",
      "06/30/2020 16:44:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.054795794957671e-05, 'epoch': 0.5671225230253977, 'step': 2032}\n",
      "06/30/2020 16:44:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0538654758582195e-05, 'epoch': 0.5676807144850684, 'step': 2034}\n",
      "06/30/2020 16:44:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.052935156758769e-05, 'epoch': 0.568238905944739, 'step': 2036}\n",
      "06/30/2020 16:44:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0520048376593176e-05, 'epoch': 0.5687970974044098, 'step': 2038}\n",
      "06/30/2020 16:44:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.051074518559866e-05, 'epoch': 0.5693552888640804, 'step': 2040}\n",
      "06/30/2020 16:44:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.050144199460415e-05, 'epoch': 0.569913480323751, 'step': 2042}\n",
      "06/30/2020 16:44:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.049213880360964e-05, 'epoch': 0.5704716717834217, 'step': 2044}\n",
      "06/30/2020 16:44:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.048283561261513e-05, 'epoch': 0.5710298632430924, 'step': 2046}\n",
      "06/30/2020 16:44:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0473532421620616e-05, 'epoch': 0.5715880547027631, 'step': 2048}\n",
      "06/30/2020 16:44:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.04642292306261e-05, 'epoch': 0.5721462461624337, 'step': 2050}\n",
      "06/30/2020 16:44:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0454926039631597e-05, 'epoch': 0.5727044376221044, 'step': 2052}\n",
      "06/30/2020 16:44:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.044562284863708e-05, 'epoch': 0.573262629081775, 'step': 2054}\n",
      "06/30/2020 16:44:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.043631965764258e-05, 'epoch': 0.5738208205414457, 'step': 2056}\n",
      "06/30/2020 16:44:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.042701646664806e-05, 'epoch': 0.5743790120011164, 'step': 2058}\n",
      "06/30/2020 16:44:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.041771327565355e-05, 'epoch': 0.574937203460787, 'step': 2060}\n",
      "06/30/2020 16:44:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.040841008465904e-05, 'epoch': 0.5754953949204578, 'step': 2062}\n",
      "06/30/2020 16:44:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.039910689366453e-05, 'epoch': 0.5760535863801284, 'step': 2064}\n",
      "06/30/2020 16:44:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.038980370267002e-05, 'epoch': 0.576611777839799, 'step': 2066}\n",
      "06/30/2020 16:44:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0380500511675504e-05, 'epoch': 0.5771699692994697, 'step': 2068}\n",
      "06/30/2020 16:44:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0371197320681e-05, 'epoch': 0.5777281607591404, 'step': 2070}\n",
      "06/30/2020 16:44:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0361894129686485e-05, 'epoch': 0.5782863522188111, 'step': 2072}\n",
      "06/30/2020 16:44:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.035259093869198e-05, 'epoch': 0.5788445436784817, 'step': 2074}\n",
      "06/30/2020 16:44:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.034328774769746e-05, 'epoch': 0.5794027351381524, 'step': 2076}\n",
      "06/30/2020 16:44:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.033398455670295e-05, 'epoch': 0.5799609265978231, 'step': 2078}\n",
      "06/30/2020 16:44:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.032468136570844e-05, 'epoch': 0.5805191180574937, 'step': 2080}\n",
      "06/30/2020 16:44:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.031537817471393e-05, 'epoch': 0.5810773095171644, 'step': 2082}\n",
      "06/30/2020 16:44:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.030607498371942e-05, 'epoch': 0.581635500976835, 'step': 2084}\n",
      "06/30/2020 16:44:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0296771792724906e-05, 'epoch': 0.5821936924365058, 'step': 2086}\n",
      "06/30/2020 16:44:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.028746860173039e-05, 'epoch': 0.5827518838961764, 'step': 2088}\n",
      "06/30/2020 16:44:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0278165410735886e-05, 'epoch': 0.583310075355847, 'step': 2090}\n",
      "06/30/2020 16:44:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.026886221974137e-05, 'epoch': 0.5838682668155177, 'step': 2092}\n",
      "06/30/2020 16:44:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.025955902874686e-05, 'epoch': 0.5844264582751884, 'step': 2094}\n",
      "06/30/2020 16:44:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0250255837752346e-05, 'epoch': 0.5849846497348591, 'step': 2096}\n",
      "06/30/2020 16:44:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.024095264675784e-05, 'epoch': 0.5855428411945297, 'step': 2098}\n",
      "06/30/2020 16:44:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0231649455763326e-05, 'epoch': 0.5861010326542004, 'step': 2100}\n",
      "06/30/2020 16:44:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.022234626476882e-05, 'epoch': 0.5866592241138711, 'step': 2102}\n",
      "06/30/2020 16:44:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.021304307377431e-05, 'epoch': 0.5872174155735417, 'step': 2104}\n",
      "06/30/2020 16:44:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0203739882779794e-05, 'epoch': 0.5877756070332124, 'step': 2106}\n",
      "06/30/2020 16:44:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.019443669178529e-05, 'epoch': 0.588333798492883, 'step': 2108}\n",
      "06/30/2020 16:44:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0185133500790774e-05, 'epoch': 0.5888919899525538, 'step': 2110}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:44:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.017583030979627e-05, 'epoch': 0.5894501814122244, 'step': 2112}\n",
      "06/30/2020 16:44:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.016652711880175e-05, 'epoch': 0.5900083728718951, 'step': 2114}\n",
      "06/30/2020 16:44:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.015722392780724e-05, 'epoch': 0.5905665643315657, 'step': 2116}\n",
      "06/30/2020 16:44:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.014792073681273e-05, 'epoch': 0.5911247557912364, 'step': 2118}\n",
      "06/30/2020 16:44:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.013861754581822e-05, 'epoch': 0.5916829472509071, 'step': 2120}\n",
      "06/30/2020 16:44:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.012931435482371e-05, 'epoch': 0.5922411387105777, 'step': 2122}\n",
      "06/30/2020 16:44:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0120011163829195e-05, 'epoch': 0.5927993301702484, 'step': 2124}\n",
      "06/30/2020 16:44:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.011070797283468e-05, 'epoch': 0.5933575216299191, 'step': 2126}\n",
      "06/30/2020 16:44:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0101404781840175e-05, 'epoch': 0.5939157130895897, 'step': 2128}\n",
      "06/30/2020 16:44:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.009210159084566e-05, 'epoch': 0.5944739045492604, 'step': 2130}\n",
      "06/30/2020 16:44:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.008279839985115e-05, 'epoch': 0.595032096008931, 'step': 2132}\n",
      "06/30/2020 16:44:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0073495208856635e-05, 'epoch': 0.5955902874686018, 'step': 2134}\n",
      "06/30/2020 16:44:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.006419201786213e-05, 'epoch': 0.5961484789282724, 'step': 2136}\n",
      "06/30/2020 16:44:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0054888826867616e-05, 'epoch': 0.5967066703879431, 'step': 2138}\n",
      "06/30/2020 16:44:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.004558563587311e-05, 'epoch': 0.5972648618476137, 'step': 2140}\n",
      "06/30/2020 16:44:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0036282444878596e-05, 'epoch': 0.5978230533072844, 'step': 2142}\n",
      "06/30/2020 16:44:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.002697925388408e-05, 'epoch': 0.5983812447669551, 'step': 2144}\n",
      "06/30/2020 16:44:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0017676062889576e-05, 'epoch': 0.5989394362266257, 'step': 2146}\n",
      "06/30/2020 16:44:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.000837287189506e-05, 'epoch': 0.5994976276862964, 'step': 2148}\n",
      "06/30/2020 16:44:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.999906968090055e-05, 'epoch': 0.6000558191459671, 'step': 2150}\n",
      "06/30/2020 16:44:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.998976648990604e-05, 'epoch': 0.6006140106056377, 'step': 2152}\n",
      "06/30/2020 16:44:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.998046329891153e-05, 'epoch': 0.6011722020653084, 'step': 2154}\n",
      "06/30/2020 16:44:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.997116010791702e-05, 'epoch': 0.601730393524979, 'step': 2156}\n",
      "06/30/2020 16:44:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.996185691692251e-05, 'epoch': 0.6022885849846498, 'step': 2158}\n",
      "06/30/2020 16:45:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.995255372592799e-05, 'epoch': 0.6028467764443204, 'step': 2160}\n",
      "06/30/2020 16:45:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9943250534933484e-05, 'epoch': 0.6034049679039911, 'step': 2162}\n",
      "06/30/2020 16:45:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.993394734393897e-05, 'epoch': 0.6039631593636617, 'step': 2164}\n",
      "06/30/2020 16:45:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9924644152944464e-05, 'epoch': 0.6045213508233324, 'step': 2166}\n",
      "06/30/2020 16:45:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.991534096194995e-05, 'epoch': 0.6050795422830031, 'step': 2168}\n",
      "06/30/2020 16:45:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.990603777095544e-05, 'epoch': 0.6056377337426737, 'step': 2170}\n",
      "06/30/2020 16:45:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9896734579960925e-05, 'epoch': 0.6061959252023444, 'step': 2172}\n",
      "06/30/2020 16:45:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.988743138896642e-05, 'epoch': 0.6067541166620151, 'step': 2174}\n",
      "06/30/2020 16:45:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.987812819797191e-05, 'epoch': 0.6073123081216857, 'step': 2176}\n",
      "06/30/2020 16:45:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.986882500697739e-05, 'epoch': 0.6078704995813564, 'step': 2178}\n",
      "06/30/2020 16:45:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9859521815982885e-05, 'epoch': 0.608428691041027, 'step': 2180}\n",
      "06/30/2020 16:45:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.985021862498837e-05, 'epoch': 0.6089868825006978, 'step': 2182}\n",
      "06/30/2020 16:45:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9840915433993866e-05, 'epoch': 0.6095450739603684, 'step': 2184}\n",
      "06/30/2020 16:45:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.983161224299935e-05, 'epoch': 0.6101032654200391, 'step': 2186}\n",
      "06/30/2020 16:45:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.982230905200484e-05, 'epoch': 0.6106614568797097, 'step': 2188}\n",
      "06/30/2020 16:45:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9813005861010326e-05, 'epoch': 0.6112196483393804, 'step': 2190}\n",
      "06/30/2020 16:45:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.980370267001582e-05, 'epoch': 0.6117778397990511, 'step': 2192}\n",
      "06/30/2020 16:45:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9794399479021306e-05, 'epoch': 0.6123360312587217, 'step': 2194}\n",
      "06/30/2020 16:45:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.978509628802679e-05, 'epoch': 0.6128942227183924, 'step': 2196}\n",
      "06/30/2020 16:45:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.977579309703228e-05, 'epoch': 0.6134524141780631, 'step': 2198}\n",
      "06/30/2020 16:45:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.976648990603777e-05, 'epoch': 0.6140106056377338, 'step': 2200}\n",
      "06/30/2020 16:45:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.975718671504326e-05, 'epoch': 0.6145687970974044, 'step': 2202}\n",
      "06/30/2020 16:45:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9747883524048754e-05, 'epoch': 0.615126988557075, 'step': 2204}\n",
      "06/30/2020 16:45:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.973858033305424e-05, 'epoch': 0.6156851800167458, 'step': 2206}\n",
      "06/30/2020 16:45:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.972927714205973e-05, 'epoch': 0.6162433714764164, 'step': 2208}\n",
      "06/30/2020 16:45:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9719973951065214e-05, 'epoch': 0.6168015629360871, 'step': 2210}\n",
      "06/30/2020 16:45:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.971067076007071e-05, 'epoch': 0.6173597543957577, 'step': 2212}\n",
      "06/30/2020 16:45:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9701367569076194e-05, 'epoch': 0.6179179458554284, 'step': 2214}\n",
      "06/30/2020 16:45:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.969206437808168e-05, 'epoch': 0.6184761373150991, 'step': 2216}\n",
      "06/30/2020 16:45:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9682761187087175e-05, 'epoch': 0.6190343287747697, 'step': 2218}\n",
      "06/30/2020 16:45:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.967345799609266e-05, 'epoch': 0.6195925202344404, 'step': 2220}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:45:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9664154805098155e-05, 'epoch': 0.6201507116941111, 'step': 2222}\n",
      "06/30/2020 16:45:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.965485161410364e-05, 'epoch': 0.6207089031537818, 'step': 2224}\n",
      "06/30/2020 16:45:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.964554842310913e-05, 'epoch': 0.6212670946134524, 'step': 2226}\n",
      "06/30/2020 16:45:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9636245232114615e-05, 'epoch': 0.621825286073123, 'step': 2228}\n",
      "06/30/2020 16:45:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.962694204112011e-05, 'epoch': 0.6223834775327938, 'step': 2230}\n",
      "06/30/2020 16:45:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9617638850125596e-05, 'epoch': 0.6229416689924644, 'step': 2232}\n",
      "06/30/2020 16:45:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.960833565913108e-05, 'epoch': 0.6234998604521351, 'step': 2234}\n",
      "06/30/2020 16:45:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.959903246813657e-05, 'epoch': 0.6240580519118057, 'step': 2236}\n",
      "06/30/2020 16:45:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.958972927714206e-05, 'epoch': 0.6246162433714764, 'step': 2238}\n",
      "06/30/2020 16:45:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.958042608614755e-05, 'epoch': 0.6251744348311471, 'step': 2240}\n",
      "06/30/2020 16:45:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.957112289515304e-05, 'epoch': 0.6257326262908177, 'step': 2242}\n",
      "06/30/2020 16:45:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.956181970415852e-05, 'epoch': 0.6262908177504884, 'step': 2244}\n",
      "06/30/2020 16:45:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9552516513164017e-05, 'epoch': 0.6268490092101591, 'step': 2246}\n",
      "06/30/2020 16:45:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.95432133221695e-05, 'epoch': 0.6274072006698298, 'step': 2248}\n",
      "06/30/2020 16:45:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9533910131175e-05, 'epoch': 0.6279653921295004, 'step': 2250}\n",
      "06/30/2020 16:45:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9524606940180484e-05, 'epoch': 0.628523583589171, 'step': 2252}\n",
      "06/30/2020 16:45:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.951530374918597e-05, 'epoch': 0.6290817750488418, 'step': 2254}\n",
      "06/30/2020 16:45:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9506000558191464e-05, 'epoch': 0.6296399665085124, 'step': 2256}\n",
      "06/30/2020 16:45:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.949669736719695e-05, 'epoch': 0.6301981579681831, 'step': 2258}\n",
      "06/30/2020 16:45:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9487394176202444e-05, 'epoch': 0.6307563494278537, 'step': 2260}\n",
      "06/30/2020 16:45:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9478090985207924e-05, 'epoch': 0.6313145408875244, 'step': 2262}\n",
      "06/30/2020 16:45:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.946878779421342e-05, 'epoch': 0.6318727323471951, 'step': 2264}\n",
      "06/30/2020 16:45:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9459484603218905e-05, 'epoch': 0.6324309238068657, 'step': 2266}\n",
      "06/30/2020 16:45:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.94501814122244e-05, 'epoch': 0.6329891152665365, 'step': 2268}\n",
      "06/30/2020 16:45:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9440878221229885e-05, 'epoch': 0.6335473067262071, 'step': 2270}\n",
      "06/30/2020 16:45:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.943157503023537e-05, 'epoch': 0.6341054981858778, 'step': 2272}\n",
      "06/30/2020 16:45:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.942227183924086e-05, 'epoch': 0.6346636896455484, 'step': 2274}\n",
      "06/30/2020 16:45:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.941296864824635e-05, 'epoch': 0.635221881105219, 'step': 2276}\n",
      "06/30/2020 16:45:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.940366545725184e-05, 'epoch': 0.6357800725648898, 'step': 2278}\n",
      "06/30/2020 16:45:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9394362266257325e-05, 'epoch': 0.6363382640245604, 'step': 2280}\n",
      "06/30/2020 16:45:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.938505907526281e-05, 'epoch': 0.6368964554842311, 'step': 2282}\n",
      "06/30/2020 16:45:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9375755884268306e-05, 'epoch': 0.6374546469439017, 'step': 2284}\n",
      "06/30/2020 16:45:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.936645269327379e-05, 'epoch': 0.6380128384035725, 'step': 2286}\n",
      "06/30/2020 16:45:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9357149502279286e-05, 'epoch': 0.6385710298632431, 'step': 2288}\n",
      "06/30/2020 16:45:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.934784631128477e-05, 'epoch': 0.6391292213229137, 'step': 2290}\n",
      "06/30/2020 16:45:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.933854312029026e-05, 'epoch': 0.6396874127825845, 'step': 2292}\n",
      "06/30/2020 16:45:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.932923992929575e-05, 'epoch': 0.6402456042422551, 'step': 2294}\n",
      "06/30/2020 16:45:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.931993673830124e-05, 'epoch': 0.6408037957019258, 'step': 2296}\n",
      "06/30/2020 16:45:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.931063354730673e-05, 'epoch': 0.6413619871615964, 'step': 2298}\n",
      "06/30/2020 16:45:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9301330356312214e-05, 'epoch': 0.641920178621267, 'step': 2300}\n",
      "06/30/2020 16:45:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.929202716531771e-05, 'epoch': 0.6424783700809378, 'step': 2302}\n",
      "06/30/2020 16:45:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9282723974323194e-05, 'epoch': 0.6430365615406084, 'step': 2304}\n",
      "06/30/2020 16:45:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.927342078332869e-05, 'epoch': 0.6435947530002791, 'step': 2306}\n",
      "06/30/2020 16:45:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9264117592334174e-05, 'epoch': 0.6441529444599498, 'step': 2308}\n",
      "06/30/2020 16:45:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.925481440133966e-05, 'epoch': 0.6447111359196205, 'step': 2310}\n",
      "06/30/2020 16:45:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.924551121034515e-05, 'epoch': 0.6452693273792911, 'step': 2312}\n",
      "06/30/2020 16:45:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.923620801935064e-05, 'epoch': 0.6458275188389617, 'step': 2314}\n",
      "06/30/2020 16:45:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.922690482835613e-05, 'epoch': 0.6463857102986325, 'step': 2316}\n",
      "06/30/2020 16:45:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9217601637361615e-05, 'epoch': 0.6469439017583031, 'step': 2318}\n",
      "06/30/2020 16:45:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.92082984463671e-05, 'epoch': 0.6475020932179738, 'step': 2320}\n",
      "06/30/2020 16:45:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9198995255372595e-05, 'epoch': 0.6480602846776444, 'step': 2322}\n",
      "06/30/2020 16:45:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.918969206437809e-05, 'epoch': 0.648618476137315, 'step': 2324}\n",
      "06/30/2020 16:45:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9180388873383575e-05, 'epoch': 0.6491766675969858, 'step': 2326}\n",
      "06/30/2020 16:45:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.917108568238906e-05, 'epoch': 0.6497348590566564, 'step': 2328}\n",
      "06/30/2020 16:45:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.916178249139455e-05, 'epoch': 0.6502930505163271, 'step': 2330}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:45:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.915247930040004e-05, 'epoch': 0.6508512419759978, 'step': 2332}\n",
      "06/30/2020 16:45:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.914317610940553e-05, 'epoch': 0.6514094334356685, 'step': 2334}\n",
      "06/30/2020 16:45:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9133872918411016e-05, 'epoch': 0.6519676248953391, 'step': 2336}\n",
      "06/30/2020 16:45:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.91245697274165e-05, 'epoch': 0.6525258163550097, 'step': 2338}\n",
      "06/30/2020 16:45:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9115266536421996e-05, 'epoch': 0.6530840078146805, 'step': 2340}\n",
      "06/30/2020 16:45:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.910596334542748e-05, 'epoch': 0.6536421992743511, 'step': 2342}\n",
      "06/30/2020 16:45:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.909666015443298e-05, 'epoch': 0.6542003907340218, 'step': 2344}\n",
      "06/30/2020 16:45:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.908735696343846e-05, 'epoch': 0.6547585821936924, 'step': 2346}\n",
      "06/30/2020 16:45:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.907805377244395e-05, 'epoch': 0.655316773653363, 'step': 2348}\n",
      "06/30/2020 16:45:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.906875058144944e-05, 'epoch': 0.6558749651130338, 'step': 2350}\n",
      "06/30/2020 16:45:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.905944739045493e-05, 'epoch': 0.6564331565727044, 'step': 2352}\n",
      "06/30/2020 16:45:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.905014419946042e-05, 'epoch': 0.6569913480323751, 'step': 2354}\n",
      "06/30/2020 16:45:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9040841008465904e-05, 'epoch': 0.6575495394920458, 'step': 2356}\n",
      "06/30/2020 16:45:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.903153781747139e-05, 'epoch': 0.6581077309517165, 'step': 2358}\n",
      "06/30/2020 16:45:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9022234626476884e-05, 'epoch': 0.6586659224113871, 'step': 2360}\n",
      "06/30/2020 16:45:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.901293143548238e-05, 'epoch': 0.6592241138710577, 'step': 2362}\n",
      "06/30/2020 16:45:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.900362824448786e-05, 'epoch': 0.6597823053307285, 'step': 2364}\n",
      "06/30/2020 16:45:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.899432505349335e-05, 'epoch': 0.6603404967903991, 'step': 2366}\n",
      "06/30/2020 16:45:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.898502186249884e-05, 'epoch': 0.6608986882500698, 'step': 2368}\n",
      "06/30/2020 16:45:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.897571867150433e-05, 'epoch': 0.6614568797097404, 'step': 2370}\n",
      "06/30/2020 16:45:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.896641548050982e-05, 'epoch': 0.6620150711694112, 'step': 2372}\n",
      "06/30/2020 16:45:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8957112289515305e-05, 'epoch': 0.6625732626290818, 'step': 2374}\n",
      "06/30/2020 16:45:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.894780909852079e-05, 'epoch': 0.6631314540887524, 'step': 2376}\n",
      "06/30/2020 16:45:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8938505907526286e-05, 'epoch': 0.6636896455484231, 'step': 2378}\n",
      "06/30/2020 16:45:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.892920271653177e-05, 'epoch': 0.6642478370080938, 'step': 2380}\n",
      "06/30/2020 16:45:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.891989952553726e-05, 'epoch': 0.6648060284677645, 'step': 2382}\n",
      "06/30/2020 16:45:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8910596334542746e-05, 'epoch': 0.6653642199274351, 'step': 2384}\n",
      "06/30/2020 16:45:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.890129314354824e-05, 'epoch': 0.6659224113871057, 'step': 2386}\n",
      "06/30/2020 16:45:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8891989952553726e-05, 'epoch': 0.6664806028467765, 'step': 2388}\n",
      "06/30/2020 16:45:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.888268676155922e-05, 'epoch': 0.6670387943064471, 'step': 2390}\n",
      "06/30/2020 16:45:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.88733835705647e-05, 'epoch': 0.6675969857661178, 'step': 2392}\n",
      "06/30/2020 16:45:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.886408037957019e-05, 'epoch': 0.6681551772257884, 'step': 2394}\n",
      "06/30/2020 16:45:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.885477718857568e-05, 'epoch': 0.6687133686854592, 'step': 2396}\n",
      "06/30/2020 16:45:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8845473997581174e-05, 'epoch': 0.6692715601451298, 'step': 2398}\n",
      "06/30/2020 16:45:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.883617080658666e-05, 'epoch': 0.6698297516048004, 'step': 2400}\n",
      "06/30/2020 16:45:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.882686761559215e-05, 'epoch': 0.6703879430644711, 'step': 2402}\n",
      "06/30/2020 16:45:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.881756442459764e-05, 'epoch': 0.6709461345241418, 'step': 2404}\n",
      "06/30/2020 16:45:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.880826123360313e-05, 'epoch': 0.6715043259838125, 'step': 2406}\n",
      "06/30/2020 16:45:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.879895804260862e-05, 'epoch': 0.6720625174434831, 'step': 2408}\n",
      "06/30/2020 16:45:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.878965485161411e-05, 'epoch': 0.6726207089031537, 'step': 2410}\n",
      "06/30/2020 16:45:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8780351660619595e-05, 'epoch': 0.6731789003628245, 'step': 2412}\n",
      "06/30/2020 16:45:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.877104846962508e-05, 'epoch': 0.6737370918224951, 'step': 2414}\n",
      "06/30/2020 16:45:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8761745278630575e-05, 'epoch': 0.6742952832821658, 'step': 2416}\n",
      "06/30/2020 16:45:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.875244208763606e-05, 'epoch': 0.6748534747418364, 'step': 2418}\n",
      "06/30/2020 16:45:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.874313889664155e-05, 'epoch': 0.6754116662015072, 'step': 2420}\n",
      "06/30/2020 16:45:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8733835705647035e-05, 'epoch': 0.6759698576611778, 'step': 2422}\n",
      "06/30/2020 16:45:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.872453251465253e-05, 'epoch': 0.6765280491208484, 'step': 2424}\n",
      "06/30/2020 16:45:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8715229323658016e-05, 'epoch': 0.6770862405805191, 'step': 2426}\n",
      "06/30/2020 16:45:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.870592613266351e-05, 'epoch': 0.6776444320401898, 'step': 2428}\n",
      "06/30/2020 16:45:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.869662294166899e-05, 'epoch': 0.6782026234998605, 'step': 2430}\n",
      "06/30/2020 16:45:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.868731975067448e-05, 'epoch': 0.6787608149595311, 'step': 2432}\n",
      "06/30/2020 16:45:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8678016559679976e-05, 'epoch': 0.6793190064192017, 'step': 2434}\n",
      "06/30/2020 16:45:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.866871336868546e-05, 'epoch': 0.6798771978788725, 'step': 2436}\n",
      "06/30/2020 16:45:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.865941017769095e-05, 'epoch': 0.6804353893385431, 'step': 2438}\n",
      "06/30/2020 16:45:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8650106986696436e-05, 'epoch': 0.6809935807982138, 'step': 2440}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:45:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.864080379570193e-05, 'epoch': 0.6815517722578844, 'step': 2442}\n",
      "06/30/2020 16:45:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.863150060470742e-05, 'epoch': 0.6821099637175552, 'step': 2444}\n",
      "06/30/2020 16:45:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.862219741371291e-05, 'epoch': 0.6826681551772258, 'step': 2446}\n",
      "06/30/2020 16:45:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.861289422271839e-05, 'epoch': 0.6832263466368964, 'step': 2448}\n",
      "06/30/2020 16:45:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8603591031723884e-05, 'epoch': 0.6837845380965671, 'step': 2450}\n",
      "06/30/2020 16:45:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.859428784072937e-05, 'epoch': 0.6843427295562378, 'step': 2452}\n",
      "06/30/2020 16:45:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8584984649734864e-05, 'epoch': 0.6849009210159085, 'step': 2454}\n",
      "06/30/2020 16:45:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.857568145874035e-05, 'epoch': 0.6854591124755791, 'step': 2456}\n",
      "06/30/2020 16:45:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.856637826774584e-05, 'epoch': 0.6860173039352498, 'step': 2458}\n",
      "06/30/2020 16:45:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8557075076751324e-05, 'epoch': 0.6865754953949205, 'step': 2460}\n",
      "06/30/2020 16:45:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.854777188575682e-05, 'epoch': 0.6871336868545911, 'step': 2462}\n",
      "06/30/2020 16:45:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8538468694762305e-05, 'epoch': 0.6876918783142618, 'step': 2464}\n",
      "06/30/2020 16:45:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.852916550376779e-05, 'epoch': 0.6882500697739324, 'step': 2466}\n",
      "06/30/2020 16:45:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.851986231277328e-05, 'epoch': 0.6888082612336032, 'step': 2468}\n",
      "06/30/2020 16:45:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.851055912177877e-05, 'epoch': 0.6893664526932738, 'step': 2470}\n",
      "06/30/2020 16:45:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8501255930784265e-05, 'epoch': 0.6899246441529444, 'step': 2472}\n",
      "06/30/2020 16:45:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.849195273978975e-05, 'epoch': 0.6904828356126151, 'step': 2474}\n",
      "06/30/2020 16:45:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.848264954879524e-05, 'epoch': 0.6910410270722858, 'step': 2476}\n",
      "06/30/2020 16:45:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8473346357800726e-05, 'epoch': 0.6915992185319565, 'step': 2478}\n",
      "06/30/2020 16:45:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.846404316680622e-05, 'epoch': 0.6921574099916271, 'step': 2480}\n",
      "06/30/2020 16:45:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8454739975811706e-05, 'epoch': 0.6927156014512978, 'step': 2482}\n",
      "06/30/2020 16:45:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.844543678481719e-05, 'epoch': 0.6932737929109685, 'step': 2484}\n",
      "06/30/2020 16:45:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.843613359382268e-05, 'epoch': 0.6938319843706391, 'step': 2486}\n",
      "06/30/2020 16:45:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.842683040282817e-05, 'epoch': 0.6943901758303098, 'step': 2488}\n",
      "06/30/2020 16:45:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.841752721183366e-05, 'epoch': 0.6949483672899804, 'step': 2490}\n",
      "06/30/2020 16:45:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8408224020839153e-05, 'epoch': 0.6955065587496512, 'step': 2492}\n",
      "06/30/2020 16:45:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8398920829844633e-05, 'epoch': 0.6960647502093218, 'step': 2494}\n",
      "06/30/2020 16:45:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.838961763885013e-05, 'epoch': 0.6966229416689924, 'step': 2496}\n",
      "06/30/2020 16:45:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8380314447855614e-05, 'epoch': 0.6971811331286631, 'step': 2498}\n",
      "06/30/2020 16:45:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.837101125686111e-05, 'epoch': 0.6977393245883338, 'step': 2500}\n",
      "06/30/2020 16:45:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8361708065866594e-05, 'epoch': 0.6982975160480045, 'step': 2502}\n",
      "06/30/2020 16:45:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.835240487487208e-05, 'epoch': 0.6988557075076751, 'step': 2504}\n",
      "06/30/2020 16:45:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.834310168387757e-05, 'epoch': 0.6994138989673458, 'step': 2506}\n",
      "06/30/2020 16:45:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.833379849288306e-05, 'epoch': 0.6999720904270165, 'step': 2508}\n",
      "06/30/2020 16:45:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8324495301888555e-05, 'epoch': 0.7005302818866871, 'step': 2510}\n",
      "06/30/2020 16:45:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.831519211089404e-05, 'epoch': 0.7010884733463578, 'step': 2512}\n",
      "06/30/2020 16:45:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.830588891989953e-05, 'epoch': 0.7016466648060284, 'step': 2514}\n",
      "06/30/2020 16:45:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8296585728905015e-05, 'epoch': 0.7022048562656992, 'step': 2516}\n",
      "06/30/2020 16:45:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.828728253791051e-05, 'epoch': 0.7027630477253698, 'step': 2518}\n",
      "06/30/2020 16:45:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8277979346915995e-05, 'epoch': 0.7033212391850404, 'step': 2520}\n",
      "06/30/2020 16:45:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.826867615592148e-05, 'epoch': 0.7038794306447111, 'step': 2522}\n",
      "06/30/2020 16:45:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.825937296492697e-05, 'epoch': 0.7044376221043818, 'step': 2524}\n",
      "06/30/2020 16:45:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.825006977393246e-05, 'epoch': 0.7049958135640525, 'step': 2526}\n",
      "06/30/2020 16:45:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.824076658293795e-05, 'epoch': 0.7055540050237231, 'step': 2528}\n",
      "06/30/2020 16:45:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.823146339194344e-05, 'epoch': 0.7061121964833939, 'step': 2530}\n",
      "06/30/2020 16:45:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.822216020094892e-05, 'epoch': 0.7066703879430645, 'step': 2532}\n",
      "06/30/2020 16:45:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8212857009954416e-05, 'epoch': 0.7072285794027351, 'step': 2534}\n",
      "06/30/2020 16:45:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.82035538189599e-05, 'epoch': 0.7077867708624058, 'step': 2536}\n",
      "06/30/2020 16:45:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8194250627965397e-05, 'epoch': 0.7083449623220764, 'step': 2538}\n",
      "06/30/2020 16:45:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.818494743697088e-05, 'epoch': 0.7089031537817472, 'step': 2540}\n",
      "06/30/2020 16:45:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.817564424597637e-05, 'epoch': 0.7094613452414178, 'step': 2542}\n",
      "06/30/2020 16:45:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.816634105498186e-05, 'epoch': 0.7100195367010885, 'step': 2544}\n",
      "06/30/2020 16:45:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.815703786398735e-05, 'epoch': 0.7105777281607591, 'step': 2546}\n",
      "06/30/2020 16:45:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8147734672992844e-05, 'epoch': 0.7111359196204298, 'step': 2548}\n",
      "06/30/2020 16:45:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8138431481998324e-05, 'epoch': 0.7116941110801005, 'step': 2550}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:45:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.812912829100382e-05, 'epoch': 0.7122523025397711, 'step': 2552}\n",
      "06/30/2020 16:45:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8119825100009304e-05, 'epoch': 0.7128104939994419, 'step': 2554}\n",
      "06/30/2020 16:45:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.81105219090148e-05, 'epoch': 0.7133686854591125, 'step': 2556}\n",
      "06/30/2020 16:45:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8101218718020285e-05, 'epoch': 0.7139268769187831, 'step': 2558}\n",
      "06/30/2020 16:45:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.809191552702577e-05, 'epoch': 0.7144850683784538, 'step': 2560}\n",
      "06/30/2020 16:45:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.808261233603126e-05, 'epoch': 0.7150432598381244, 'step': 2562}\n",
      "06/30/2020 16:45:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.807330914503675e-05, 'epoch': 0.7156014512977952, 'step': 2564}\n",
      "06/30/2020 16:45:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.806400595404224e-05, 'epoch': 0.7161596427574658, 'step': 2566}\n",
      "06/30/2020 16:45:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8054702763047725e-05, 'epoch': 0.7167178342171365, 'step': 2568}\n",
      "06/30/2020 16:45:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.804539957205321e-05, 'epoch': 0.7172760256768071, 'step': 2570}\n",
      "06/30/2020 16:45:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8036096381058706e-05, 'epoch': 0.7178342171364778, 'step': 2572}\n",
      "06/30/2020 16:45:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.802679319006419e-05, 'epoch': 0.7183924085961485, 'step': 2574}\n",
      "06/30/2020 16:45:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8017489999069686e-05, 'epoch': 0.7189506000558191, 'step': 2576}\n",
      "06/30/2020 16:45:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8008186808075166e-05, 'epoch': 0.7195087915154899, 'step': 2578}\n",
      "06/30/2020 16:45:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.799888361708066e-05, 'epoch': 0.7200669829751605, 'step': 2580}\n",
      "06/30/2020 16:45:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.798958042608615e-05, 'epoch': 0.7206251744348311, 'step': 2582}\n",
      "06/30/2020 16:45:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.798027723509164e-05, 'epoch': 0.7211833658945018, 'step': 2584}\n",
      "06/30/2020 16:45:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7970974044097127e-05, 'epoch': 0.7217415573541724, 'step': 2586}\n",
      "06/30/2020 16:45:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.796167085310261e-05, 'epoch': 0.7222997488138432, 'step': 2588}\n",
      "06/30/2020 16:45:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.795236766210811e-05, 'epoch': 0.7228579402735138, 'step': 2590}\n",
      "06/30/2020 16:45:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7943064471113594e-05, 'epoch': 0.7234161317331845, 'step': 2592}\n",
      "06/30/2020 16:45:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.793376128011909e-05, 'epoch': 0.7239743231928552, 'step': 2594}\n",
      "06/30/2020 16:45:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.792445808912457e-05, 'epoch': 0.7245325146525258, 'step': 2596}\n",
      "06/30/2020 16:45:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.791515489813006e-05, 'epoch': 0.7250907061121965, 'step': 2598}\n",
      "06/30/2020 16:45:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.790585170713555e-05, 'epoch': 0.7256488975718671, 'step': 2600}\n",
      "06/30/2020 16:45:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.789654851614104e-05, 'epoch': 0.7262070890315379, 'step': 2602}\n",
      "06/30/2020 16:45:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.788724532514653e-05, 'epoch': 0.7267652804912085, 'step': 2604}\n",
      "06/30/2020 16:45:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7877942134152015e-05, 'epoch': 0.7273234719508791, 'step': 2606}\n",
      "06/30/2020 16:45:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.78686389431575e-05, 'epoch': 0.7278816634105498, 'step': 2608}\n",
      "06/30/2020 16:45:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7859335752162995e-05, 'epoch': 0.7284398548702204, 'step': 2610}\n",
      "06/30/2020 16:45:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.785003256116848e-05, 'epoch': 0.7289980463298912, 'step': 2612}\n",
      "06/30/2020 16:45:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7840729370173975e-05, 'epoch': 0.7295562377895618, 'step': 2614}\n",
      "06/30/2020 16:45:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7831426179179455e-05, 'epoch': 0.7301144292492325, 'step': 2616}\n",
      "06/30/2020 16:45:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.782212298818495e-05, 'epoch': 0.7306726207089032, 'step': 2618}\n",
      "06/30/2020 16:45:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.781281979719044e-05, 'epoch': 0.7312308121685738, 'step': 2620}\n",
      "06/30/2020 16:45:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.780351660619593e-05, 'epoch': 0.7317890036282445, 'step': 2622}\n",
      "06/30/2020 16:45:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7794213415201416e-05, 'epoch': 0.7323471950879151, 'step': 2624}\n",
      "06/30/2020 16:45:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.77849102242069e-05, 'epoch': 0.7329053865475859, 'step': 2626}\n",
      "06/30/2020 16:45:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7775607033212396e-05, 'epoch': 0.7334635780072565, 'step': 2628}\n",
      "06/30/2020 16:45:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.776630384221788e-05, 'epoch': 0.7340217694669272, 'step': 2630}\n",
      "06/30/2020 16:45:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7757000651223376e-05, 'epoch': 0.7345799609265978, 'step': 2632}\n",
      "06/30/2020 16:45:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7747697460228856e-05, 'epoch': 0.7351381523862685, 'step': 2634}\n",
      "06/30/2020 16:45:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.773839426923435e-05, 'epoch': 0.7356963438459392, 'step': 2636}\n",
      "06/30/2020 16:45:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.772909107823984e-05, 'epoch': 0.7362545353056098, 'step': 2638}\n",
      "06/30/2020 16:45:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.771978788724533e-05, 'epoch': 0.7368127267652805, 'step': 2640}\n",
      "06/30/2020 16:45:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.771048469625082e-05, 'epoch': 0.7373709182249512, 'step': 2642}\n",
      "06/30/2020 16:45:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7701181505256304e-05, 'epoch': 0.7379291096846218, 'step': 2644}\n",
      "06/30/2020 16:45:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.769187831426179e-05, 'epoch': 0.7384873011442925, 'step': 2646}\n",
      "06/30/2020 16:45:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7682575123267284e-05, 'epoch': 0.7390454926039631, 'step': 2648}\n",
      "06/30/2020 16:45:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.767327193227277e-05, 'epoch': 0.7396036840636339, 'step': 2650}\n",
      "06/30/2020 16:45:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.766396874127826e-05, 'epoch': 0.7401618755233045, 'step': 2652}\n",
      "06/30/2020 16:45:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7654665550283744e-05, 'epoch': 0.7407200669829752, 'step': 2654}\n",
      "06/30/2020 16:45:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.764536235928924e-05, 'epoch': 0.7412782584426458, 'step': 2656}\n",
      "06/30/2020 16:45:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.763605916829473e-05, 'epoch': 0.7418364499023165, 'step': 2658}\n",
      "06/30/2020 16:45:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.762675597730022e-05, 'epoch': 0.7423946413619872, 'step': 2660}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:45:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7617452786305705e-05, 'epoch': 0.7429528328216578, 'step': 2662}\n",
      "06/30/2020 16:45:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.760814959531119e-05, 'epoch': 0.7435110242813285, 'step': 2664}\n",
      "06/30/2020 16:45:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7598846404316685e-05, 'epoch': 0.7440692157409992, 'step': 2666}\n",
      "06/30/2020 16:45:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.758954321332217e-05, 'epoch': 0.7446274072006698, 'step': 2668}\n",
      "06/30/2020 16:45:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.758024002232766e-05, 'epoch': 0.7451855986603405, 'step': 2670}\n",
      "06/30/2020 16:45:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7570936831333146e-05, 'epoch': 0.7457437901200111, 'step': 2672}\n",
      "06/30/2020 16:45:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.756163364033864e-05, 'epoch': 0.7463019815796819, 'step': 2674}\n",
      "06/30/2020 16:45:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7552330449344126e-05, 'epoch': 0.7468601730393525, 'step': 2676}\n",
      "06/30/2020 16:45:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.754302725834962e-05, 'epoch': 0.7474183644990232, 'step': 2678}\n",
      "06/30/2020 16:45:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.75337240673551e-05, 'epoch': 0.7479765559586938, 'step': 2680}\n",
      "06/30/2020 16:45:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.752442087636059e-05, 'epoch': 0.7485347474183645, 'step': 2682}\n",
      "06/30/2020 16:45:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.751511768536608e-05, 'epoch': 0.7490929388780352, 'step': 2684}\n",
      "06/30/2020 16:45:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7505814494371573e-05, 'epoch': 0.7496511303377058, 'step': 2686}\n",
      "06/30/2020 16:45:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.749651130337706e-05, 'epoch': 0.7502093217973765, 'step': 2688}\n",
      "06/30/2020 16:45:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.748720811238255e-05, 'epoch': 0.7507675132570472, 'step': 2690}\n",
      "06/30/2020 16:45:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.747790492138804e-05, 'epoch': 0.7513257047167178, 'step': 2692}\n",
      "06/30/2020 16:45:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.746860173039353e-05, 'epoch': 0.7518838961763885, 'step': 2694}\n",
      "06/30/2020 16:45:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.745929853939902e-05, 'epoch': 0.7524420876360591, 'step': 2696}\n",
      "06/30/2020 16:45:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.74499953484045e-05, 'epoch': 0.7530002790957299, 'step': 2698}\n",
      "06/30/2020 16:45:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7440692157409994e-05, 'epoch': 0.7535584705554005, 'step': 2700}\n",
      "06/30/2020 16:45:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.743138896641548e-05, 'epoch': 0.7541166620150712, 'step': 2702}\n",
      "06/30/2020 16:45:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7422085775420975e-05, 'epoch': 0.7546748534747418, 'step': 2704}\n",
      "06/30/2020 16:45:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.741278258442646e-05, 'epoch': 0.7552330449344125, 'step': 2706}\n",
      "06/30/2020 16:45:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.740347939343195e-05, 'epoch': 0.7557912363940832, 'step': 2708}\n",
      "06/30/2020 16:45:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7394176202437435e-05, 'epoch': 0.7563494278537538, 'step': 2710}\n",
      "06/30/2020 16:45:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.738487301144293e-05, 'epoch': 0.7569076193134245, 'step': 2712}\n",
      "06/30/2020 16:45:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7375569820448415e-05, 'epoch': 0.7574658107730952, 'step': 2714}\n",
      "06/30/2020 16:45:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.73662666294539e-05, 'epoch': 0.7580240022327659, 'step': 2716}\n",
      "06/30/2020 16:45:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.735696343845939e-05, 'epoch': 0.7585821936924365, 'step': 2718}\n",
      "06/30/2020 16:45:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.734766024746488e-05, 'epoch': 0.7591403851521071, 'step': 2720}\n",
      "06/30/2020 16:45:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.733835705647037e-05, 'epoch': 0.7596985766117779, 'step': 2722}\n",
      "06/30/2020 16:45:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.732905386547586e-05, 'epoch': 0.7602567680714485, 'step': 2724}\n",
      "06/30/2020 16:45:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.731975067448135e-05, 'epoch': 0.7608149595311192, 'step': 2726}\n",
      "06/30/2020 16:45:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7310447483486836e-05, 'epoch': 0.7613731509907898, 'step': 2728}\n",
      "06/30/2020 16:45:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.730114429249233e-05, 'epoch': 0.7619313424504605, 'step': 2730}\n",
      "06/30/2020 16:45:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7291841101497817e-05, 'epoch': 0.7624895339101312, 'step': 2732}\n",
      "06/30/2020 16:45:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.728253791050331e-05, 'epoch': 0.7630477253698018, 'step': 2734}\n",
      "06/30/2020 16:45:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.727323471950879e-05, 'epoch': 0.7636059168294725, 'step': 2736}\n",
      "06/30/2020 16:45:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7263931528514284e-05, 'epoch': 0.7641641082891432, 'step': 2738}\n",
      "06/30/2020 16:45:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.725462833751977e-05, 'epoch': 0.7647222997488139, 'step': 2740}\n",
      "06/30/2020 16:45:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7245325146525264e-05, 'epoch': 0.7652804912084845, 'step': 2742}\n",
      "06/30/2020 16:45:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.723602195553075e-05, 'epoch': 0.7658386826681551, 'step': 2744}\n",
      "06/30/2020 16:45:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.722671876453624e-05, 'epoch': 0.7663968741278259, 'step': 2746}\n",
      "06/30/2020 16:45:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7217415573541724e-05, 'epoch': 0.7669550655874965, 'step': 2748}\n",
      "06/30/2020 16:45:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.720811238254722e-05, 'epoch': 0.7675132570471672, 'step': 2750}\n",
      "06/30/2020 16:45:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7198809191552705e-05, 'epoch': 0.7680714485068378, 'step': 2752}\n",
      "06/30/2020 16:45:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.718950600055819e-05, 'epoch': 0.7686296399665085, 'step': 2754}\n",
      "06/30/2020 16:45:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.718020280956368e-05, 'epoch': 0.7691878314261792, 'step': 2756}\n",
      "06/30/2020 16:45:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.717089961856917e-05, 'epoch': 0.7697460228858498, 'step': 2758}\n",
      "06/30/2020 16:45:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.716159642757466e-05, 'epoch': 0.7703042143455205, 'step': 2760}\n",
      "06/30/2020 16:45:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.715229323658015e-05, 'epoch': 0.7708624058051912, 'step': 2762}\n",
      "06/30/2020 16:45:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.714299004558563e-05, 'epoch': 0.7714205972648619, 'step': 2764}\n",
      "06/30/2020 16:45:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7133686854591126e-05, 'epoch': 0.7719787887245325, 'step': 2766}\n",
      "06/30/2020 16:45:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.712438366359662e-05, 'epoch': 0.7725369801842031, 'step': 2768}\n",
      "06/30/2020 16:45:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7115080472602106e-05, 'epoch': 0.7730951716438739, 'step': 2770}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:45:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.710577728160759e-05, 'epoch': 0.7736533631035445, 'step': 2772}\n",
      "06/30/2020 16:45:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.709647409061308e-05, 'epoch': 0.7742115545632152, 'step': 2774}\n",
      "06/30/2020 16:45:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.708717089961857e-05, 'epoch': 0.7747697460228858, 'step': 2776}\n",
      "06/30/2020 16:45:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.707786770862406e-05, 'epoch': 0.7753279374825565, 'step': 2778}\n",
      "06/30/2020 16:45:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.706856451762955e-05, 'epoch': 0.7758861289422272, 'step': 2780}\n",
      "06/30/2020 16:45:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.705926132663503e-05, 'epoch': 0.7764443204018978, 'step': 2782}\n",
      "06/30/2020 16:45:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.704995813564053e-05, 'epoch': 0.7770025118615685, 'step': 2784}\n",
      "06/30/2020 16:45:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7040654944646014e-05, 'epoch': 0.7775607033212392, 'step': 2786}\n",
      "06/30/2020 16:45:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.703135175365151e-05, 'epoch': 0.7781188947809099, 'step': 2788}\n",
      "06/30/2020 16:45:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7022048562656994e-05, 'epoch': 0.7786770862405805, 'step': 2790}\n",
      "06/30/2020 16:45:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.701274537166248e-05, 'epoch': 0.7792352777002511, 'step': 2792}\n",
      "06/30/2020 16:45:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.700344218066797e-05, 'epoch': 0.7797934691599219, 'step': 2794}\n",
      "06/30/2020 16:45:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.699413898967346e-05, 'epoch': 0.7803516606195925, 'step': 2796}\n",
      "06/30/2020 16:45:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.698483579867895e-05, 'epoch': 0.7809098520792632, 'step': 2798}\n",
      "06/30/2020 16:45:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6975532607684434e-05, 'epoch': 0.7814680435389338, 'step': 2800}\n",
      "06/30/2020 16:45:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.696622941668992e-05, 'epoch': 0.7820262349986046, 'step': 2802}\n",
      "06/30/2020 16:45:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6956926225695415e-05, 'epoch': 0.7825844264582752, 'step': 2804}\n",
      "06/30/2020 16:45:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.694762303470091e-05, 'epoch': 0.7831426179179458, 'step': 2806}\n",
      "06/30/2020 16:45:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6938319843706395e-05, 'epoch': 0.7837008093776165, 'step': 2808}\n",
      "06/30/2020 16:45:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.692901665271188e-05, 'epoch': 0.7842590008372872, 'step': 2810}\n",
      "06/30/2020 16:45:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.691971346171737e-05, 'epoch': 0.7848171922969579, 'step': 2812}\n",
      "06/30/2020 16:45:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.691041027072286e-05, 'epoch': 0.7853753837566285, 'step': 2814}\n",
      "06/30/2020 16:45:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.690110707972835e-05, 'epoch': 0.7859335752162991, 'step': 2816}\n",
      "06/30/2020 16:45:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6891803888733836e-05, 'epoch': 0.7864917666759699, 'step': 2818}\n",
      "06/30/2020 16:45:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.688250069773932e-05, 'epoch': 0.7870499581356405, 'step': 2820}\n",
      "06/30/2020 16:45:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6873197506744816e-05, 'epoch': 0.7876081495953112, 'step': 2822}\n",
      "06/30/2020 16:45:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.68638943157503e-05, 'epoch': 0.7881663410549818, 'step': 2824}\n",
      "06/30/2020 16:45:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6854591124755796e-05, 'epoch': 0.7887245325146526, 'step': 2826}\n",
      "06/30/2020 16:45:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.684528793376128e-05, 'epoch': 0.7892827239743232, 'step': 2828}\n",
      "06/30/2020 16:45:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.683598474276677e-05, 'epoch': 0.7898409154339938, 'step': 2830}\n",
      "06/30/2020 16:45:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.682668155177226e-05, 'epoch': 0.7903991068936645, 'step': 2832}\n",
      "06/30/2020 16:45:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.681737836077775e-05, 'epoch': 0.7909572983533352, 'step': 2834}\n",
      "06/30/2020 16:45:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.680807516978324e-05, 'epoch': 0.7915154898130059, 'step': 2836}\n",
      "06/30/2020 16:45:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6798771978788724e-05, 'epoch': 0.7920736812726765, 'step': 2838}\n",
      "06/30/2020 16:45:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.678946878779422e-05, 'epoch': 0.7926318727323471, 'step': 2840}\n",
      "06/30/2020 16:45:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6780165596799704e-05, 'epoch': 0.7931900641920179, 'step': 2842}\n",
      "06/30/2020 16:45:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.67708624058052e-05, 'epoch': 0.7937482556516885, 'step': 2844}\n",
      "06/30/2020 16:45:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6761559214810684e-05, 'epoch': 0.7943064471113592, 'step': 2846}\n",
      "06/30/2020 16:45:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.675225602381617e-05, 'epoch': 0.7948646385710298, 'step': 2848}\n",
      "06/30/2020 16:45:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.674295283282166e-05, 'epoch': 0.7954228300307006, 'step': 2850}\n",
      "06/30/2020 16:45:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.673364964182715e-05, 'epoch': 0.7959810214903712, 'step': 2852}\n",
      "06/30/2020 16:45:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.672434645083264e-05, 'epoch': 0.7965392129500418, 'step': 2854}\n",
      "06/30/2020 16:45:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6715043259838125e-05, 'epoch': 0.7970974044097126, 'step': 2856}\n",
      "06/30/2020 16:45:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.670574006884361e-05, 'epoch': 0.7976555958693832, 'step': 2858}\n",
      "06/30/2020 16:45:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6696436877849105e-05, 'epoch': 0.7982137873290539, 'step': 2860}\n",
      "06/30/2020 16:45:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.668713368685459e-05, 'epoch': 0.7987719787887245, 'step': 2862}\n",
      "06/30/2020 16:45:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6677830495860086e-05, 'epoch': 0.7993301702483951, 'step': 2864}\n",
      "06/30/2020 16:45:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6668527304865566e-05, 'epoch': 0.7998883617080659, 'step': 2866}\n",
      "06/30/2020 16:45:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.665922411387106e-05, 'epoch': 0.8004465531677365, 'step': 2868}\n",
      "06/30/2020 16:45:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6649920922876546e-05, 'epoch': 0.8010047446274072, 'step': 2870}\n",
      "06/30/2020 16:45:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.664061773188204e-05, 'epoch': 0.8015629360870778, 'step': 2872}\n",
      "06/30/2020 16:45:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6631314540887526e-05, 'epoch': 0.8021211275467486, 'step': 2874}\n",
      "06/30/2020 16:45:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.662201134989301e-05, 'epoch': 0.8026793190064192, 'step': 2876}\n",
      "06/30/2020 16:45:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6612708158898507e-05, 'epoch': 0.8032375104660898, 'step': 2878}\n",
      "06/30/2020 16:45:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.660340496790399e-05, 'epoch': 0.8037957019257606, 'step': 2880}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:45:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.659410177690949e-05, 'epoch': 0.8043538933854312, 'step': 2882}\n",
      "06/30/2020 16:45:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.658479858591497e-05, 'epoch': 0.8049120848451019, 'step': 2884}\n",
      "06/30/2020 16:45:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.657549539492046e-05, 'epoch': 0.8054702763047725, 'step': 2886}\n",
      "06/30/2020 16:45:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.656619220392595e-05, 'epoch': 0.8060284677644433, 'step': 2888}\n",
      "06/30/2020 16:45:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.655688901293144e-05, 'epoch': 0.8065866592241139, 'step': 2890}\n",
      "06/30/2020 16:45:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.654758582193693e-05, 'epoch': 0.8071448506837845, 'step': 2892}\n",
      "06/30/2020 16:45:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6538282630942414e-05, 'epoch': 0.8077030421434552, 'step': 2894}\n",
      "06/30/2020 16:45:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.65289794399479e-05, 'epoch': 0.8082612336031259, 'step': 2896}\n",
      "06/30/2020 16:45:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6519676248953395e-05, 'epoch': 0.8088194250627966, 'step': 2898}\n",
      "06/30/2020 16:45:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.651037305795888e-05, 'epoch': 0.8093776165224672, 'step': 2900}\n",
      "06/30/2020 16:45:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.650106986696437e-05, 'epoch': 0.8099358079821378, 'step': 2902}\n",
      "06/30/2020 16:45:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6491766675969855e-05, 'epoch': 0.8104939994418086, 'step': 2904}\n",
      "06/30/2020 16:45:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.648246348497535e-05, 'epoch': 0.8110521909014792, 'step': 2906}\n",
      "06/30/2020 16:45:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6473160293980835e-05, 'epoch': 0.8116103823611499, 'step': 2908}\n",
      "06/30/2020 16:45:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.646385710298633e-05, 'epoch': 0.8121685738208205, 'step': 2910}\n",
      "06/30/2020 16:45:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6454553911991816e-05, 'epoch': 0.8127267652804913, 'step': 2912}\n",
      "06/30/2020 16:45:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.64452507209973e-05, 'epoch': 0.8132849567401619, 'step': 2914}\n",
      "06/30/2020 16:45:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6435947530002796e-05, 'epoch': 0.8138431481998325, 'step': 2916}\n",
      "06/30/2020 16:45:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.642664433900828e-05, 'epoch': 0.8144013396595032, 'step': 2918}\n",
      "06/30/2020 16:45:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.641734114801377e-05, 'epoch': 0.8149595311191739, 'step': 2920}\n",
      "06/30/2020 16:45:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6408037957019256e-05, 'epoch': 0.8155177225788446, 'step': 2922}\n",
      "06/30/2020 16:45:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.639873476602475e-05, 'epoch': 0.8160759140385152, 'step': 2924}\n",
      "06/30/2020 16:45:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6389431575030237e-05, 'epoch': 0.8166341054981858, 'step': 2926}\n",
      "06/30/2020 16:45:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.638012838403573e-05, 'epoch': 0.8171922969578566, 'step': 2928}\n",
      "06/30/2020 16:45:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.637082519304122e-05, 'epoch': 0.8177504884175272, 'step': 2930}\n",
      "06/30/2020 16:45:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6361522002046704e-05, 'epoch': 0.8183086798771979, 'step': 2932}\n",
      "06/30/2020 16:45:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.635221881105219e-05, 'epoch': 0.8188668713368685, 'step': 2934}\n",
      "06/30/2020 16:45:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6342915620057684e-05, 'epoch': 0.8194250627965393, 'step': 2936}\n",
      "06/30/2020 16:45:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.633361242906317e-05, 'epoch': 0.8199832542562099, 'step': 2938}\n",
      "06/30/2020 16:45:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.632430923806866e-05, 'epoch': 0.8205414457158805, 'step': 2940}\n",
      "06/30/2020 16:45:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6315006047074144e-05, 'epoch': 0.8210996371755512, 'step': 2942}\n",
      "06/30/2020 16:45:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.630570285607964e-05, 'epoch': 0.8216578286352219, 'step': 2944}\n",
      "06/30/2020 16:45:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6296399665085125e-05, 'epoch': 0.8222160200948926, 'step': 2946}\n",
      "06/30/2020 16:45:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.628709647409062e-05, 'epoch': 0.8227742115545632, 'step': 2948}\n",
      "06/30/2020 16:45:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6277793283096105e-05, 'epoch': 0.8233324030142338, 'step': 2950}\n",
      "06/30/2020 16:45:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.626849009210159e-05, 'epoch': 0.8238905944739046, 'step': 2952}\n",
      "06/30/2020 16:45:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6259186901107085e-05, 'epoch': 0.8244487859335752, 'step': 2954}\n",
      "06/30/2020 16:45:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.624988371011257e-05, 'epoch': 0.8250069773932459, 'step': 2956}\n",
      "06/30/2020 16:45:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.624058051911806e-05, 'epoch': 0.8255651688529165, 'step': 2958}\n",
      "06/30/2020 16:45:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6231277328123545e-05, 'epoch': 0.8261233603125873, 'step': 2960}\n",
      "06/30/2020 16:45:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.622197413712904e-05, 'epoch': 0.8266815517722579, 'step': 2962}\n",
      "06/30/2020 16:45:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6212670946134526e-05, 'epoch': 0.8272397432319285, 'step': 2964}\n",
      "06/30/2020 16:45:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.620336775514002e-05, 'epoch': 0.8277979346915992, 'step': 2966}\n",
      "06/30/2020 16:45:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.61940645641455e-05, 'epoch': 0.8283561261512699, 'step': 2968}\n",
      "06/30/2020 16:45:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.618476137315099e-05, 'epoch': 0.8289143176109406, 'step': 2970}\n",
      "06/30/2020 16:45:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.617545818215648e-05, 'epoch': 0.8294725090706112, 'step': 2972}\n",
      "06/30/2020 16:45:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.616615499116197e-05, 'epoch': 0.8300307005302819, 'step': 2974}\n",
      "06/30/2020 16:45:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.615685180016746e-05, 'epoch': 0.8305888919899526, 'step': 2976}\n",
      "06/30/2020 16:45:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.614754860917295e-05, 'epoch': 0.8311470834496232, 'step': 2978}\n",
      "06/30/2020 16:45:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6138245418178433e-05, 'epoch': 0.8317052749092939, 'step': 2980}\n",
      "06/30/2020 16:45:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.612894222718393e-05, 'epoch': 0.8322634663689645, 'step': 2982}\n",
      "06/30/2020 16:45:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6119639036189414e-05, 'epoch': 0.8328216578286353, 'step': 2984}\n",
      "06/30/2020 16:45:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.61103358451949e-05, 'epoch': 0.8333798492883059, 'step': 2986}\n",
      "06/30/2020 16:45:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6101032654200394e-05, 'epoch': 0.8339380407479765, 'step': 2988}\n",
      "06/30/2020 16:45:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.609172946320588e-05, 'epoch': 0.8344962322076472, 'step': 2990}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:45:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6082426272211374e-05, 'epoch': 0.8350544236673179, 'step': 2992}\n",
      "06/30/2020 16:45:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.607312308121686e-05, 'epoch': 0.8356126151269886, 'step': 2994}\n",
      "06/30/2020 16:45:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.606381989022235e-05, 'epoch': 0.8361708065866592, 'step': 2996}\n",
      "06/30/2020 16:45:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6054516699227835e-05, 'epoch': 0.8367289980463299, 'step': 2998}\n",
      "06/30/2020 16:45:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.604521350823333e-05, 'epoch': 0.8372871895060006, 'step': 3000}\n",
      "06/30/2020 16:45:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6035910317238815e-05, 'epoch': 0.8378453809656712, 'step': 3002}\n",
      "06/30/2020 16:45:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.60266071262443e-05, 'epoch': 0.8384035724253419, 'step': 3004}\n",
      "06/30/2020 16:45:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.601730393524979e-05, 'epoch': 0.8389617638850125, 'step': 3006}\n",
      "06/30/2020 16:45:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.600800074425528e-05, 'epoch': 0.8395199553446833, 'step': 3008}\n",
      "06/30/2020 16:45:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.599869755326077e-05, 'epoch': 0.8400781468043539, 'step': 3010}\n",
      "06/30/2020 16:45:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.598939436226626e-05, 'epoch': 0.8406363382640245, 'step': 3012}\n",
      "06/30/2020 16:45:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.598009117127175e-05, 'epoch': 0.8411945297236952, 'step': 3014}\n",
      "06/30/2020 16:45:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5970787980277236e-05, 'epoch': 0.8417527211833659, 'step': 3016}\n",
      "06/30/2020 16:45:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.596148478928272e-05, 'epoch': 0.8423109126430366, 'step': 3018}\n",
      "06/30/2020 16:45:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5952181598288216e-05, 'epoch': 0.8428691041027072, 'step': 3020}\n",
      "06/30/2020 16:45:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.59428784072937e-05, 'epoch': 0.8434272955623779, 'step': 3022}\n",
      "06/30/2020 16:45:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.593357521629919e-05, 'epoch': 0.8439854870220486, 'step': 3024}\n",
      "06/30/2020 16:45:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5924272025304683e-05, 'epoch': 0.8445436784817192, 'step': 3026}\n",
      "06/30/2020 16:45:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.591496883431017e-05, 'epoch': 0.8451018699413899, 'step': 3028}\n",
      "06/30/2020 16:45:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5905665643315664e-05, 'epoch': 0.8456600614010605, 'step': 3030}\n",
      "06/30/2020 16:45:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.589636245232115e-05, 'epoch': 0.8462182528607313, 'step': 3032}\n",
      "06/30/2020 16:45:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.588705926132664e-05, 'epoch': 0.8467764443204019, 'step': 3034}\n",
      "06/30/2020 16:45:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5877756070332124e-05, 'epoch': 0.8473346357800726, 'step': 3036}\n",
      "06/30/2020 16:45:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.586845287933762e-05, 'epoch': 0.8478928272397432, 'step': 3038}\n",
      "06/30/2020 16:45:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5859149688343104e-05, 'epoch': 0.8484510186994139, 'step': 3040}\n",
      "06/30/2020 16:45:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.584984649734859e-05, 'epoch': 0.8490092101590846, 'step': 3042}\n",
      "06/30/2020 16:46:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.584054330635408e-05, 'epoch': 0.8495674016187552, 'step': 3044}\n",
      "06/30/2020 16:46:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.583124011535957e-05, 'epoch': 0.850125593078426, 'step': 3046}\n",
      "06/30/2020 16:46:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.582193692436506e-05, 'epoch': 0.8506837845380966, 'step': 3048}\n",
      "06/30/2020 16:46:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.581263373337055e-05, 'epoch': 0.8512419759977672, 'step': 3050}\n",
      "06/30/2020 16:46:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.580333054237603e-05, 'epoch': 0.8518001674574379, 'step': 3052}\n",
      "06/30/2020 16:46:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5794027351381525e-05, 'epoch': 0.8523583589171085, 'step': 3054}\n",
      "06/30/2020 16:46:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.578472416038701e-05, 'epoch': 0.8529165503767793, 'step': 3056}\n",
      "06/30/2020 16:46:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5775420969392506e-05, 'epoch': 0.8534747418364499, 'step': 3058}\n",
      "06/30/2020 16:46:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.576611777839799e-05, 'epoch': 0.8540329332961206, 'step': 3060}\n",
      "06/30/2020 16:46:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.575681458740348e-05, 'epoch': 0.8545911247557912, 'step': 3062}\n",
      "06/30/2020 16:46:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.574751139640897e-05, 'epoch': 0.8551493162154619, 'step': 3064}\n",
      "06/30/2020 16:46:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.573820820541446e-05, 'epoch': 0.8557075076751326, 'step': 3066}\n",
      "06/30/2020 16:46:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.572890501441995e-05, 'epoch': 0.8562656991348032, 'step': 3068}\n",
      "06/30/2020 16:46:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.571960182342543e-05, 'epoch': 0.856823890594474, 'step': 3070}\n",
      "06/30/2020 16:46:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5710298632430927e-05, 'epoch': 0.8573820820541446, 'step': 3072}\n",
      "06/30/2020 16:46:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.570099544143641e-05, 'epoch': 0.8579402735138152, 'step': 3074}\n",
      "06/30/2020 16:46:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.569169225044191e-05, 'epoch': 0.8584984649734859, 'step': 3076}\n",
      "06/30/2020 16:46:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5682389059447394e-05, 'epoch': 0.8590566564331565, 'step': 3078}\n",
      "06/30/2020 16:46:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.567308586845288e-05, 'epoch': 0.8596148478928273, 'step': 3080}\n",
      "06/30/2020 16:46:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.566378267745837e-05, 'epoch': 0.8601730393524979, 'step': 3082}\n",
      "06/30/2020 16:46:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.565447948646386e-05, 'epoch': 0.8607312308121686, 'step': 3084}\n",
      "06/30/2020 16:46:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.564517629546935e-05, 'epoch': 0.8612894222718392, 'step': 3086}\n",
      "06/30/2020 16:46:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5635873104474834e-05, 'epoch': 0.8618476137315099, 'step': 3088}\n",
      "06/30/2020 16:46:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.562656991348032e-05, 'epoch': 0.8624058051911806, 'step': 3090}\n",
      "06/30/2020 16:46:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5617266722485815e-05, 'epoch': 0.8629639966508512, 'step': 3092}\n",
      "06/30/2020 16:46:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.56079635314913e-05, 'epoch': 0.863522188110522, 'step': 3094}\n",
      "06/30/2020 16:46:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5598660340496795e-05, 'epoch': 0.8640803795701926, 'step': 3096}\n",
      "06/30/2020 16:46:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.558935714950228e-05, 'epoch': 0.8646385710298632, 'step': 3098}\n",
      "06/30/2020 16:46:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.558005395850777e-05, 'epoch': 0.8651967624895339, 'step': 3100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:46:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.557075076751326e-05, 'epoch': 0.8657549539492045, 'step': 3102}\n",
      "06/30/2020 16:46:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.556144757651875e-05, 'epoch': 0.8663131454088753, 'step': 3104}\n",
      "06/30/2020 16:46:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5552144385524236e-05, 'epoch': 0.8668713368685459, 'step': 3106}\n",
      "06/30/2020 16:46:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.554284119452972e-05, 'epoch': 0.8674295283282166, 'step': 3108}\n",
      "06/30/2020 16:46:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5533538003535216e-05, 'epoch': 0.8679877197878872, 'step': 3110}\n",
      "06/30/2020 16:46:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.55242348125407e-05, 'epoch': 0.8685459112475579, 'step': 3112}\n",
      "06/30/2020 16:46:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5514931621546196e-05, 'epoch': 0.8691041027072286, 'step': 3114}\n",
      "06/30/2020 16:46:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.550562843055168e-05, 'epoch': 0.8696622941668992, 'step': 3116}\n",
      "06/30/2020 16:46:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.549632523955717e-05, 'epoch': 0.87022048562657, 'step': 3118}\n",
      "06/30/2020 16:46:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5487022048562656e-05, 'epoch': 0.8707786770862406, 'step': 3120}\n",
      "06/30/2020 16:46:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.547771885756815e-05, 'epoch': 0.8713368685459113, 'step': 3122}\n",
      "06/30/2020 16:46:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.546841566657364e-05, 'epoch': 0.8718950600055819, 'step': 3124}\n",
      "06/30/2020 16:46:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5459112475579124e-05, 'epoch': 0.8724532514652525, 'step': 3126}\n",
      "06/30/2020 16:46:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.544980928458461e-05, 'epoch': 0.8730114429249233, 'step': 3128}\n",
      "06/30/2020 16:46:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5440506093590104e-05, 'epoch': 0.8735696343845939, 'step': 3130}\n",
      "06/30/2020 16:46:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.543120290259559e-05, 'epoch': 0.8741278258442646, 'step': 3132}\n",
      "06/30/2020 16:46:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5421899711601084e-05, 'epoch': 0.8746860173039352, 'step': 3134}\n",
      "06/30/2020 16:46:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.541259652060657e-05, 'epoch': 0.8752442087636059, 'step': 3136}\n",
      "06/30/2020 16:46:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.540329332961206e-05, 'epoch': 0.8758024002232766, 'step': 3138}\n",
      "06/30/2020 16:46:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.539399013861755e-05, 'epoch': 0.8763605916829472, 'step': 3140}\n",
      "06/30/2020 16:46:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.538468694762304e-05, 'epoch': 0.876918783142618, 'step': 3142}\n",
      "06/30/2020 16:46:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5375383756628525e-05, 'epoch': 0.8774769746022886, 'step': 3144}\n",
      "06/30/2020 16:46:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.536608056563401e-05, 'epoch': 0.8780351660619593, 'step': 3146}\n",
      "06/30/2020 16:46:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5356777374639505e-05, 'epoch': 0.8785933575216299, 'step': 3148}\n",
      "06/30/2020 16:46:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.534747418364499e-05, 'epoch': 0.8791515489813005, 'step': 3150}\n",
      "06/30/2020 16:46:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5338170992650485e-05, 'epoch': 0.8797097404409713, 'step': 3152}\n",
      "06/30/2020 16:46:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5328867801655965e-05, 'epoch': 0.8802679319006419, 'step': 3154}\n",
      "06/30/2020 16:46:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.531956461066146e-05, 'epoch': 0.8808261233603126, 'step': 3156}\n",
      "06/30/2020 16:46:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5310261419666946e-05, 'epoch': 0.8813843148199833, 'step': 3158}\n",
      "06/30/2020 16:46:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.530095822867244e-05, 'epoch': 0.8819425062796539, 'step': 3160}\n",
      "06/30/2020 16:46:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5291655037677926e-05, 'epoch': 0.8825006977393246, 'step': 3162}\n",
      "06/30/2020 16:46:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.528235184668341e-05, 'epoch': 0.8830588891989952, 'step': 3164}\n",
      "06/30/2020 16:46:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.52730486556889e-05, 'epoch': 0.883617080658666, 'step': 3166}\n",
      "06/30/2020 16:46:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.526374546469439e-05, 'epoch': 0.8841752721183366, 'step': 3168}\n",
      "06/30/2020 16:46:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.525444227369988e-05, 'epoch': 0.8847334635780073, 'step': 3170}\n",
      "06/30/2020 16:46:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.524513908270537e-05, 'epoch': 0.8852916550376779, 'step': 3172}\n",
      "06/30/2020 16:46:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.523583589171086e-05, 'epoch': 0.8858498464973485, 'step': 3174}\n",
      "06/30/2020 16:46:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.522653270071635e-05, 'epoch': 0.8864080379570193, 'step': 3176}\n",
      "06/30/2020 16:46:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.521722950972184e-05, 'epoch': 0.8869662294166899, 'step': 3178}\n",
      "06/30/2020 16:46:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.520792631872733e-05, 'epoch': 0.8875244208763606, 'step': 3180}\n",
      "06/30/2020 16:46:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5198623127732814e-05, 'epoch': 0.8880826123360313, 'step': 3182}\n",
      "06/30/2020 16:46:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.51893199367383e-05, 'epoch': 0.8886408037957019, 'step': 3184}\n",
      "06/30/2020 16:46:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5180016745743794e-05, 'epoch': 0.8891989952553726, 'step': 3186}\n",
      "06/30/2020 16:46:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.517071355474928e-05, 'epoch': 0.8897571867150432, 'step': 3188}\n",
      "06/30/2020 16:46:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.516141036375477e-05, 'epoch': 0.890315378174714, 'step': 3190}\n",
      "06/30/2020 16:46:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5152107172760255e-05, 'epoch': 0.8908735696343846, 'step': 3192}\n",
      "06/30/2020 16:46:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.514280398176575e-05, 'epoch': 0.8914317610940553, 'step': 3194}\n",
      "06/30/2020 16:46:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5133500790771235e-05, 'epoch': 0.8919899525537259, 'step': 3196}\n",
      "06/30/2020 16:46:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.512419759977673e-05, 'epoch': 0.8925481440133965, 'step': 3198}\n",
      "06/30/2020 16:46:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.511489440878221e-05, 'epoch': 0.8931063354730673, 'step': 3200}\n",
      "06/30/2020 16:46:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.51055912177877e-05, 'epoch': 0.8936645269327379, 'step': 3202}\n",
      "06/30/2020 16:46:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.509628802679319e-05, 'epoch': 0.8942227183924086, 'step': 3204}\n",
      "06/30/2020 16:46:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.508698483579868e-05, 'epoch': 0.8947809098520793, 'step': 3206}\n",
      "06/30/2020 16:46:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.507768164480417e-05, 'epoch': 0.89533910131175, 'step': 3208}\n",
      "06/30/2020 16:46:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5068378453809656e-05, 'epoch': 0.8958972927714206, 'step': 3210}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:46:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.505907526281515e-05, 'epoch': 0.8964554842310912, 'step': 3212}\n",
      "06/30/2020 16:46:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5049772071820636e-05, 'epoch': 0.897013675690762, 'step': 3214}\n",
      "06/30/2020 16:46:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.504046888082613e-05, 'epoch': 0.8975718671504326, 'step': 3216}\n",
      "06/30/2020 16:46:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.503116568983161e-05, 'epoch': 0.8981300586101033, 'step': 3218}\n",
      "06/30/2020 16:46:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.50218624988371e-05, 'epoch': 0.8986882500697739, 'step': 3220}\n",
      "06/30/2020 16:46:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.501255930784259e-05, 'epoch': 0.8992464415294446, 'step': 3222}\n",
      "06/30/2020 16:46:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5003256116848084e-05, 'epoch': 0.8998046329891153, 'step': 3224}\n",
      "06/30/2020 16:46:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.499395292585357e-05, 'epoch': 0.9003628244487859, 'step': 3226}\n",
      "06/30/2020 16:46:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.498464973485906e-05, 'epoch': 0.9009210159084566, 'step': 3228}\n",
      "06/30/2020 16:46:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4975346543864544e-05, 'epoch': 0.9014792073681273, 'step': 3230}\n",
      "06/30/2020 16:46:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.496604335287004e-05, 'epoch': 0.902037398827798, 'step': 3232}\n",
      "06/30/2020 16:46:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4956740161875524e-05, 'epoch': 0.9025955902874686, 'step': 3234}\n",
      "06/30/2020 16:46:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.494743697088102e-05, 'epoch': 0.9031537817471392, 'step': 3236}\n",
      "06/30/2020 16:46:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.49381337798865e-05, 'epoch': 0.90371197320681, 'step': 3238}\n",
      "06/30/2020 16:46:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.492883058889199e-05, 'epoch': 0.9042701646664806, 'step': 3240}\n",
      "06/30/2020 16:46:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.491952739789748e-05, 'epoch': 0.9048283561261513, 'step': 3242}\n",
      "06/30/2020 16:46:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.491022420690297e-05, 'epoch': 0.9053865475858219, 'step': 3244}\n",
      "06/30/2020 16:46:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.490092101590846e-05, 'epoch': 0.9059447390454926, 'step': 3246}\n",
      "06/30/2020 16:46:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4891617824913945e-05, 'epoch': 0.9065029305051633, 'step': 3248}\n",
      "06/30/2020 16:46:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.488231463391944e-05, 'epoch': 0.9070611219648339, 'step': 3250}\n",
      "06/30/2020 16:46:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4873011442924926e-05, 'epoch': 0.9076193134245046, 'step': 3252}\n",
      "06/30/2020 16:46:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.486370825193042e-05, 'epoch': 0.9081775048841753, 'step': 3254}\n",
      "06/30/2020 16:46:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.48544050609359e-05, 'epoch': 0.908735696343846, 'step': 3256}\n",
      "06/30/2020 16:46:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.484510186994139e-05, 'epoch': 0.9092938878035166, 'step': 3258}\n",
      "06/30/2020 16:46:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.483579867894688e-05, 'epoch': 0.9098520792631872, 'step': 3260}\n",
      "06/30/2020 16:46:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.482649548795237e-05, 'epoch': 0.910410270722858, 'step': 3262}\n",
      "06/30/2020 16:46:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.481719229695786e-05, 'epoch': 0.9109684621825286, 'step': 3264}\n",
      "06/30/2020 16:46:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4807889105963347e-05, 'epoch': 0.9115266536421993, 'step': 3266}\n",
      "06/30/2020 16:46:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.479858591496883e-05, 'epoch': 0.9120848451018699, 'step': 3268}\n",
      "06/30/2020 16:46:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.478928272397433e-05, 'epoch': 0.9126430365615406, 'step': 3270}\n",
      "06/30/2020 16:46:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4779979532979814e-05, 'epoch': 0.9132012280212113, 'step': 3272}\n",
      "06/30/2020 16:46:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.47706763419853e-05, 'epoch': 0.9137594194808819, 'step': 3274}\n",
      "06/30/2020 16:46:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.476137315099079e-05, 'epoch': 0.9143176109405526, 'step': 3276}\n",
      "06/30/2020 16:46:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.475206995999628e-05, 'epoch': 0.9148758024002233, 'step': 3278}\n",
      "06/30/2020 16:46:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.474276676900177e-05, 'epoch': 0.915433993859894, 'step': 3280}\n",
      "06/30/2020 16:46:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.473346357800726e-05, 'epoch': 0.9159921853195646, 'step': 3282}\n",
      "06/30/2020 16:46:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.472416038701275e-05, 'epoch': 0.9165503767792352, 'step': 3284}\n",
      "06/30/2020 16:46:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4714857196018235e-05, 'epoch': 0.917108568238906, 'step': 3286}\n",
      "06/30/2020 16:46:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.470555400502373e-05, 'epoch': 0.9176667596985766, 'step': 3288}\n",
      "06/30/2020 16:46:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4696250814029215e-05, 'epoch': 0.9182249511582473, 'step': 3290}\n",
      "06/30/2020 16:46:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.46869476230347e-05, 'epoch': 0.9187831426179179, 'step': 3292}\n",
      "06/30/2020 16:46:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.467764443204019e-05, 'epoch': 0.9193413340775887, 'step': 3294}\n",
      "06/30/2020 16:46:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.466834124104568e-05, 'epoch': 0.9198995255372593, 'step': 3296}\n",
      "06/30/2020 16:46:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.465903805005117e-05, 'epoch': 0.9204577169969299, 'step': 3298}\n",
      "06/30/2020 16:46:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.464973485905666e-05, 'epoch': 0.9210159084566006, 'step': 3300}\n",
      "06/30/2020 16:46:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.464043166806214e-05, 'epoch': 0.9215740999162713, 'step': 3302}\n",
      "06/30/2020 16:46:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4631128477067636e-05, 'epoch': 0.922132291375942, 'step': 3304}\n",
      "06/30/2020 16:46:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.462182528607312e-05, 'epoch': 0.9226904828356126, 'step': 3306}\n",
      "06/30/2020 16:46:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4612522095078616e-05, 'epoch': 0.9232486742952832, 'step': 3308}\n",
      "06/30/2020 16:46:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.46032189040841e-05, 'epoch': 0.923806865754954, 'step': 3310}\n",
      "06/30/2020 16:46:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.459391571308959e-05, 'epoch': 0.9243650572146246, 'step': 3312}\n",
      "06/30/2020 16:46:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4584612522095076e-05, 'epoch': 0.9249232486742953, 'step': 3314}\n",
      "06/30/2020 16:46:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.457530933110057e-05, 'epoch': 0.9254814401339659, 'step': 3316}\n",
      "06/30/2020 16:46:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.456600614010606e-05, 'epoch': 0.9260396315936367, 'step': 3318}\n",
      "06/30/2020 16:46:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4556702949111543e-05, 'epoch': 0.9265978230533073, 'step': 3320}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:46:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.454739975811704e-05, 'epoch': 0.9271560145129779, 'step': 3322}\n",
      "06/30/2020 16:46:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4538096567122524e-05, 'epoch': 0.9277142059726486, 'step': 3324}\n",
      "06/30/2020 16:46:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.452879337612802e-05, 'epoch': 0.9282723974323193, 'step': 3326}\n",
      "06/30/2020 16:46:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4519490185133504e-05, 'epoch': 0.92883058889199, 'step': 3328}\n",
      "06/30/2020 16:46:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.451018699413899e-05, 'epoch': 0.9293887803516606, 'step': 3330}\n",
      "06/30/2020 16:46:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.450088380314448e-05, 'epoch': 0.9299469718113312, 'step': 3332}\n",
      "06/30/2020 16:46:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.449158061214997e-05, 'epoch': 0.930505163271002, 'step': 3334}\n",
      "06/30/2020 16:46:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.448227742115546e-05, 'epoch': 0.9310633547306726, 'step': 3336}\n",
      "06/30/2020 16:46:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.447297423016095e-05, 'epoch': 0.9316215461903433, 'step': 3338}\n",
      "06/30/2020 16:46:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.446367103916643e-05, 'epoch': 0.9321797376500139, 'step': 3340}\n",
      "06/30/2020 16:46:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4454367848171925e-05, 'epoch': 0.9327379291096847, 'step': 3342}\n",
      "06/30/2020 16:46:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.444506465717741e-05, 'epoch': 0.9332961205693553, 'step': 3344}\n",
      "06/30/2020 16:46:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4435761466182905e-05, 'epoch': 0.9338543120290259, 'step': 3346}\n",
      "06/30/2020 16:46:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.442645827518839e-05, 'epoch': 0.9344125034886966, 'step': 3348}\n",
      "06/30/2020 16:46:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.441715508419388e-05, 'epoch': 0.9349706949483673, 'step': 3350}\n",
      "06/30/2020 16:46:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4407851893199366e-05, 'epoch': 0.935528886408038, 'step': 3352}\n",
      "06/30/2020 16:46:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.439854870220486e-05, 'epoch': 0.9360870778677086, 'step': 3354}\n",
      "06/30/2020 16:46:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.438924551121035e-05, 'epoch': 0.9366452693273792, 'step': 3356}\n",
      "06/30/2020 16:46:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.437994232021583e-05, 'epoch': 0.93720346078705, 'step': 3358}\n",
      "06/30/2020 16:46:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4370639129221326e-05, 'epoch': 0.9377616522467206, 'step': 3360}\n",
      "06/30/2020 16:46:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.436133593822681e-05, 'epoch': 0.9383198437063913, 'step': 3362}\n",
      "06/30/2020 16:46:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.435203274723231e-05, 'epoch': 0.9388780351660619, 'step': 3364}\n",
      "06/30/2020 16:46:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4342729556237793e-05, 'epoch': 0.9394362266257327, 'step': 3366}\n",
      "06/30/2020 16:46:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.433342636524328e-05, 'epoch': 0.9399944180854033, 'step': 3368}\n",
      "06/30/2020 16:46:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.432412317424877e-05, 'epoch': 0.9405526095450739, 'step': 3370}\n",
      "06/30/2020 16:46:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.431481998325426e-05, 'epoch': 0.9411108010047446, 'step': 3372}\n",
      "06/30/2020 16:46:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.430551679225975e-05, 'epoch': 0.9416689924644153, 'step': 3374}\n",
      "06/30/2020 16:46:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4296213601265234e-05, 'epoch': 0.942227183924086, 'step': 3376}\n",
      "06/30/2020 16:46:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.428691041027072e-05, 'epoch': 0.9427853753837566, 'step': 3378}\n",
      "06/30/2020 16:46:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4277607219276214e-05, 'epoch': 0.9433435668434274, 'step': 3380}\n",
      "06/30/2020 16:46:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.42683040282817e-05, 'epoch': 0.943901758303098, 'step': 3382}\n",
      "06/30/2020 16:46:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4259000837287195e-05, 'epoch': 0.9444599497627686, 'step': 3384}\n",
      "06/30/2020 16:46:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4249697646292675e-05, 'epoch': 0.9450181412224393, 'step': 3386}\n",
      "06/30/2020 16:46:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.424039445529817e-05, 'epoch': 0.9455763326821099, 'step': 3388}\n",
      "06/30/2020 16:46:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4231091264303655e-05, 'epoch': 0.9461345241417807, 'step': 3390}\n",
      "06/30/2020 16:46:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.422178807330915e-05, 'epoch': 0.9466927156014513, 'step': 3392}\n",
      "06/30/2020 16:46:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4212484882314635e-05, 'epoch': 0.9472509070611219, 'step': 3394}\n",
      "06/30/2020 16:46:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.420318169132012e-05, 'epoch': 0.9478090985207926, 'step': 3396}\n",
      "06/30/2020 16:46:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4193878500325616e-05, 'epoch': 0.9483672899804633, 'step': 3398}\n",
      "06/30/2020 16:46:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.41845753093311e-05, 'epoch': 0.948925481440134, 'step': 3400}\n",
      "06/30/2020 16:46:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4175272118336596e-05, 'epoch': 0.9494836728998046, 'step': 3402}\n",
      "06/30/2020 16:46:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4165968927342076e-05, 'epoch': 0.9500418643594754, 'step': 3404}\n",
      "06/30/2020 16:46:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.415666573634757e-05, 'epoch': 0.950600055819146, 'step': 3406}\n",
      "06/30/2020 16:46:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4147362545353056e-05, 'epoch': 0.9511582472788166, 'step': 3408}\n",
      "06/30/2020 16:46:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.413805935435855e-05, 'epoch': 0.9517164387384873, 'step': 3410}\n",
      "06/30/2020 16:46:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4128756163364037e-05, 'epoch': 0.952274630198158, 'step': 3412}\n",
      "06/30/2020 16:46:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.411945297236952e-05, 'epoch': 0.9528328216578287, 'step': 3414}\n",
      "06/30/2020 16:46:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.411014978137501e-05, 'epoch': 0.9533910131174993, 'step': 3416}\n",
      "06/30/2020 16:46:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4100846590380504e-05, 'epoch': 0.9539492045771699, 'step': 3418}\n",
      "06/30/2020 16:46:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.409154339938599e-05, 'epoch': 0.9545073960368406, 'step': 3420}\n",
      "06/30/2020 16:46:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.408224020839148e-05, 'epoch': 0.9550655874965113, 'step': 3422}\n",
      "06/30/2020 16:46:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4072937017396964e-05, 'epoch': 0.955623778956182, 'step': 3424}\n",
      "06/30/2020 16:46:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.406363382640246e-05, 'epoch': 0.9561819704158526, 'step': 3426}\n",
      "06/30/2020 16:46:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4054330635407944e-05, 'epoch': 0.9567401618755234, 'step': 3428}\n",
      "06/30/2020 16:46:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.404502744441344e-05, 'epoch': 0.957298353335194, 'step': 3430}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:46:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4035724253418925e-05, 'epoch': 0.9578565447948646, 'step': 3432}\n",
      "06/30/2020 16:46:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.402642106242441e-05, 'epoch': 0.9584147362545353, 'step': 3434}\n",
      "06/30/2020 16:46:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4017117871429905e-05, 'epoch': 0.958972927714206, 'step': 3436}\n",
      "06/30/2020 16:46:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.400781468043539e-05, 'epoch': 0.9595311191738767, 'step': 3438}\n",
      "06/30/2020 16:46:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3998511489440885e-05, 'epoch': 0.9600893106335473, 'step': 3440}\n",
      "06/30/2020 16:46:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3989208298446365e-05, 'epoch': 0.9606475020932179, 'step': 3442}\n",
      "06/30/2020 16:46:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.397990510745186e-05, 'epoch': 0.9612056935528887, 'step': 3444}\n",
      "06/30/2020 16:46:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3970601916457346e-05, 'epoch': 0.9617638850125593, 'step': 3446}\n",
      "06/30/2020 16:46:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.396129872546284e-05, 'epoch': 0.96232207647223, 'step': 3448}\n",
      "06/30/2020 16:46:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3951995534468326e-05, 'epoch': 0.9628802679319006, 'step': 3450}\n",
      "06/30/2020 16:46:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.394269234347381e-05, 'epoch': 0.9634384593915714, 'step': 3452}\n",
      "06/30/2020 16:46:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.39333891524793e-05, 'epoch': 0.963996650851242, 'step': 3454}\n",
      "06/30/2020 16:46:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.392408596148479e-05, 'epoch': 0.9645548423109126, 'step': 3456}\n",
      "06/30/2020 16:46:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.391478277049028e-05, 'epoch': 0.9651130337705833, 'step': 3458}\n",
      "06/30/2020 16:46:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3905479579495766e-05, 'epoch': 0.965671225230254, 'step': 3460}\n",
      "06/30/2020 16:46:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.389617638850125e-05, 'epoch': 0.9662294166899247, 'step': 3462}\n",
      "06/30/2020 16:46:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.388687319750675e-05, 'epoch': 0.9667876081495953, 'step': 3464}\n",
      "06/30/2020 16:46:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3877570006512234e-05, 'epoch': 0.967345799609266, 'step': 3466}\n",
      "06/30/2020 16:46:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.386826681551773e-05, 'epoch': 0.9679039910689367, 'step': 3468}\n",
      "06/30/2020 16:46:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3858963624523214e-05, 'epoch': 0.9684621825286073, 'step': 3470}\n",
      "06/30/2020 16:46:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.38496604335287e-05, 'epoch': 0.969020373988278, 'step': 3472}\n",
      "06/30/2020 16:46:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3840357242534194e-05, 'epoch': 0.9695785654479486, 'step': 3474}\n",
      "06/30/2020 16:46:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.383105405153968e-05, 'epoch': 0.9701367569076194, 'step': 3476}\n",
      "06/30/2020 16:46:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.382175086054517e-05, 'epoch': 0.97069494836729, 'step': 3478}\n",
      "06/30/2020 16:46:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3812447669550654e-05, 'epoch': 0.9712531398269606, 'step': 3480}\n",
      "06/30/2020 16:46:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.380314447855615e-05, 'epoch': 0.9718113312866313, 'step': 3482}\n",
      "06/30/2020 16:46:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3793841287561635e-05, 'epoch': 0.972369522746302, 'step': 3484}\n",
      "06/30/2020 16:46:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.378453809656713e-05, 'epoch': 0.9729277142059727, 'step': 3486}\n",
      "06/30/2020 16:46:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.377523490557261e-05, 'epoch': 0.9734859056656433, 'step': 3488}\n",
      "06/30/2020 16:46:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.37659317145781e-05, 'epoch': 0.974044097125314, 'step': 3490}\n",
      "06/30/2020 16:46:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.375662852358359e-05, 'epoch': 0.9746022885849847, 'step': 3492}\n",
      "06/30/2020 16:46:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.374732533258908e-05, 'epoch': 0.9751604800446553, 'step': 3494}\n",
      "06/30/2020 16:46:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.373802214159457e-05, 'epoch': 0.975718671504326, 'step': 3496}\n",
      "06/30/2020 16:46:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3728718950600056e-05, 'epoch': 0.9762768629639966, 'step': 3498}\n",
      "06/30/2020 16:46:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.371941575960554e-05, 'epoch': 0.9768350544236674, 'step': 3500}\n",
      "06/30/2020 16:46:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3710112568611036e-05, 'epoch': 0.977393245883338, 'step': 3502}\n",
      "06/30/2020 16:46:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.370080937761653e-05, 'epoch': 0.9779514373430086, 'step': 3504}\n",
      "06/30/2020 16:46:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.369150618662201e-05, 'epoch': 0.9785096288026793, 'step': 3506}\n",
      "06/30/2020 16:46:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.36822029956275e-05, 'epoch': 0.97906782026235, 'step': 3508}\n",
      "06/30/2020 16:46:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.367289980463299e-05, 'epoch': 0.9796260117220207, 'step': 3510}\n",
      "06/30/2020 16:46:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3663596613638483e-05, 'epoch': 0.9801842031816913, 'step': 3512}\n",
      "06/30/2020 16:46:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.365429342264397e-05, 'epoch': 0.980742394641362, 'step': 3514}\n",
      "06/30/2020 16:46:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.364499023164946e-05, 'epoch': 0.9813005861010327, 'step': 3516}\n",
      "06/30/2020 16:46:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3635687040654944e-05, 'epoch': 0.9818587775607033, 'step': 3518}\n",
      "06/30/2020 16:46:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.362638384966044e-05, 'epoch': 0.982416969020374, 'step': 3520}\n",
      "06/30/2020 16:46:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3617080658665924e-05, 'epoch': 0.9829751604800446, 'step': 3522}\n",
      "06/30/2020 16:46:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.360777746767141e-05, 'epoch': 0.9835333519397154, 'step': 3524}\n",
      "06/30/2020 16:46:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.35984742766769e-05, 'epoch': 0.984091543399386, 'step': 3526}\n",
      "06/30/2020 16:46:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.358917108568239e-05, 'epoch': 0.9846497348590566, 'step': 3528}\n",
      "06/30/2020 16:46:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.357986789468788e-05, 'epoch': 0.9852079263187273, 'step': 3530}\n",
      "06/30/2020 16:46:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.357056470369337e-05, 'epoch': 0.985766117778398, 'step': 3532}\n",
      "06/30/2020 16:46:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.356126151269886e-05, 'epoch': 0.9863243092380687, 'step': 3534}\n",
      "06/30/2020 16:46:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3551958321704345e-05, 'epoch': 0.9868825006977393, 'step': 3536}\n",
      "06/30/2020 16:46:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.354265513070983e-05, 'epoch': 0.98744069215741, 'step': 3538}\n",
      "06/30/2020 16:46:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3533351939715325e-05, 'epoch': 0.9879988836170807, 'step': 3540}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:46:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.352404874872081e-05, 'epoch': 0.9885570750767513, 'step': 3542}\n",
      "06/30/2020 16:46:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.35147455577263e-05, 'epoch': 0.989115266536422, 'step': 3544}\n",
      "06/30/2020 16:46:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.350544236673179e-05, 'epoch': 0.9896734579960926, 'step': 3546}\n",
      "06/30/2020 16:46:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.349613917573728e-05, 'epoch': 0.9902316494557634, 'step': 3548}\n",
      "06/30/2020 16:46:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.348683598474277e-05, 'epoch': 0.990789840915434, 'step': 3550}\n",
      "06/30/2020 16:46:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.347753279374826e-05, 'epoch': 0.9913480323751047, 'step': 3552}\n",
      "06/30/2020 16:46:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3468229602753746e-05, 'epoch': 0.9919062238347753, 'step': 3554}\n",
      "06/30/2020 16:46:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.345892641175923e-05, 'epoch': 0.992464415294446, 'step': 3556}\n",
      "06/30/2020 16:46:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3449623220764727e-05, 'epoch': 0.9930226067541167, 'step': 3558}\n",
      "06/30/2020 16:46:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.344032002977021e-05, 'epoch': 0.9935807982137873, 'step': 3560}\n",
      "06/30/2020 16:46:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.34310168387757e-05, 'epoch': 0.994138989673458, 'step': 3562}\n",
      "06/30/2020 16:46:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.342171364778119e-05, 'epoch': 0.9946971811331287, 'step': 3564}\n",
      "06/30/2020 16:46:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.341241045678668e-05, 'epoch': 0.9952553725927993, 'step': 3566}\n",
      "06/30/2020 16:46:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.340310726579217e-05, 'epoch': 0.99581356405247, 'step': 3568}\n",
      "06/30/2020 16:46:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.339380407479766e-05, 'epoch': 0.9963717555121406, 'step': 3570}\n",
      "06/30/2020 16:46:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.338450088380314e-05, 'epoch': 0.9969299469718114, 'step': 3572}\n",
      "06/30/2020 16:46:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3375197692808634e-05, 'epoch': 0.997488138431482, 'step': 3574}\n",
      "06/30/2020 16:46:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.336589450181412e-05, 'epoch': 0.9980463298911527, 'step': 3576}\n",
      "06/30/2020 16:46:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3356591310819615e-05, 'epoch': 0.9986045213508233, 'step': 3578}\n",
      "06/30/2020 16:46:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.33472881198251e-05, 'epoch': 0.999162712810494, 'step': 3580}\n",
      "06/30/2020 16:46:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.333798492883059e-05, 'epoch': 0.9997209042701647, 'step': 3582}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56a382faae84183a4de83f6e3e6e333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=3583.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:46:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.332868173783608e-05, 'epoch': 1.0002790957298353, 'step': 3584}\n",
      "06/30/2020 16:46:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.331937854684157e-05, 'epoch': 1.000837287189506, 'step': 3586}\n",
      "06/30/2020 16:46:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.331007535584706e-05, 'epoch': 1.0013954786491768, 'step': 3588}\n",
      "06/30/2020 16:46:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.330077216485254e-05, 'epoch': 1.0019536701088474, 'step': 3590}\n",
      "06/30/2020 16:46:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3291468973858036e-05, 'epoch': 1.002511861568518, 'step': 3592}\n",
      "06/30/2020 16:46:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.328216578286352e-05, 'epoch': 1.0030700530281886, 'step': 3594}\n",
      "06/30/2020 16:46:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3272862591869016e-05, 'epoch': 1.0036282444878593, 'step': 3596}\n",
      "06/30/2020 16:46:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.32635594008745e-05, 'epoch': 1.00418643594753, 'step': 3598}\n",
      "06/30/2020 16:46:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.325425620987999e-05, 'epoch': 1.0047446274072007, 'step': 3600}\n",
      "06/30/2020 16:46:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3244953018885476e-05, 'epoch': 1.0053028188668713, 'step': 3602}\n",
      "06/30/2020 16:46:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.323564982789097e-05, 'epoch': 1.005861010326542, 'step': 3604}\n",
      "06/30/2020 16:46:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3226346636896456e-05, 'epoch': 1.0064192017862126, 'step': 3606}\n",
      "06/30/2020 16:46:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.321704344590194e-05, 'epoch': 1.0069773932458834, 'step': 3608}\n",
      "06/30/2020 16:46:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.320774025490743e-05, 'epoch': 1.007535584705554, 'step': 3610}\n",
      "06/30/2020 16:46:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3198437063912924e-05, 'epoch': 1.0080937761652247, 'step': 3612}\n",
      "06/30/2020 16:46:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.318913387291842e-05, 'epoch': 1.0086519676248953, 'step': 3614}\n",
      "06/30/2020 16:46:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3179830681923904e-05, 'epoch': 1.009210159084566, 'step': 3616}\n",
      "06/30/2020 16:46:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.317052749092939e-05, 'epoch': 1.0097683505442367, 'step': 3618}\n",
      "06/30/2020 16:46:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.316122429993488e-05, 'epoch': 1.0103265420039074, 'step': 3620}\n",
      "06/30/2020 16:46:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.315192110894037e-05, 'epoch': 1.010884733463578, 'step': 3622}\n",
      "06/30/2020 16:46:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.314261791794586e-05, 'epoch': 1.0114429249232486, 'step': 3624}\n",
      "06/30/2020 16:46:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3133314726951345e-05, 'epoch': 1.0120011163829195, 'step': 3626}\n",
      "06/30/2020 16:46:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.312401153595683e-05, 'epoch': 1.01255930784259, 'step': 3628}\n",
      "06/30/2020 16:46:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3114708344962325e-05, 'epoch': 1.0131174993022607, 'step': 3630}\n",
      "06/30/2020 16:46:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.310540515396781e-05, 'epoch': 1.0136756907619313, 'step': 3632}\n",
      "06/30/2020 16:46:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3096101962973305e-05, 'epoch': 1.014233882221602, 'step': 3634}\n",
      "06/30/2020 16:46:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.308679877197879e-05, 'epoch': 1.0147920736812728, 'step': 3636}\n",
      "06/30/2020 16:46:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.307749558098428e-05, 'epoch': 1.0153502651409434, 'step': 3638}\n",
      "06/30/2020 16:46:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3068192389989765e-05, 'epoch': 1.015908456600614, 'step': 3640}\n",
      "06/30/2020 16:46:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.305888919899526e-05, 'epoch': 1.0164666480602846, 'step': 3642}\n",
      "06/30/2020 16:46:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3049586008000746e-05, 'epoch': 1.0170248395199553, 'step': 3644}\n",
      "06/30/2020 16:46:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.304028281700623e-05, 'epoch': 1.017583030979626, 'step': 3646}\n",
      "06/30/2020 16:46:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.303097962601172e-05, 'epoch': 1.0181412224392967, 'step': 3648}\n",
      "06/30/2020 16:46:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.302167643501721e-05, 'epoch': 1.0186994138989673, 'step': 3650}\n",
      "06/30/2020 16:46:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3012373244022706e-05, 'epoch': 1.019257605358638, 'step': 3652}\n",
      "06/30/2020 16:46:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.300307005302819e-05, 'epoch': 1.0198157968183086, 'step': 3654}\n",
      "06/30/2020 16:46:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.299376686203368e-05, 'epoch': 1.0203739882779794, 'step': 3656}\n",
      "06/30/2020 16:46:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.298446367103917e-05, 'epoch': 1.02093217973765, 'step': 3658}\n",
      "06/30/2020 16:46:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.297516048004466e-05, 'epoch': 1.0214903711973207, 'step': 3660}\n",
      "06/30/2020 16:46:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.296585728905015e-05, 'epoch': 1.0220485626569913, 'step': 3662}\n",
      "06/30/2020 16:46:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2956554098055634e-05, 'epoch': 1.022606754116662, 'step': 3664}\n",
      "06/30/2020 16:46:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.294725090706112e-05, 'epoch': 1.0231649455763328, 'step': 3666}\n",
      "06/30/2020 16:46:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2937947716066614e-05, 'epoch': 1.0237231370360034, 'step': 3668}\n",
      "06/30/2020 16:46:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.29286445250721e-05, 'epoch': 1.024281328495674, 'step': 3670}\n",
      "06/30/2020 16:46:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2919341334077594e-05, 'epoch': 1.0248395199553446, 'step': 3672}\n",
      "06/30/2020 16:46:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2910038143083074e-05, 'epoch': 1.0253977114150155, 'step': 3674}\n",
      "06/30/2020 16:46:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.290073495208857e-05, 'epoch': 1.025955902874686, 'step': 3676}\n",
      "06/30/2020 16:46:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2891431761094055e-05, 'epoch': 1.0265140943343567, 'step': 3678}\n",
      "06/30/2020 16:46:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.288212857009955e-05, 'epoch': 1.0270722857940273, 'step': 3680}\n",
      "06/30/2020 16:46:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2872825379105035e-05, 'epoch': 1.027630477253698, 'step': 3682}\n",
      "06/30/2020 16:46:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.286352218811052e-05, 'epoch': 1.0281886687133688, 'step': 3684}\n",
      "06/30/2020 16:46:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.285421899711601e-05, 'epoch': 1.0287468601730394, 'step': 3686}\n",
      "06/30/2020 16:46:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.28449158061215e-05, 'epoch': 1.02930505163271, 'step': 3688}\n",
      "06/30/2020 16:46:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2835612615126996e-05, 'epoch': 1.0298632430923806, 'step': 3690}\n",
      "06/30/2020 16:46:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2826309424132476e-05, 'epoch': 1.0304214345520513, 'step': 3692}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:46:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.281700623313797e-05, 'epoch': 1.030979626011722, 'step': 3694}\n",
      "06/30/2020 16:46:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2807703042143456e-05, 'epoch': 1.0315378174713927, 'step': 3696}\n",
      "06/30/2020 16:46:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.279839985114895e-05, 'epoch': 1.0320960089310633, 'step': 3698}\n",
      "06/30/2020 16:46:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2789096660154436e-05, 'epoch': 1.032654200390734, 'step': 3700}\n",
      "06/30/2020 16:46:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.277979346915992e-05, 'epoch': 1.0332123918504046, 'step': 3702}\n",
      "06/30/2020 16:46:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.277049027816541e-05, 'epoch': 1.0337705833100754, 'step': 3704}\n",
      "06/30/2020 16:46:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2761187087170903e-05, 'epoch': 1.034328774769746, 'step': 3706}\n",
      "06/30/2020 16:46:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.275188389617639e-05, 'epoch': 1.0348869662294167, 'step': 3708}\n",
      "06/30/2020 16:46:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.274258070518188e-05, 'epoch': 1.0354451576890873, 'step': 3710}\n",
      "06/30/2020 16:46:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2733277514187364e-05, 'epoch': 1.036003349148758, 'step': 3712}\n",
      "06/30/2020 16:46:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.272397432319286e-05, 'epoch': 1.0365615406084288, 'step': 3714}\n",
      "06/30/2020 16:46:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2714671132198344e-05, 'epoch': 1.0371197320680994, 'step': 3716}\n",
      "06/30/2020 16:46:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.270536794120384e-05, 'epoch': 1.03767792352777, 'step': 3718}\n",
      "06/30/2020 16:46:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.269606475020932e-05, 'epoch': 1.0382361149874406, 'step': 3720}\n",
      "06/30/2020 16:46:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.268676155921481e-05, 'epoch': 1.0387943064471115, 'step': 3722}\n",
      "06/30/2020 16:46:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.26774583682203e-05, 'epoch': 1.039352497906782, 'step': 3724}\n",
      "06/30/2020 16:46:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.266815517722579e-05, 'epoch': 1.0399106893664527, 'step': 3726}\n",
      "06/30/2020 16:46:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.265885198623128e-05, 'epoch': 1.0404688808261233, 'step': 3728}\n",
      "06/30/2020 16:46:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2649548795236765e-05, 'epoch': 1.041027072285794, 'step': 3730}\n",
      "06/30/2020 16:46:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.264024560424226e-05, 'epoch': 1.0415852637454648, 'step': 3732}\n",
      "06/30/2020 16:46:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2630942413247745e-05, 'epoch': 1.0421434552051354, 'step': 3734}\n",
      "06/30/2020 16:46:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.262163922225324e-05, 'epoch': 1.042701646664806, 'step': 3736}\n",
      "06/30/2020 16:46:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2612336031258726e-05, 'epoch': 1.0432598381244766, 'step': 3738}\n",
      "06/30/2020 16:46:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.260303284026421e-05, 'epoch': 1.0438180295841473, 'step': 3740}\n",
      "06/30/2020 16:46:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.25937296492697e-05, 'epoch': 1.044376221043818, 'step': 3742}\n",
      "06/30/2020 16:46:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.258442645827519e-05, 'epoch': 1.0449344125034887, 'step': 3744}\n",
      "06/30/2020 16:46:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.257512326728068e-05, 'epoch': 1.0454926039631594, 'step': 3746}\n",
      "06/30/2020 16:46:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2565820076286166e-05, 'epoch': 1.04605079542283, 'step': 3748}\n",
      "06/30/2020 16:46:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.255651688529165e-05, 'epoch': 1.0466089868825006, 'step': 3750}\n",
      "06/30/2020 16:46:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2547213694297147e-05, 'epoch': 1.0471671783421714, 'step': 3752}\n",
      "06/30/2020 16:46:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.253791050330263e-05, 'epoch': 1.047725369801842, 'step': 3754}\n",
      "06/30/2020 16:46:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.252860731230813e-05, 'epoch': 1.0482835612615127, 'step': 3756}\n",
      "06/30/2020 16:46:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.251930412131361e-05, 'epoch': 1.0488417527211833, 'step': 3758}\n",
      "06/30/2020 16:46:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.25100009303191e-05, 'epoch': 1.0493999441808541, 'step': 3760}\n",
      "06/30/2020 16:46:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2500697739324594e-05, 'epoch': 1.0499581356405248, 'step': 3762}\n",
      "06/30/2020 16:46:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.249139454833008e-05, 'epoch': 1.0505163271001954, 'step': 3764}\n",
      "06/30/2020 16:46:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.248209135733557e-05, 'epoch': 1.051074518559866, 'step': 3766}\n",
      "06/30/2020 16:46:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2472788166341054e-05, 'epoch': 1.0516327100195366, 'step': 3768}\n",
      "06/30/2020 16:46:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.246348497534655e-05, 'epoch': 1.0521909014792075, 'step': 3770}\n",
      "06/30/2020 16:46:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2454181784352035e-05, 'epoch': 1.052749092938878, 'step': 3772}\n",
      "06/30/2020 16:46:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.244487859335753e-05, 'epoch': 1.0533072843985487, 'step': 3774}\n",
      "06/30/2020 16:46:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.243557540236301e-05, 'epoch': 1.0538654758582193, 'step': 3776}\n",
      "06/30/2020 16:46:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.24262722113685e-05, 'epoch': 1.05442366731789, 'step': 3778}\n",
      "06/30/2020 16:46:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.241696902037399e-05, 'epoch': 1.0549818587775608, 'step': 3780}\n",
      "06/30/2020 16:46:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.240766582937948e-05, 'epoch': 1.0555400502372314, 'step': 3782}\n",
      "06/30/2020 16:46:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.239836263838497e-05, 'epoch': 1.056098241696902, 'step': 3784}\n",
      "06/30/2020 16:46:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2389059447390456e-05, 'epoch': 1.0566564331565726, 'step': 3786}\n",
      "06/30/2020 16:46:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.237975625639594e-05, 'epoch': 1.0572146246162433, 'step': 3788}\n",
      "06/30/2020 16:46:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2370453065401436e-05, 'epoch': 1.0577728160759141, 'step': 3790}\n",
      "06/30/2020 16:46:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.236114987440692e-05, 'epoch': 1.0583310075355847, 'step': 3792}\n",
      "06/30/2020 16:46:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.235184668341241e-05, 'epoch': 1.0588891989952554, 'step': 3794}\n",
      "06/30/2020 16:46:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2342543492417896e-05, 'epoch': 1.059447390454926, 'step': 3796}\n",
      "06/30/2020 16:46:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.233324030142339e-05, 'epoch': 1.0600055819145968, 'step': 3798}\n",
      "06/30/2020 16:46:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.232393711042888e-05, 'epoch': 1.0605637733742674, 'step': 3800}\n",
      "06/30/2020 16:46:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.231463391943437e-05, 'epoch': 1.061121964833938, 'step': 3802}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:46:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.230533072843986e-05, 'epoch': 1.0616801562936087, 'step': 3804}\n",
      "06/30/2020 16:46:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2296027537445344e-05, 'epoch': 1.0622383477532793, 'step': 3806}\n",
      "06/30/2020 16:46:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.228672434645084e-05, 'epoch': 1.0627965392129501, 'step': 3808}\n",
      "06/30/2020 16:46:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2277421155456324e-05, 'epoch': 1.0633547306726208, 'step': 3810}\n",
      "06/30/2020 16:46:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.226811796446181e-05, 'epoch': 1.0639129221322914, 'step': 3812}\n",
      "06/30/2020 16:46:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.22588147734673e-05, 'epoch': 1.064471113591962, 'step': 3814}\n",
      "06/30/2020 16:46:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.224951158247279e-05, 'epoch': 1.0650293050516326, 'step': 3816}\n",
      "06/30/2020 16:46:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.224020839147828e-05, 'epoch': 1.0655874965113035, 'step': 3818}\n",
      "06/30/2020 16:46:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.223090520048377e-05, 'epoch': 1.066145687970974, 'step': 3820}\n",
      "06/30/2020 16:46:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.222160200948925e-05, 'epoch': 1.0667038794306447, 'step': 3822}\n",
      "06/30/2020 16:46:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2212298818494745e-05, 'epoch': 1.0672620708903153, 'step': 3824}\n",
      "06/30/2020 16:46:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.220299562750023e-05, 'epoch': 1.067820262349986, 'step': 3826}\n",
      "06/30/2020 16:46:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2193692436505725e-05, 'epoch': 1.0683784538096568, 'step': 3828}\n",
      "06/30/2020 16:46:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.218438924551121e-05, 'epoch': 1.0689366452693274, 'step': 3830}\n",
      "06/30/2020 16:46:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.21750860545167e-05, 'epoch': 1.069494836728998, 'step': 3832}\n",
      "06/30/2020 16:46:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2165782863522185e-05, 'epoch': 1.0700530281886687, 'step': 3834}\n",
      "06/30/2020 16:46:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.215647967252768e-05, 'epoch': 1.0706112196483395, 'step': 3836}\n",
      "06/30/2020 16:46:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.214717648153317e-05, 'epoch': 1.0711694111080101, 'step': 3838}\n",
      "06/30/2020 16:46:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.213787329053866e-05, 'epoch': 1.0717276025676807, 'step': 3840}\n",
      "06/30/2020 16:46:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2128570099544146e-05, 'epoch': 1.0722857940273514, 'step': 3842}\n",
      "06/30/2020 16:46:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.211926690854963e-05, 'epoch': 1.072843985487022, 'step': 3844}\n",
      "06/30/2020 16:46:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2109963717555126e-05, 'epoch': 1.0734021769466926, 'step': 3846}\n",
      "06/30/2020 16:46:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.210066052656061e-05, 'epoch': 1.0739603684063634, 'step': 3848}\n",
      "06/30/2020 16:46:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.20913573355661e-05, 'epoch': 1.074518559866034, 'step': 3850}\n",
      "06/30/2020 16:46:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.208205414457159e-05, 'epoch': 1.0750767513257047, 'step': 3852}\n",
      "06/30/2020 16:46:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.207275095357708e-05, 'epoch': 1.0756349427853753, 'step': 3854}\n",
      "06/30/2020 16:46:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.206344776258257e-05, 'epoch': 1.0761931342450461, 'step': 3856}\n",
      "06/30/2020 16:46:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.205414457158806e-05, 'epoch': 1.0767513257047168, 'step': 3858}\n",
      "06/30/2020 16:46:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.204484138059354e-05, 'epoch': 1.0773095171643874, 'step': 3860}\n",
      "06/30/2020 16:46:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2035538189599034e-05, 'epoch': 1.077867708624058, 'step': 3862}\n",
      "06/30/2020 16:46:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.202623499860452e-05, 'epoch': 1.0784259000837286, 'step': 3864}\n",
      "06/30/2020 16:46:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2016931807610014e-05, 'epoch': 1.0789840915433995, 'step': 3866}\n",
      "06/30/2020 16:46:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.20076286166155e-05, 'epoch': 1.07954228300307, 'step': 3868}\n",
      "06/30/2020 16:46:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.199832542562099e-05, 'epoch': 1.0801004744627407, 'step': 3870}\n",
      "06/30/2020 16:46:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.198902223462648e-05, 'epoch': 1.0806586659224113, 'step': 3872}\n",
      "06/30/2020 16:46:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.197971904363197e-05, 'epoch': 1.081216857382082, 'step': 3874}\n",
      "06/30/2020 16:46:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.197041585263746e-05, 'epoch': 1.0817750488417528, 'step': 3876}\n",
      "06/30/2020 16:46:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.196111266164294e-05, 'epoch': 1.0823332403014234, 'step': 3878}\n",
      "06/30/2020 16:46:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1951809470648435e-05, 'epoch': 1.082891431761094, 'step': 3880}\n",
      "06/30/2020 16:46:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.194250627965392e-05, 'epoch': 1.0834496232207647, 'step': 3882}\n",
      "06/30/2020 16:46:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1933203088659416e-05, 'epoch': 1.0840078146804353, 'step': 3884}\n",
      "06/30/2020 16:47:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.19238998976649e-05, 'epoch': 1.0845660061401061, 'step': 3886}\n",
      "06/30/2020 16:47:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.191459670667039e-05, 'epoch': 1.0851241975997767, 'step': 3888}\n",
      "06/30/2020 16:47:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1905293515675876e-05, 'epoch': 1.0856823890594474, 'step': 3890}\n",
      "06/30/2020 16:47:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.189599032468137e-05, 'epoch': 1.086240580519118, 'step': 3892}\n",
      "06/30/2020 16:47:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1886687133686856e-05, 'epoch': 1.0867987719787888, 'step': 3894}\n",
      "06/30/2020 16:47:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.187738394269234e-05, 'epoch': 1.0873569634384594, 'step': 3896}\n",
      "06/30/2020 16:47:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.186808075169783e-05, 'epoch': 1.08791515489813, 'step': 3898}\n",
      "06/30/2020 16:47:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.185877756070332e-05, 'epoch': 1.0884733463578007, 'step': 3900}\n",
      "06/30/2020 16:47:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.184947436970881e-05, 'epoch': 1.0890315378174713, 'step': 3902}\n",
      "06/30/2020 16:47:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1840171178714304e-05, 'epoch': 1.0895897292771421, 'step': 3904}\n",
      "06/30/2020 16:47:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1830867987719784e-05, 'epoch': 1.0901479207368128, 'step': 3906}\n",
      "06/30/2020 16:47:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.182156479672528e-05, 'epoch': 1.0907061121964834, 'step': 3908}\n",
      "06/30/2020 16:47:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.181226160573077e-05, 'epoch': 1.091264303656154, 'step': 3910}\n",
      "06/30/2020 16:47:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.180295841473626e-05, 'epoch': 1.0918224951158246, 'step': 3912}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:47:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1793655223741744e-05, 'epoch': 1.0923806865754955, 'step': 3914}\n",
      "06/30/2020 16:47:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.178435203274723e-05, 'epoch': 1.092938878035166, 'step': 3916}\n",
      "06/30/2020 16:47:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1775048841752725e-05, 'epoch': 1.0934970694948367, 'step': 3918}\n",
      "06/30/2020 16:47:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.176574565075821e-05, 'epoch': 1.0940552609545073, 'step': 3920}\n",
      "06/30/2020 16:47:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1756442459763705e-05, 'epoch': 1.094613452414178, 'step': 3922}\n",
      "06/30/2020 16:47:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1747139268769185e-05, 'epoch': 1.0951716438738488, 'step': 3924}\n",
      "06/30/2020 16:47:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.173783607777468e-05, 'epoch': 1.0957298353335194, 'step': 3926}\n",
      "06/30/2020 16:47:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1728532886780165e-05, 'epoch': 1.09628802679319, 'step': 3928}\n",
      "06/30/2020 16:47:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.171922969578566e-05, 'epoch': 1.0968462182528607, 'step': 3930}\n",
      "06/30/2020 16:47:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1709926504791146e-05, 'epoch': 1.0974044097125315, 'step': 3932}\n",
      "06/30/2020 16:47:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.170062331379663e-05, 'epoch': 1.0979626011722021, 'step': 3934}\n",
      "06/30/2020 16:47:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.169132012280212e-05, 'epoch': 1.0985207926318727, 'step': 3936}\n",
      "06/30/2020 16:47:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.168201693180761e-05, 'epoch': 1.0990789840915434, 'step': 3938}\n",
      "06/30/2020 16:47:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.16727137408131e-05, 'epoch': 1.099637175551214, 'step': 3940}\n",
      "06/30/2020 16:47:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1663410549818586e-05, 'epoch': 1.1001953670108848, 'step': 3942}\n",
      "06/30/2020 16:47:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.165410735882407e-05, 'epoch': 1.1007535584705554, 'step': 3944}\n",
      "06/30/2020 16:47:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1644804167829566e-05, 'epoch': 1.101311749930226, 'step': 3946}\n",
      "06/30/2020 16:47:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.163550097683506e-05, 'epoch': 1.1018699413898967, 'step': 3948}\n",
      "06/30/2020 16:47:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.162619778584055e-05, 'epoch': 1.1024281328495673, 'step': 3950}\n",
      "06/30/2020 16:47:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1616894594846034e-05, 'epoch': 1.1029863243092382, 'step': 3952}\n",
      "06/30/2020 16:47:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.160759140385152e-05, 'epoch': 1.1035445157689088, 'step': 3954}\n",
      "06/30/2020 16:47:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1598288212857014e-05, 'epoch': 1.1041027072285794, 'step': 3956}\n",
      "06/30/2020 16:47:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.15889850218625e-05, 'epoch': 1.10466089868825, 'step': 3958}\n",
      "06/30/2020 16:47:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1579681830867994e-05, 'epoch': 1.1052190901479206, 'step': 3960}\n",
      "06/30/2020 16:47:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1570378639873474e-05, 'epoch': 1.1057772816075915, 'step': 3962}\n",
      "06/30/2020 16:47:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.156107544887897e-05, 'epoch': 1.106335473067262, 'step': 3964}\n",
      "06/30/2020 16:47:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1551772257884455e-05, 'epoch': 1.1068936645269327, 'step': 3966}\n",
      "06/30/2020 16:47:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.154246906688995e-05, 'epoch': 1.1074518559866033, 'step': 3968}\n",
      "06/30/2020 16:47:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1533165875895435e-05, 'epoch': 1.1080100474462742, 'step': 3970}\n",
      "06/30/2020 16:47:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.152386268490092e-05, 'epoch': 1.1085682389059448, 'step': 3972}\n",
      "06/30/2020 16:47:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.151455949390641e-05, 'epoch': 1.1091264303656154, 'step': 3974}\n",
      "06/30/2020 16:47:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.15052563029119e-05, 'epoch': 1.109684621825286, 'step': 3976}\n",
      "06/30/2020 16:47:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.149595311191739e-05, 'epoch': 1.1102428132849567, 'step': 3978}\n",
      "06/30/2020 16:47:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1486649920922875e-05, 'epoch': 1.1108010047446275, 'step': 3980}\n",
      "06/30/2020 16:47:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.147734672992836e-05, 'epoch': 1.1113591962042981, 'step': 3982}\n",
      "06/30/2020 16:47:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1468043538933856e-05, 'epoch': 1.1119173876639687, 'step': 3984}\n",
      "06/30/2020 16:47:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.145874034793935e-05, 'epoch': 1.1124755791236394, 'step': 3986}\n",
      "06/30/2020 16:47:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1449437156944836e-05, 'epoch': 1.11303377058331, 'step': 3988}\n",
      "06/30/2020 16:47:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.144013396595032e-05, 'epoch': 1.1135919620429808, 'step': 3990}\n",
      "06/30/2020 16:47:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.143083077495581e-05, 'epoch': 1.1141501535026515, 'step': 3992}\n",
      "06/30/2020 16:47:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.14215275839613e-05, 'epoch': 1.114708344962322, 'step': 3994}\n",
      "06/30/2020 16:47:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.141222439296679e-05, 'epoch': 1.1152665364219927, 'step': 3996}\n",
      "06/30/2020 16:47:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.140292120197228e-05, 'epoch': 1.1158247278816633, 'step': 3998}\n",
      "06/30/2020 16:47:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1393618010977763e-05, 'epoch': 1.1163829193413342, 'step': 4000}\n",
      "06/30/2020 16:47:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.138431481998326e-05, 'epoch': 1.1169411108010048, 'step': 4002}\n",
      "06/30/2020 16:47:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1375011628988744e-05, 'epoch': 1.1174993022606754, 'step': 4004}\n",
      "06/30/2020 16:47:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.136570843799424e-05, 'epoch': 1.118057493720346, 'step': 4006}\n",
      "06/30/2020 16:47:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.135640524699972e-05, 'epoch': 1.1186156851800169, 'step': 4008}\n",
      "06/30/2020 16:47:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.134710205600521e-05, 'epoch': 1.1191738766396875, 'step': 4010}\n",
      "06/30/2020 16:47:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.13377988650107e-05, 'epoch': 1.119732068099358, 'step': 4012}\n",
      "06/30/2020 16:47:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.132849567401619e-05, 'epoch': 1.1202902595590287, 'step': 4014}\n",
      "06/30/2020 16:47:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.131919248302168e-05, 'epoch': 1.1208484510186993, 'step': 4016}\n",
      "06/30/2020 16:47:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1309889292027165e-05, 'epoch': 1.12140664247837, 'step': 4018}\n",
      "06/30/2020 16:47:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.130058610103266e-05, 'epoch': 1.1219648339380408, 'step': 4020}\n",
      "06/30/2020 16:47:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1291282910038145e-05, 'epoch': 1.1225230253977114, 'step': 4022}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:47:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.128197971904364e-05, 'epoch': 1.123081216857382, 'step': 4024}\n",
      "06/30/2020 16:47:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.127267652804912e-05, 'epoch': 1.1236394083170527, 'step': 4026}\n",
      "06/30/2020 16:47:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.126337333705461e-05, 'epoch': 1.1241975997767235, 'step': 4028}\n",
      "06/30/2020 16:47:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.12540701460601e-05, 'epoch': 1.1247557912363941, 'step': 4030}\n",
      "06/30/2020 16:47:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.124476695506559e-05, 'epoch': 1.1253139826960648, 'step': 4032}\n",
      "06/30/2020 16:47:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.123546376407108e-05, 'epoch': 1.1258721741557354, 'step': 4034}\n",
      "06/30/2020 16:47:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1226160573076566e-05, 'epoch': 1.126430365615406, 'step': 4036}\n",
      "06/30/2020 16:47:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.121685738208205e-05, 'epoch': 1.1269885570750768, 'step': 4038}\n",
      "06/30/2020 16:47:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1207554191087546e-05, 'epoch': 1.1275467485347475, 'step': 4040}\n",
      "06/30/2020 16:47:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.119825100009303e-05, 'epoch': 1.128104939994418, 'step': 4042}\n",
      "06/30/2020 16:47:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.118894780909852e-05, 'epoch': 1.1286631314540887, 'step': 4044}\n",
      "06/30/2020 16:47:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.117964461810401e-05, 'epoch': 1.1292213229137595, 'step': 4046}\n",
      "06/30/2020 16:47:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.11703414271095e-05, 'epoch': 1.1297795143734302, 'step': 4048}\n",
      "06/30/2020 16:47:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.116103823611499e-05, 'epoch': 1.1303377058331008, 'step': 4050}\n",
      "06/30/2020 16:47:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.115173504512048e-05, 'epoch': 1.1308958972927714, 'step': 4052}\n",
      "06/30/2020 16:47:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.114243185412597e-05, 'epoch': 1.131454088752442, 'step': 4054}\n",
      "06/30/2020 16:47:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1133128663131454e-05, 'epoch': 1.1320122802121126, 'step': 4056}\n",
      "06/30/2020 16:47:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.112382547213695e-05, 'epoch': 1.1325704716717835, 'step': 4058}\n",
      "06/30/2020 16:47:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1114522281142434e-05, 'epoch': 1.133128663131454, 'step': 4060}\n",
      "06/30/2020 16:47:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.110521909014793e-05, 'epoch': 1.1336868545911247, 'step': 4062}\n",
      "06/30/2020 16:47:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.109591589915341e-05, 'epoch': 1.1342450460507953, 'step': 4064}\n",
      "06/30/2020 16:47:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.10866127081589e-05, 'epoch': 1.1348032375104662, 'step': 4066}\n",
      "06/30/2020 16:47:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.107730951716439e-05, 'epoch': 1.1353614289701368, 'step': 4068}\n",
      "06/30/2020 16:47:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.106800632616988e-05, 'epoch': 1.1359196204298074, 'step': 4070}\n",
      "06/30/2020 16:47:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.105870313517537e-05, 'epoch': 1.136477811889478, 'step': 4072}\n",
      "06/30/2020 16:47:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1049399944180855e-05, 'epoch': 1.1370360033491487, 'step': 4074}\n",
      "06/30/2020 16:47:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.104009675318634e-05, 'epoch': 1.1375941948088195, 'step': 4076}\n",
      "06/30/2020 16:47:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1030793562191836e-05, 'epoch': 1.1381523862684901, 'step': 4078}\n",
      "06/30/2020 16:47:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.102149037119732e-05, 'epoch': 1.1387105777281608, 'step': 4080}\n",
      "06/30/2020 16:47:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.101218718020281e-05, 'epoch': 1.1392687691878314, 'step': 4082}\n",
      "06/30/2020 16:47:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1002883989208296e-05, 'epoch': 1.139826960647502, 'step': 4084}\n",
      "06/30/2020 16:47:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.099358079821379e-05, 'epoch': 1.1403851521071728, 'step': 4086}\n",
      "06/30/2020 16:47:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0984277607219276e-05, 'epoch': 1.1409433435668435, 'step': 4088}\n",
      "06/30/2020 16:47:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.097497441622477e-05, 'epoch': 1.141501535026514, 'step': 4090}\n",
      "06/30/2020 16:47:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.096567122523025e-05, 'epoch': 1.1420597264861847, 'step': 4092}\n",
      "06/30/2020 16:47:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.095636803423574e-05, 'epoch': 1.1426179179458553, 'step': 4094}\n",
      "06/30/2020 16:47:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.094706484324124e-05, 'epoch': 1.1431761094055262, 'step': 4096}\n",
      "06/30/2020 16:47:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0937761652246724e-05, 'epoch': 1.1437343008651968, 'step': 4098}\n",
      "06/30/2020 16:47:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.092845846125221e-05, 'epoch': 1.1442924923248674, 'step': 4100}\n",
      "06/30/2020 16:47:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.09191552702577e-05, 'epoch': 1.144850683784538, 'step': 4102}\n",
      "06/30/2020 16:47:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.090985207926319e-05, 'epoch': 1.1454088752442089, 'step': 4104}\n",
      "06/30/2020 16:47:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.090054888826868e-05, 'epoch': 1.1459670667038795, 'step': 4106}\n",
      "06/30/2020 16:47:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.089124569727417e-05, 'epoch': 1.14652525816355, 'step': 4108}\n",
      "06/30/2020 16:47:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.088194250627965e-05, 'epoch': 1.1470834496232207, 'step': 4110}\n",
      "06/30/2020 16:47:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0872639315285145e-05, 'epoch': 1.1476416410828914, 'step': 4112}\n",
      "06/30/2020 16:47:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.086333612429063e-05, 'epoch': 1.1481998325425622, 'step': 4114}\n",
      "06/30/2020 16:47:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0854032933296125e-05, 'epoch': 1.1487580240022328, 'step': 4116}\n",
      "06/30/2020 16:47:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.084472974230161e-05, 'epoch': 1.1493162154619034, 'step': 4118}\n",
      "06/30/2020 16:47:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.08354265513071e-05, 'epoch': 1.149874406921574, 'step': 4120}\n",
      "06/30/2020 16:47:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0826123360312585e-05, 'epoch': 1.1504325983812447, 'step': 4122}\n",
      "06/30/2020 16:47:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.081682016931808e-05, 'epoch': 1.1509907898409155, 'step': 4124}\n",
      "06/30/2020 16:47:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0807516978323566e-05, 'epoch': 1.1515489813005861, 'step': 4126}\n",
      "06/30/2020 16:47:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.079821378732905e-05, 'epoch': 1.1521071727602568, 'step': 4128}\n",
      "06/30/2020 16:47:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0788910596334546e-05, 'epoch': 1.1526653642199274, 'step': 4130}\n",
      "06/30/2020 16:47:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.077960740534003e-05, 'epoch': 1.153223555679598, 'step': 4132}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:47:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0770304214345526e-05, 'epoch': 1.1537817471392688, 'step': 4134}\n",
      "06/30/2020 16:47:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.076100102335101e-05, 'epoch': 1.1543399385989395, 'step': 4136}\n",
      "06/30/2020 16:47:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.07516978323565e-05, 'epoch': 1.15489813005861, 'step': 4138}\n",
      "06/30/2020 16:47:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0742394641361986e-05, 'epoch': 1.1554563215182807, 'step': 4140}\n",
      "06/30/2020 16:47:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.073309145036748e-05, 'epoch': 1.1560145129779515, 'step': 4142}\n",
      "06/30/2020 16:47:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.072378825937297e-05, 'epoch': 1.1565727044376222, 'step': 4144}\n",
      "06/30/2020 16:47:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0714485068378454e-05, 'epoch': 1.1571308958972928, 'step': 4146}\n",
      "06/30/2020 16:47:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.070518187738394e-05, 'epoch': 1.1576890873569634, 'step': 4148}\n",
      "06/30/2020 16:47:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0695878686389434e-05, 'epoch': 1.158247278816634, 'step': 4150}\n",
      "06/30/2020 16:47:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.068657549539492e-05, 'epoch': 1.1588054702763046, 'step': 4152}\n",
      "06/30/2020 16:47:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0677272304400414e-05, 'epoch': 1.1593636617359755, 'step': 4154}\n",
      "06/30/2020 16:47:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.06679691134059e-05, 'epoch': 1.1599218531956461, 'step': 4156}\n",
      "06/30/2020 16:47:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.065866592241139e-05, 'epoch': 1.1604800446553167, 'step': 4158}\n",
      "06/30/2020 16:47:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0649362731416874e-05, 'epoch': 1.1610382361149874, 'step': 4160}\n",
      "06/30/2020 16:47:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.064005954042237e-05, 'epoch': 1.1615964275746582, 'step': 4162}\n",
      "06/30/2020 16:47:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0630756349427855e-05, 'epoch': 1.1621546190343288, 'step': 4164}\n",
      "06/30/2020 16:47:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.062145315843334e-05, 'epoch': 1.1627128104939994, 'step': 4166}\n",
      "06/30/2020 16:47:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0612149967438835e-05, 'epoch': 1.16327100195367, 'step': 4168}\n",
      "06/30/2020 16:47:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.060284677644432e-05, 'epoch': 1.1638291934133407, 'step': 4170}\n",
      "06/30/2020 16:47:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0593543585449815e-05, 'epoch': 1.1643873848730115, 'step': 4172}\n",
      "06/30/2020 16:47:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.05842403944553e-05, 'epoch': 1.1649455763326821, 'step': 4174}\n",
      "06/30/2020 16:47:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.057493720346079e-05, 'epoch': 1.1655037677923528, 'step': 4176}\n",
      "06/30/2020 16:47:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0565634012466276e-05, 'epoch': 1.1660619592520234, 'step': 4178}\n",
      "06/30/2020 16:47:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.055633082147177e-05, 'epoch': 1.1666201507116942, 'step': 4180}\n",
      "06/30/2020 16:47:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0547027630477256e-05, 'epoch': 1.1671783421713648, 'step': 4182}\n",
      "06/30/2020 16:47:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.053772443948274e-05, 'epoch': 1.1677365336310355, 'step': 4184}\n",
      "06/30/2020 16:47:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.052842124848823e-05, 'epoch': 1.168294725090706, 'step': 4186}\n",
      "06/30/2020 16:47:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.051911805749372e-05, 'epoch': 1.1688529165503767, 'step': 4188}\n",
      "06/30/2020 16:47:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.050981486649921e-05, 'epoch': 1.1694111080100473, 'step': 4190}\n",
      "06/30/2020 16:47:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.05005116755047e-05, 'epoch': 1.1699692994697182, 'step': 4192}\n",
      "06/30/2020 16:47:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0491208484510187e-05, 'epoch': 1.1705274909293888, 'step': 4194}\n",
      "06/30/2020 16:47:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0481905293515677e-05, 'epoch': 1.1710856823890594, 'step': 4196}\n",
      "06/30/2020 16:47:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0472602102521164e-05, 'epoch': 1.17164387384873, 'step': 4198}\n",
      "06/30/2020 16:47:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0463298911526654e-05, 'epoch': 1.1722020653084009, 'step': 4200}\n",
      "06/30/2020 16:47:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.045399572053214e-05, 'epoch': 1.1727602567680715, 'step': 4202}\n",
      "06/30/2020 16:47:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0444692529537634e-05, 'epoch': 1.1733184482277421, 'step': 4204}\n",
      "06/30/2020 16:47:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0435389338543124e-05, 'epoch': 1.1738766396874127, 'step': 4206}\n",
      "06/30/2020 16:47:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.042608614754861e-05, 'epoch': 1.1744348311470834, 'step': 4208}\n",
      "06/30/2020 16:47:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.04167829565541e-05, 'epoch': 1.1749930226067542, 'step': 4210}\n",
      "06/30/2020 16:47:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0407479765559588e-05, 'epoch': 1.1755512140664248, 'step': 4212}\n",
      "06/30/2020 16:47:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0398176574565078e-05, 'epoch': 1.1761094055260954, 'step': 4214}\n",
      "06/30/2020 16:47:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0388873383570565e-05, 'epoch': 1.176667596985766, 'step': 4216}\n",
      "06/30/2020 16:47:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0379570192576055e-05, 'epoch': 1.177225788445437, 'step': 4218}\n",
      "06/30/2020 16:47:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0370267001581542e-05, 'epoch': 1.1777839799051075, 'step': 4220}\n",
      "06/30/2020 16:47:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0360963810587035e-05, 'epoch': 1.1783421713647781, 'step': 4222}\n",
      "06/30/2020 16:47:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.035166061959252e-05, 'epoch': 1.1789003628244488, 'step': 4224}\n",
      "06/30/2020 16:47:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0342357428598012e-05, 'epoch': 1.1794585542841194, 'step': 4226}\n",
      "06/30/2020 16:47:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.03330542376035e-05, 'epoch': 1.18001674574379, 'step': 4228}\n",
      "06/30/2020 16:47:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.032375104660899e-05, 'epoch': 1.1805749372034609, 'step': 4230}\n",
      "06/30/2020 16:47:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0314447855614476e-05, 'epoch': 1.1811331286631315, 'step': 4232}\n",
      "06/30/2020 16:47:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0305144664619966e-05, 'epoch': 1.181691320122802, 'step': 4234}\n",
      "06/30/2020 16:47:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0295841473625453e-05, 'epoch': 1.1822495115824727, 'step': 4236}\n",
      "06/30/2020 16:47:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0286538282630943e-05, 'epoch': 1.1828077030421436, 'step': 4238}\n",
      "06/30/2020 16:47:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.027723509163643e-05, 'epoch': 1.1833658945018142, 'step': 4240}\n",
      "06/30/2020 16:47:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.026793190064192e-05, 'epoch': 1.1839240859614848, 'step': 4242}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:47:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0258628709647414e-05, 'epoch': 1.1844822774211554, 'step': 4244}\n",
      "06/30/2020 16:47:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.02493255186529e-05, 'epoch': 1.185040468880826, 'step': 4246}\n",
      "06/30/2020 16:47:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.024002232765839e-05, 'epoch': 1.1855986603404969, 'step': 4248}\n",
      "06/30/2020 16:47:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0230719136663877e-05, 'epoch': 1.1861568518001675, 'step': 4250}\n",
      "06/30/2020 16:47:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0221415945669368e-05, 'epoch': 1.1867150432598381, 'step': 4252}\n",
      "06/30/2020 16:47:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0212112754674854e-05, 'epoch': 1.1872732347195087, 'step': 4254}\n",
      "06/30/2020 16:47:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0202809563680344e-05, 'epoch': 1.1878314261791794, 'step': 4256}\n",
      "06/30/2020 16:47:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.019350637268583e-05, 'epoch': 1.1883896176388502, 'step': 4258}\n",
      "06/30/2020 16:47:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.018420318169132e-05, 'epoch': 1.1889478090985208, 'step': 4260}\n",
      "06/30/2020 16:47:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0174899990696808e-05, 'epoch': 1.1895060005581914, 'step': 4262}\n",
      "06/30/2020 16:47:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0165596799702302e-05, 'epoch': 1.190064192017862, 'step': 4264}\n",
      "06/30/2020 16:47:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0156293608707785e-05, 'epoch': 1.1906223834775327, 'step': 4266}\n",
      "06/30/2020 16:47:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.014699041771328e-05, 'epoch': 1.1911805749372035, 'step': 4268}\n",
      "06/30/2020 16:47:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0137687226718765e-05, 'epoch': 1.1917387663968741, 'step': 4270}\n",
      "06/30/2020 16:47:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0128384035724256e-05, 'epoch': 1.1922969578565448, 'step': 4272}\n",
      "06/30/2020 16:47:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0119080844729742e-05, 'epoch': 1.1928551493162154, 'step': 4274}\n",
      "06/30/2020 16:47:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0109777653735232e-05, 'epoch': 1.1934133407758862, 'step': 4276}\n",
      "06/30/2020 16:47:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0100474462740723e-05, 'epoch': 1.1939715322355569, 'step': 4278}\n",
      "06/30/2020 16:47:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.009117127174621e-05, 'epoch': 1.1945297236952275, 'step': 4280}\n",
      "06/30/2020 16:47:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0081868080751703e-05, 'epoch': 1.195087915154898, 'step': 4282}\n",
      "06/30/2020 16:47:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0072564889757186e-05, 'epoch': 1.1956461066145687, 'step': 4284}\n",
      "06/30/2020 16:47:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.006326169876268e-05, 'epoch': 1.1962042980742396, 'step': 4286}\n",
      "06/30/2020 16:47:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0053958507768167e-05, 'epoch': 1.1967624895339102, 'step': 4288}\n",
      "06/30/2020 16:47:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0044655316773657e-05, 'epoch': 1.1973206809935808, 'step': 4290}\n",
      "06/30/2020 16:47:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0035352125779144e-05, 'epoch': 1.1978788724532514, 'step': 4292}\n",
      "06/30/2020 16:47:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0026048934784634e-05, 'epoch': 1.198437063912922, 'step': 4294}\n",
      "06/30/2020 16:47:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.001674574379012e-05, 'epoch': 1.1989952553725929, 'step': 4296}\n",
      "06/30/2020 16:47:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.000744255279561e-05, 'epoch': 1.1995534468322635, 'step': 4298}\n",
      "06/30/2020 16:47:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9998139361801097e-05, 'epoch': 1.2001116382919341, 'step': 4300}\n",
      "06/30/2020 16:47:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9988836170806588e-05, 'epoch': 1.2006698297516047, 'step': 4302}\n",
      "06/30/2020 16:47:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9979532979812074e-05, 'epoch': 1.2012280212112754, 'step': 4304}\n",
      "06/30/2020 16:47:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9970229788817568e-05, 'epoch': 1.2017862126709462, 'step': 4306}\n",
      "06/30/2020 16:47:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.996092659782305e-05, 'epoch': 1.2023444041306168, 'step': 4308}\n",
      "06/30/2020 16:47:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9951623406828545e-05, 'epoch': 1.2029025955902874, 'step': 4310}\n",
      "06/30/2020 16:47:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9942320215834028e-05, 'epoch': 1.203460787049958, 'step': 4312}\n",
      "06/30/2020 16:47:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9933017024839522e-05, 'epoch': 1.204018978509629, 'step': 4314}\n",
      "06/30/2020 16:47:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9923713833845012e-05, 'epoch': 1.2045771699692995, 'step': 4316}\n",
      "06/30/2020 16:47:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.99144106428505e-05, 'epoch': 1.2051353614289702, 'step': 4318}\n",
      "06/30/2020 16:47:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.990510745185599e-05, 'epoch': 1.2056935528886408, 'step': 4320}\n",
      "06/30/2020 16:47:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9895804260861476e-05, 'epoch': 1.2062517443483114, 'step': 4322}\n",
      "06/30/2020 16:47:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.988650106986697e-05, 'epoch': 1.206809935807982, 'step': 4324}\n",
      "06/30/2020 16:47:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9877197878872453e-05, 'epoch': 1.2073681272676529, 'step': 4326}\n",
      "06/30/2020 16:47:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9867894687877946e-05, 'epoch': 1.2079263187273235, 'step': 4328}\n",
      "06/30/2020 16:47:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9858591496883433e-05, 'epoch': 1.208484510186994, 'step': 4330}\n",
      "06/30/2020 16:47:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9849288305888923e-05, 'epoch': 1.2090427016466647, 'step': 4332}\n",
      "06/30/2020 16:47:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.983998511489441e-05, 'epoch': 1.2096008931063356, 'step': 4334}\n",
      "06/30/2020 16:47:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.98306819238999e-05, 'epoch': 1.2101590845660062, 'step': 4336}\n",
      "06/30/2020 16:47:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9821378732905387e-05, 'epoch': 1.2107172760256768, 'step': 4338}\n",
      "06/30/2020 16:47:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9812075541910877e-05, 'epoch': 1.2112754674853474, 'step': 4340}\n",
      "06/30/2020 16:47:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9802772350916364e-05, 'epoch': 1.211833658945018, 'step': 4342}\n",
      "06/30/2020 16:47:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9793469159921854e-05, 'epoch': 1.2123918504046889, 'step': 4344}\n",
      "06/30/2020 16:47:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.978416596892734e-05, 'epoch': 1.2129500418643595, 'step': 4346}\n",
      "06/30/2020 16:47:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9774862777932834e-05, 'epoch': 1.2135082333240301, 'step': 4348}\n",
      "06/30/2020 16:47:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9765559586938318e-05, 'epoch': 1.2140664247837007, 'step': 4350}\n",
      "06/30/2020 16:47:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.975625639594381e-05, 'epoch': 1.2146246162433716, 'step': 4352}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:47:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.97469532049493e-05, 'epoch': 1.2151828077030422, 'step': 4354}\n",
      "06/30/2020 16:47:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9737650013954788e-05, 'epoch': 1.2157409991627128, 'step': 4356}\n",
      "06/30/2020 16:47:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9728346822960278e-05, 'epoch': 1.2162991906223835, 'step': 4358}\n",
      "06/30/2020 16:47:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9719043631965765e-05, 'epoch': 1.216857382082054, 'step': 4360}\n",
      "06/30/2020 16:47:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9709740440971255e-05, 'epoch': 1.2174155735417247, 'step': 4362}\n",
      "06/30/2020 16:47:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9700437249976742e-05, 'epoch': 1.2179737650013955, 'step': 4364}\n",
      "06/30/2020 16:47:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9691134058982235e-05, 'epoch': 1.2185319564610662, 'step': 4366}\n",
      "06/30/2020 16:47:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.968183086798772e-05, 'epoch': 1.2190901479207368, 'step': 4368}\n",
      "06/30/2020 16:47:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9672527676993212e-05, 'epoch': 1.2196483393804074, 'step': 4370}\n",
      "06/30/2020 16:47:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.96632244859987e-05, 'epoch': 1.2202065308400782, 'step': 4372}\n",
      "06/30/2020 16:47:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.965392129500419e-05, 'epoch': 1.2207647222997489, 'step': 4374}\n",
      "06/30/2020 16:47:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9644618104009676e-05, 'epoch': 1.2213229137594195, 'step': 4376}\n",
      "06/30/2020 16:47:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9635314913015166e-05, 'epoch': 1.22188110521909, 'step': 4378}\n",
      "06/30/2020 16:47:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9626011722020653e-05, 'epoch': 1.2224392966787607, 'step': 4380}\n",
      "06/30/2020 16:47:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9616708531026143e-05, 'epoch': 1.2229974881384316, 'step': 4382}\n",
      "06/30/2020 16:47:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.960740534003163e-05, 'epoch': 1.2235556795981022, 'step': 4384}\n",
      "06/30/2020 16:47:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.959810214903712e-05, 'epoch': 1.2241138710577728, 'step': 4386}\n",
      "06/30/2020 16:47:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9588798958042607e-05, 'epoch': 1.2246720625174434, 'step': 4388}\n",
      "06/30/2020 16:47:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.95794957670481e-05, 'epoch': 1.2252302539771143, 'step': 4390}\n",
      "06/30/2020 16:47:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.957019257605359e-05, 'epoch': 1.225788445436785, 'step': 4392}\n",
      "06/30/2020 16:47:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9560889385059077e-05, 'epoch': 1.2263466368964555, 'step': 4394}\n",
      "06/30/2020 16:47:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9551586194064567e-05, 'epoch': 1.2269048283561261, 'step': 4396}\n",
      "06/30/2020 16:47:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9542283003070054e-05, 'epoch': 1.2274630198157968, 'step': 4398}\n",
      "06/30/2020 16:47:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9532979812075544e-05, 'epoch': 1.2280212112754674, 'step': 4400}\n",
      "06/30/2020 16:47:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.952367662108103e-05, 'epoch': 1.2285794027351382, 'step': 4402}\n",
      "06/30/2020 16:47:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.951437343008652e-05, 'epoch': 1.2291375941948088, 'step': 4404}\n",
      "06/30/2020 16:47:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9505070239092008e-05, 'epoch': 1.2296957856544795, 'step': 4406}\n",
      "06/30/2020 16:47:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.94957670480975e-05, 'epoch': 1.23025397711415, 'step': 4408}\n",
      "06/30/2020 16:47:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9486463857102985e-05, 'epoch': 1.230812168573821, 'step': 4410}\n",
      "06/30/2020 16:47:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.947716066610848e-05, 'epoch': 1.2313703600334915, 'step': 4412}\n",
      "06/30/2020 16:47:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9467857475113962e-05, 'epoch': 1.2319285514931622, 'step': 4414}\n",
      "06/30/2020 16:47:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9458554284119455e-05, 'epoch': 1.2324867429528328, 'step': 4416}\n",
      "06/30/2020 16:47:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9449251093124942e-05, 'epoch': 1.2330449344125034, 'step': 4418}\n",
      "06/30/2020 16:47:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9439947902130432e-05, 'epoch': 1.2336031258721742, 'step': 4420}\n",
      "06/30/2020 16:47:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.943064471113592e-05, 'epoch': 1.2341613173318449, 'step': 4422}\n",
      "06/30/2020 16:47:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.942134152014141e-05, 'epoch': 1.2347195087915155, 'step': 4424}\n",
      "06/30/2020 16:47:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9412038329146903e-05, 'epoch': 1.235277700251186, 'step': 4426}\n",
      "06/30/2020 16:47:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9402735138152386e-05, 'epoch': 1.235835891710857, 'step': 4428}\n",
      "06/30/2020 16:47:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.939343194715788e-05, 'epoch': 1.2363940831705276, 'step': 4430}\n",
      "06/30/2020 16:47:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9384128756163367e-05, 'epoch': 1.2369522746301982, 'step': 4432}\n",
      "06/30/2020 16:47:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9374825565168857e-05, 'epoch': 1.2375104660898688, 'step': 4434}\n",
      "06/30/2020 16:47:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9365522374174343e-05, 'epoch': 1.2380686575495394, 'step': 4436}\n",
      "06/30/2020 16:47:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9356219183179834e-05, 'epoch': 1.23862684900921, 'step': 4438}\n",
      "06/30/2020 16:47:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.934691599218532e-05, 'epoch': 1.239185040468881, 'step': 4440}\n",
      "06/30/2020 16:47:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.933761280119081e-05, 'epoch': 1.2397432319285515, 'step': 4442}\n",
      "06/30/2020 16:47:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9328309610196297e-05, 'epoch': 1.2403014233882221, 'step': 4444}\n",
      "06/30/2020 16:47:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9319006419201787e-05, 'epoch': 1.2408596148478928, 'step': 4446}\n",
      "06/30/2020 16:47:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9309703228207274e-05, 'epoch': 1.2414178063075636, 'step': 4448}\n",
      "06/30/2020 16:47:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9300400037212768e-05, 'epoch': 1.2419759977672342, 'step': 4450}\n",
      "06/30/2020 16:47:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.929109684621825e-05, 'epoch': 1.2425341892269048, 'step': 4452}\n",
      "06/30/2020 16:47:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9281793655223745e-05, 'epoch': 1.2430923806865755, 'step': 4454}\n",
      "06/30/2020 16:47:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9272490464229228e-05, 'epoch': 1.243650572146246, 'step': 4456}\n",
      "06/30/2020 16:47:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.926318727323472e-05, 'epoch': 1.244208763605917, 'step': 4458}\n",
      "06/30/2020 16:47:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.925388408224021e-05, 'epoch': 1.2447669550655875, 'step': 4460}\n",
      "06/30/2020 16:47:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.92445808912457e-05, 'epoch': 1.2453251465252582, 'step': 4462}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:47:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.923527770025119e-05, 'epoch': 1.2458833379849288, 'step': 4464}\n",
      "06/30/2020 16:47:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9225974509256676e-05, 'epoch': 1.2464415294445994, 'step': 4466}\n",
      "06/30/2020 16:47:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.921667131826217e-05, 'epoch': 1.2469997209042702, 'step': 4468}\n",
      "06/30/2020 16:47:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9207368127267652e-05, 'epoch': 1.2475579123639409, 'step': 4470}\n",
      "06/30/2020 16:47:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9198064936273146e-05, 'epoch': 1.2481161038236115, 'step': 4472}\n",
      "06/30/2020 16:47:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.918876174527863e-05, 'epoch': 1.248674295283282, 'step': 4474}\n",
      "06/30/2020 16:47:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9179458554284123e-05, 'epoch': 1.2492324867429527, 'step': 4476}\n",
      "06/30/2020 16:47:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.917015536328961e-05, 'epoch': 1.2497906782026236, 'step': 4478}\n",
      "06/30/2020 16:47:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.91608521722951e-05, 'epoch': 1.2503488696622942, 'step': 4480}\n",
      "06/30/2020 16:47:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9151548981300587e-05, 'epoch': 1.2509070611219648, 'step': 4482}\n",
      "06/30/2020 16:47:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9142245790306077e-05, 'epoch': 1.2514652525816354, 'step': 4484}\n",
      "06/30/2020 16:47:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9132942599311564e-05, 'epoch': 1.2520234440413063, 'step': 4486}\n",
      "06/30/2020 16:47:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9123639408317054e-05, 'epoch': 1.252581635500977, 'step': 4488}\n",
      "06/30/2020 16:47:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.911433621732254e-05, 'epoch': 1.2531398269606475, 'step': 4490}\n",
      "06/30/2020 16:47:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9105033026328034e-05, 'epoch': 1.2536980184203181, 'step': 4492}\n",
      "06/30/2020 16:47:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9095729835333517e-05, 'epoch': 1.2542562098799888, 'step': 4494}\n",
      "06/30/2020 16:47:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.908642664433901e-05, 'epoch': 1.2548144013396594, 'step': 4496}\n",
      "06/30/2020 16:47:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9077123453344494e-05, 'epoch': 1.2553725927993302, 'step': 4498}\n",
      "06/30/2020 16:47:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9067820262349988e-05, 'epoch': 1.2559307842590008, 'step': 4500}\n",
      "06/30/2020 16:47:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9058517071355478e-05, 'epoch': 1.2564889757186715, 'step': 4502}\n",
      "06/30/2020 16:47:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9049213880360965e-05, 'epoch': 1.2570471671783423, 'step': 4504}\n",
      "06/30/2020 16:47:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9039910689366455e-05, 'epoch': 1.257605358638013, 'step': 4506}\n",
      "06/30/2020 16:47:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9030607498371942e-05, 'epoch': 1.2581635500976835, 'step': 4508}\n",
      "06/30/2020 16:47:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9021304307377435e-05, 'epoch': 1.2587217415573542, 'step': 4510}\n",
      "06/30/2020 16:47:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.901200111638292e-05, 'epoch': 1.2592799330170248, 'step': 4512}\n",
      "06/30/2020 16:47:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9002697925388412e-05, 'epoch': 1.2598381244766954, 'step': 4514}\n",
      "06/30/2020 16:47:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8993394734393896e-05, 'epoch': 1.2603963159363663, 'step': 4516}\n",
      "06/30/2020 16:47:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.898409154339939e-05, 'epoch': 1.2609545073960369, 'step': 4518}\n",
      "06/30/2020 16:47:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8974788352404876e-05, 'epoch': 1.2615126988557075, 'step': 4520}\n",
      "06/30/2020 16:47:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8965485161410366e-05, 'epoch': 1.2620708903153781, 'step': 4522}\n",
      "06/30/2020 16:47:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8956181970415853e-05, 'epoch': 1.262629081775049, 'step': 4524}\n",
      "06/30/2020 16:47:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8946878779421343e-05, 'epoch': 1.2631872732347196, 'step': 4526}\n",
      "06/30/2020 16:47:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.893757558842683e-05, 'epoch': 1.2637454646943902, 'step': 4528}\n",
      "06/30/2020 16:47:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.892827239743232e-05, 'epoch': 1.2643036561540608, 'step': 4530}\n",
      "06/30/2020 16:47:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8918969206437807e-05, 'epoch': 1.2648618476137314, 'step': 4532}\n",
      "06/30/2020 16:47:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.89096660154433e-05, 'epoch': 1.265420039073402, 'step': 4534}\n",
      "06/30/2020 16:47:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.890036282444879e-05, 'epoch': 1.265978230533073, 'step': 4536}\n",
      "06/30/2020 16:47:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8891059633454277e-05, 'epoch': 1.2665364219927435, 'step': 4538}\n",
      "06/30/2020 16:47:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8881756442459767e-05, 'epoch': 1.2670946134524141, 'step': 4540}\n",
      "06/30/2020 16:47:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8872453251465254e-05, 'epoch': 1.2676528049120848, 'step': 4542}\n",
      "06/30/2020 16:47:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8863150060470744e-05, 'epoch': 1.2682109963717556, 'step': 4544}\n",
      "06/30/2020 16:47:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.885384686947623e-05, 'epoch': 1.2687691878314262, 'step': 4546}\n",
      "06/30/2020 16:47:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.884454367848172e-05, 'epoch': 1.2693273792910968, 'step': 4548}\n",
      "06/30/2020 16:47:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8835240487487208e-05, 'epoch': 1.2698855707507675, 'step': 4550}\n",
      "06/30/2020 16:47:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.88259372964927e-05, 'epoch': 1.270443762210438, 'step': 4552}\n",
      "06/30/2020 16:47:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8816634105498185e-05, 'epoch': 1.271001953670109, 'step': 4554}\n",
      "06/30/2020 16:47:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.880733091450368e-05, 'epoch': 1.2715601451297796, 'step': 4556}\n",
      "06/30/2020 16:47:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8798027723509162e-05, 'epoch': 1.2721183365894502, 'step': 4558}\n",
      "06/30/2020 16:47:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8788724532514655e-05, 'epoch': 1.2726765280491208, 'step': 4560}\n",
      "06/30/2020 16:47:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8779421341520142e-05, 'epoch': 1.2732347195087916, 'step': 4562}\n",
      "06/30/2020 16:47:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8770118150525632e-05, 'epoch': 1.2737929109684623, 'step': 4564}\n",
      "06/30/2020 16:47:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.876081495953112e-05, 'epoch': 1.2743511024281329, 'step': 4566}\n",
      "06/30/2020 16:47:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.875151176853661e-05, 'epoch': 1.2749092938878035, 'step': 4568}\n",
      "06/30/2020 16:47:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8742208577542096e-05, 'epoch': 1.2754674853474741, 'step': 4570}\n",
      "06/30/2020 16:47:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8732905386547586e-05, 'epoch': 1.2760256768071447, 'step': 4572}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:47:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.872360219555308e-05, 'epoch': 1.2765838682668156, 'step': 4574}\n",
      "06/30/2020 16:47:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8714299004558563e-05, 'epoch': 1.2771420597264862, 'step': 4576}\n",
      "06/30/2020 16:47:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8704995813564057e-05, 'epoch': 1.2777002511861568, 'step': 4578}\n",
      "06/30/2020 16:47:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8695692622569543e-05, 'epoch': 1.2782584426458274, 'step': 4580}\n",
      "06/30/2020 16:47:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8686389431575034e-05, 'epoch': 1.2788166341054983, 'step': 4582}\n",
      "06/30/2020 16:47:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.867708624058052e-05, 'epoch': 1.279374825565169, 'step': 4584}\n",
      "06/30/2020 16:47:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.866778304958601e-05, 'epoch': 1.2799330170248395, 'step': 4586}\n",
      "06/30/2020 16:47:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8658479858591497e-05, 'epoch': 1.2804912084845101, 'step': 4588}\n",
      "06/30/2020 16:47:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8649176667596987e-05, 'epoch': 1.2810493999441808, 'step': 4590}\n",
      "06/30/2020 16:47:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8639873476602474e-05, 'epoch': 1.2816075914038514, 'step': 4592}\n",
      "06/30/2020 16:47:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8630570285607968e-05, 'epoch': 1.2821657828635222, 'step': 4594}\n",
      "06/30/2020 16:47:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.862126709461345e-05, 'epoch': 1.2827239743231929, 'step': 4596}\n",
      "06/30/2020 16:47:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8611963903618945e-05, 'epoch': 1.2832821657828635, 'step': 4598}\n",
      "06/30/2020 16:47:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8602660712624428e-05, 'epoch': 1.2838403572425343, 'step': 4600}\n",
      "06/30/2020 16:47:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.859335752162992e-05, 'epoch': 1.284398548702205, 'step': 4602}\n",
      "06/30/2020 16:47:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.858405433063541e-05, 'epoch': 1.2849567401618756, 'step': 4604}\n",
      "06/30/2020 16:47:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.85747511396409e-05, 'epoch': 1.2855149316215462, 'step': 4606}\n",
      "06/30/2020 16:47:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8565447948646385e-05, 'epoch': 1.2860731230812168, 'step': 4608}\n",
      "06/30/2020 16:47:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8556144757651875e-05, 'epoch': 1.2866313145408874, 'step': 4610}\n",
      "06/30/2020 16:47:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.854684156665737e-05, 'epoch': 1.2871895060005583, 'step': 4612}\n",
      "06/30/2020 16:47:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8537538375662852e-05, 'epoch': 1.2877476974602289, 'step': 4614}\n",
      "06/30/2020 16:47:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8528235184668346e-05, 'epoch': 1.2883058889198995, 'step': 4616}\n",
      "06/30/2020 16:47:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.851893199367383e-05, 'epoch': 1.2888640803795701, 'step': 4618}\n",
      "06/30/2020 16:47:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8509628802679323e-05, 'epoch': 1.289422271839241, 'step': 4620}\n",
      "06/30/2020 16:47:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.850032561168481e-05, 'epoch': 1.2899804632989116, 'step': 4622}\n",
      "06/30/2020 16:47:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.84910224206903e-05, 'epoch': 1.2905386547585822, 'step': 4624}\n",
      "06/30/2020 16:47:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8481719229695786e-05, 'epoch': 1.2910968462182528, 'step': 4626}\n",
      "06/30/2020 16:47:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8472416038701277e-05, 'epoch': 1.2916550376779234, 'step': 4628}\n",
      "06/30/2020 16:47:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8463112847706763e-05, 'epoch': 1.292213229137594, 'step': 4630}\n",
      "06/30/2020 16:47:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8453809656712254e-05, 'epoch': 1.292771420597265, 'step': 4632}\n",
      "06/30/2020 16:47:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.844450646571774e-05, 'epoch': 1.2933296120569355, 'step': 4634}\n",
      "06/30/2020 16:47:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.843520327472323e-05, 'epoch': 1.2938878035166061, 'step': 4636}\n",
      "06/30/2020 16:47:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8425900083728717e-05, 'epoch': 1.294445994976277, 'step': 4638}\n",
      "06/30/2020 16:47:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.841659689273421e-05, 'epoch': 1.2950041864359476, 'step': 4640}\n",
      "06/30/2020 16:47:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8407293701739694e-05, 'epoch': 1.2955623778956182, 'step': 4642}\n",
      "06/30/2020 16:47:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8397990510745188e-05, 'epoch': 1.2961205693552889, 'step': 4644}\n",
      "06/30/2020 16:47:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8388687319750675e-05, 'epoch': 1.2966787608149595, 'step': 4646}\n",
      "06/30/2020 16:47:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8379384128756165e-05, 'epoch': 1.29723695227463, 'step': 4648}\n",
      "06/30/2020 16:47:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8370080937761655e-05, 'epoch': 1.297795143734301, 'step': 4650}\n",
      "06/30/2020 16:47:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.836077774676714e-05, 'epoch': 1.2983533351939716, 'step': 4652}\n",
      "06/30/2020 16:47:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8351474555772635e-05, 'epoch': 1.2989115266536422, 'step': 4654}\n",
      "06/30/2020 16:47:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.834217136477812e-05, 'epoch': 1.2994697181133128, 'step': 4656}\n",
      "06/30/2020 16:47:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8332868173783612e-05, 'epoch': 1.3000279095729836, 'step': 4658}\n",
      "06/30/2020 16:47:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8323564982789095e-05, 'epoch': 1.3005861010326543, 'step': 4660}\n",
      "06/30/2020 16:47:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.831426179179459e-05, 'epoch': 1.3011442924923249, 'step': 4662}\n",
      "06/30/2020 16:47:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8304958600800076e-05, 'epoch': 1.3017024839519955, 'step': 4664}\n",
      "06/30/2020 16:47:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8295655409805566e-05, 'epoch': 1.3022606754116661, 'step': 4666}\n",
      "06/30/2020 16:47:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8286352218811053e-05, 'epoch': 1.3028188668713367, 'step': 4668}\n",
      "06/30/2020 16:47:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8277049027816543e-05, 'epoch': 1.3033770583310076, 'step': 4670}\n",
      "06/30/2020 16:47:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.826774583682203e-05, 'epoch': 1.3039352497906782, 'step': 4672}\n",
      "06/30/2020 16:47:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.825844264582752e-05, 'epoch': 1.3044934412503488, 'step': 4674}\n",
      "06/30/2020 16:47:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8249139454833007e-05, 'epoch': 1.3050516327100197, 'step': 4676}\n",
      "06/30/2020 16:47:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8239836263838497e-05, 'epoch': 1.3056098241696903, 'step': 4678}\n",
      "06/30/2020 16:47:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8230533072843983e-05, 'epoch': 1.306168015629361, 'step': 4680}\n",
      "06/30/2020 16:47:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8221229881849477e-05, 'epoch': 1.3067262070890315, 'step': 4682}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:47:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8211926690854967e-05, 'epoch': 1.3072843985487022, 'step': 4684}\n",
      "06/30/2020 16:47:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8202623499860454e-05, 'epoch': 1.3078425900083728, 'step': 4686}\n",
      "06/30/2020 16:47:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8193320308865944e-05, 'epoch': 1.3084007814680436, 'step': 4688}\n",
      "06/30/2020 16:47:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.818401711787143e-05, 'epoch': 1.3089589729277142, 'step': 4690}\n",
      "06/30/2020 16:47:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.817471392687692e-05, 'epoch': 1.3095171643873849, 'step': 4692}\n",
      "06/30/2020 16:47:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8165410735882408e-05, 'epoch': 1.3100753558470555, 'step': 4694}\n",
      "06/30/2020 16:47:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.81561075448879e-05, 'epoch': 1.3106335473067263, 'step': 4696}\n",
      "06/30/2020 16:47:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8146804353893385e-05, 'epoch': 1.311191738766397, 'step': 4698}\n",
      "06/30/2020 16:47:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8137501162898878e-05, 'epoch': 1.3117499302260676, 'step': 4700}\n",
      "06/30/2020 16:47:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.812819797190436e-05, 'epoch': 1.3123081216857382, 'step': 4702}\n",
      "06/30/2020 16:47:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8118894780909855e-05, 'epoch': 1.3128663131454088, 'step': 4704}\n",
      "06/30/2020 16:47:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8109591589915342e-05, 'epoch': 1.3134245046050794, 'step': 4706}\n",
      "06/30/2020 16:47:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8100288398920832e-05, 'epoch': 1.3139826960647503, 'step': 4708}\n",
      "06/30/2020 16:47:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.809098520792632e-05, 'epoch': 1.3145408875244209, 'step': 4710}\n",
      "06/30/2020 16:47:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.808168201693181e-05, 'epoch': 1.3150990789840915, 'step': 4712}\n",
      "06/30/2020 16:47:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8072378825937296e-05, 'epoch': 1.3156572704437621, 'step': 4714}\n",
      "06/30/2020 16:48:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8063075634942786e-05, 'epoch': 1.316215461903433, 'step': 4716}\n",
      "06/30/2020 16:48:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8053772443948273e-05, 'epoch': 1.3167736533631036, 'step': 4718}\n",
      "06/30/2020 16:48:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8044469252953763e-05, 'epoch': 1.3173318448227742, 'step': 4720}\n",
      "06/30/2020 16:48:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8035166061959256e-05, 'epoch': 1.3178900362824448, 'step': 4722}\n",
      "06/30/2020 16:48:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8025862870964743e-05, 'epoch': 1.3184482277421155, 'step': 4724}\n",
      "06/30/2020 16:48:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8016559679970233e-05, 'epoch': 1.3190064192017863, 'step': 4726}\n",
      "06/30/2020 16:48:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.800725648897572e-05, 'epoch': 1.319564610661457, 'step': 4728}\n",
      "06/30/2020 16:48:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.799795329798121e-05, 'epoch': 1.3201228021211275, 'step': 4730}\n",
      "06/30/2020 16:48:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7988650106986697e-05, 'epoch': 1.3206809935807982, 'step': 4732}\n",
      "06/30/2020 16:48:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7979346915992187e-05, 'epoch': 1.321239185040469, 'step': 4734}\n",
      "06/30/2020 16:48:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7970043724997674e-05, 'epoch': 1.3217973765001396, 'step': 4736}\n",
      "06/30/2020 16:48:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7960740534003164e-05, 'epoch': 1.3223555679598102, 'step': 4738}\n",
      "06/30/2020 16:48:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.795143734300865e-05, 'epoch': 1.3229137594194809, 'step': 4740}\n",
      "06/30/2020 16:48:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7942134152014144e-05, 'epoch': 1.3234719508791515, 'step': 4742}\n",
      "06/30/2020 16:48:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7932830961019628e-05, 'epoch': 1.324030142338822, 'step': 4744}\n",
      "06/30/2020 16:48:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.792352777002512e-05, 'epoch': 1.324588333798493, 'step': 4746}\n",
      "06/30/2020 16:48:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7914224579030608e-05, 'epoch': 1.3251465252581636, 'step': 4748}\n",
      "06/30/2020 16:48:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.79049213880361e-05, 'epoch': 1.3257047167178342, 'step': 4750}\n",
      "06/30/2020 16:48:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7895618197041585e-05, 'epoch': 1.3262629081775048, 'step': 4752}\n",
      "06/30/2020 16:48:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7886315006047075e-05, 'epoch': 1.3268210996371756, 'step': 4754}\n",
      "06/30/2020 16:48:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7877011815052562e-05, 'epoch': 1.3273792910968463, 'step': 4756}\n",
      "06/30/2020 16:48:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7867708624058052e-05, 'epoch': 1.327937482556517, 'step': 4758}\n",
      "06/30/2020 16:48:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7858405433063546e-05, 'epoch': 1.3284956740161875, 'step': 4760}\n",
      "06/30/2020 16:48:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.784910224206903e-05, 'epoch': 1.3290538654758581, 'step': 4762}\n",
      "06/30/2020 16:48:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7839799051074523e-05, 'epoch': 1.3296120569355288, 'step': 4764}\n",
      "06/30/2020 16:48:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.783049586008001e-05, 'epoch': 1.3301702483951996, 'step': 4766}\n",
      "06/30/2020 16:48:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.78211926690855e-05, 'epoch': 1.3307284398548702, 'step': 4768}\n",
      "06/30/2020 16:48:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7811889478090986e-05, 'epoch': 1.3312866313145408, 'step': 4770}\n",
      "06/30/2020 16:48:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7802586287096477e-05, 'epoch': 1.3318448227742117, 'step': 4772}\n",
      "06/30/2020 16:48:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7793283096101963e-05, 'epoch': 1.3324030142338823, 'step': 4774}\n",
      "06/30/2020 16:48:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7783979905107453e-05, 'epoch': 1.332961205693553, 'step': 4776}\n",
      "06/30/2020 16:48:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.777467671411294e-05, 'epoch': 1.3335193971532235, 'step': 4778}\n",
      "06/30/2020 16:48:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.776537352311843e-05, 'epoch': 1.3340775886128942, 'step': 4780}\n",
      "06/30/2020 16:48:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7756070332123917e-05, 'epoch': 1.3346357800725648, 'step': 4782}\n",
      "06/30/2020 16:48:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.774676714112941e-05, 'epoch': 1.3351939715322356, 'step': 4784}\n",
      "06/30/2020 16:48:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7737463950134894e-05, 'epoch': 1.3357521629919062, 'step': 4786}\n",
      "06/30/2020 16:48:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7728160759140388e-05, 'epoch': 1.3363103544515769, 'step': 4788}\n",
      "06/30/2020 16:48:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7718857568145874e-05, 'epoch': 1.3368685459112475, 'step': 4790}\n",
      "06/30/2020 16:48:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7709554377151365e-05, 'epoch': 1.3374267373709183, 'step': 4792}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:48:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7700251186156855e-05, 'epoch': 1.337984928830589, 'step': 4794}\n",
      "06/30/2020 16:48:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.769094799516234e-05, 'epoch': 1.3385431202902596, 'step': 4796}\n",
      "06/30/2020 16:48:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7681644804167835e-05, 'epoch': 1.3391013117499302, 'step': 4798}\n",
      "06/30/2020 16:48:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.767234161317332e-05, 'epoch': 1.3396595032096008, 'step': 4800}\n",
      "06/30/2020 16:48:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7663038422178812e-05, 'epoch': 1.3402176946692714, 'step': 4802}\n",
      "06/30/2020 16:48:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7653735231184295e-05, 'epoch': 1.3407758861289423, 'step': 4804}\n",
      "06/30/2020 16:48:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.764443204018979e-05, 'epoch': 1.341334077588613, 'step': 4806}\n",
      "06/30/2020 16:48:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7635128849195276e-05, 'epoch': 1.3418922690482835, 'step': 4808}\n",
      "06/30/2020 16:48:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7625825658200766e-05, 'epoch': 1.3424504605079544, 'step': 4810}\n",
      "06/30/2020 16:48:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7616522467206253e-05, 'epoch': 1.343008651967625, 'step': 4812}\n",
      "06/30/2020 16:48:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7607219276211743e-05, 'epoch': 1.3435668434272956, 'step': 4814}\n",
      "06/30/2020 16:48:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.759791608521723e-05, 'epoch': 1.3441250348869662, 'step': 4816}\n",
      "06/30/2020 16:48:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.758861289422272e-05, 'epoch': 1.3446832263466368, 'step': 4818}\n",
      "06/30/2020 16:48:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7579309703228206e-05, 'epoch': 1.3452414178063075, 'step': 4820}\n",
      "06/30/2020 16:48:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7570006512233697e-05, 'epoch': 1.3457996092659783, 'step': 4822}\n",
      "06/30/2020 16:48:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7560703321239183e-05, 'epoch': 1.346357800725649, 'step': 4824}\n",
      "06/30/2020 16:48:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7551400130244677e-05, 'epoch': 1.3469159921853195, 'step': 4826}\n",
      "06/30/2020 16:48:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.754209693925016e-05, 'epoch': 1.3474741836449902, 'step': 4828}\n",
      "06/30/2020 16:48:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7532793748255654e-05, 'epoch': 1.348032375104661, 'step': 4830}\n",
      "06/30/2020 16:48:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7523490557261144e-05, 'epoch': 1.3485905665643316, 'step': 4832}\n",
      "06/30/2020 16:48:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.751418736626663e-05, 'epoch': 1.3491487580240022, 'step': 4834}\n",
      "06/30/2020 16:48:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.750488417527212e-05, 'epoch': 1.3497069494836729, 'step': 4836}\n",
      "06/30/2020 16:48:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7495580984277608e-05, 'epoch': 1.3502651409433435, 'step': 4838}\n",
      "06/30/2020 16:48:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7486277793283098e-05, 'epoch': 1.350823332403014, 'step': 4840}\n",
      "06/30/2020 16:48:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7476974602288585e-05, 'epoch': 1.351381523862685, 'step': 4842}\n",
      "06/30/2020 16:48:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7467671411294078e-05, 'epoch': 1.3519397153223556, 'step': 4844}\n",
      "06/30/2020 16:48:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.745836822029956e-05, 'epoch': 1.3524979067820262, 'step': 4846}\n",
      "06/30/2020 16:48:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7449065029305055e-05, 'epoch': 1.353056098241697, 'step': 4848}\n",
      "06/30/2020 16:48:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7439761838310542e-05, 'epoch': 1.3536142897013677, 'step': 4850}\n",
      "06/30/2020 16:48:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7430458647316032e-05, 'epoch': 1.3541724811610383, 'step': 4852}\n",
      "06/30/2020 16:48:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.742115545632152e-05, 'epoch': 1.354730672620709, 'step': 4854}\n",
      "06/30/2020 16:48:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.741185226532701e-05, 'epoch': 1.3552888640803795, 'step': 4856}\n",
      "06/30/2020 16:48:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7402549074332496e-05, 'epoch': 1.3558470555400501, 'step': 4858}\n",
      "06/30/2020 16:48:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7393245883337986e-05, 'epoch': 1.356405246999721, 'step': 4860}\n",
      "06/30/2020 16:48:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7383942692343473e-05, 'epoch': 1.3569634384593916, 'step': 4862}\n",
      "06/30/2020 16:48:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7374639501348963e-05, 'epoch': 1.3575216299190622, 'step': 4864}\n",
      "06/30/2020 16:48:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.736533631035445e-05, 'epoch': 1.3580798213787328, 'step': 4866}\n",
      "06/30/2020 16:48:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7356033119359943e-05, 'epoch': 1.3586380128384037, 'step': 4868}\n",
      "06/30/2020 16:48:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7346729928365433e-05, 'epoch': 1.3591962042980743, 'step': 4870}\n",
      "06/30/2020 16:48:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.733742673737092e-05, 'epoch': 1.359754395757745, 'step': 4872}\n",
      "06/30/2020 16:48:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.732812354637641e-05, 'epoch': 1.3603125872174155, 'step': 4874}\n",
      "06/30/2020 16:48:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7318820355381897e-05, 'epoch': 1.3608707786770862, 'step': 4876}\n",
      "06/30/2020 16:48:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7309517164387387e-05, 'epoch': 1.3614289701367568, 'step': 4878}\n",
      "06/30/2020 16:48:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7300213973392874e-05, 'epoch': 1.3619871615964276, 'step': 4880}\n",
      "06/30/2020 16:48:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7290910782398364e-05, 'epoch': 1.3625453530560983, 'step': 4882}\n",
      "06/30/2020 16:48:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.728160759140385e-05, 'epoch': 1.3631035445157689, 'step': 4884}\n",
      "06/30/2020 16:48:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7272304400409344e-05, 'epoch': 1.3636617359754395, 'step': 4886}\n",
      "06/30/2020 16:48:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7263001209414828e-05, 'epoch': 1.3642199274351103, 'step': 4888}\n",
      "06/30/2020 16:48:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.725369801842032e-05, 'epoch': 1.364778118894781, 'step': 4890}\n",
      "06/30/2020 16:48:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7244394827425808e-05, 'epoch': 1.3653363103544516, 'step': 4892}\n",
      "06/30/2020 16:48:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7235091636431298e-05, 'epoch': 1.3658945018141222, 'step': 4894}\n",
      "06/30/2020 16:48:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7225788445436785e-05, 'epoch': 1.3664526932737928, 'step': 4896}\n",
      "06/30/2020 16:48:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7216485254442275e-05, 'epoch': 1.3670108847334637, 'step': 4898}\n",
      "06/30/2020 16:48:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7207182063447762e-05, 'epoch': 1.3675690761931343, 'step': 4900}\n",
      "06/30/2020 16:48:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7197878872453252e-05, 'epoch': 1.368127267652805, 'step': 4902}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:48:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.718857568145874e-05, 'epoch': 1.3686854591124755, 'step': 4904}\n",
      "06/30/2020 16:48:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.717927249046423e-05, 'epoch': 1.3692436505721464, 'step': 4906}\n",
      "06/30/2020 16:48:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7169969299469723e-05, 'epoch': 1.369801842031817, 'step': 4908}\n",
      "06/30/2020 16:48:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.716066610847521e-05, 'epoch': 1.3703600334914876, 'step': 4910}\n",
      "06/30/2020 16:48:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.71513629174807e-05, 'epoch': 1.3709182249511582, 'step': 4912}\n",
      "06/30/2020 16:48:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7142059726486186e-05, 'epoch': 1.3714764164108288, 'step': 4914}\n",
      "06/30/2020 16:48:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7132756535491676e-05, 'epoch': 1.3720346078704995, 'step': 4916}\n",
      "06/30/2020 16:48:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7123453344497163e-05, 'epoch': 1.3725927993301703, 'step': 4918}\n",
      "06/30/2020 16:48:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7114150153502653e-05, 'epoch': 1.373150990789841, 'step': 4920}\n",
      "06/30/2020 16:48:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.710484696250814e-05, 'epoch': 1.3737091822495116, 'step': 4922}\n",
      "06/30/2020 16:48:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.709554377151363e-05, 'epoch': 1.3742673737091822, 'step': 4924}\n",
      "06/30/2020 16:48:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7086240580519117e-05, 'epoch': 1.374825565168853, 'step': 4926}\n",
      "06/30/2020 16:48:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.707693738952461e-05, 'epoch': 1.3753837566285236, 'step': 4928}\n",
      "06/30/2020 16:48:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7067634198530094e-05, 'epoch': 1.3759419480881943, 'step': 4930}\n",
      "06/30/2020 16:48:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7058331007535588e-05, 'epoch': 1.3765001395478649, 'step': 4932}\n",
      "06/30/2020 16:48:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7049027816541074e-05, 'epoch': 1.3770583310075355, 'step': 4934}\n",
      "06/30/2020 16:48:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7039724625546564e-05, 'epoch': 1.3776165224672061, 'step': 4936}\n",
      "06/30/2020 16:48:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.703042143455205e-05, 'epoch': 1.378174713926877, 'step': 4938}\n",
      "06/30/2020 16:48:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.702111824355754e-05, 'epoch': 1.3787329053865476, 'step': 4940}\n",
      "06/30/2020 16:48:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.701181505256303e-05, 'epoch': 1.3792910968462182, 'step': 4942}\n",
      "06/30/2020 16:48:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.700251186156852e-05, 'epoch': 1.379849288305889, 'step': 4944}\n",
      "06/30/2020 16:48:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6993208670574012e-05, 'epoch': 1.3804074797655597, 'step': 4946}\n",
      "06/30/2020 16:48:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6983905479579495e-05, 'epoch': 1.3809656712252303, 'step': 4948}\n",
      "06/30/2020 16:48:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.697460228858499e-05, 'epoch': 1.381523862684901, 'step': 4950}\n",
      "06/30/2020 16:48:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6965299097590476e-05, 'epoch': 1.3820820541445715, 'step': 4952}\n",
      "06/30/2020 16:48:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6955995906595966e-05, 'epoch': 1.3826402456042421, 'step': 4954}\n",
      "06/30/2020 16:48:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6946692715601452e-05, 'epoch': 1.383198437063913, 'step': 4956}\n",
      "06/30/2020 16:48:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6937389524606943e-05, 'epoch': 1.3837566285235836, 'step': 4958}\n",
      "06/30/2020 16:48:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.692808633361243e-05, 'epoch': 1.3843148199832542, 'step': 4960}\n",
      "06/30/2020 16:48:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.691878314261792e-05, 'epoch': 1.3848730114429249, 'step': 4962}\n",
      "06/30/2020 16:48:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6909479951623406e-05, 'epoch': 1.3854312029025957, 'step': 4964}\n",
      "06/30/2020 16:48:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6900176760628896e-05, 'epoch': 1.3859893943622663, 'step': 4966}\n",
      "06/30/2020 16:48:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6890873569634383e-05, 'epoch': 1.386547585821937, 'step': 4968}\n",
      "06/30/2020 16:48:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6881570378639877e-05, 'epoch': 1.3871057772816076, 'step': 4970}\n",
      "06/30/2020 16:48:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.687226718764536e-05, 'epoch': 1.3876639687412782, 'step': 4972}\n",
      "06/30/2020 16:48:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6862963996650854e-05, 'epoch': 1.3882221602009488, 'step': 4974}\n",
      "06/30/2020 16:48:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6853660805656337e-05, 'epoch': 1.3887803516606196, 'step': 4976}\n",
      "06/30/2020 16:48:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.684435761466183e-05, 'epoch': 1.3893385431202903, 'step': 4978}\n",
      "06/30/2020 16:48:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.683505442366732e-05, 'epoch': 1.3898967345799609, 'step': 4980}\n",
      "06/30/2020 16:48:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6825751232672808e-05, 'epoch': 1.3904549260396317, 'step': 4982}\n",
      "06/30/2020 16:48:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6816448041678298e-05, 'epoch': 1.3910131174993023, 'step': 4984}\n",
      "06/30/2020 16:48:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6807144850683785e-05, 'epoch': 1.391571308958973, 'step': 4986}\n",
      "06/30/2020 16:48:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6797841659689278e-05, 'epoch': 1.3921295004186436, 'step': 4988}\n",
      "06/30/2020 16:48:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.678853846869476e-05, 'epoch': 1.3926876918783142, 'step': 4990}\n",
      "06/30/2020 16:48:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6779235277700255e-05, 'epoch': 1.3932458833379848, 'step': 4992}\n",
      "06/30/2020 16:48:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6769932086705742e-05, 'epoch': 1.3938040747976557, 'step': 4994}\n",
      "06/30/2020 16:48:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6760628895711232e-05, 'epoch': 1.3943622662573263, 'step': 4996}\n",
      "06/30/2020 16:48:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.675132570471672e-05, 'epoch': 1.394920457716997, 'step': 4998}\n",
      "06/30/2020 16:48:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.674202251372221e-05, 'epoch': 1.3954786491766675, 'step': 5000}\n",
      "06/30/2020 16:48:20 - INFO - transformers.trainer -   Saving model checkpoint to ../../weights/gpt2/papers_milan/checkpoint-5000\n",
      "06/30/2020 16:48:20 - INFO - transformers.configuration_utils -   Configuration saved in ../../weights/gpt2/papers_milan/checkpoint-5000/config.json\n",
      "06/30/2020 16:48:21 - INFO - transformers.modeling_utils -   Model weights saved in ../../weights/gpt2/papers_milan/checkpoint-5000/pytorch_model.bin\n",
      "/home/camilojd/Environments/als-env/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "06/30/2020 16:48:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6732719322727696e-05, 'epoch': 1.3960368406363384, 'step': 5002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:48:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6723416131733186e-05, 'epoch': 1.396595032096009, 'step': 5004}\n",
      "06/30/2020 16:48:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6714112940738673e-05, 'epoch': 1.3971532235556796, 'step': 5006}\n",
      "06/30/2020 16:48:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6704809749744163e-05, 'epoch': 1.3977114150153502, 'step': 5008}\n",
      "06/30/2020 16:48:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.669550655874965e-05, 'epoch': 1.3982696064750209, 'step': 5010}\n",
      "06/30/2020 16:48:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6686203367755143e-05, 'epoch': 1.3988277979346915, 'step': 5012}\n",
      "06/30/2020 16:48:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6676900176760626e-05, 'epoch': 1.3993859893943623, 'step': 5014}\n",
      "06/30/2020 16:48:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.666759698576612e-05, 'epoch': 1.399944180854033, 'step': 5016}\n",
      "06/30/2020 16:48:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.665829379477161e-05, 'epoch': 1.4005023723137036, 'step': 5018}\n",
      "06/30/2020 16:48:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6648990603777097e-05, 'epoch': 1.4010605637733744, 'step': 5020}\n",
      "06/30/2020 16:48:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6639687412782587e-05, 'epoch': 1.401618755233045, 'step': 5022}\n",
      "06/30/2020 16:48:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6630384221788074e-05, 'epoch': 1.4021769466927156, 'step': 5024}\n",
      "06/30/2020 16:48:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6621081030793564e-05, 'epoch': 1.4027351381523863, 'step': 5026}\n",
      "06/30/2020 16:48:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.661177783979905e-05, 'epoch': 1.4032933296120569, 'step': 5028}\n",
      "06/30/2020 16:48:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6602474648804544e-05, 'epoch': 1.4038515210717275, 'step': 5030}\n",
      "06/30/2020 16:48:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6593171457810028e-05, 'epoch': 1.4044097125313983, 'step': 5032}\n",
      "06/30/2020 16:48:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.658386826681552e-05, 'epoch': 1.404967903991069, 'step': 5034}\n",
      "06/30/2020 16:48:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6574565075821008e-05, 'epoch': 1.4055260954507396, 'step': 5036}\n",
      "06/30/2020 16:48:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6565261884826498e-05, 'epoch': 1.4060842869104102, 'step': 5038}\n",
      "06/30/2020 16:48:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6555958693831985e-05, 'epoch': 1.406642478370081, 'step': 5040}\n",
      "06/30/2020 16:48:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6546655502837475e-05, 'epoch': 1.4072006698297517, 'step': 5042}\n",
      "06/30/2020 16:48:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6537352311842962e-05, 'epoch': 1.4077588612894223, 'step': 5044}\n",
      "06/30/2020 16:48:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6528049120848452e-05, 'epoch': 1.408317052749093, 'step': 5046}\n",
      "06/30/2020 16:48:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.651874592985394e-05, 'epoch': 1.4088752442087635, 'step': 5048}\n",
      "06/30/2020 16:48:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.650944273885943e-05, 'epoch': 1.4094334356684342, 'step': 5050}\n",
      "06/30/2020 16:48:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6500139547864922e-05, 'epoch': 1.409991627128105, 'step': 5052}\n",
      "06/30/2020 16:48:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.649083635687041e-05, 'epoch': 1.4105498185877756, 'step': 5054}\n",
      "06/30/2020 16:48:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.64815331658759e-05, 'epoch': 1.4111080100474462, 'step': 5056}\n",
      "06/30/2020 16:48:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6472229974881386e-05, 'epoch': 1.4116662015071169, 'step': 5058}\n",
      "06/30/2020 16:48:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6462926783886876e-05, 'epoch': 1.4122243929667877, 'step': 5060}\n",
      "06/30/2020 16:48:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6453623592892363e-05, 'epoch': 1.4127825844264583, 'step': 5062}\n",
      "06/30/2020 16:48:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6444320401897853e-05, 'epoch': 1.413340775886129, 'step': 5064}\n",
      "06/30/2020 16:48:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.643501721090334e-05, 'epoch': 1.4138989673457996, 'step': 5066}\n",
      "06/30/2020 16:48:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.642571401990883e-05, 'epoch': 1.4144571588054702, 'step': 5068}\n",
      "06/30/2020 16:48:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6416410828914317e-05, 'epoch': 1.415015350265141, 'step': 5070}\n",
      "06/30/2020 16:48:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.640710763791981e-05, 'epoch': 1.4155735417248116, 'step': 5072}\n",
      "06/30/2020 16:48:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6397804446925294e-05, 'epoch': 1.4161317331844823, 'step': 5074}\n",
      "06/30/2020 16:48:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6388501255930787e-05, 'epoch': 1.4166899246441529, 'step': 5076}\n",
      "06/30/2020 16:48:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.637919806493627e-05, 'epoch': 1.4172481161038237, 'step': 5078}\n",
      "06/30/2020 16:48:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6369894873941764e-05, 'epoch': 1.4178063075634944, 'step': 5080}\n",
      "06/30/2020 16:48:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.636059168294725e-05, 'epoch': 1.418364499023165, 'step': 5082}\n",
      "06/30/2020 16:48:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.635128849195274e-05, 'epoch': 1.4189226904828356, 'step': 5084}\n",
      "06/30/2020 16:48:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6341985300958228e-05, 'epoch': 1.4194808819425062, 'step': 5086}\n",
      "06/30/2020 16:48:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6332682109963718e-05, 'epoch': 1.4200390734021768, 'step': 5088}\n",
      "06/30/2020 16:48:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6323378918969212e-05, 'epoch': 1.4205972648618477, 'step': 5090}\n",
      "06/30/2020 16:48:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6314075727974695e-05, 'epoch': 1.4211554563215183, 'step': 5092}\n",
      "06/30/2020 16:48:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.630477253698019e-05, 'epoch': 1.421713647781189, 'step': 5094}\n",
      "06/30/2020 16:48:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6295469345985675e-05, 'epoch': 1.4222718392408595, 'step': 5096}\n",
      "06/30/2020 16:48:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6286166154991166e-05, 'epoch': 1.4228300307005304, 'step': 5098}\n",
      "06/30/2020 16:48:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6276862963996652e-05, 'epoch': 1.423388222160201, 'step': 5100}\n",
      "06/30/2020 16:48:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6267559773002143e-05, 'epoch': 1.4239464136198716, 'step': 5102}\n",
      "06/30/2020 16:48:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.625825658200763e-05, 'epoch': 1.4245046050795422, 'step': 5104}\n",
      "06/30/2020 16:48:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.624895339101312e-05, 'epoch': 1.4250627965392129, 'step': 5106}\n",
      "06/30/2020 16:48:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6239650200018606e-05, 'epoch': 1.4256209879988835, 'step': 5108}\n",
      "06/30/2020 16:48:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6230347009024096e-05, 'epoch': 1.4261791794585543, 'step': 5110}\n",
      "06/30/2020 16:48:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6221043818029583e-05, 'epoch': 1.426737370918225, 'step': 5112}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:48:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6211740627035077e-05, 'epoch': 1.4272955623778956, 'step': 5114}\n",
      "06/30/2020 16:48:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.620243743604056e-05, 'epoch': 1.4278537538375664, 'step': 5116}\n",
      "06/30/2020 16:48:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6193134245046054e-05, 'epoch': 1.428411945297237, 'step': 5118}\n",
      "06/30/2020 16:48:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6183831054051537e-05, 'epoch': 1.4289701367569076, 'step': 5120}\n",
      "06/30/2020 16:48:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.617452786305703e-05, 'epoch': 1.4295283282165783, 'step': 5122}\n",
      "06/30/2020 16:48:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6165224672062517e-05, 'epoch': 1.430086519676249, 'step': 5124}\n",
      "06/30/2020 16:48:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6155921481068007e-05, 'epoch': 1.4306447111359195, 'step': 5126}\n",
      "06/30/2020 16:48:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6146618290073498e-05, 'epoch': 1.4312029025955904, 'step': 5128}\n",
      "06/30/2020 16:48:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6137315099078984e-05, 'epoch': 1.431761094055261, 'step': 5130}\n",
      "06/30/2020 16:48:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6128011908084478e-05, 'epoch': 1.4323192855149316, 'step': 5132}\n",
      "06/30/2020 16:48:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.611870871708996e-05, 'epoch': 1.4328774769746022, 'step': 5134}\n",
      "06/30/2020 16:48:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6109405526095455e-05, 'epoch': 1.433435668434273, 'step': 5136}\n",
      "06/30/2020 16:48:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6100102335100938e-05, 'epoch': 1.4339938598939437, 'step': 5138}\n",
      "06/30/2020 16:48:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6090799144106432e-05, 'epoch': 1.4345520513536143, 'step': 5140}\n",
      "06/30/2020 16:48:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.608149595311192e-05, 'epoch': 1.435110242813285, 'step': 5142}\n",
      "06/30/2020 16:48:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.607219276211741e-05, 'epoch': 1.4356684342729555, 'step': 5144}\n",
      "06/30/2020 16:48:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6062889571122896e-05, 'epoch': 1.4362266257326262, 'step': 5146}\n",
      "06/30/2020 16:48:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6053586380128386e-05, 'epoch': 1.436784817192297, 'step': 5148}\n",
      "06/30/2020 16:48:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6044283189133872e-05, 'epoch': 1.4373430086519676, 'step': 5150}\n",
      "06/30/2020 16:48:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6034979998139363e-05, 'epoch': 1.4379012001116382, 'step': 5152}\n",
      "06/30/2020 16:48:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.602567680714485e-05, 'epoch': 1.438459391571309, 'step': 5154}\n",
      "06/30/2020 16:48:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6016373616150343e-05, 'epoch': 1.4390175830309797, 'step': 5156}\n",
      "06/30/2020 16:48:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6007070425155826e-05, 'epoch': 1.4395757744906503, 'step': 5158}\n",
      "06/30/2020 16:48:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.599776723416132e-05, 'epoch': 1.440133965950321, 'step': 5160}\n",
      "06/30/2020 16:48:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5988464043166803e-05, 'epoch': 1.4406921574099916, 'step': 5162}\n",
      "06/30/2020 16:48:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5979160852172297e-05, 'epoch': 1.4412503488696622, 'step': 5164}\n",
      "06/30/2020 16:48:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5969857661177787e-05, 'epoch': 1.441808540329333, 'step': 5166}\n",
      "06/30/2020 16:48:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5960554470183274e-05, 'epoch': 1.4423667317890037, 'step': 5168}\n",
      "06/30/2020 16:48:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5951251279188764e-05, 'epoch': 1.4429249232486743, 'step': 5170}\n",
      "06/30/2020 16:48:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.594194808819425e-05, 'epoch': 1.443483114708345, 'step': 5172}\n",
      "06/30/2020 16:48:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5932644897199744e-05, 'epoch': 1.4440413061680157, 'step': 5174}\n",
      "06/30/2020 16:48:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5923341706205228e-05, 'epoch': 1.4445994976276864, 'step': 5176}\n",
      "06/30/2020 16:48:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.591403851521072e-05, 'epoch': 1.445157689087357, 'step': 5178}\n",
      "06/30/2020 16:48:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5904735324216204e-05, 'epoch': 1.4457158805470276, 'step': 5180}\n",
      "06/30/2020 16:48:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5895432133221698e-05, 'epoch': 1.4462740720066982, 'step': 5182}\n",
      "06/30/2020 16:48:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5886128942227185e-05, 'epoch': 1.4468322634663688, 'step': 5184}\n",
      "06/30/2020 16:48:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5876825751232675e-05, 'epoch': 1.4473904549260397, 'step': 5186}\n",
      "06/30/2020 16:48:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5867522560238162e-05, 'epoch': 1.4479486463857103, 'step': 5188}\n",
      "06/30/2020 16:48:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5858219369243652e-05, 'epoch': 1.448506837845381, 'step': 5190}\n",
      "06/30/2020 16:48:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.584891617824914e-05, 'epoch': 1.4490650293050518, 'step': 5192}\n",
      "06/30/2020 16:48:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.583961298725463e-05, 'epoch': 1.4496232207647224, 'step': 5194}\n",
      "06/30/2020 16:48:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5830309796260116e-05, 'epoch': 1.450181412224393, 'step': 5196}\n",
      "06/30/2020 16:48:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.582100660526561e-05, 'epoch': 1.4507396036840636, 'step': 5198}\n",
      "06/30/2020 16:48:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.58117034142711e-05, 'epoch': 1.4512977951437342, 'step': 5200}\n",
      "06/30/2020 16:48:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5802400223276586e-05, 'epoch': 1.4518559866034049, 'step': 5202}\n",
      "06/30/2020 16:48:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5793097032282076e-05, 'epoch': 1.4524141780630757, 'step': 5204}\n",
      "06/30/2020 16:48:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5783793841287563e-05, 'epoch': 1.4529723695227463, 'step': 5206}\n",
      "06/30/2020 16:48:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5774490650293053e-05, 'epoch': 1.453530560982417, 'step': 5208}\n",
      "06/30/2020 16:48:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.576518745929854e-05, 'epoch': 1.4540887524420876, 'step': 5210}\n",
      "06/30/2020 16:48:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.575588426830403e-05, 'epoch': 1.4546469439017584, 'step': 5212}\n",
      "06/30/2020 16:48:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5746581077309517e-05, 'epoch': 1.455205135361429, 'step': 5214}\n",
      "06/30/2020 16:48:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.573727788631501e-05, 'epoch': 1.4557633268210997, 'step': 5216}\n",
      "06/30/2020 16:48:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5727974695320494e-05, 'epoch': 1.4563215182807703, 'step': 5218}\n",
      "06/30/2020 16:48:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5718671504325987e-05, 'epoch': 1.456879709740441, 'step': 5220}\n",
      "06/30/2020 16:48:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.570936831333147e-05, 'epoch': 1.4574379012001115, 'step': 5222}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:48:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5700065122336964e-05, 'epoch': 1.4579960926597824, 'step': 5224}\n",
      "06/30/2020 16:48:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.569076193134245e-05, 'epoch': 1.458554284119453, 'step': 5226}\n",
      "06/30/2020 16:48:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.568145874034794e-05, 'epoch': 1.4591124755791236, 'step': 5228}\n",
      "06/30/2020 16:48:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5672155549353428e-05, 'epoch': 1.4596706670387944, 'step': 5230}\n",
      "06/30/2020 16:48:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5662852358358918e-05, 'epoch': 1.460228858498465, 'step': 5232}\n",
      "06/30/2020 16:48:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5653549167364405e-05, 'epoch': 1.4607870499581357, 'step': 5234}\n",
      "06/30/2020 16:48:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5644245976369895e-05, 'epoch': 1.4613452414178063, 'step': 5236}\n",
      "06/30/2020 16:48:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.563494278537539e-05, 'epoch': 1.461903432877477, 'step': 5238}\n",
      "06/30/2020 16:48:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5625639594380872e-05, 'epoch': 1.4624616243371475, 'step': 5240}\n",
      "06/30/2020 16:48:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5616336403386365e-05, 'epoch': 1.4630198157968184, 'step': 5242}\n",
      "06/30/2020 16:48:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5607033212391852e-05, 'epoch': 1.463578007256489, 'step': 5244}\n",
      "06/30/2020 16:48:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5597730021397342e-05, 'epoch': 1.4641361987161596, 'step': 5246}\n",
      "06/30/2020 16:48:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.558842683040283e-05, 'epoch': 1.4646943901758303, 'step': 5248}\n",
      "06/30/2020 16:48:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.557912363940832e-05, 'epoch': 1.465252581635501, 'step': 5250}\n",
      "06/30/2020 16:48:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5569820448413806e-05, 'epoch': 1.4658107730951717, 'step': 5252}\n",
      "06/30/2020 16:48:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5560517257419296e-05, 'epoch': 1.4663689645548423, 'step': 5254}\n",
      "06/30/2020 16:48:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5551214066424783e-05, 'epoch': 1.466927156014513, 'step': 5256}\n",
      "06/30/2020 16:48:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5541910875430277e-05, 'epoch': 1.4674853474741836, 'step': 5258}\n",
      "06/30/2020 16:48:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.553260768443576e-05, 'epoch': 1.4680435389338542, 'step': 5260}\n",
      "06/30/2020 16:48:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5523304493441254e-05, 'epoch': 1.468601730393525, 'step': 5262}\n",
      "06/30/2020 16:48:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5514001302446737e-05, 'epoch': 1.4691599218531957, 'step': 5264}\n",
      "06/30/2020 16:48:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.550469811145223e-05, 'epoch': 1.4697181133128663, 'step': 5266}\n",
      "06/30/2020 16:48:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5495394920457717e-05, 'epoch': 1.470276304772537, 'step': 5268}\n",
      "06/30/2020 16:48:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5486091729463207e-05, 'epoch': 1.4708344962322077, 'step': 5270}\n",
      "06/30/2020 16:48:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5476788538468694e-05, 'epoch': 1.4713926876918784, 'step': 5272}\n",
      "06/30/2020 16:48:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5467485347474184e-05, 'epoch': 1.471950879151549, 'step': 5274}\n",
      "06/30/2020 16:48:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5458182156479678e-05, 'epoch': 1.4725090706112196, 'step': 5276}\n",
      "06/30/2020 16:48:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.544887896548516e-05, 'epoch': 1.4730672620708902, 'step': 5278}\n",
      "06/30/2020 16:48:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5439575774490655e-05, 'epoch': 1.4736254535305608, 'step': 5280}\n",
      "06/30/2020 16:48:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5430272583496138e-05, 'epoch': 1.4741836449902317, 'step': 5282}\n",
      "06/30/2020 16:48:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.542096939250163e-05, 'epoch': 1.4747418364499023, 'step': 5284}\n",
      "06/30/2020 16:48:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.541166620150712e-05, 'epoch': 1.475300027909573, 'step': 5286}\n",
      "06/30/2020 16:48:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.540236301051261e-05, 'epoch': 1.4758582193692438, 'step': 5288}\n",
      "06/30/2020 16:48:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5393059819518095e-05, 'epoch': 1.4764164108289144, 'step': 5290}\n",
      "06/30/2020 16:48:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5383756628523586e-05, 'epoch': 1.476974602288585, 'step': 5292}\n",
      "06/30/2020 16:48:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5374453437529072e-05, 'epoch': 1.4775327937482556, 'step': 5294}\n",
      "06/30/2020 16:48:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5365150246534562e-05, 'epoch': 1.4780909852079263, 'step': 5296}\n",
      "06/30/2020 16:48:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.535584705554005e-05, 'epoch': 1.4786491766675969, 'step': 5298}\n",
      "06/30/2020 16:48:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.534654386454554e-05, 'epoch': 1.4792073681272677, 'step': 5300}\n",
      "06/30/2020 16:48:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5337240673551026e-05, 'epoch': 1.4797655595869383, 'step': 5302}\n",
      "06/30/2020 16:48:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.532793748255652e-05, 'epoch': 1.480323751046609, 'step': 5304}\n",
      "06/30/2020 16:48:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5318634291562003e-05, 'epoch': 1.4808819425062796, 'step': 5306}\n",
      "06/30/2020 16:48:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5309331100567497e-05, 'epoch': 1.4814401339659504, 'step': 5308}\n",
      "06/30/2020 16:48:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5300027909572987e-05, 'epoch': 1.481998325425621, 'step': 5310}\n",
      "06/30/2020 16:48:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5290724718578474e-05, 'epoch': 1.4825565168852917, 'step': 5312}\n",
      "06/30/2020 16:48:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5281421527583964e-05, 'epoch': 1.4831147083449623, 'step': 5314}\n",
      "06/30/2020 16:48:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.527211833658945e-05, 'epoch': 1.483672899804633, 'step': 5316}\n",
      "06/30/2020 16:48:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5262815145594944e-05, 'epoch': 1.4842310912643035, 'step': 5318}\n",
      "06/30/2020 16:48:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5253511954600427e-05, 'epoch': 1.4847892827239744, 'step': 5320}\n",
      "06/30/2020 16:48:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.524420876360592e-05, 'epoch': 1.485347474183645, 'step': 5322}\n",
      "06/30/2020 16:48:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5234905572611404e-05, 'epoch': 1.4859056656433156, 'step': 5324}\n",
      "06/30/2020 16:48:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5225602381616898e-05, 'epoch': 1.4864638571029865, 'step': 5326}\n",
      "06/30/2020 16:48:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5216299190622385e-05, 'epoch': 1.487022048562657, 'step': 5328}\n",
      "06/30/2020 16:48:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5206995999627875e-05, 'epoch': 1.4875802400223277, 'step': 5330}\n",
      "06/30/2020 16:48:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.519769280863336e-05, 'epoch': 1.4881384314819983, 'step': 5332}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:48:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5188389617638852e-05, 'epoch': 1.488696622941669, 'step': 5334}\n",
      "06/30/2020 16:48:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.517908642664434e-05, 'epoch': 1.4892548144013396, 'step': 5336}\n",
      "06/30/2020 16:48:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.516978323564983e-05, 'epoch': 1.4898130058610104, 'step': 5338}\n",
      "06/30/2020 16:48:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5160480044655315e-05, 'epoch': 1.490371197320681, 'step': 5340}\n",
      "06/30/2020 16:48:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5151176853660806e-05, 'epoch': 1.4909293887803516, 'step': 5342}\n",
      "06/30/2020 16:48:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5141873662666292e-05, 'epoch': 1.4914875802400223, 'step': 5344}\n",
      "06/30/2020 16:48:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5132570471671786e-05, 'epoch': 1.492045771699693, 'step': 5346}\n",
      "06/30/2020 16:48:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5123267280677276e-05, 'epoch': 1.4926039631593637, 'step': 5348}\n",
      "06/30/2020 16:48:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5113964089682763e-05, 'epoch': 1.4931621546190343, 'step': 5350}\n",
      "06/30/2020 16:48:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5104660898688253e-05, 'epoch': 1.493720346078705, 'step': 5352}\n",
      "06/30/2020 16:48:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.509535770769374e-05, 'epoch': 1.4942785375383756, 'step': 5354}\n",
      "06/30/2020 16:48:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.508605451669923e-05, 'epoch': 1.4948367289980462, 'step': 5356}\n",
      "06/30/2020 16:48:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5076751325704717e-05, 'epoch': 1.495394920457717, 'step': 5358}\n",
      "06/30/2020 16:48:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.506744813471021e-05, 'epoch': 1.4959531119173877, 'step': 5360}\n",
      "06/30/2020 16:48:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5058144943715694e-05, 'epoch': 1.4965113033770583, 'step': 5362}\n",
      "06/30/2020 16:48:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5048841752721187e-05, 'epoch': 1.4970694948367291, 'step': 5364}\n",
      "06/30/2020 16:48:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.503953856172667e-05, 'epoch': 1.4976276862963998, 'step': 5366}\n",
      "06/30/2020 16:48:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5030235370732164e-05, 'epoch': 1.4981858777560704, 'step': 5368}\n",
      "06/30/2020 16:48:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.502093217973765e-05, 'epoch': 1.498744069215741, 'step': 5370}\n",
      "06/30/2020 16:48:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.501162898874314e-05, 'epoch': 1.4993022606754116, 'step': 5372}\n",
      "06/30/2020 16:48:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5002325797748628e-05, 'epoch': 1.4998604521350822, 'step': 5374}\n",
      "06/30/2020 16:48:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4993022606754118e-05, 'epoch': 1.5004186435947529, 'step': 5376}\n",
      "06/30/2020 16:48:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4983719415759608e-05, 'epoch': 1.5009768350544237, 'step': 5378}\n",
      "06/30/2020 16:48:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4974416224765095e-05, 'epoch': 1.5015350265140943, 'step': 5380}\n",
      "06/30/2020 16:48:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4965113033770585e-05, 'epoch': 1.5020932179737652, 'step': 5382}\n",
      "06/30/2020 16:48:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4955809842776072e-05, 'epoch': 1.5026514094334358, 'step': 5384}\n",
      "06/30/2020 16:48:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4946506651781562e-05, 'epoch': 1.5032096008931064, 'step': 5386}\n",
      "06/30/2020 16:48:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4937203460787052e-05, 'epoch': 1.503767792352777, 'step': 5388}\n",
      "06/30/2020 16:48:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.492790026979254e-05, 'epoch': 1.5043259838124476, 'step': 5390}\n",
      "06/30/2020 16:48:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.491859707879803e-05, 'epoch': 1.5048841752721183, 'step': 5392}\n",
      "06/30/2020 16:48:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4909293887803516e-05, 'epoch': 1.5054423667317889, 'step': 5394}\n",
      "06/30/2020 16:48:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4899990696809006e-05, 'epoch': 1.5060005581914597, 'step': 5396}\n",
      "06/30/2020 16:48:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4890687505814496e-05, 'epoch': 1.5065587496511303, 'step': 5398}\n",
      "06/30/2020 16:48:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4881384314819983e-05, 'epoch': 1.507116941110801, 'step': 5400}\n",
      "06/30/2020 16:48:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4872081123825473e-05, 'epoch': 1.5076751325704718, 'step': 5402}\n",
      "06/30/2020 16:48:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4862777932830963e-05, 'epoch': 1.5082333240301424, 'step': 5404}\n",
      "06/30/2020 16:48:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4853474741836453e-05, 'epoch': 1.508791515489813, 'step': 5406}\n",
      "06/30/2020 16:48:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.484417155084194e-05, 'epoch': 1.5093497069494837, 'step': 5408}\n",
      "06/30/2020 16:48:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.483486835984743e-05, 'epoch': 1.5099078984091543, 'step': 5410}\n",
      "06/30/2020 16:48:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4825565168852917e-05, 'epoch': 1.510466089868825, 'step': 5412}\n",
      "06/30/2020 16:48:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4816261977858407e-05, 'epoch': 1.5110242813284955, 'step': 5414}\n",
      "06/30/2020 16:48:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4806958786863897e-05, 'epoch': 1.5115824727881664, 'step': 5416}\n",
      "06/30/2020 16:48:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4797655595869384e-05, 'epoch': 1.512140664247837, 'step': 5418}\n",
      "06/30/2020 16:48:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4788352404874874e-05, 'epoch': 1.5126988557075078, 'step': 5420}\n",
      "06/30/2020 16:48:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.477904921388036e-05, 'epoch': 1.5132570471671785, 'step': 5422}\n",
      "06/30/2020 16:48:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.476974602288585e-05, 'epoch': 1.513815238626849, 'step': 5424}\n",
      "06/30/2020 16:48:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4760442831891338e-05, 'epoch': 1.5143734300865197, 'step': 5426}\n",
      "06/30/2020 16:48:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4751139640896828e-05, 'epoch': 1.5149316215461903, 'step': 5428}\n",
      "06/30/2020 16:48:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.474183644990232e-05, 'epoch': 1.515489813005861, 'step': 5430}\n",
      "06/30/2020 16:48:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4732533258907805e-05, 'epoch': 1.5160480044655316, 'step': 5432}\n",
      "06/30/2020 16:48:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4723230067913295e-05, 'epoch': 1.5166061959252022, 'step': 5434}\n",
      "06/30/2020 16:48:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4713926876918782e-05, 'epoch': 1.517164387384873, 'step': 5436}\n",
      "06/30/2020 16:48:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4704623685924272e-05, 'epoch': 1.5177225788445436, 'step': 5438}\n",
      "06/30/2020 16:48:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4695320494929762e-05, 'epoch': 1.5182807703042145, 'step': 5440}\n",
      "06/30/2020 16:48:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4686017303935253e-05, 'epoch': 1.518838961763885, 'step': 5442}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:48:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.467671411294074e-05, 'epoch': 1.5193971532235557, 'step': 5444}\n",
      "06/30/2020 16:48:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.466741092194623e-05, 'epoch': 1.5199553446832264, 'step': 5446}\n",
      "06/30/2020 16:48:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.465810773095172e-05, 'epoch': 1.520513536142897, 'step': 5448}\n",
      "06/30/2020 16:48:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4648804539957206e-05, 'epoch': 1.5210717276025676, 'step': 5450}\n",
      "06/30/2020 16:48:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4639501348962697e-05, 'epoch': 1.5216299190622382, 'step': 5452}\n",
      "06/30/2020 16:48:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4630198157968183e-05, 'epoch': 1.522188110521909, 'step': 5454}\n",
      "06/30/2020 16:48:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4620894966973673e-05, 'epoch': 1.5227463019815797, 'step': 5456}\n",
      "06/30/2020 16:48:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4611591775979164e-05, 'epoch': 1.5233044934412503, 'step': 5458}\n",
      "06/30/2020 16:48:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.460228858498465e-05, 'epoch': 1.5238626849009211, 'step': 5460}\n",
      "06/30/2020 16:48:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.459298539399014e-05, 'epoch': 1.5244208763605918, 'step': 5462}\n",
      "06/30/2020 16:48:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4583682202995627e-05, 'epoch': 1.5249790678202624, 'step': 5464}\n",
      "06/30/2020 16:48:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4574379012001117e-05, 'epoch': 1.525537259279933, 'step': 5466}\n",
      "06/30/2020 16:48:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4565075821006604e-05, 'epoch': 1.5260954507396036, 'step': 5468}\n",
      "06/30/2020 16:48:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4555772630012094e-05, 'epoch': 1.5266536421992742, 'step': 5470}\n",
      "06/30/2020 16:48:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4546469439017585e-05, 'epoch': 1.5272118336589449, 'step': 5472}\n",
      "06/30/2020 16:48:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.453716624802307e-05, 'epoch': 1.5277700251186157, 'step': 5474}\n",
      "06/30/2020 16:48:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4527863057028565e-05, 'epoch': 1.5283282165782863, 'step': 5476}\n",
      "06/30/2020 16:48:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.451855986603405e-05, 'epoch': 1.5288864080379572, 'step': 5478}\n",
      "06/30/2020 16:48:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4509256675039542e-05, 'epoch': 1.5294445994976278, 'step': 5480}\n",
      "06/30/2020 16:48:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.449995348404503e-05, 'epoch': 1.5300027909572984, 'step': 5482}\n",
      "06/30/2020 16:48:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.449065029305052e-05, 'epoch': 1.530560982416969, 'step': 5484}\n",
      "06/30/2020 16:48:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4481347102056006e-05, 'epoch': 1.5311191738766396, 'step': 5486}\n",
      "06/30/2020 16:48:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4472043911061496e-05, 'epoch': 1.5316773653363103, 'step': 5488}\n",
      "06/30/2020 16:48:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4462740720066986e-05, 'epoch': 1.532235556795981, 'step': 5490}\n",
      "06/30/2020 16:48:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4453437529072473e-05, 'epoch': 1.5327937482556517, 'step': 5492}\n",
      "06/30/2020 16:48:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4444134338077963e-05, 'epoch': 1.5333519397153224, 'step': 5494}\n",
      "06/30/2020 16:48:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.443483114708345e-05, 'epoch': 1.533910131174993, 'step': 5496}\n",
      "06/30/2020 16:48:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.442552795608894e-05, 'epoch': 1.5344683226346638, 'step': 5498}\n",
      "06/30/2020 16:48:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4416224765094426e-05, 'epoch': 1.5350265140943344, 'step': 5500}\n",
      "06/30/2020 16:48:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4406921574099917e-05, 'epoch': 1.535584705554005, 'step': 5502}\n",
      "06/30/2020 16:48:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4397618383105407e-05, 'epoch': 1.5361428970136757, 'step': 5504}\n",
      "06/30/2020 16:48:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4388315192110894e-05, 'epoch': 1.5367010884733463, 'step': 5506}\n",
      "06/30/2020 16:48:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4379012001116384e-05, 'epoch': 1.537259279933017, 'step': 5508}\n",
      "06/30/2020 16:48:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.436970881012187e-05, 'epoch': 1.5378174713926875, 'step': 5510}\n",
      "06/30/2020 16:48:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.436040561912736e-05, 'epoch': 1.5383756628523584, 'step': 5512}\n",
      "06/30/2020 16:48:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.435110242813285e-05, 'epoch': 1.538933854312029, 'step': 5514}\n",
      "06/30/2020 16:48:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.434179923713834e-05, 'epoch': 1.5394920457716998, 'step': 5516}\n",
      "06/30/2020 16:48:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.433249604614383e-05, 'epoch': 1.5400502372313705, 'step': 5518}\n",
      "06/30/2020 16:48:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4323192855149318e-05, 'epoch': 1.540608428691041, 'step': 5520}\n",
      "06/30/2020 16:49:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4313889664154808e-05, 'epoch': 1.5411666201507117, 'step': 5522}\n",
      "06/30/2020 16:49:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4304586473160295e-05, 'epoch': 1.5417248116103823, 'step': 5524}\n",
      "06/30/2020 16:49:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4295283282165785e-05, 'epoch': 1.542283003070053, 'step': 5526}\n",
      "06/30/2020 16:49:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4285980091171272e-05, 'epoch': 1.5428411945297236, 'step': 5528}\n",
      "06/30/2020 16:49:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4276676900176762e-05, 'epoch': 1.5433993859893944, 'step': 5530}\n",
      "06/30/2020 16:49:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4267373709182252e-05, 'epoch': 1.543957577449065, 'step': 5532}\n",
      "06/30/2020 16:49:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.425807051818774e-05, 'epoch': 1.5445157689087357, 'step': 5534}\n",
      "06/30/2020 16:49:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.424876732719323e-05, 'epoch': 1.5450739603684065, 'step': 5536}\n",
      "06/30/2020 16:49:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4239464136198716e-05, 'epoch': 1.5456321518280771, 'step': 5538}\n",
      "06/30/2020 16:49:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4230160945204206e-05, 'epoch': 1.5461903432877477, 'step': 5540}\n",
      "06/30/2020 16:49:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4220857754209693e-05, 'epoch': 1.5467485347474184, 'step': 5542}\n",
      "06/30/2020 16:49:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4211554563215183e-05, 'epoch': 1.547306726207089, 'step': 5544}\n",
      "06/30/2020 16:49:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4202251372220673e-05, 'epoch': 1.5478649176667596, 'step': 5546}\n",
      "06/30/2020 16:49:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.419294818122616e-05, 'epoch': 1.5484231091264302, 'step': 5548}\n",
      "06/30/2020 16:49:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4183644990231653e-05, 'epoch': 1.548981300586101, 'step': 5550}\n",
      "06/30/2020 16:49:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.417434179923714e-05, 'epoch': 1.5495394920457717, 'step': 5552}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:49:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.416503860824263e-05, 'epoch': 1.5500976835054425, 'step': 5554}\n",
      "06/30/2020 16:49:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4155735417248117e-05, 'epoch': 1.5506558749651131, 'step': 5556}\n",
      "06/30/2020 16:49:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4146432226253607e-05, 'epoch': 1.5512140664247838, 'step': 5558}\n",
      "06/30/2020 16:49:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4137129035259097e-05, 'epoch': 1.5517722578844544, 'step': 5560}\n",
      "06/30/2020 16:49:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4127825844264584e-05, 'epoch': 1.552330449344125, 'step': 5562}\n",
      "06/30/2020 16:49:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4118522653270074e-05, 'epoch': 1.5528886408037956, 'step': 5564}\n",
      "06/30/2020 16:49:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.410921946227556e-05, 'epoch': 1.5534468322634662, 'step': 5566}\n",
      "06/30/2020 16:49:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.409991627128105e-05, 'epoch': 1.554005023723137, 'step': 5568}\n",
      "06/30/2020 16:49:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4090613080286538e-05, 'epoch': 1.5545632151828077, 'step': 5570}\n",
      "06/30/2020 16:49:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4081309889292028e-05, 'epoch': 1.5551214066424783, 'step': 5572}\n",
      "06/30/2020 16:49:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4072006698297518e-05, 'epoch': 1.5556795981021492, 'step': 5574}\n",
      "06/30/2020 16:49:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4062703507303005e-05, 'epoch': 1.5562377895618198, 'step': 5576}\n",
      "06/30/2020 16:49:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4053400316308495e-05, 'epoch': 1.5567959810214904, 'step': 5578}\n",
      "06/30/2020 16:49:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4044097125313982e-05, 'epoch': 1.557354172481161, 'step': 5580}\n",
      "06/30/2020 16:49:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4034793934319472e-05, 'epoch': 1.5579123639408317, 'step': 5582}\n",
      "06/30/2020 16:49:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.402549074332496e-05, 'epoch': 1.5584705554005023, 'step': 5584}\n",
      "06/30/2020 16:49:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.401618755233045e-05, 'epoch': 1.559028746860173, 'step': 5586}\n",
      "06/30/2020 16:49:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.400688436133594e-05, 'epoch': 1.5595869383198437, 'step': 5588}\n",
      "06/30/2020 16:49:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.399758117034143e-05, 'epoch': 1.5601451297795144, 'step': 5590}\n",
      "06/30/2020 16:49:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.398827797934692e-05, 'epoch': 1.5607033212391852, 'step': 5592}\n",
      "06/30/2020 16:49:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3978974788352406e-05, 'epoch': 1.5612615126988558, 'step': 5594}\n",
      "06/30/2020 16:49:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3969671597357896e-05, 'epoch': 1.5618197041585264, 'step': 5596}\n",
      "06/30/2020 16:49:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3960368406363383e-05, 'epoch': 1.562377895618197, 'step': 5598}\n",
      "06/30/2020 16:49:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3951065215368873e-05, 'epoch': 1.5629360870778677, 'step': 5600}\n",
      "06/30/2020 16:49:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.394176202437436e-05, 'epoch': 1.5634942785375383, 'step': 5602}\n",
      "06/30/2020 16:49:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.393245883337985e-05, 'epoch': 1.564052469997209, 'step': 5604}\n",
      "06/30/2020 16:49:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.392315564238534e-05, 'epoch': 1.5646106614568795, 'step': 5606}\n",
      "06/30/2020 16:49:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3913852451390827e-05, 'epoch': 1.5651688529165504, 'step': 5608}\n",
      "06/30/2020 16:49:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3904549260396317e-05, 'epoch': 1.565727044376221, 'step': 5610}\n",
      "06/30/2020 16:49:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3895246069401804e-05, 'epoch': 1.5662852358358919, 'step': 5612}\n",
      "06/30/2020 16:49:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3885942878407294e-05, 'epoch': 1.5668434272955625, 'step': 5614}\n",
      "06/30/2020 16:49:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3876639687412784e-05, 'epoch': 1.567401618755233, 'step': 5616}\n",
      "06/30/2020 16:49:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.386733649641827e-05, 'epoch': 1.5679598102149037, 'step': 5618}\n",
      "06/30/2020 16:49:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.385803330542376e-05, 'epoch': 1.5685180016745743, 'step': 5620}\n",
      "06/30/2020 16:49:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3848730114429248e-05, 'epoch': 1.569076193134245, 'step': 5622}\n",
      "06/30/2020 16:49:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.383942692343474e-05, 'epoch': 1.5696343845939156, 'step': 5624}\n",
      "06/30/2020 16:49:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.383012373244023e-05, 'epoch': 1.5701925760535864, 'step': 5626}\n",
      "06/30/2020 16:49:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.382082054144572e-05, 'epoch': 1.570750767513257, 'step': 5628}\n",
      "06/30/2020 16:49:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3811517350451205e-05, 'epoch': 1.5713089589729277, 'step': 5630}\n",
      "06/30/2020 16:49:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3802214159456696e-05, 'epoch': 1.5718671504325985, 'step': 5632}\n",
      "06/30/2020 16:49:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3792910968462186e-05, 'epoch': 1.5724253418922691, 'step': 5634}\n",
      "06/30/2020 16:49:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3783607777467672e-05, 'epoch': 1.5729835333519397, 'step': 5636}\n",
      "06/30/2020 16:49:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3774304586473163e-05, 'epoch': 1.5735417248116104, 'step': 5638}\n",
      "06/30/2020 16:49:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.376500139547865e-05, 'epoch': 1.574099916271281, 'step': 5640}\n",
      "06/30/2020 16:49:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.375569820448414e-05, 'epoch': 1.5746581077309516, 'step': 5642}\n",
      "06/30/2020 16:49:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3746395013489626e-05, 'epoch': 1.5752162991906222, 'step': 5644}\n",
      "06/30/2020 16:49:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3737091822495116e-05, 'epoch': 1.575774490650293, 'step': 5646}\n",
      "06/30/2020 16:49:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3727788631500607e-05, 'epoch': 1.5763326821099637, 'step': 5648}\n",
      "06/30/2020 16:49:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3718485440506093e-05, 'epoch': 1.5768908735696345, 'step': 5650}\n",
      "06/30/2020 16:49:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3709182249511584e-05, 'epoch': 1.5774490650293052, 'step': 5652}\n",
      "06/30/2020 16:49:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.369987905851707e-05, 'epoch': 1.5780072564889758, 'step': 5654}\n",
      "06/30/2020 16:49:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.369057586752256e-05, 'epoch': 1.5785654479486464, 'step': 5656}\n",
      "06/30/2020 16:49:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.368127267652805e-05, 'epoch': 1.579123639408317, 'step': 5658}\n",
      "06/30/2020 16:49:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3671969485533537e-05, 'epoch': 1.5796818308679876, 'step': 5660}\n",
      "06/30/2020 16:49:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3662666294539028e-05, 'epoch': 1.5802400223276583, 'step': 5662}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:49:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3653363103544518e-05, 'epoch': 1.580798213787329, 'step': 5664}\n",
      "06/30/2020 16:49:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3644059912550008e-05, 'epoch': 1.5813564052469997, 'step': 5666}\n",
      "06/30/2020 16:49:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3634756721555495e-05, 'epoch': 1.5819145967066703, 'step': 5668}\n",
      "06/30/2020 16:49:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3625453530560985e-05, 'epoch': 1.5824727881663412, 'step': 5670}\n",
      "06/30/2020 16:49:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.361615033956647e-05, 'epoch': 1.5830309796260118, 'step': 5672}\n",
      "06/30/2020 16:49:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3606847148571962e-05, 'epoch': 1.5835891710856824, 'step': 5674}\n",
      "06/30/2020 16:49:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3597543957577452e-05, 'epoch': 1.584147362545353, 'step': 5676}\n",
      "06/30/2020 16:49:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.358824076658294e-05, 'epoch': 1.5847055540050237, 'step': 5678}\n",
      "06/30/2020 16:49:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.357893757558843e-05, 'epoch': 1.5852637454646943, 'step': 5680}\n",
      "06/30/2020 16:49:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3569634384593916e-05, 'epoch': 1.585821936924365, 'step': 5682}\n",
      "06/30/2020 16:49:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3560331193599406e-05, 'epoch': 1.5863801283840357, 'step': 5684}\n",
      "06/30/2020 16:49:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3551028002604893e-05, 'epoch': 1.5869383198437064, 'step': 5686}\n",
      "06/30/2020 16:49:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3541724811610383e-05, 'epoch': 1.5874965113033772, 'step': 5688}\n",
      "06/30/2020 16:49:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3532421620615873e-05, 'epoch': 1.5880547027630478, 'step': 5690}\n",
      "06/30/2020 16:49:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.352311842962136e-05, 'epoch': 1.5886128942227185, 'step': 5692}\n",
      "06/30/2020 16:49:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.351381523862685e-05, 'epoch': 1.589171085682389, 'step': 5694}\n",
      "06/30/2020 16:49:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3504512047632337e-05, 'epoch': 1.5897292771420597, 'step': 5696}\n",
      "06/30/2020 16:49:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.349520885663783e-05, 'epoch': 1.5902874686017303, 'step': 5698}\n",
      "06/30/2020 16:49:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3485905665643317e-05, 'epoch': 1.590845660061401, 'step': 5700}\n",
      "06/30/2020 16:49:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3476602474648807e-05, 'epoch': 1.5914038515210718, 'step': 5702}\n",
      "06/30/2020 16:49:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3467299283654294e-05, 'epoch': 1.5919620429807424, 'step': 5704}\n",
      "06/30/2020 16:49:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3457996092659784e-05, 'epoch': 1.592520234440413, 'step': 5706}\n",
      "06/30/2020 16:49:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3448692901665274e-05, 'epoch': 1.5930784259000839, 'step': 5708}\n",
      "06/30/2020 16:49:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.343938971067076e-05, 'epoch': 1.5936366173597545, 'step': 5710}\n",
      "06/30/2020 16:49:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.343008651967625e-05, 'epoch': 1.594194808819425, 'step': 5712}\n",
      "06/30/2020 16:49:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3420783328681738e-05, 'epoch': 1.5947530002790957, 'step': 5714}\n",
      "06/30/2020 16:49:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3411480137687228e-05, 'epoch': 1.5953111917387663, 'step': 5716}\n",
      "06/30/2020 16:49:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3402176946692718e-05, 'epoch': 1.595869383198437, 'step': 5718}\n",
      "06/30/2020 16:49:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3392873755698205e-05, 'epoch': 1.5964275746581076, 'step': 5720}\n",
      "06/30/2020 16:49:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3383570564703695e-05, 'epoch': 1.5969857661177784, 'step': 5722}\n",
      "06/30/2020 16:49:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3374267373709182e-05, 'epoch': 1.597543957577449, 'step': 5724}\n",
      "06/30/2020 16:49:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3364964182714672e-05, 'epoch': 1.59810214903712, 'step': 5726}\n",
      "06/30/2020 16:49:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.335566099172016e-05, 'epoch': 1.5986603404967905, 'step': 5728}\n",
      "06/30/2020 16:49:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.334635780072565e-05, 'epoch': 1.5992185319564611, 'step': 5730}\n",
      "06/30/2020 16:49:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.333705460973114e-05, 'epoch': 1.5997767234161318, 'step': 5732}\n",
      "06/30/2020 16:49:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3327751418736626e-05, 'epoch': 1.6003349148758024, 'step': 5734}\n",
      "06/30/2020 16:49:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.331844822774212e-05, 'epoch': 1.600893106335473, 'step': 5736}\n",
      "06/30/2020 16:49:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3309145036747606e-05, 'epoch': 1.6014512977951436, 'step': 5738}\n",
      "06/30/2020 16:49:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3299841845753096e-05, 'epoch': 1.6020094892548145, 'step': 5740}\n",
      "06/30/2020 16:49:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3290538654758583e-05, 'epoch': 1.602567680714485, 'step': 5742}\n",
      "06/30/2020 16:49:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3281235463764073e-05, 'epoch': 1.6031258721741557, 'step': 5744}\n",
      "06/30/2020 16:49:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.327193227276956e-05, 'epoch': 1.6036840636338265, 'step': 5746}\n",
      "06/30/2020 16:49:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.326262908177505e-05, 'epoch': 1.6042422550934972, 'step': 5748}\n",
      "06/30/2020 16:49:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.325332589078054e-05, 'epoch': 1.6048004465531678, 'step': 5750}\n",
      "06/30/2020 16:49:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3244022699786027e-05, 'epoch': 1.6053586380128384, 'step': 5752}\n",
      "06/30/2020 16:49:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3234719508791517e-05, 'epoch': 1.605916829472509, 'step': 5754}\n",
      "06/30/2020 16:49:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3225416317797004e-05, 'epoch': 1.6064750209321796, 'step': 5756}\n",
      "06/30/2020 16:49:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3216113126802494e-05, 'epoch': 1.6070332123918503, 'step': 5758}\n",
      "06/30/2020 16:49:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3206809935807984e-05, 'epoch': 1.607591403851521, 'step': 5760}\n",
      "06/30/2020 16:49:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.319750674481347e-05, 'epoch': 1.6081495953111917, 'step': 5762}\n",
      "06/30/2020 16:49:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.318820355381896e-05, 'epoch': 1.6087077867708626, 'step': 5764}\n",
      "06/30/2020 16:49:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3178900362824448e-05, 'epoch': 1.6092659782305332, 'step': 5766}\n",
      "06/30/2020 16:49:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3169597171829938e-05, 'epoch': 1.6098241696902038, 'step': 5768}\n",
      "06/30/2020 16:49:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3160293980835425e-05, 'epoch': 1.6103823611498744, 'step': 5770}\n",
      "06/30/2020 16:49:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.315099078984092e-05, 'epoch': 1.610940552609545, 'step': 5772}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:49:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3141687598846405e-05, 'epoch': 1.6114987440692157, 'step': 5774}\n",
      "06/30/2020 16:49:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3132384407851895e-05, 'epoch': 1.6120569355288863, 'step': 5776}\n",
      "06/30/2020 16:49:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3123081216857386e-05, 'epoch': 1.612615126988557, 'step': 5778}\n",
      "06/30/2020 16:49:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3113778025862872e-05, 'epoch': 1.6131733184482278, 'step': 5780}\n",
      "06/30/2020 16:49:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3104474834868363e-05, 'epoch': 1.6137315099078984, 'step': 5782}\n",
      "06/30/2020 16:49:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.309517164387385e-05, 'epoch': 1.6142897013675692, 'step': 5784}\n",
      "06/30/2020 16:49:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.308586845287934e-05, 'epoch': 1.6148478928272398, 'step': 5786}\n",
      "06/30/2020 16:49:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3076565261884826e-05, 'epoch': 1.6154060842869105, 'step': 5788}\n",
      "06/30/2020 16:49:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3067262070890316e-05, 'epoch': 1.615964275746581, 'step': 5790}\n",
      "06/30/2020 16:49:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3057958879895807e-05, 'epoch': 1.6165224672062517, 'step': 5792}\n",
      "06/30/2020 16:49:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3048655688901293e-05, 'epoch': 1.6170806586659223, 'step': 5794}\n",
      "06/30/2020 16:49:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3039352497906783e-05, 'epoch': 1.617638850125593, 'step': 5796}\n",
      "06/30/2020 16:49:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.303004930691227e-05, 'epoch': 1.6181970415852638, 'step': 5798}\n",
      "06/30/2020 16:49:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.302074611591776e-05, 'epoch': 1.6187552330449344, 'step': 5800}\n",
      "06/30/2020 16:49:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3011442924923247e-05, 'epoch': 1.619313424504605, 'step': 5802}\n",
      "06/30/2020 16:49:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3002139733928737e-05, 'epoch': 1.6198716159642759, 'step': 5804}\n",
      "06/30/2020 16:49:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2992836542934227e-05, 'epoch': 1.6204298074239465, 'step': 5806}\n",
      "06/30/2020 16:49:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2983533351939718e-05, 'epoch': 1.620987998883617, 'step': 5808}\n",
      "06/30/2020 16:49:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2974230160945208e-05, 'epoch': 1.6215461903432877, 'step': 5810}\n",
      "06/30/2020 16:49:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2964926969950695e-05, 'epoch': 1.6221043818029584, 'step': 5812}\n",
      "06/30/2020 16:49:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2955623778956185e-05, 'epoch': 1.622662573262629, 'step': 5814}\n",
      "06/30/2020 16:49:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.294632058796167e-05, 'epoch': 1.6232207647222996, 'step': 5816}\n",
      "06/30/2020 16:49:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.293701739696716e-05, 'epoch': 1.6237789561819704, 'step': 5818}\n",
      "06/30/2020 16:49:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2927714205972652e-05, 'epoch': 1.624337147641641, 'step': 5820}\n",
      "06/30/2020 16:49:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.291841101497814e-05, 'epoch': 1.624895339101312, 'step': 5822}\n",
      "06/30/2020 16:49:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.290910782398363e-05, 'epoch': 1.6254535305609825, 'step': 5824}\n",
      "06/30/2020 16:49:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2899804632989115e-05, 'epoch': 1.6260117220206531, 'step': 5826}\n",
      "06/30/2020 16:49:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2890501441994606e-05, 'epoch': 1.6265699134803238, 'step': 5828}\n",
      "06/30/2020 16:49:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2881198251000092e-05, 'epoch': 1.6271281049399944, 'step': 5830}\n",
      "06/30/2020 16:49:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2871895060005583e-05, 'epoch': 1.627686296399665, 'step': 5832}\n",
      "06/30/2020 16:49:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2862591869011073e-05, 'epoch': 1.6282444878593356, 'step': 5834}\n",
      "06/30/2020 16:49:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.285328867801656e-05, 'epoch': 1.6288026793190065, 'step': 5836}\n",
      "06/30/2020 16:49:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.284398548702205e-05, 'epoch': 1.629360870778677, 'step': 5838}\n",
      "06/30/2020 16:49:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2834682296027536e-05, 'epoch': 1.6299190622383477, 'step': 5840}\n",
      "06/30/2020 16:49:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2825379105033027e-05, 'epoch': 1.6304772536980185, 'step': 5842}\n",
      "06/30/2020 16:49:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2816075914038513e-05, 'epoch': 1.6310354451576892, 'step': 5844}\n",
      "06/30/2020 16:49:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2806772723044007e-05, 'epoch': 1.6315936366173598, 'step': 5846}\n",
      "06/30/2020 16:49:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2797469532049494e-05, 'epoch': 1.6321518280770304, 'step': 5848}\n",
      "06/30/2020 16:49:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2788166341054984e-05, 'epoch': 1.632710019536701, 'step': 5850}\n",
      "06/30/2020 16:49:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2778863150060474e-05, 'epoch': 1.6332682109963716, 'step': 5852}\n",
      "06/30/2020 16:49:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.276955995906596e-05, 'epoch': 1.6338264024560423, 'step': 5854}\n",
      "06/30/2020 16:49:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.276025676807145e-05, 'epoch': 1.6343845939157131, 'step': 5856}\n",
      "06/30/2020 16:49:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2750953577076938e-05, 'epoch': 1.6349427853753837, 'step': 5858}\n",
      "06/30/2020 16:49:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2741650386082428e-05, 'epoch': 1.6355009768350546, 'step': 5860}\n",
      "06/30/2020 16:49:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2732347195087918e-05, 'epoch': 1.6360591682947252, 'step': 5862}\n",
      "06/30/2020 16:49:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2723044004093405e-05, 'epoch': 1.6366173597543958, 'step': 5864}\n",
      "06/30/2020 16:49:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2713740813098895e-05, 'epoch': 1.6371755512140664, 'step': 5866}\n",
      "06/30/2020 16:49:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2704437622104382e-05, 'epoch': 1.637733742673737, 'step': 5868}\n",
      "06/30/2020 16:49:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2695134431109872e-05, 'epoch': 1.6382919341334077, 'step': 5870}\n",
      "06/30/2020 16:49:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.268583124011536e-05, 'epoch': 1.6388501255930783, 'step': 5872}\n",
      "06/30/2020 16:49:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.267652804912085e-05, 'epoch': 1.6394083170527491, 'step': 5874}\n",
      "06/30/2020 16:49:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.266722485812634e-05, 'epoch': 1.6399665085124198, 'step': 5876}\n",
      "06/30/2020 16:49:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2657921667131826e-05, 'epoch': 1.6405246999720904, 'step': 5878}\n",
      "06/30/2020 16:49:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2648618476137316e-05, 'epoch': 1.6410828914317612, 'step': 5880}\n",
      "06/30/2020 16:49:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2639315285142806e-05, 'epoch': 1.6416410828914318, 'step': 5882}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:49:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2630012094148296e-05, 'epoch': 1.6421992743511025, 'step': 5884}\n",
      "06/30/2020 16:49:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2620708903153783e-05, 'epoch': 1.642757465810773, 'step': 5886}\n",
      "06/30/2020 16:49:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2611405712159273e-05, 'epoch': 1.6433156572704437, 'step': 5888}\n",
      "06/30/2020 16:49:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.260210252116476e-05, 'epoch': 1.6438738487301143, 'step': 5890}\n",
      "06/30/2020 16:49:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.259279933017025e-05, 'epoch': 1.644432040189785, 'step': 5892}\n",
      "06/30/2020 16:49:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.258349613917574e-05, 'epoch': 1.6449902316494558, 'step': 5894}\n",
      "06/30/2020 16:49:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2574192948181227e-05, 'epoch': 1.6455484231091264, 'step': 5896}\n",
      "06/30/2020 16:49:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2564889757186717e-05, 'epoch': 1.6461066145687973, 'step': 5898}\n",
      "06/30/2020 16:49:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2555586566192204e-05, 'epoch': 1.6466648060284679, 'step': 5900}\n",
      "06/30/2020 16:49:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2546283375197694e-05, 'epoch': 1.6472229974881385, 'step': 5902}\n",
      "06/30/2020 16:49:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.253698018420318e-05, 'epoch': 1.6477811889478091, 'step': 5904}\n",
      "06/30/2020 16:49:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.252767699320867e-05, 'epoch': 1.6483393804074797, 'step': 5906}\n",
      "06/30/2020 16:49:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.251837380221416e-05, 'epoch': 1.6488975718671504, 'step': 5908}\n",
      "06/30/2020 16:49:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2509070611219648e-05, 'epoch': 1.649455763326821, 'step': 5910}\n",
      "06/30/2020 16:49:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2499767420225138e-05, 'epoch': 1.6500139547864918, 'step': 5912}\n",
      "06/30/2020 16:49:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2490464229230625e-05, 'epoch': 1.6505721462461624, 'step': 5914}\n",
      "06/30/2020 16:49:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2481161038236115e-05, 'epoch': 1.651130337705833, 'step': 5916}\n",
      "06/30/2020 16:49:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2471857847241605e-05, 'epoch': 1.651688529165504, 'step': 5918}\n",
      "06/30/2020 16:49:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2462554656247095e-05, 'epoch': 1.6522467206251745, 'step': 5920}\n",
      "06/30/2020 16:49:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2453251465252585e-05, 'epoch': 1.6528049120848451, 'step': 5922}\n",
      "06/30/2020 16:49:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2443948274258072e-05, 'epoch': 1.6533631035445158, 'step': 5924}\n",
      "06/30/2020 16:49:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2434645083263562e-05, 'epoch': 1.6539212950041864, 'step': 5926}\n",
      "06/30/2020 16:49:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.242534189226905e-05, 'epoch': 1.654479486463857, 'step': 5928}\n",
      "06/30/2020 16:49:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.241603870127454e-05, 'epoch': 1.6550376779235276, 'step': 5930}\n",
      "06/30/2020 16:49:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2406735510280026e-05, 'epoch': 1.6555958693831985, 'step': 5932}\n",
      "06/30/2020 16:49:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2397432319285516e-05, 'epoch': 1.656154060842869, 'step': 5934}\n",
      "06/30/2020 16:49:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2388129128291006e-05, 'epoch': 1.65671225230254, 'step': 5936}\n",
      "06/30/2020 16:49:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2378825937296493e-05, 'epoch': 1.6572704437622106, 'step': 5938}\n",
      "06/30/2020 16:49:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2369522746301983e-05, 'epoch': 1.6578286352218812, 'step': 5940}\n",
      "06/30/2020 16:49:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.236021955530747e-05, 'epoch': 1.6583868266815518, 'step': 5942}\n",
      "06/30/2020 16:49:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.235091636431296e-05, 'epoch': 1.6589450181412224, 'step': 5944}\n",
      "06/30/2020 16:49:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2341613173318447e-05, 'epoch': 1.659503209600893, 'step': 5946}\n",
      "06/30/2020 16:49:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2332309982323937e-05, 'epoch': 1.6600614010605637, 'step': 5948}\n",
      "06/30/2020 16:49:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2323006791329427e-05, 'epoch': 1.6606195925202343, 'step': 5950}\n",
      "06/30/2020 16:49:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2313703600334914e-05, 'epoch': 1.6611777839799051, 'step': 5952}\n",
      "06/30/2020 16:49:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2304400409340404e-05, 'epoch': 1.6617359754395757, 'step': 5954}\n",
      "06/30/2020 16:49:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2295097218345894e-05, 'epoch': 1.6622941668992466, 'step': 5956}\n",
      "06/30/2020 16:49:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2285794027351385e-05, 'epoch': 1.6628523583589172, 'step': 5958}\n",
      "06/30/2020 16:49:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.227649083635687e-05, 'epoch': 1.6634105498185878, 'step': 5960}\n",
      "06/30/2020 16:49:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.226718764536236e-05, 'epoch': 1.6639687412782584, 'step': 5962}\n",
      "06/30/2020 16:49:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2257884454367848e-05, 'epoch': 1.664526932737929, 'step': 5964}\n",
      "06/30/2020 16:49:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.224858126337334e-05, 'epoch': 1.6650851241975997, 'step': 5966}\n",
      "06/30/2020 16:49:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.223927807237883e-05, 'epoch': 1.6656433156572703, 'step': 5968}\n",
      "06/30/2020 16:49:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2229974881384315e-05, 'epoch': 1.6662015071169411, 'step': 5970}\n",
      "06/30/2020 16:49:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2220671690389806e-05, 'epoch': 1.6667596985766118, 'step': 5972}\n",
      "06/30/2020 16:49:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2211368499395292e-05, 'epoch': 1.6673178900362824, 'step': 5974}\n",
      "06/30/2020 16:49:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2202065308400782e-05, 'epoch': 1.6678760814959532, 'step': 5976}\n",
      "06/30/2020 16:49:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2192762117406273e-05, 'epoch': 1.6684342729556239, 'step': 5978}\n",
      "06/30/2020 16:49:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.218345892641176e-05, 'epoch': 1.6689924644152945, 'step': 5980}\n",
      "06/30/2020 16:49:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.217415573541725e-05, 'epoch': 1.669550655874965, 'step': 5982}\n",
      "06/30/2020 16:49:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2164852544422736e-05, 'epoch': 1.6701088473346357, 'step': 5984}\n",
      "06/30/2020 16:49:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2155549353428226e-05, 'epoch': 1.6706670387943063, 'step': 5986}\n",
      "06/30/2020 16:49:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2146246162433713e-05, 'epoch': 1.671225230253977, 'step': 5988}\n",
      "06/30/2020 16:49:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2136942971439203e-05, 'epoch': 1.6717834217136478, 'step': 5990}\n",
      "06/30/2020 16:49:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2127639780444694e-05, 'epoch': 1.6723416131733184, 'step': 5992}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:49:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2118336589450184e-05, 'epoch': 1.6728998046329893, 'step': 5994}\n",
      "06/30/2020 16:49:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2109033398455674e-05, 'epoch': 1.6734579960926599, 'step': 5996}\n",
      "06/30/2020 16:49:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.209973020746116e-05, 'epoch': 1.6740161875523305, 'step': 5998}\n",
      "06/30/2020 16:49:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.209042701646665e-05, 'epoch': 1.6745743790120011, 'step': 6000}\n",
      "06/30/2020 16:49:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2081123825472138e-05, 'epoch': 1.6751325704716717, 'step': 6002}\n",
      "06/30/2020 16:49:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2071820634477628e-05, 'epoch': 1.6756907619313424, 'step': 6004}\n",
      "06/30/2020 16:49:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2062517443483115e-05, 'epoch': 1.676248953391013, 'step': 6006}\n",
      "06/30/2020 16:49:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2053214252488605e-05, 'epoch': 1.6768071448506838, 'step': 6008}\n",
      "06/30/2020 16:49:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2043911061494095e-05, 'epoch': 1.6773653363103544, 'step': 6010}\n",
      "06/30/2020 16:49:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.203460787049958e-05, 'epoch': 1.677923527770025, 'step': 6012}\n",
      "06/30/2020 16:49:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2025304679505072e-05, 'epoch': 1.678481719229696, 'step': 6014}\n",
      "06/30/2020 16:49:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.201600148851056e-05, 'epoch': 1.6790399106893665, 'step': 6016}\n",
      "06/30/2020 16:49:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.200669829751605e-05, 'epoch': 1.6795981021490372, 'step': 6018}\n",
      "06/30/2020 16:49:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.199739510652154e-05, 'epoch': 1.6801562936087078, 'step': 6020}\n",
      "06/30/2020 16:49:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1988091915527026e-05, 'epoch': 1.6807144850683784, 'step': 6022}\n",
      "06/30/2020 16:49:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1978788724532516e-05, 'epoch': 1.681272676528049, 'step': 6024}\n",
      "06/30/2020 16:49:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1969485533538003e-05, 'epoch': 1.6818308679877196, 'step': 6026}\n",
      "06/30/2020 16:49:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1960182342543493e-05, 'epoch': 1.6823890594473905, 'step': 6028}\n",
      "06/30/2020 16:49:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1950879151548983e-05, 'epoch': 1.682947250907061, 'step': 6030}\n",
      "06/30/2020 16:49:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1941575960554473e-05, 'epoch': 1.683505442366732, 'step': 6032}\n",
      "06/30/2020 16:49:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.193227276955996e-05, 'epoch': 1.6840636338264026, 'step': 6034}\n",
      "06/30/2020 16:49:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.192296957856545e-05, 'epoch': 1.6846218252860732, 'step': 6036}\n",
      "06/30/2020 16:49:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.191366638757094e-05, 'epoch': 1.6851800167457438, 'step': 6038}\n",
      "06/30/2020 16:49:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1904363196576427e-05, 'epoch': 1.6857382082054144, 'step': 6040}\n",
      "06/30/2020 16:49:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1895060005581917e-05, 'epoch': 1.686296399665085, 'step': 6042}\n",
      "06/30/2020 16:49:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1885756814587404e-05, 'epoch': 1.6868545911247557, 'step': 6044}\n",
      "06/30/2020 16:49:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1876453623592894e-05, 'epoch': 1.6874127825844265, 'step': 6046}\n",
      "06/30/2020 16:49:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.186715043259838e-05, 'epoch': 1.6879709740440971, 'step': 6048}\n",
      "06/30/2020 16:49:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.185784724160387e-05, 'epoch': 1.6885291655037677, 'step': 6050}\n",
      "06/30/2020 16:49:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.184854405060936e-05, 'epoch': 1.6890873569634386, 'step': 6052}\n",
      "06/30/2020 16:49:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1839240859614848e-05, 'epoch': 1.6896455484231092, 'step': 6054}\n",
      "06/30/2020 16:49:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1829937668620338e-05, 'epoch': 1.6902037398827798, 'step': 6056}\n",
      "06/30/2020 16:49:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1820634477625825e-05, 'epoch': 1.6907619313424505, 'step': 6058}\n",
      "06/30/2020 16:49:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1811331286631315e-05, 'epoch': 1.691320122802121, 'step': 6060}\n",
      "06/30/2020 16:49:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1802028095636805e-05, 'epoch': 1.6918783142617917, 'step': 6062}\n",
      "06/30/2020 16:49:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1792724904642292e-05, 'epoch': 1.6924365057214623, 'step': 6064}\n",
      "06/30/2020 16:49:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1783421713647782e-05, 'epoch': 1.6929946971811332, 'step': 6066}\n",
      "06/30/2020 16:49:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1774118522653272e-05, 'epoch': 1.6935528886408038, 'step': 6068}\n",
      "06/30/2020 16:49:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1764815331658762e-05, 'epoch': 1.6941110801004746, 'step': 6070}\n",
      "06/30/2020 16:49:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.175551214066425e-05, 'epoch': 1.6946692715601452, 'step': 6072}\n",
      "06/30/2020 16:49:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.174620894966974e-05, 'epoch': 1.6952274630198159, 'step': 6074}\n",
      "06/30/2020 16:49:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1736905758675226e-05, 'epoch': 1.6957856544794865, 'step': 6076}\n",
      "06/30/2020 16:49:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1727602567680716e-05, 'epoch': 1.696343845939157, 'step': 6078}\n",
      "06/30/2020 16:49:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1718299376686206e-05, 'epoch': 1.6969020373988277, 'step': 6080}\n",
      "06/30/2020 16:49:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1708996185691693e-05, 'epoch': 1.6974602288584983, 'step': 6082}\n",
      "06/30/2020 16:49:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1699692994697183e-05, 'epoch': 1.6980184203181692, 'step': 6084}\n",
      "06/30/2020 16:49:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.169038980370267e-05, 'epoch': 1.6985766117778398, 'step': 6086}\n",
      "06/30/2020 16:49:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.168108661270816e-05, 'epoch': 1.6991348032375104, 'step': 6088}\n",
      "06/30/2020 16:49:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1671783421713647e-05, 'epoch': 1.6996929946971813, 'step': 6090}\n",
      "06/30/2020 16:49:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1662480230719137e-05, 'epoch': 1.700251186156852, 'step': 6092}\n",
      "06/30/2020 16:49:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1653177039724627e-05, 'epoch': 1.7008093776165225, 'step': 6094}\n",
      "06/30/2020 16:49:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1643873848730114e-05, 'epoch': 1.7013675690761931, 'step': 6096}\n",
      "06/30/2020 16:49:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1634570657735604e-05, 'epoch': 1.7019257605358638, 'step': 6098}\n",
      "06/30/2020 16:49:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.162526746674109e-05, 'epoch': 1.7024839519955344, 'step': 6100}\n",
      "06/30/2020 16:49:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.161596427574658e-05, 'epoch': 1.703042143455205, 'step': 6102}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:49:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.160666108475207e-05, 'epoch': 1.7036003349148758, 'step': 6104}\n",
      "06/30/2020 16:49:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.159735789375756e-05, 'epoch': 1.7041585263745465, 'step': 6106}\n",
      "06/30/2020 16:49:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1588054702763048e-05, 'epoch': 1.7047167178342173, 'step': 6108}\n",
      "06/30/2020 16:49:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.157875151176854e-05, 'epoch': 1.705274909293888, 'step': 6110}\n",
      "06/30/2020 16:49:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.156944832077403e-05, 'epoch': 1.7058331007535585, 'step': 6112}\n",
      "06/30/2020 16:49:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1560145129779515e-05, 'epoch': 1.7063912922132292, 'step': 6114}\n",
      "06/30/2020 16:49:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1550841938785005e-05, 'epoch': 1.7069494836728998, 'step': 6116}\n",
      "06/30/2020 16:49:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1541538747790492e-05, 'epoch': 1.7075076751325704, 'step': 6118}\n",
      "06/30/2020 16:49:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1532235556795982e-05, 'epoch': 1.708065866592241, 'step': 6120}\n",
      "06/30/2020 16:49:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1522932365801473e-05, 'epoch': 1.7086240580519116, 'step': 6122}\n",
      "06/30/2020 16:49:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.151362917480696e-05, 'epoch': 1.7091822495115825, 'step': 6124}\n",
      "06/30/2020 16:49:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.150432598381245e-05, 'epoch': 1.709740440971253, 'step': 6126}\n",
      "06/30/2020 16:49:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1495022792817936e-05, 'epoch': 1.710298632430924, 'step': 6128}\n",
      "06/30/2020 16:49:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1485719601823426e-05, 'epoch': 1.7108568238905946, 'step': 6130}\n",
      "06/30/2020 16:49:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1476416410828913e-05, 'epoch': 1.7114150153502652, 'step': 6132}\n",
      "06/30/2020 16:49:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1467113219834403e-05, 'epoch': 1.7119732068099358, 'step': 6134}\n",
      "06/30/2020 16:49:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1457810028839893e-05, 'epoch': 1.7125313982696064, 'step': 6136}\n",
      "06/30/2020 16:49:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.144850683784538e-05, 'epoch': 1.713089589729277, 'step': 6138}\n",
      "06/30/2020 16:49:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1439203646850874e-05, 'epoch': 1.7136477811889477, 'step': 6140}\n",
      "06/30/2020 16:49:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.142990045585636e-05, 'epoch': 1.7142059726486185, 'step': 6142}\n",
      "06/30/2020 16:49:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.142059726486185e-05, 'epoch': 1.7147641641082891, 'step': 6144}\n",
      "06/30/2020 16:49:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1411294073867337e-05, 'epoch': 1.7153223555679598, 'step': 6146}\n",
      "06/30/2020 16:49:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1401990882872828e-05, 'epoch': 1.7158805470276306, 'step': 6148}\n",
      "06/30/2020 16:49:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1392687691878314e-05, 'epoch': 1.7164387384873012, 'step': 6150}\n",
      "06/30/2020 16:49:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1383384500883805e-05, 'epoch': 1.7169969299469718, 'step': 6152}\n",
      "06/30/2020 16:49:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1374081309889295e-05, 'epoch': 1.7175551214066425, 'step': 6154}\n",
      "06/30/2020 16:49:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.136477811889478e-05, 'epoch': 1.718113312866313, 'step': 6156}\n",
      "06/30/2020 16:49:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.135547492790027e-05, 'epoch': 1.7186715043259837, 'step': 6158}\n",
      "06/30/2020 16:49:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.134617173690576e-05, 'epoch': 1.7192296957856543, 'step': 6160}\n",
      "06/30/2020 16:49:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.133686854591125e-05, 'epoch': 1.7197878872453252, 'step': 6162}\n",
      "06/30/2020 16:49:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1327565354916735e-05, 'epoch': 1.7203460787049958, 'step': 6164}\n",
      "06/30/2020 16:49:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1318262163922225e-05, 'epoch': 1.7209042701646666, 'step': 6166}\n",
      "06/30/2020 16:49:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1308958972927716e-05, 'epoch': 1.7214624616243372, 'step': 6168}\n",
      "06/30/2020 16:49:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1299655781933202e-05, 'epoch': 1.7220206530840079, 'step': 6170}\n",
      "06/30/2020 16:49:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1290352590938693e-05, 'epoch': 1.7225788445436785, 'step': 6172}\n",
      "06/30/2020 16:49:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.128104939994418e-05, 'epoch': 1.723137036003349, 'step': 6174}\n",
      "06/30/2020 16:49:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.127174620894967e-05, 'epoch': 1.7236952274630197, 'step': 6176}\n",
      "06/30/2020 16:49:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.126244301795516e-05, 'epoch': 1.7242534189226904, 'step': 6178}\n",
      "06/30/2020 16:49:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.125313982696065e-05, 'epoch': 1.7248116103823612, 'step': 6180}\n",
      "06/30/2020 16:49:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.124383663596614e-05, 'epoch': 1.7253698018420318, 'step': 6182}\n",
      "06/30/2020 16:49:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1234533444971627e-05, 'epoch': 1.7259279933017024, 'step': 6184}\n",
      "06/30/2020 16:49:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1225230253977117e-05, 'epoch': 1.7264861847613733, 'step': 6186}\n",
      "06/30/2020 16:49:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1215927062982604e-05, 'epoch': 1.727044376221044, 'step': 6188}\n",
      "06/30/2020 16:49:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1206623871988094e-05, 'epoch': 1.7276025676807145, 'step': 6190}\n",
      "06/30/2020 16:49:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.119732068099358e-05, 'epoch': 1.7281607591403851, 'step': 6192}\n",
      "06/30/2020 16:49:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.118801748999907e-05, 'epoch': 1.7287189506000558, 'step': 6194}\n",
      "06/30/2020 16:49:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.117871429900456e-05, 'epoch': 1.7292771420597264, 'step': 6196}\n",
      "06/30/2020 16:49:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1169411108010048e-05, 'epoch': 1.729835333519397, 'step': 6198}\n",
      "06/30/2020 16:49:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1160107917015538e-05, 'epoch': 1.7303935249790678, 'step': 6200}\n",
      "06/30/2020 16:49:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1150804726021025e-05, 'epoch': 1.7309517164387385, 'step': 6202}\n",
      "06/30/2020 16:49:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1141501535026515e-05, 'epoch': 1.7315099078984093, 'step': 6204}\n",
      "06/30/2020 16:49:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1132198344032e-05, 'epoch': 1.73206809935808, 'step': 6206}\n",
      "06/30/2020 16:49:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1122895153037492e-05, 'epoch': 1.7326262908177505, 'step': 6208}\n",
      "06/30/2020 16:49:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1113591962042982e-05, 'epoch': 1.7331844822774212, 'step': 6210}\n",
      "06/30/2020 16:49:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.110428877104847e-05, 'epoch': 1.7337426737370918, 'step': 6212}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:49:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1094985580053962e-05, 'epoch': 1.7343008651967624, 'step': 6214}\n",
      "06/30/2020 16:49:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.108568238905945e-05, 'epoch': 1.734859056656433, 'step': 6216}\n",
      "06/30/2020 16:49:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.107637919806494e-05, 'epoch': 1.7354172481161039, 'step': 6218}\n",
      "06/30/2020 16:49:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1067076007070426e-05, 'epoch': 1.7359754395757745, 'step': 6220}\n",
      "06/30/2020 16:49:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1057772816075916e-05, 'epoch': 1.7365336310354451, 'step': 6222}\n",
      "06/30/2020 16:49:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1048469625081406e-05, 'epoch': 1.737091822495116, 'step': 6224}\n",
      "06/30/2020 16:49:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1039166434086893e-05, 'epoch': 1.7376500139547866, 'step': 6226}\n",
      "06/30/2020 16:49:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1029863243092383e-05, 'epoch': 1.7382082054144572, 'step': 6228}\n",
      "06/30/2020 16:49:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.102056005209787e-05, 'epoch': 1.7387663968741278, 'step': 6230}\n",
      "06/30/2020 16:49:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.101125686110336e-05, 'epoch': 1.7393245883337984, 'step': 6232}\n",
      "06/30/2020 16:49:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1001953670108847e-05, 'epoch': 1.739882779793469, 'step': 6234}\n",
      "06/30/2020 16:49:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0992650479114337e-05, 'epoch': 1.7404409712531397, 'step': 6236}\n",
      "06/30/2020 16:49:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0983347288119827e-05, 'epoch': 1.7409991627128105, 'step': 6238}\n",
      "06/30/2020 16:49:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0974044097125314e-05, 'epoch': 1.7415573541724811, 'step': 6240}\n",
      "06/30/2020 16:49:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0964740906130804e-05, 'epoch': 1.742115545632152, 'step': 6242}\n",
      "06/30/2020 16:49:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.095543771513629e-05, 'epoch': 1.7426737370918226, 'step': 6244}\n",
      "06/30/2020 16:49:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.094613452414178e-05, 'epoch': 1.7432319285514932, 'step': 6246}\n",
      "06/30/2020 16:49:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0936831333147268e-05, 'epoch': 1.7437901200111638, 'step': 6248}\n",
      "06/30/2020 16:49:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0927528142152758e-05, 'epoch': 1.7443483114708345, 'step': 6250}\n",
      "06/30/2020 16:49:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0918224951158248e-05, 'epoch': 1.744906502930505, 'step': 6252}\n",
      "06/30/2020 16:49:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0908921760163738e-05, 'epoch': 1.7454646943901757, 'step': 6254}\n",
      "06/30/2020 16:49:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.089961856916923e-05, 'epoch': 1.7460228858498466, 'step': 6256}\n",
      "06/30/2020 16:49:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0890315378174715e-05, 'epoch': 1.7465810773095172, 'step': 6258}\n",
      "06/30/2020 16:49:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0881012187180205e-05, 'epoch': 1.7471392687691878, 'step': 6260}\n",
      "06/30/2020 16:49:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0871708996185692e-05, 'epoch': 1.7476974602288586, 'step': 6262}\n",
      "06/30/2020 16:49:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0862405805191182e-05, 'epoch': 1.7482556516885293, 'step': 6264}\n",
      "06/30/2020 16:49:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.085310261419667e-05, 'epoch': 1.7488138431481999, 'step': 6266}\n",
      "06/30/2020 16:49:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.084379942320216e-05, 'epoch': 1.7493720346078705, 'step': 6268}\n",
      "06/30/2020 16:49:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.083449623220765e-05, 'epoch': 1.7499302260675411, 'step': 6270}\n",
      "06/30/2020 16:49:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0825193041213136e-05, 'epoch': 1.7504884175272117, 'step': 6272}\n",
      "06/30/2020 16:49:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0815889850218626e-05, 'epoch': 1.7510466089868824, 'step': 6274}\n",
      "06/30/2020 16:49:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0806586659224113e-05, 'epoch': 1.7516048004465532, 'step': 6276}\n",
      "06/30/2020 16:49:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0797283468229603e-05, 'epoch': 1.7521629919062238, 'step': 6278}\n",
      "06/30/2020 16:49:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0787980277235093e-05, 'epoch': 1.7527211833658947, 'step': 6280}\n",
      "06/30/2020 16:49:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.077867708624058e-05, 'epoch': 1.7532793748255653, 'step': 6282}\n",
      "06/30/2020 16:49:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.076937389524607e-05, 'epoch': 1.753837566285236, 'step': 6284}\n",
      "06/30/2020 16:49:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0760070704251557e-05, 'epoch': 1.7543957577449065, 'step': 6286}\n",
      "06/30/2020 16:49:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.075076751325705e-05, 'epoch': 1.7549539492045771, 'step': 6288}\n",
      "06/30/2020 16:49:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0741464322262537e-05, 'epoch': 1.7555121406642478, 'step': 6290}\n",
      "06/30/2020 16:49:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0732161131268028e-05, 'epoch': 1.7560703321239184, 'step': 6292}\n",
      "06/30/2020 16:49:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0722857940273514e-05, 'epoch': 1.756628523583589, 'step': 6294}\n",
      "06/30/2020 16:49:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0713554749279004e-05, 'epoch': 1.7571867150432599, 'step': 6296}\n",
      "06/30/2020 16:49:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0704251558284495e-05, 'epoch': 1.7577449065029305, 'step': 6298}\n",
      "06/30/2020 16:49:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.069494836728998e-05, 'epoch': 1.7583030979626013, 'step': 6300}\n",
      "06/30/2020 16:49:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.068564517629547e-05, 'epoch': 1.758861289422272, 'step': 6302}\n",
      "06/30/2020 16:49:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0676341985300958e-05, 'epoch': 1.7594194808819426, 'step': 6304}\n",
      "06/30/2020 16:49:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.066703879430645e-05, 'epoch': 1.7599776723416132, 'step': 6306}\n",
      "06/30/2020 16:49:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0657735603311935e-05, 'epoch': 1.7605358638012838, 'step': 6308}\n",
      "06/30/2020 16:49:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0648432412317425e-05, 'epoch': 1.7610940552609544, 'step': 6310}\n",
      "06/30/2020 16:49:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0639129221322916e-05, 'epoch': 1.761652246720625, 'step': 6312}\n",
      "06/30/2020 16:49:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0629826030328402e-05, 'epoch': 1.7622104381802959, 'step': 6314}\n",
      "06/30/2020 16:49:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0620522839333892e-05, 'epoch': 1.7627686296399665, 'step': 6316}\n",
      "06/30/2020 16:49:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.061121964833938e-05, 'epoch': 1.7633268210996371, 'step': 6318}\n",
      "06/30/2020 16:49:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.060191645734487e-05, 'epoch': 1.763885012559308, 'step': 6320}\n",
      "06/30/2020 16:49:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.059261326635036e-05, 'epoch': 1.7644432040189786, 'step': 6322}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:49:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0583310075355846e-05, 'epoch': 1.7650013954786492, 'step': 6324}\n",
      "06/30/2020 16:49:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0574006884361336e-05, 'epoch': 1.7655595869383198, 'step': 6326}\n",
      "06/30/2020 16:49:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0564703693366827e-05, 'epoch': 1.7661177783979904, 'step': 6328}\n",
      "06/30/2020 16:49:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0555400502372317e-05, 'epoch': 1.766675969857661, 'step': 6330}\n",
      "06/30/2020 16:49:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0546097311377804e-05, 'epoch': 1.7672341613173317, 'step': 6332}\n",
      "06/30/2020 16:49:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0536794120383294e-05, 'epoch': 1.7677923527770025, 'step': 6334}\n",
      "06/30/2020 16:49:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.052749092938878e-05, 'epoch': 1.7683505442366731, 'step': 6336}\n",
      "06/30/2020 16:49:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.051818773839427e-05, 'epoch': 1.768908735696344, 'step': 6338}\n",
      "06/30/2020 16:49:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.050888454739976e-05, 'epoch': 1.7694669271560146, 'step': 6340}\n",
      "06/30/2020 16:49:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0499581356405248e-05, 'epoch': 1.7700251186156852, 'step': 6342}\n",
      "06/30/2020 16:49:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0490278165410738e-05, 'epoch': 1.7705833100753559, 'step': 6344}\n",
      "06/30/2020 16:49:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0480974974416225e-05, 'epoch': 1.7711415015350265, 'step': 6346}\n",
      "06/30/2020 16:49:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0471671783421715e-05, 'epoch': 1.771699692994697, 'step': 6348}\n",
      "06/30/2020 16:49:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.04623685924272e-05, 'epoch': 1.7722578844543677, 'step': 6350}\n",
      "06/30/2020 16:49:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.045306540143269e-05, 'epoch': 1.7728160759140386, 'step': 6352}\n",
      "06/30/2020 16:49:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0443762210438182e-05, 'epoch': 1.7733742673737092, 'step': 6354}\n",
      "06/30/2020 16:49:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.043445901944367e-05, 'epoch': 1.7739324588333798, 'step': 6356}\n",
      "06/30/2020 16:49:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.042515582844916e-05, 'epoch': 1.7744906502930506, 'step': 6358}\n",
      "06/30/2020 16:49:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0415852637454645e-05, 'epoch': 1.7750488417527213, 'step': 6360}\n",
      "06/30/2020 16:49:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.040654944646014e-05, 'epoch': 1.7756070332123919, 'step': 6362}\n",
      "06/30/2020 16:49:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0397246255465626e-05, 'epoch': 1.7761652246720625, 'step': 6364}\n",
      "06/30/2020 16:49:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0387943064471116e-05, 'epoch': 1.7767234161317331, 'step': 6366}\n",
      "06/30/2020 16:49:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0378639873476603e-05, 'epoch': 1.7772816075914037, 'step': 6368}\n",
      "06/30/2020 16:49:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0369336682482093e-05, 'epoch': 1.7778397990510744, 'step': 6370}\n",
      "06/30/2020 16:49:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0360033491487583e-05, 'epoch': 1.7783979905107452, 'step': 6372}\n",
      "06/30/2020 16:49:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.035073030049307e-05, 'epoch': 1.7789561819704158, 'step': 6374}\n",
      "06/30/2020 16:49:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.034142710949856e-05, 'epoch': 1.7795143734300867, 'step': 6376}\n",
      "06/30/2020 16:49:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0332123918504047e-05, 'epoch': 1.7800725648897573, 'step': 6378}\n",
      "06/30/2020 16:50:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0322820727509537e-05, 'epoch': 1.780630756349428, 'step': 6380}\n",
      "06/30/2020 16:50:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0313517536515027e-05, 'epoch': 1.7811889478090985, 'step': 6382}\n",
      "06/30/2020 16:50:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0304214345520514e-05, 'epoch': 1.7817471392687692, 'step': 6384}\n",
      "06/30/2020 16:50:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0294911154526004e-05, 'epoch': 1.7823053307284398, 'step': 6386}\n",
      "06/30/2020 16:50:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.028560796353149e-05, 'epoch': 1.7828635221881104, 'step': 6388}\n",
      "06/30/2020 16:50:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.027630477253698e-05, 'epoch': 1.7834217136477812, 'step': 6390}\n",
      "06/30/2020 16:50:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0267001581542468e-05, 'epoch': 1.7839799051074519, 'step': 6392}\n",
      "06/30/2020 16:50:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0257698390547958e-05, 'epoch': 1.7845380965671225, 'step': 6394}\n",
      "06/30/2020 16:50:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0248395199553448e-05, 'epoch': 1.7850962880267933, 'step': 6396}\n",
      "06/30/2020 16:50:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0239092008558938e-05, 'epoch': 1.785654479486464, 'step': 6398}\n",
      "06/30/2020 16:50:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0229788817564428e-05, 'epoch': 1.7862126709461346, 'step': 6400}\n",
      "06/30/2020 16:50:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0220485626569915e-05, 'epoch': 1.7867708624058052, 'step': 6402}\n",
      "06/30/2020 16:50:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0211182435575405e-05, 'epoch': 1.7873290538654758, 'step': 6404}\n",
      "06/30/2020 16:50:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0201879244580892e-05, 'epoch': 1.7878872453251464, 'step': 6406}\n",
      "06/30/2020 16:50:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0192576053586382e-05, 'epoch': 1.788445436784817, 'step': 6408}\n",
      "06/30/2020 16:50:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.018327286259187e-05, 'epoch': 1.7890036282444879, 'step': 6410}\n",
      "06/30/2020 16:50:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.017396967159736e-05, 'epoch': 1.7895618197041585, 'step': 6412}\n",
      "06/30/2020 16:50:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.016466648060285e-05, 'epoch': 1.7901200111638293, 'step': 6414}\n",
      "06/30/2020 16:50:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0155363289608336e-05, 'epoch': 1.7906782026235, 'step': 6416}\n",
      "06/30/2020 16:50:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0146060098613826e-05, 'epoch': 1.7912363940831706, 'step': 6418}\n",
      "06/30/2020 16:50:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0136756907619313e-05, 'epoch': 1.7917945855428412, 'step': 6420}\n",
      "06/30/2020 16:50:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0127453716624803e-05, 'epoch': 1.7923527770025118, 'step': 6422}\n",
      "06/30/2020 16:50:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0118150525630293e-05, 'epoch': 1.7929109684621825, 'step': 6424}\n",
      "06/30/2020 16:50:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.010884733463578e-05, 'epoch': 1.793469159921853, 'step': 6426}\n",
      "06/30/2020 16:50:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.009954414364127e-05, 'epoch': 1.794027351381524, 'step': 6428}\n",
      "06/30/2020 16:50:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0090240952646757e-05, 'epoch': 1.7945855428411945, 'step': 6430}\n",
      "06/30/2020 16:50:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0080937761652247e-05, 'epoch': 1.7951437343008652, 'step': 6432}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:50:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0071634570657734e-05, 'epoch': 1.795701925760536, 'step': 6434}\n",
      "06/30/2020 16:50:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0062331379663227e-05, 'epoch': 1.7962601172202066, 'step': 6436}\n",
      "06/30/2020 16:50:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0053028188668714e-05, 'epoch': 1.7968183086798772, 'step': 6438}\n",
      "06/30/2020 16:50:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0043724997674204e-05, 'epoch': 1.7973765001395479, 'step': 6440}\n",
      "06/30/2020 16:50:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0034421806679694e-05, 'epoch': 1.7979346915992185, 'step': 6442}\n",
      "06/30/2020 16:50:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.002511861568518e-05, 'epoch': 1.798492883058889, 'step': 6444}\n",
      "06/30/2020 16:50:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.001581542469067e-05, 'epoch': 1.7990510745185597, 'step': 6446}\n",
      "06/30/2020 16:50:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0006512233696158e-05, 'epoch': 1.7996092659782306, 'step': 6448}\n",
      "06/30/2020 16:50:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.999720904270165e-05, 'epoch': 1.8001674574379012, 'step': 6450}\n",
      "06/30/2020 16:50:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9987905851707135e-05, 'epoch': 1.800725648897572, 'step': 6452}\n",
      "06/30/2020 16:50:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9978602660712625e-05, 'epoch': 1.8012838403572426, 'step': 6454}\n",
      "06/30/2020 16:50:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9969299469718115e-05, 'epoch': 1.8018420318169133, 'step': 6456}\n",
      "06/30/2020 16:50:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9959996278723602e-05, 'epoch': 1.802400223276584, 'step': 6458}\n",
      "06/30/2020 16:50:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9950693087729092e-05, 'epoch': 1.8029584147362545, 'step': 6460}\n",
      "06/30/2020 16:50:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.994138989673458e-05, 'epoch': 1.8035166061959251, 'step': 6462}\n",
      "06/30/2020 16:50:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.993208670574007e-05, 'epoch': 1.8040747976555958, 'step': 6464}\n",
      "06/30/2020 16:50:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9922783514745556e-05, 'epoch': 1.8046329891152664, 'step': 6466}\n",
      "06/30/2020 16:50:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9913480323751046e-05, 'epoch': 1.8051911805749372, 'step': 6468}\n",
      "06/30/2020 16:50:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9904177132756536e-05, 'epoch': 1.8057493720346078, 'step': 6470}\n",
      "06/30/2020 16:50:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9894873941762027e-05, 'epoch': 1.8063075634942787, 'step': 6472}\n",
      "06/30/2020 16:50:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9885570750767517e-05, 'epoch': 1.8068657549539493, 'step': 6474}\n",
      "06/30/2020 16:50:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9876267559773003e-05, 'epoch': 1.80742394641362, 'step': 6476}\n",
      "06/30/2020 16:50:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9866964368778494e-05, 'epoch': 1.8079821378732905, 'step': 6478}\n",
      "06/30/2020 16:50:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.985766117778398e-05, 'epoch': 1.8085403293329612, 'step': 6480}\n",
      "06/30/2020 16:50:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.984835798678947e-05, 'epoch': 1.8090985207926318, 'step': 6482}\n",
      "06/30/2020 16:50:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.983905479579496e-05, 'epoch': 1.8096567122523024, 'step': 6484}\n",
      "06/30/2020 16:50:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9829751604800447e-05, 'epoch': 1.8102149037119732, 'step': 6486}\n",
      "06/30/2020 16:50:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9820448413805938e-05, 'epoch': 1.8107730951716439, 'step': 6488}\n",
      "06/30/2020 16:50:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9811145222811424e-05, 'epoch': 1.8113312866313145, 'step': 6490}\n",
      "06/30/2020 16:50:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9801842031816915e-05, 'epoch': 1.8118894780909853, 'step': 6492}\n",
      "06/30/2020 16:50:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.97925388408224e-05, 'epoch': 1.812447669550656, 'step': 6494}\n",
      "06/30/2020 16:50:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.978323564982789e-05, 'epoch': 1.8130058610103266, 'step': 6496}\n",
      "06/30/2020 16:50:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.977393245883338e-05, 'epoch': 1.8135640524699972, 'step': 6498}\n",
      "06/30/2020 16:50:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.976462926783887e-05, 'epoch': 1.8141222439296678, 'step': 6500}\n",
      "06/30/2020 16:50:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.975532607684436e-05, 'epoch': 1.8146804353893384, 'step': 6502}\n",
      "06/30/2020 16:50:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9746022885849845e-05, 'epoch': 1.815238626849009, 'step': 6504}\n",
      "06/30/2020 16:50:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9736719694855335e-05, 'epoch': 1.81579681830868, 'step': 6506}\n",
      "06/30/2020 16:50:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9727416503860822e-05, 'epoch': 1.8163550097683505, 'step': 6508}\n",
      "06/30/2020 16:50:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9718113312866316e-05, 'epoch': 1.8169132012280214, 'step': 6510}\n",
      "06/30/2020 16:50:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9708810121871803e-05, 'epoch': 1.817471392687692, 'step': 6512}\n",
      "06/30/2020 16:50:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9699506930877293e-05, 'epoch': 1.8180295841473626, 'step': 6514}\n",
      "06/30/2020 16:50:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9690203739882783e-05, 'epoch': 1.8185877756070332, 'step': 6516}\n",
      "06/30/2020 16:50:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.968090054888827e-05, 'epoch': 1.8191459670667038, 'step': 6518}\n",
      "06/30/2020 16:50:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.967159735789376e-05, 'epoch': 1.8197041585263745, 'step': 6520}\n",
      "06/30/2020 16:50:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9662294166899247e-05, 'epoch': 1.820262349986045, 'step': 6522}\n",
      "06/30/2020 16:50:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9652990975904737e-05, 'epoch': 1.820820541445716, 'step': 6524}\n",
      "06/30/2020 16:50:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9643687784910224e-05, 'epoch': 1.8213787329053865, 'step': 6526}\n",
      "06/30/2020 16:50:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9634384593915714e-05, 'epoch': 1.8219369243650572, 'step': 6528}\n",
      "06/30/2020 16:50:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9625081402921204e-05, 'epoch': 1.822495115824728, 'step': 6530}\n",
      "06/30/2020 16:50:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.961577821192669e-05, 'epoch': 1.8230533072843986, 'step': 6532}\n",
      "06/30/2020 16:50:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.960647502093218e-05, 'epoch': 1.8236114987440692, 'step': 6534}\n",
      "06/30/2020 16:50:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9597171829937668e-05, 'epoch': 1.8241696902037399, 'step': 6536}\n",
      "06/30/2020 16:50:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9587868638943158e-05, 'epoch': 1.8247278816634105, 'step': 6538}\n",
      "06/30/2020 16:50:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9578565447948648e-05, 'epoch': 1.825286073123081, 'step': 6540}\n",
      "06/30/2020 16:50:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9569262256954135e-05, 'epoch': 1.8258442645827517, 'step': 6542}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:50:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9559959065959625e-05, 'epoch': 1.8264024560424226, 'step': 6544}\n",
      "06/30/2020 16:50:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9550655874965115e-05, 'epoch': 1.8269606475020932, 'step': 6546}\n",
      "06/30/2020 16:50:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9541352683970605e-05, 'epoch': 1.827518838961764, 'step': 6548}\n",
      "06/30/2020 16:50:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9532049492976092e-05, 'epoch': 1.8280770304214347, 'step': 6550}\n",
      "06/30/2020 16:50:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9522746301981582e-05, 'epoch': 1.8286352218811053, 'step': 6552}\n",
      "06/30/2020 16:50:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.951344311098707e-05, 'epoch': 1.829193413340776, 'step': 6554}\n",
      "06/30/2020 16:50:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.950413991999256e-05, 'epoch': 1.8297516048004465, 'step': 6556}\n",
      "06/30/2020 16:50:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.949483672899805e-05, 'epoch': 1.8303097962601171, 'step': 6558}\n",
      "06/30/2020 16:50:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9485533538003536e-05, 'epoch': 1.8308679877197878, 'step': 6560}\n",
      "06/30/2020 16:50:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9476230347009026e-05, 'epoch': 1.8314261791794586, 'step': 6562}\n",
      "06/30/2020 16:50:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9466927156014513e-05, 'epoch': 1.8319843706391292, 'step': 6564}\n",
      "06/30/2020 16:50:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9457623965020003e-05, 'epoch': 1.8325425620987998, 'step': 6566}\n",
      "06/30/2020 16:50:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.944832077402549e-05, 'epoch': 1.8331007535584707, 'step': 6568}\n",
      "06/30/2020 16:50:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.943901758303098e-05, 'epoch': 1.8336589450181413, 'step': 6570}\n",
      "06/30/2020 16:50:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.942971439203647e-05, 'epoch': 1.834217136477812, 'step': 6572}\n",
      "06/30/2020 16:50:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9420411201041957e-05, 'epoch': 1.8347753279374825, 'step': 6574}\n",
      "06/30/2020 16:50:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9411108010047447e-05, 'epoch': 1.8353335193971532, 'step': 6576}\n",
      "06/30/2020 16:50:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9401804819052934e-05, 'epoch': 1.8358917108568238, 'step': 6578}\n",
      "06/30/2020 16:50:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9392501628058424e-05, 'epoch': 1.8364499023164944, 'step': 6580}\n",
      "06/30/2020 16:50:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9383198437063914e-05, 'epoch': 1.8370080937761653, 'step': 6582}\n",
      "06/30/2020 16:50:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9373895246069404e-05, 'epoch': 1.8375662852358359, 'step': 6584}\n",
      "06/30/2020 16:50:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9364592055074894e-05, 'epoch': 1.8381244766955067, 'step': 6586}\n",
      "06/30/2020 16:50:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.935528886408038e-05, 'epoch': 1.8386826681551773, 'step': 6588}\n",
      "06/30/2020 16:50:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.934598567308587e-05, 'epoch': 1.839240859614848, 'step': 6590}\n",
      "06/30/2020 16:50:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9336682482091358e-05, 'epoch': 1.8397990510745186, 'step': 6592}\n",
      "06/30/2020 16:50:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9327379291096848e-05, 'epoch': 1.8403572425341892, 'step': 6594}\n",
      "06/30/2020 16:50:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9318076100102335e-05, 'epoch': 1.8409154339938598, 'step': 6596}\n",
      "06/30/2020 16:50:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9308772909107825e-05, 'epoch': 1.8414736254535304, 'step': 6598}\n",
      "06/30/2020 16:50:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9299469718113315e-05, 'epoch': 1.8420318169132013, 'step': 6600}\n",
      "06/30/2020 16:50:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9290166527118802e-05, 'epoch': 1.842590008372872, 'step': 6602}\n",
      "06/30/2020 16:50:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9280863336124292e-05, 'epoch': 1.8431481998325425, 'step': 6604}\n",
      "06/30/2020 16:50:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.927156014512978e-05, 'epoch': 1.8437063912922134, 'step': 6606}\n",
      "06/30/2020 16:50:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.926225695413527e-05, 'epoch': 1.844264582751884, 'step': 6608}\n",
      "06/30/2020 16:50:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9252953763140756e-05, 'epoch': 1.8448227742115546, 'step': 6610}\n",
      "06/30/2020 16:50:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9243650572146246e-05, 'epoch': 1.8453809656712252, 'step': 6612}\n",
      "06/30/2020 16:50:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9234347381151736e-05, 'epoch': 1.8459391571308958, 'step': 6614}\n",
      "06/30/2020 16:50:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9225044190157223e-05, 'epoch': 1.8464973485905665, 'step': 6616}\n",
      "06/30/2020 16:50:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9215740999162713e-05, 'epoch': 1.847055540050237, 'step': 6618}\n",
      "06/30/2020 16:50:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9206437808168203e-05, 'epoch': 1.847613731509908, 'step': 6620}\n",
      "06/30/2020 16:50:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9197134617173694e-05, 'epoch': 1.8481719229695786, 'step': 6622}\n",
      "06/30/2020 16:50:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.918783142617918e-05, 'epoch': 1.8487301144292494, 'step': 6624}\n",
      "06/30/2020 16:50:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.917852823518467e-05, 'epoch': 1.84928830588892, 'step': 6626}\n",
      "06/30/2020 16:50:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9169225044190157e-05, 'epoch': 1.8498464973485906, 'step': 6628}\n",
      "06/30/2020 16:50:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9159921853195647e-05, 'epoch': 1.8504046888082613, 'step': 6630}\n",
      "06/30/2020 16:50:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9150618662201138e-05, 'epoch': 1.8509628802679319, 'step': 6632}\n",
      "06/30/2020 16:50:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9141315471206624e-05, 'epoch': 1.8515210717276025, 'step': 6634}\n",
      "06/30/2020 16:50:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9132012280212114e-05, 'epoch': 1.8520792631872731, 'step': 6636}\n",
      "06/30/2020 16:50:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.91227090892176e-05, 'epoch': 1.8526374546469437, 'step': 6638}\n",
      "06/30/2020 16:50:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.911340589822309e-05, 'epoch': 1.8531956461066146, 'step': 6640}\n",
      "06/30/2020 16:50:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.910410270722858e-05, 'epoch': 1.8537538375662852, 'step': 6642}\n",
      "06/30/2020 16:50:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9094799516234068e-05, 'epoch': 1.854312029025956, 'step': 6644}\n",
      "06/30/2020 16:50:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.908549632523956e-05, 'epoch': 1.8548702204856267, 'step': 6646}\n",
      "06/30/2020 16:50:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9076193134245045e-05, 'epoch': 1.8554284119452973, 'step': 6648}\n",
      "06/30/2020 16:50:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9066889943250535e-05, 'epoch': 1.855986603404968, 'step': 6650}\n",
      "06/30/2020 16:50:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9057586752256022e-05, 'epoch': 1.8565447948646385, 'step': 6652}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:50:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9048283561261512e-05, 'epoch': 1.8571029863243091, 'step': 6654}\n",
      "06/30/2020 16:50:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9038980370267002e-05, 'epoch': 1.8576611777839798, 'step': 6656}\n",
      "06/30/2020 16:50:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9029677179272493e-05, 'epoch': 1.8582193692436506, 'step': 6658}\n",
      "06/30/2020 16:50:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9020373988277983e-05, 'epoch': 1.8587775607033212, 'step': 6660}\n",
      "06/30/2020 16:50:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.901107079728347e-05, 'epoch': 1.859335752162992, 'step': 6662}\n",
      "06/30/2020 16:50:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.900176760628896e-05, 'epoch': 1.8598939436226627, 'step': 6664}\n",
      "06/30/2020 16:50:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8992464415294446e-05, 'epoch': 1.8604521350823333, 'step': 6666}\n",
      "06/30/2020 16:50:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8983161224299937e-05, 'epoch': 1.861010326542004, 'step': 6668}\n",
      "06/30/2020 16:50:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8973858033305423e-05, 'epoch': 1.8615685180016746, 'step': 6670}\n",
      "06/30/2020 16:50:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8964554842310914e-05, 'epoch': 1.8621267094613452, 'step': 6672}\n",
      "06/30/2020 16:50:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8955251651316404e-05, 'epoch': 1.8626849009210158, 'step': 6674}\n",
      "06/30/2020 16:50:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.894594846032189e-05, 'epoch': 1.8632430923806864, 'step': 6676}\n",
      "06/30/2020 16:50:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.893664526932738e-05, 'epoch': 1.8638012838403573, 'step': 6678}\n",
      "06/30/2020 16:50:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8927342078332867e-05, 'epoch': 1.8643594753000279, 'step': 6680}\n",
      "06/30/2020 16:50:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8918038887338358e-05, 'epoch': 1.8649176667596987, 'step': 6682}\n",
      "06/30/2020 16:50:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8908735696343848e-05, 'epoch': 1.8654758582193693, 'step': 6684}\n",
      "06/30/2020 16:50:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8899432505349335e-05, 'epoch': 1.86603404967904, 'step': 6686}\n",
      "06/30/2020 16:50:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8890129314354825e-05, 'epoch': 1.8665922411387106, 'step': 6688}\n",
      "06/30/2020 16:50:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.888082612336031e-05, 'epoch': 1.8671504325983812, 'step': 6690}\n",
      "06/30/2020 16:50:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.88715229323658e-05, 'epoch': 1.8677086240580518, 'step': 6692}\n",
      "06/30/2020 16:50:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8862219741371292e-05, 'epoch': 1.8682668155177224, 'step': 6694}\n",
      "06/30/2020 16:50:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8852916550376782e-05, 'epoch': 1.8688250069773933, 'step': 6696}\n",
      "06/30/2020 16:50:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.884361335938227e-05, 'epoch': 1.869383198437064, 'step': 6698}\n",
      "06/30/2020 16:50:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.883431016838776e-05, 'epoch': 1.8699413898967345, 'step': 6700}\n",
      "06/30/2020 16:50:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.882500697739325e-05, 'epoch': 1.8704995813564054, 'step': 6702}\n",
      "06/30/2020 16:50:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8815703786398736e-05, 'epoch': 1.871057772816076, 'step': 6704}\n",
      "06/30/2020 16:50:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8806400595404226e-05, 'epoch': 1.8716159642757466, 'step': 6706}\n",
      "06/30/2020 16:50:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8797097404409713e-05, 'epoch': 1.8721741557354172, 'step': 6708}\n",
      "06/30/2020 16:50:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8787794213415203e-05, 'epoch': 1.8727323471950879, 'step': 6710}\n",
      "06/30/2020 16:50:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.877849102242069e-05, 'epoch': 1.8732905386547585, 'step': 6712}\n",
      "06/30/2020 16:50:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.876918783142618e-05, 'epoch': 1.873848730114429, 'step': 6714}\n",
      "06/30/2020 16:50:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.875988464043167e-05, 'epoch': 1.8744069215741, 'step': 6716}\n",
      "06/30/2020 16:50:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8750581449437157e-05, 'epoch': 1.8749651130337706, 'step': 6718}\n",
      "06/30/2020 16:50:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8741278258442647e-05, 'epoch': 1.8755233044934414, 'step': 6720}\n",
      "06/30/2020 16:50:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8731975067448134e-05, 'epoch': 1.876081495953112, 'step': 6722}\n",
      "06/30/2020 16:50:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8722671876453624e-05, 'epoch': 1.8766396874127826, 'step': 6724}\n",
      "06/30/2020 16:50:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8713368685459114e-05, 'epoch': 1.8771978788724533, 'step': 6726}\n",
      "06/30/2020 16:50:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.87040654944646e-05, 'epoch': 1.8777560703321239, 'step': 6728}\n",
      "06/30/2020 16:50:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.869476230347009e-05, 'epoch': 1.8783142617917945, 'step': 6730}\n",
      "06/30/2020 16:50:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.868545911247558e-05, 'epoch': 1.8788724532514651, 'step': 6732}\n",
      "06/30/2020 16:50:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.867615592148107e-05, 'epoch': 1.879430644711136, 'step': 6734}\n",
      "06/30/2020 16:50:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8666852730486558e-05, 'epoch': 1.8799888361708066, 'step': 6736}\n",
      "06/30/2020 16:50:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8657549539492048e-05, 'epoch': 1.8805470276304772, 'step': 6738}\n",
      "06/30/2020 16:50:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8648246348497535e-05, 'epoch': 1.881105219090148, 'step': 6740}\n",
      "06/30/2020 16:50:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8638943157503025e-05, 'epoch': 1.8816634105498187, 'step': 6742}\n",
      "06/30/2020 16:50:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8629639966508515e-05, 'epoch': 1.8822216020094893, 'step': 6744}\n",
      "06/30/2020 16:50:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8620336775514002e-05, 'epoch': 1.88277979346916, 'step': 6746}\n",
      "06/30/2020 16:50:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8611033584519492e-05, 'epoch': 1.8833379849288305, 'step': 6748}\n",
      "06/30/2020 16:50:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.860173039352498e-05, 'epoch': 1.8838961763885012, 'step': 6750}\n",
      "06/30/2020 16:50:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.859242720253047e-05, 'epoch': 1.8844543678481718, 'step': 6752}\n",
      "06/30/2020 16:50:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8583124011535956e-05, 'epoch': 1.8850125593078426, 'step': 6754}\n",
      "06/30/2020 16:50:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8573820820541446e-05, 'epoch': 1.8855707507675132, 'step': 6756}\n",
      "06/30/2020 16:50:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8564517629546936e-05, 'epoch': 1.886128942227184, 'step': 6758}\n",
      "06/30/2020 16:50:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8555214438552423e-05, 'epoch': 1.8866871336868547, 'step': 6760}\n",
      "06/30/2020 16:50:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8545911247557913e-05, 'epoch': 1.8872453251465253, 'step': 6762}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:50:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.85366080565634e-05, 'epoch': 1.887803516606196, 'step': 6764}\n",
      "06/30/2020 16:50:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.852730486556889e-05, 'epoch': 1.8883617080658666, 'step': 6766}\n",
      "06/30/2020 16:50:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.851800167457438e-05, 'epoch': 1.8889198995255372, 'step': 6768}\n",
      "06/30/2020 16:50:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.850869848357987e-05, 'epoch': 1.8894780909852078, 'step': 6770}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:50:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8499395292585357e-05, 'epoch': 1.8900362824448786, 'step': 6772}\n",
      "06/30/2020 16:50:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8490092101590847e-05, 'epoch': 1.8905944739045493, 'step': 6774}\n",
      "06/30/2020 16:50:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8480788910596337e-05, 'epoch': 1.8911526653642199, 'step': 6776}\n",
      "06/30/2020 16:50:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8471485719601824e-05, 'epoch': 1.8917108568238907, 'step': 6778}\n",
      "06/30/2020 16:50:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8462182528607314e-05, 'epoch': 1.8922690482835614, 'step': 6780}\n",
      "06/30/2020 16:50:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.84528793376128e-05, 'epoch': 1.892827239743232, 'step': 6782}\n",
      "06/30/2020 16:50:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.844357614661829e-05, 'epoch': 1.8933854312029026, 'step': 6784}\n",
      "06/30/2020 16:50:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.843427295562378e-05, 'epoch': 1.8939436226625732, 'step': 6786}\n",
      "06/30/2020 16:50:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8424969764629268e-05, 'epoch': 1.8945018141222438, 'step': 6788}\n",
      "06/30/2020 16:50:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.841566657363476e-05, 'epoch': 1.8950600055819145, 'step': 6790}\n",
      "06/30/2020 16:50:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8406363382640245e-05, 'epoch': 1.8956181970415853, 'step': 6792}\n",
      "06/30/2020 16:50:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8397060191645735e-05, 'epoch': 1.896176388501256, 'step': 6794}\n",
      "06/30/2020 16:50:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8387757000651222e-05, 'epoch': 1.8967345799609268, 'step': 6796}\n",
      "06/30/2020 16:50:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8378453809656712e-05, 'epoch': 1.8972927714205974, 'step': 6798}\n",
      "06/30/2020 16:50:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8369150618662202e-05, 'epoch': 1.897850962880268, 'step': 6800}\n",
      "06/30/2020 16:50:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.835984742766769e-05, 'epoch': 1.8984091543399386, 'step': 6802}\n",
      "06/30/2020 16:50:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8350544236673183e-05, 'epoch': 1.8989673457996092, 'step': 6804}\n",
      "06/30/2020 16:50:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.834124104567867e-05, 'epoch': 1.8995255372592799, 'step': 6806}\n",
      "06/30/2020 16:50:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.833193785468416e-05, 'epoch': 1.9000837287189505, 'step': 6808}\n",
      "06/30/2020 16:50:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8322634663689646e-05, 'epoch': 1.900641920178621, 'step': 6810}\n",
      "06/30/2020 16:50:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8313331472695137e-05, 'epoch': 1.901200111638292, 'step': 6812}\n",
      "06/30/2020 16:50:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8304028281700623e-05, 'epoch': 1.9017583030979626, 'step': 6814}\n",
      "06/30/2020 16:50:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8294725090706113e-05, 'epoch': 1.9023164945576334, 'step': 6816}\n",
      "06/30/2020 16:50:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8285421899711604e-05, 'epoch': 1.902874686017304, 'step': 6818}\n",
      "06/30/2020 16:50:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.827611870871709e-05, 'epoch': 1.9034328774769746, 'step': 6820}\n",
      "06/30/2020 16:50:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.826681551772258e-05, 'epoch': 1.9039910689366453, 'step': 6822}\n",
      "06/30/2020 16:50:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8257512326728067e-05, 'epoch': 1.904549260396316, 'step': 6824}\n",
      "06/30/2020 16:50:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8248209135733557e-05, 'epoch': 1.9051074518559865, 'step': 6826}\n",
      "06/30/2020 16:50:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8238905944739044e-05, 'epoch': 1.9056656433156571, 'step': 6828}\n",
      "06/30/2020 16:50:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8229602753744534e-05, 'epoch': 1.906223834775328, 'step': 6830}\n",
      "06/30/2020 16:50:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8220299562750025e-05, 'epoch': 1.9067820262349986, 'step': 6832}\n",
      "06/30/2020 16:50:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.821099637175551e-05, 'epoch': 1.9073402176946694, 'step': 6834}\n",
      "06/30/2020 16:50:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8201693180761e-05, 'epoch': 1.90789840915434, 'step': 6836}\n",
      "06/30/2020 16:50:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8192389989766488e-05, 'epoch': 1.9084566006140107, 'step': 6838}\n",
      "06/30/2020 16:50:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.818308679877198e-05, 'epoch': 1.9090147920736813, 'step': 6840}\n",
      "06/30/2020 16:50:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.817378360777747e-05, 'epoch': 1.909572983533352, 'step': 6842}\n",
      "06/30/2020 16:50:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.816448041678296e-05, 'epoch': 1.9101311749930225, 'step': 6844}\n",
      "06/30/2020 16:50:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.815517722578845e-05, 'epoch': 1.9106893664526932, 'step': 6846}\n",
      "06/30/2020 16:50:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8145874034793936e-05, 'epoch': 1.9112475579123638, 'step': 6848}\n",
      "06/30/2020 16:50:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8136570843799426e-05, 'epoch': 1.9118057493720346, 'step': 6850}\n",
      "06/30/2020 16:50:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8127267652804913e-05, 'epoch': 1.9123639408317052, 'step': 6852}\n",
      "06/30/2020 16:50:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8117964461810403e-05, 'epoch': 1.912922132291376, 'step': 6854}\n",
      "06/30/2020 16:50:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.810866127081589e-05, 'epoch': 1.9134803237510467, 'step': 6856}\n",
      "06/30/2020 16:50:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.809935807982138e-05, 'epoch': 1.9140385152107173, 'step': 6858}\n",
      "06/30/2020 16:50:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.809005488882687e-05, 'epoch': 1.914596706670388, 'step': 6860}\n",
      "06/30/2020 16:50:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8080751697832357e-05, 'epoch': 1.9151548981300586, 'step': 6862}\n",
      "06/30/2020 16:50:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8071448506837847e-05, 'epoch': 1.9157130895897292, 'step': 6864}\n",
      "06/30/2020 16:50:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8062145315843334e-05, 'epoch': 1.9162712810493998, 'step': 6866}\n",
      "06/30/2020 16:50:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8052842124848824e-05, 'epoch': 1.9168294725090707, 'step': 6868}\n",
      "06/30/2020 16:50:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.804353893385431e-05, 'epoch': 1.9173876639687413, 'step': 6870}\n",
      "06/30/2020 16:50:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.80342357428598e-05, 'epoch': 1.917945855428412, 'step': 6872}\n",
      "06/30/2020 16:50:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.802493255186529e-05, 'epoch': 1.9185040468880827, 'step': 6874}\n",
      "06/30/2020 16:50:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8015629360870778e-05, 'epoch': 1.9190622383477534, 'step': 6876}\n",
      "06/30/2020 16:50:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.800632616987627e-05, 'epoch': 1.919620429807424, 'step': 6878}\n",
      "06/30/2020 16:50:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7997022978881758e-05, 'epoch': 1.9201786212670946, 'step': 6880}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:50:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7987719787887248e-05, 'epoch': 1.9207368127267652, 'step': 6882}\n",
      "06/30/2020 16:50:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7978416596892735e-05, 'epoch': 1.9212950041864358, 'step': 6884}\n",
      "06/30/2020 16:50:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7969113405898225e-05, 'epoch': 1.9218531956461065, 'step': 6886}\n",
      "06/30/2020 16:50:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7959810214903715e-05, 'epoch': 1.9224113871057773, 'step': 6888}\n",
      "06/30/2020 16:50:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7950507023909202e-05, 'epoch': 1.922969578565448, 'step': 6890}\n",
      "06/30/2020 16:50:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7941203832914692e-05, 'epoch': 1.9235277700251188, 'step': 6892}\n",
      "06/30/2020 16:50:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.793190064192018e-05, 'epoch': 1.9240859614847894, 'step': 6894}\n",
      "06/30/2020 16:50:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.792259745092567e-05, 'epoch': 1.92464415294446, 'step': 6896}\n",
      "06/30/2020 16:50:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7913294259931156e-05, 'epoch': 1.9252023444041306, 'step': 6898}\n",
      "06/30/2020 16:50:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7903991068936646e-05, 'epoch': 1.9257605358638012, 'step': 6900}\n",
      "06/30/2020 16:50:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7894687877942136e-05, 'epoch': 1.9263187273234719, 'step': 6902}\n",
      "06/30/2020 16:50:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7885384686947623e-05, 'epoch': 1.9268769187831425, 'step': 6904}\n",
      "06/30/2020 16:50:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7876081495953113e-05, 'epoch': 1.9274351102428133, 'step': 6906}\n",
      "06/30/2020 16:50:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.78667783049586e-05, 'epoch': 1.927993301702484, 'step': 6908}\n",
      "06/30/2020 16:50:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.785747511396409e-05, 'epoch': 1.9285514931621546, 'step': 6910}\n",
      "06/30/2020 16:50:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7848171922969577e-05, 'epoch': 1.9291096846218254, 'step': 6912}\n",
      "06/30/2020 16:50:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7838868731975067e-05, 'epoch': 1.929667876081496, 'step': 6914}\n",
      "06/30/2020 16:50:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7829565540980557e-05, 'epoch': 1.9302260675411667, 'step': 6916}\n",
      "06/30/2020 16:50:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7820262349986047e-05, 'epoch': 1.9307842590008373, 'step': 6918}\n",
      "06/30/2020 16:50:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7810959158991537e-05, 'epoch': 1.931342450460508, 'step': 6920}\n",
      "06/30/2020 16:50:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7801655967997024e-05, 'epoch': 1.9319006419201785, 'step': 6922}\n",
      "06/30/2020 16:50:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7792352777002514e-05, 'epoch': 1.9324588333798491, 'step': 6924}\n",
      "06/30/2020 16:50:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7783049586008e-05, 'epoch': 1.93301702483952, 'step': 6926}\n",
      "06/30/2020 16:50:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.777374639501349e-05, 'epoch': 1.9335752162991906, 'step': 6928}\n",
      "06/30/2020 16:50:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7764443204018978e-05, 'epoch': 1.9341334077588614, 'step': 6930}\n",
      "06/30/2020 16:50:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7755140013024468e-05, 'epoch': 1.934691599218532, 'step': 6932}\n",
      "06/30/2020 16:50:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7745836822029958e-05, 'epoch': 1.9352497906782027, 'step': 6934}\n",
      "06/30/2020 16:50:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7736533631035445e-05, 'epoch': 1.9358079821378733, 'step': 6936}\n",
      "06/30/2020 16:50:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7727230440040935e-05, 'epoch': 1.936366173597544, 'step': 6938}\n",
      "06/30/2020 16:50:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7717927249046422e-05, 'epoch': 1.9369243650572145, 'step': 6940}\n",
      "06/30/2020 16:50:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7708624058051912e-05, 'epoch': 1.9374825565168852, 'step': 6942}\n",
      "06/30/2020 16:50:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7699320867057402e-05, 'epoch': 1.938040747976556, 'step': 6944}\n",
      "06/30/2020 16:50:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.769001767606289e-05, 'epoch': 1.9385989394362266, 'step': 6946}\n",
      "06/30/2020 16:50:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.768071448506838e-05, 'epoch': 1.9391571308958973, 'step': 6948}\n",
      "06/30/2020 16:50:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7671411294073866e-05, 'epoch': 1.939715322355568, 'step': 6950}\n",
      "06/30/2020 16:50:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.766210810307936e-05, 'epoch': 1.9402735138152387, 'step': 6952}\n",
      "06/30/2020 16:50:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7652804912084846e-05, 'epoch': 1.9408317052749093, 'step': 6954}\n",
      "06/30/2020 16:50:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7643501721090336e-05, 'epoch': 1.94138989673458, 'step': 6956}\n",
      "06/30/2020 16:50:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7634198530095823e-05, 'epoch': 1.9419480881942506, 'step': 6958}\n",
      "06/30/2020 16:50:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7624895339101313e-05, 'epoch': 1.9425062796539212, 'step': 6960}\n",
      "06/30/2020 16:50:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7615592148106803e-05, 'epoch': 1.9430644711135918, 'step': 6962}\n",
      "06/30/2020 16:50:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.760628895711229e-05, 'epoch': 1.9436226625732627, 'step': 6964}\n",
      "06/30/2020 16:50:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.759698576611778e-05, 'epoch': 1.9441808540329333, 'step': 6966}\n",
      "06/30/2020 16:50:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7587682575123267e-05, 'epoch': 1.9447390454926041, 'step': 6968}\n",
      "06/30/2020 16:50:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7578379384128757e-05, 'epoch': 1.9452972369522747, 'step': 6970}\n",
      "06/30/2020 16:50:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7569076193134244e-05, 'epoch': 1.9458554284119454, 'step': 6972}\n",
      "06/30/2020 16:50:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7559773002139734e-05, 'epoch': 1.946413619871616, 'step': 6974}\n",
      "06/30/2020 16:50:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7550469811145224e-05, 'epoch': 1.9469718113312866, 'step': 6976}\n",
      "06/30/2020 16:50:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.754116662015071e-05, 'epoch': 1.9475300027909572, 'step': 6978}\n",
      "06/30/2020 16:50:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.75318634291562e-05, 'epoch': 1.9480881942506278, 'step': 6980}\n",
      "06/30/2020 16:50:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7522560238161688e-05, 'epoch': 1.9486463857102985, 'step': 6982}\n",
      "06/30/2020 16:50:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7513257047167178e-05, 'epoch': 1.9492045771699693, 'step': 6984}\n",
      "06/30/2020 16:50:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.750395385617267e-05, 'epoch': 1.94976276862964, 'step': 6986}\n",
      "06/30/2020 16:50:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.749465066517816e-05, 'epoch': 1.9503209600893108, 'step': 6988}\n",
      "06/30/2020 16:50:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7485347474183645e-05, 'epoch': 1.9508791515489814, 'step': 6990}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:50:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7476044283189136e-05, 'epoch': 1.951437343008652, 'step': 6992}\n",
      "06/30/2020 16:50:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7466741092194626e-05, 'epoch': 1.9519955344683226, 'step': 6994}\n",
      "06/30/2020 16:50:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7457437901200112e-05, 'epoch': 1.9525537259279933, 'step': 6996}\n",
      "06/30/2020 16:50:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7448134710205603e-05, 'epoch': 1.9531119173876639, 'step': 6998}\n",
      "06/30/2020 16:50:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.743883151921109e-05, 'epoch': 1.9536701088473345, 'step': 7000}\n",
      "06/30/2020 16:50:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.742952832821658e-05, 'epoch': 1.9542283003070053, 'step': 7002}\n",
      "06/30/2020 16:50:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.742022513722207e-05, 'epoch': 1.954786491766676, 'step': 7004}\n",
      "06/30/2020 16:50:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7410921946227556e-05, 'epoch': 1.9553446832263468, 'step': 7006}\n",
      "06/30/2020 16:50:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7401618755233047e-05, 'epoch': 1.9559028746860174, 'step': 7008}\n",
      "06/30/2020 16:50:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7392315564238533e-05, 'epoch': 1.956461066145688, 'step': 7010}\n",
      "06/30/2020 16:50:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7383012373244024e-05, 'epoch': 1.9570192576053587, 'step': 7012}\n",
      "06/30/2020 16:50:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.737370918224951e-05, 'epoch': 1.9575774490650293, 'step': 7014}\n",
      "06/30/2020 16:50:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7364405991255e-05, 'epoch': 1.9581356405247, 'step': 7016}\n",
      "06/30/2020 16:50:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.735510280026049e-05, 'epoch': 1.9586938319843705, 'step': 7018}\n",
      "06/30/2020 16:50:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7345799609265977e-05, 'epoch': 1.9592520234440411, 'step': 7020}\n",
      "06/30/2020 16:50:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7336496418271468e-05, 'epoch': 1.959810214903712, 'step': 7022}\n",
      "06/30/2020 16:50:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7327193227276954e-05, 'epoch': 1.9603684063633826, 'step': 7024}\n",
      "06/30/2020 16:50:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7317890036282448e-05, 'epoch': 1.9609265978230535, 'step': 7026}\n",
      "06/30/2020 16:50:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7308586845287935e-05, 'epoch': 1.961484789282724, 'step': 7028}\n",
      "06/30/2020 16:50:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7299283654293425e-05, 'epoch': 1.9620429807423947, 'step': 7030}\n",
      "06/30/2020 16:50:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.728998046329891e-05, 'epoch': 1.9626011722020653, 'step': 7032}\n",
      "06/30/2020 16:50:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7280677272304402e-05, 'epoch': 1.963159363661736, 'step': 7034}\n",
      "06/30/2020 16:50:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7271374081309892e-05, 'epoch': 1.9637175551214066, 'step': 7036}\n",
      "06/30/2020 16:50:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.726207089031538e-05, 'epoch': 1.9642757465810772, 'step': 7038}\n",
      "06/30/2020 16:50:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.725276769932087e-05, 'epoch': 1.964833938040748, 'step': 7040}\n",
      "06/30/2020 16:50:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7243464508326356e-05, 'epoch': 1.9653921295004186, 'step': 7042}\n",
      "06/30/2020 16:50:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7234161317331846e-05, 'epoch': 1.9659503209600893, 'step': 7044}\n",
      "06/30/2020 16:50:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7224858126337336e-05, 'epoch': 1.96650851241976, 'step': 7046}\n",
      "06/30/2020 16:50:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7215554935342823e-05, 'epoch': 1.9670667038794307, 'step': 7048}\n",
      "06/30/2020 16:50:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7206251744348313e-05, 'epoch': 1.9676248953391013, 'step': 7050}\n",
      "06/30/2020 16:50:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.71969485533538e-05, 'epoch': 1.968183086798772, 'step': 7052}\n",
      "06/30/2020 16:50:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.718764536235929e-05, 'epoch': 1.9687412782584426, 'step': 7054}\n",
      "06/30/2020 16:50:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7178342171364777e-05, 'epoch': 1.9692994697181132, 'step': 7056}\n",
      "06/30/2020 16:50:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7169038980370267e-05, 'epoch': 1.9698576611777838, 'step': 7058}\n",
      "06/30/2020 16:50:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7159735789375757e-05, 'epoch': 1.9704158526374547, 'step': 7060}\n",
      "06/30/2020 16:50:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7150432598381247e-05, 'epoch': 1.9709740440971253, 'step': 7062}\n",
      "06/30/2020 16:50:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7141129407386737e-05, 'epoch': 1.9715322355567961, 'step': 7064}\n",
      "06/30/2020 16:50:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7131826216392224e-05, 'epoch': 1.9720904270164668, 'step': 7066}\n",
      "06/30/2020 16:50:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7122523025397714e-05, 'epoch': 1.9726486184761374, 'step': 7068}\n",
      "06/30/2020 16:50:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.71132198344032e-05, 'epoch': 1.973206809935808, 'step': 7070}\n",
      "06/30/2020 16:50:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.710391664340869e-05, 'epoch': 1.9737650013954786, 'step': 7072}\n",
      "06/30/2020 16:50:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7094613452414178e-05, 'epoch': 1.9743231928551492, 'step': 7074}\n",
      "06/30/2020 16:50:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7085310261419668e-05, 'epoch': 1.9748813843148199, 'step': 7076}\n",
      "06/30/2020 16:50:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7076007070425158e-05, 'epoch': 1.9754395757744907, 'step': 7078}\n",
      "06/30/2020 16:50:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7066703879430645e-05, 'epoch': 1.9759977672341613, 'step': 7080}\n",
      "06/30/2020 16:50:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7057400688436135e-05, 'epoch': 1.976555958693832, 'step': 7082}\n",
      "06/30/2020 16:50:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7048097497441622e-05, 'epoch': 1.9771141501535028, 'step': 7084}\n",
      "06/30/2020 16:50:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7038794306447112e-05, 'epoch': 1.9776723416131734, 'step': 7086}\n",
      "06/30/2020 16:50:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7029491115452602e-05, 'epoch': 1.978230533072844, 'step': 7088}\n",
      "06/30/2020 16:50:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.702018792445809e-05, 'epoch': 1.9787887245325146, 'step': 7090}\n",
      "06/30/2020 16:50:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.701088473346358e-05, 'epoch': 1.9793469159921853, 'step': 7092}\n",
      "06/30/2020 16:50:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7001581542469066e-05, 'epoch': 1.9799051074518559, 'step': 7094}\n",
      "06/30/2020 16:50:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6992278351474556e-05, 'epoch': 1.9804632989115265, 'step': 7096}\n",
      "06/30/2020 16:50:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6982975160480043e-05, 'epoch': 1.9810214903711973, 'step': 7098}\n",
      "06/30/2020 16:50:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6973671969485536e-05, 'epoch': 1.981579681830868, 'step': 7100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:50:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6964368778491023e-05, 'epoch': 1.9821378732905388, 'step': 7102}\n",
      "06/30/2020 16:50:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6955065587496513e-05, 'epoch': 1.9826960647502094, 'step': 7104}\n",
      "06/30/2020 16:50:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6945762396502003e-05, 'epoch': 1.98325425620988, 'step': 7106}\n",
      "06/30/2020 16:50:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.693645920550749e-05, 'epoch': 1.9838124476695507, 'step': 7108}\n",
      "06/30/2020 16:50:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.692715601451298e-05, 'epoch': 1.9843706391292213, 'step': 7110}\n",
      "06/30/2020 16:50:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6917852823518467e-05, 'epoch': 1.984928830588892, 'step': 7112}\n",
      "06/30/2020 16:50:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6908549632523957e-05, 'epoch': 1.9854870220485625, 'step': 7114}\n",
      "06/30/2020 16:50:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6899246441529444e-05, 'epoch': 1.9860452135082334, 'step': 7116}\n",
      "06/30/2020 16:50:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6889943250534934e-05, 'epoch': 1.986603404967904, 'step': 7118}\n",
      "06/30/2020 16:50:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6880640059540424e-05, 'epoch': 1.9871615964275746, 'step': 7120}\n",
      "06/30/2020 16:50:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.687133686854591e-05, 'epoch': 1.9877197878872455, 'step': 7122}\n",
      "06/30/2020 16:50:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.68620336775514e-05, 'epoch': 1.988277979346916, 'step': 7124}\n",
      "06/30/2020 16:50:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6852730486556888e-05, 'epoch': 1.9888361708065867, 'step': 7126}\n",
      "06/30/2020 16:50:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6843427295562378e-05, 'epoch': 1.9893943622662573, 'step': 7128}\n",
      "06/30/2020 16:50:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6834124104567865e-05, 'epoch': 1.989952553725928, 'step': 7130}\n",
      "06/30/2020 16:50:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6824820913573355e-05, 'epoch': 1.9905107451855986, 'step': 7132}\n",
      "06/30/2020 16:50:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6815517722578845e-05, 'epoch': 1.9910689366452692, 'step': 7134}\n",
      "06/30/2020 16:50:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6806214531584335e-05, 'epoch': 1.99162712810494, 'step': 7136}\n",
      "06/30/2020 16:50:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6796911340589826e-05, 'epoch': 1.9921853195646106, 'step': 7138}\n",
      "06/30/2020 16:50:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6787608149595312e-05, 'epoch': 1.9927435110242815, 'step': 7140}\n",
      "06/30/2020 16:50:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6778304958600803e-05, 'epoch': 1.993301702483952, 'step': 7142}\n",
      "06/30/2020 16:50:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.676900176760629e-05, 'epoch': 1.9938598939436227, 'step': 7144}\n",
      "06/30/2020 16:50:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.675969857661178e-05, 'epoch': 1.9944180854032934, 'step': 7146}\n",
      "06/30/2020 16:50:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.675039538561727e-05, 'epoch': 1.994976276862964, 'step': 7148}\n",
      "06/30/2020 16:50:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6741092194622756e-05, 'epoch': 1.9955344683226346, 'step': 7150}\n",
      "06/30/2020 16:50:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6731789003628247e-05, 'epoch': 1.9960926597823052, 'step': 7152}\n",
      "06/30/2020 16:50:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6722485812633733e-05, 'epoch': 1.9966508512419758, 'step': 7154}\n",
      "06/30/2020 16:50:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6713182621639223e-05, 'epoch': 1.9972090427016467, 'step': 7156}\n",
      "06/30/2020 16:50:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.670387943064471e-05, 'epoch': 1.9977672341613173, 'step': 7158}\n",
      "06/30/2020 16:50:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.66945762396502e-05, 'epoch': 1.9983254256209881, 'step': 7160}\n",
      "06/30/2020 16:50:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.668527304865569e-05, 'epoch': 1.9988836170806588, 'step': 7162}\n",
      "06/30/2020 16:50:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6675969857661177e-05, 'epoch': 1.9994418085403294, 'step': 7164}\n",
      "06/30/2020 16:50:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0, 'step': 7166}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40c09c7d21f4f9591199dfa838edee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=3583.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:50:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6657363475672154e-05, 'epoch': 2.0005581914596706, 'step': 7168}\n",
      "06/30/2020 16:50:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6648060284677644e-05, 'epoch': 2.0011163829193412, 'step': 7170}\n",
      "06/30/2020 16:50:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.663875709368313e-05, 'epoch': 2.001674574379012, 'step': 7172}\n",
      "06/30/2020 16:50:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6629453902688625e-05, 'epoch': 2.0022327658386825, 'step': 7174}\n",
      "06/30/2020 16:50:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.662015071169411e-05, 'epoch': 2.0027909572983535, 'step': 7176}\n",
      "06/30/2020 16:50:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.66108475206996e-05, 'epoch': 2.003349148758024, 'step': 7178}\n",
      "06/30/2020 16:50:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6601544329705092e-05, 'epoch': 2.003907340217695, 'step': 7180}\n",
      "06/30/2020 16:50:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.659224113871058e-05, 'epoch': 2.0044655316773654, 'step': 7182}\n",
      "06/30/2020 16:50:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.658293794771607e-05, 'epoch': 2.005023723137036, 'step': 7184}\n",
      "06/30/2020 16:50:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6573634756721555e-05, 'epoch': 2.0055819145967066, 'step': 7186}\n",
      "06/30/2020 16:50:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6564331565727046e-05, 'epoch': 2.0061401060563773, 'step': 7188}\n",
      "06/30/2020 16:50:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6555028374732532e-05, 'epoch': 2.006698297516048, 'step': 7190}\n",
      "06/30/2020 16:50:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6545725183738023e-05, 'epoch': 2.0072564889757185, 'step': 7192}\n",
      "06/30/2020 16:50:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6536421992743513e-05, 'epoch': 2.007814680435389, 'step': 7194}\n",
      "06/30/2020 16:50:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6527118801749e-05, 'epoch': 2.00837287189506, 'step': 7196}\n",
      "06/30/2020 16:50:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.651781561075449e-05, 'epoch': 2.008931063354731, 'step': 7198}\n",
      "06/30/2020 16:50:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6508512419759976e-05, 'epoch': 2.0094892548144014, 'step': 7200}\n",
      "06/30/2020 16:50:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6499209228765467e-05, 'epoch': 2.010047446274072, 'step': 7202}\n",
      "06/30/2020 16:50:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6489906037770957e-05, 'epoch': 2.0106056377337427, 'step': 7204}\n",
      "06/30/2020 16:50:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6480602846776444e-05, 'epoch': 2.0111638291934133, 'step': 7206}\n",
      "06/30/2020 16:50:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6471299655781934e-05, 'epoch': 2.011722020653084, 'step': 7208}\n",
      "06/30/2020 16:50:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6461996464787424e-05, 'epoch': 2.0122802121127545, 'step': 7210}\n",
      "06/30/2020 16:50:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6452693273792914e-05, 'epoch': 2.012838403572425, 'step': 7212}\n",
      "06/30/2020 16:50:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.64433900827984e-05, 'epoch': 2.0133965950320962, 'step': 7214}\n",
      "06/30/2020 16:50:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.643408689180389e-05, 'epoch': 2.013954786491767, 'step': 7216}\n",
      "06/30/2020 16:50:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6424783700809378e-05, 'epoch': 2.0145129779514375, 'step': 7218}\n",
      "06/30/2020 16:50:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6415480509814868e-05, 'epoch': 2.015071169411108, 'step': 7220}\n",
      "06/30/2020 16:50:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6406177318820358e-05, 'epoch': 2.0156293608707787, 'step': 7222}\n",
      "06/30/2020 16:50:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6396874127825845e-05, 'epoch': 2.0161875523304493, 'step': 7224}\n",
      "06/30/2020 16:50:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6387570936831335e-05, 'epoch': 2.01674574379012, 'step': 7226}\n",
      "06/30/2020 16:50:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6378267745836822e-05, 'epoch': 2.0173039352497906, 'step': 7228}\n",
      "06/30/2020 16:50:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6368964554842312e-05, 'epoch': 2.017862126709461, 'step': 7230}\n",
      "06/30/2020 16:50:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.63596613638478e-05, 'epoch': 2.018420318169132, 'step': 7232}\n",
      "06/30/2020 16:51:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.635035817285329e-05, 'epoch': 2.018978509628803, 'step': 7234}\n",
      "06/30/2020 16:51:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.634105498185878e-05, 'epoch': 2.0195367010884735, 'step': 7236}\n",
      "06/30/2020 16:51:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6331751790864266e-05, 'epoch': 2.020094892548144, 'step': 7238}\n",
      "06/30/2020 16:51:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6322448599869756e-05, 'epoch': 2.0206530840078147, 'step': 7240}\n",
      "06/30/2020 16:51:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6313145408875243e-05, 'epoch': 2.0212112754674854, 'step': 7242}\n",
      "06/30/2020 16:51:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6303842217880733e-05, 'epoch': 2.021769466927156, 'step': 7244}\n",
      "06/30/2020 16:51:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6294539026886223e-05, 'epoch': 2.0223276583868266, 'step': 7246}\n",
      "06/30/2020 16:51:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6285235835891713e-05, 'epoch': 2.022885849846497, 'step': 7248}\n",
      "06/30/2020 16:51:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6275932644897203e-05, 'epoch': 2.023444041306168, 'step': 7250}\n",
      "06/30/2020 16:51:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.626662945390269e-05, 'epoch': 2.024002232765839, 'step': 7252}\n",
      "06/30/2020 16:51:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.625732626290818e-05, 'epoch': 2.0245604242255095, 'step': 7254}\n",
      "06/30/2020 16:51:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6248023071913667e-05, 'epoch': 2.02511861568518, 'step': 7256}\n",
      "06/30/2020 16:51:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6238719880919157e-05, 'epoch': 2.0256768071448508, 'step': 7258}\n",
      "06/30/2020 16:51:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6229416689924644e-05, 'epoch': 2.0262349986045214, 'step': 7260}\n",
      "06/30/2020 16:51:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6220113498930134e-05, 'epoch': 2.026793190064192, 'step': 7262}\n",
      "06/30/2020 16:51:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6210810307935624e-05, 'epoch': 2.0273513815238626, 'step': 7264}\n",
      "06/30/2020 16:51:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.620150711694111e-05, 'epoch': 2.0279095729835332, 'step': 7266}\n",
      "06/30/2020 16:51:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.61922039259466e-05, 'epoch': 2.028467764443204, 'step': 7268}\n",
      "06/30/2020 16:51:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6182900734952088e-05, 'epoch': 2.0290259559028745, 'step': 7270}\n",
      "06/30/2020 16:51:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6173597543957578e-05, 'epoch': 2.0295841473625456, 'step': 7272}\n",
      "06/30/2020 16:51:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6164294352963065e-05, 'epoch': 2.030142338822216, 'step': 7274}\n",
      "06/30/2020 16:51:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6154991161968555e-05, 'epoch': 2.030700530281887, 'step': 7276}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:51:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6145687970974045e-05, 'epoch': 2.0312587217415574, 'step': 7278}\n",
      "06/30/2020 16:51:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6136384779979532e-05, 'epoch': 2.031816913201228, 'step': 7280}\n",
      "06/30/2020 16:51:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6127081588985022e-05, 'epoch': 2.0323751046608987, 'step': 7282}\n",
      "06/30/2020 16:51:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6117778397990512e-05, 'epoch': 2.0329332961205693, 'step': 7284}\n",
      "06/30/2020 16:51:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6108475206996002e-05, 'epoch': 2.03349148758024, 'step': 7286}\n",
      "06/30/2020 16:51:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.609917201600149e-05, 'epoch': 2.0340496790399105, 'step': 7288}\n",
      "06/30/2020 16:51:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.608986882500698e-05, 'epoch': 2.034607870499581, 'step': 7290}\n",
      "06/30/2020 16:51:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6080565634012466e-05, 'epoch': 2.035166061959252, 'step': 7292}\n",
      "06/30/2020 16:51:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6071262443017956e-05, 'epoch': 2.035724253418923, 'step': 7294}\n",
      "06/30/2020 16:51:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6061959252023446e-05, 'epoch': 2.0362824448785934, 'step': 7296}\n",
      "06/30/2020 16:51:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6052656061028933e-05, 'epoch': 2.036840636338264, 'step': 7298}\n",
      "06/30/2020 16:51:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6043352870034423e-05, 'epoch': 2.0373988277979347, 'step': 7300}\n",
      "06/30/2020 16:51:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.603404967903991e-05, 'epoch': 2.0379570192576053, 'step': 7302}\n",
      "06/30/2020 16:51:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.60247464880454e-05, 'epoch': 2.038515210717276, 'step': 7304}\n",
      "06/30/2020 16:51:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.601544329705089e-05, 'epoch': 2.0390734021769465, 'step': 7306}\n",
      "06/30/2020 16:51:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6006140106056377e-05, 'epoch': 2.039631593636617, 'step': 7308}\n",
      "06/30/2020 16:51:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5996836915061867e-05, 'epoch': 2.0401897850962882, 'step': 7310}\n",
      "06/30/2020 16:51:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5987533724067354e-05, 'epoch': 2.040747976555959, 'step': 7312}\n",
      "06/30/2020 16:51:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5978230533072844e-05, 'epoch': 2.0413061680156295, 'step': 7314}\n",
      "06/30/2020 16:51:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.596892734207833e-05, 'epoch': 2.0418643594753, 'step': 7316}\n",
      "06/30/2020 16:51:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.595962415108382e-05, 'epoch': 2.0424225509349707, 'step': 7318}\n",
      "06/30/2020 16:51:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.595032096008931e-05, 'epoch': 2.0429807423946413, 'step': 7320}\n",
      "06/30/2020 16:51:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.59410177690948e-05, 'epoch': 2.043538933854312, 'step': 7322}\n",
      "06/30/2020 16:51:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.593171457810029e-05, 'epoch': 2.0440971253139826, 'step': 7324}\n",
      "06/30/2020 16:51:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.592241138710578e-05, 'epoch': 2.044655316773653, 'step': 7326}\n",
      "06/30/2020 16:51:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.591310819611127e-05, 'epoch': 2.045213508233324, 'step': 7328}\n",
      "06/30/2020 16:51:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5903805005116755e-05, 'epoch': 2.045771699692995, 'step': 7330}\n",
      "06/30/2020 16:51:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5894501814122246e-05, 'epoch': 2.0463298911526655, 'step': 7332}\n",
      "06/30/2020 16:51:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5885198623127732e-05, 'epoch': 2.046888082612336, 'step': 7334}\n",
      "06/30/2020 16:51:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5875895432133222e-05, 'epoch': 2.0474462740720067, 'step': 7336}\n",
      "06/30/2020 16:51:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5866592241138713e-05, 'epoch': 2.0480044655316774, 'step': 7338}\n",
      "06/30/2020 16:51:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.58572890501442e-05, 'epoch': 2.048562656991348, 'step': 7340}\n",
      "06/30/2020 16:51:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.584798585914969e-05, 'epoch': 2.0491208484510186, 'step': 7342}\n",
      "06/30/2020 16:51:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5838682668155176e-05, 'epoch': 2.0496790399106892, 'step': 7344}\n",
      "06/30/2020 16:51:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5829379477160666e-05, 'epoch': 2.05023723137036, 'step': 7346}\n",
      "06/30/2020 16:51:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5820076286166157e-05, 'epoch': 2.050795422830031, 'step': 7348}\n",
      "06/30/2020 16:51:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5810773095171643e-05, 'epoch': 2.0513536142897015, 'step': 7350}\n",
      "06/30/2020 16:51:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5801469904177134e-05, 'epoch': 2.051911805749372, 'step': 7352}\n",
      "06/30/2020 16:51:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.579216671318262e-05, 'epoch': 2.0524699972090428, 'step': 7354}\n",
      "06/30/2020 16:51:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.578286352218811e-05, 'epoch': 2.0530281886687134, 'step': 7356}\n",
      "06/30/2020 16:51:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.57735603311936e-05, 'epoch': 2.053586380128384, 'step': 7358}\n",
      "06/30/2020 16:51:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.576425714019909e-05, 'epoch': 2.0541445715880546, 'step': 7360}\n",
      "06/30/2020 16:51:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5754953949204578e-05, 'epoch': 2.0547027630477253, 'step': 7362}\n",
      "06/30/2020 16:51:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5745650758210068e-05, 'epoch': 2.055260954507396, 'step': 7364}\n",
      "06/30/2020 16:51:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5736347567215558e-05, 'epoch': 2.0558191459670665, 'step': 7366}\n",
      "06/30/2020 16:51:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5727044376221045e-05, 'epoch': 2.0563773374267376, 'step': 7368}\n",
      "06/30/2020 16:51:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5717741185226535e-05, 'epoch': 2.056935528886408, 'step': 7370}\n",
      "06/30/2020 16:51:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.570843799423202e-05, 'epoch': 2.057493720346079, 'step': 7372}\n",
      "06/30/2020 16:51:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5699134803237512e-05, 'epoch': 2.0580519118057494, 'step': 7374}\n",
      "06/30/2020 16:51:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5689831612243e-05, 'epoch': 2.05861010326542, 'step': 7376}\n",
      "06/30/2020 16:51:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.568052842124849e-05, 'epoch': 2.0591682947250907, 'step': 7378}\n",
      "06/30/2020 16:51:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.567122523025398e-05, 'epoch': 2.0597264861847613, 'step': 7380}\n",
      "06/30/2020 16:51:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5661922039259466e-05, 'epoch': 2.060284677644432, 'step': 7382}\n",
      "06/30/2020 16:51:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5652618848264956e-05, 'epoch': 2.0608428691041025, 'step': 7384}\n",
      "06/30/2020 16:51:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5643315657270443e-05, 'epoch': 2.0614010605637736, 'step': 7386}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:51:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5634012466275933e-05, 'epoch': 2.061959252023444, 'step': 7388}\n",
      "06/30/2020 16:51:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.562470927528142e-05, 'epoch': 2.062517443483115, 'step': 7390}\n",
      "06/30/2020 16:51:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.561540608428691e-05, 'epoch': 2.0630756349427855, 'step': 7392}\n",
      "06/30/2020 16:51:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.56061028932924e-05, 'epoch': 2.063633826402456, 'step': 7394}\n",
      "06/30/2020 16:51:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.559679970229789e-05, 'epoch': 2.0641920178621267, 'step': 7396}\n",
      "06/30/2020 16:51:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.558749651130338e-05, 'epoch': 2.0647502093217973, 'step': 7398}\n",
      "06/30/2020 16:51:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5578193320308867e-05, 'epoch': 2.065308400781468, 'step': 7400}\n",
      "06/30/2020 16:51:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5568890129314357e-05, 'epoch': 2.0658665922411386, 'step': 7402}\n",
      "06/30/2020 16:51:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5559586938319844e-05, 'epoch': 2.066424783700809, 'step': 7404}\n",
      "06/30/2020 16:51:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5550283747325334e-05, 'epoch': 2.0669829751604802, 'step': 7406}\n",
      "06/30/2020 16:51:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5540980556330824e-05, 'epoch': 2.067541166620151, 'step': 7408}\n",
      "06/30/2020 16:51:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.553167736533631e-05, 'epoch': 2.0680993580798215, 'step': 7410}\n",
      "06/30/2020 16:51:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.55223741743418e-05, 'epoch': 2.068657549539492, 'step': 7412}\n",
      "06/30/2020 16:51:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5513070983347288e-05, 'epoch': 2.0692157409991627, 'step': 7414}\n",
      "06/30/2020 16:51:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5503767792352778e-05, 'epoch': 2.0697739324588333, 'step': 7416}\n",
      "06/30/2020 16:51:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5494464601358265e-05, 'epoch': 2.070332123918504, 'step': 7418}\n",
      "06/30/2020 16:51:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5485161410363755e-05, 'epoch': 2.0708903153781746, 'step': 7420}\n",
      "06/30/2020 16:51:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5475858219369245e-05, 'epoch': 2.071448506837845, 'step': 7422}\n",
      "06/30/2020 16:51:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5466555028374732e-05, 'epoch': 2.072006698297516, 'step': 7424}\n",
      "06/30/2020 16:51:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5457251837380222e-05, 'epoch': 2.072564889757187, 'step': 7426}\n",
      "06/30/2020 16:51:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.544794864638571e-05, 'epoch': 2.0731230812168575, 'step': 7428}\n",
      "06/30/2020 16:51:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.54386454553912e-05, 'epoch': 2.073681272676528, 'step': 7430}\n",
      "06/30/2020 16:51:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.542934226439669e-05, 'epoch': 2.0742394641361988, 'step': 7432}\n",
      "06/30/2020 16:51:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.542003907340218e-05, 'epoch': 2.0747976555958694, 'step': 7434}\n",
      "06/30/2020 16:51:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5410735882407666e-05, 'epoch': 2.07535584705554, 'step': 7436}\n",
      "06/30/2020 16:51:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5401432691413156e-05, 'epoch': 2.0759140385152106, 'step': 7438}\n",
      "06/30/2020 16:51:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5392129500418646e-05, 'epoch': 2.0764722299748812, 'step': 7440}\n",
      "06/30/2020 16:51:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5382826309424133e-05, 'epoch': 2.077030421434552, 'step': 7442}\n",
      "06/30/2020 16:51:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5373523118429623e-05, 'epoch': 2.077588612894223, 'step': 7444}\n",
      "06/30/2020 16:51:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.536421992743511e-05, 'epoch': 2.0781468043538935, 'step': 7446}\n",
      "06/30/2020 16:51:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.53549167364406e-05, 'epoch': 2.078704995813564, 'step': 7448}\n",
      "06/30/2020 16:51:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.534561354544609e-05, 'epoch': 2.079263187273235, 'step': 7450}\n",
      "06/30/2020 16:51:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5336310354451577e-05, 'epoch': 2.0798213787329054, 'step': 7452}\n",
      "06/30/2020 16:51:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5327007163457067e-05, 'epoch': 2.080379570192576, 'step': 7454}\n",
      "06/30/2020 16:51:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5317703972462554e-05, 'epoch': 2.0809377616522466, 'step': 7456}\n",
      "06/30/2020 16:51:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5308400781468044e-05, 'epoch': 2.0814959531119173, 'step': 7458}\n",
      "06/30/2020 16:51:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.529909759047353e-05, 'epoch': 2.082054144571588, 'step': 7460}\n",
      "06/30/2020 16:51:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.528979439947902e-05, 'epoch': 2.082612336031259, 'step': 7462}\n",
      "06/30/2020 16:51:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.528049120848451e-05, 'epoch': 2.0831705274909296, 'step': 7464}\n",
      "06/30/2020 16:51:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5271188017489998e-05, 'epoch': 2.0837287189506, 'step': 7466}\n",
      "06/30/2020 16:51:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.526188482649549e-05, 'epoch': 2.084286910410271, 'step': 7468}\n",
      "06/30/2020 16:51:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5252581635500978e-05, 'epoch': 2.0848451018699414, 'step': 7470}\n",
      "06/30/2020 16:51:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5243278444506467e-05, 'epoch': 2.085403293329612, 'step': 7472}\n",
      "06/30/2020 16:51:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5233975253511957e-05, 'epoch': 2.0859614847892827, 'step': 7474}\n",
      "06/30/2020 16:51:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5224672062517445e-05, 'epoch': 2.0865196762489533, 'step': 7476}\n",
      "06/30/2020 16:51:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5215368871522934e-05, 'epoch': 2.087077867708624, 'step': 7478}\n",
      "06/30/2020 16:51:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5206065680528422e-05, 'epoch': 2.0876360591682945, 'step': 7480}\n",
      "06/30/2020 16:51:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.519676248953391e-05, 'epoch': 2.0881942506279656, 'step': 7482}\n",
      "06/30/2020 16:51:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.51874592985394e-05, 'epoch': 2.088752442087636, 'step': 7484}\n",
      "06/30/2020 16:51:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.517815610754489e-05, 'epoch': 2.089310633547307, 'step': 7486}\n",
      "06/30/2020 16:51:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5168852916550378e-05, 'epoch': 2.0898688250069775, 'step': 7488}\n",
      "06/30/2020 16:51:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5159549725555866e-05, 'epoch': 2.090427016466648, 'step': 7490}\n",
      "06/30/2020 16:51:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5150246534561355e-05, 'epoch': 2.0909852079263187, 'step': 7492}\n",
      "06/30/2020 16:51:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5140943343566843e-05, 'epoch': 2.0915433993859893, 'step': 7494}\n",
      "06/30/2020 16:51:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5131640152572332e-05, 'epoch': 2.09210159084566, 'step': 7496}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:51:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.512233696157782e-05, 'epoch': 2.0926597823053306, 'step': 7498}\n",
      "06/30/2020 16:51:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.511303377058331e-05, 'epoch': 2.093217973765001, 'step': 7500}\n",
      "06/30/2020 16:51:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5103730579588799e-05, 'epoch': 2.0937761652246722, 'step': 7502}\n",
      "06/30/2020 16:51:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5094427388594287e-05, 'epoch': 2.094334356684343, 'step': 7504}\n",
      "06/30/2020 16:51:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.508512419759978e-05, 'epoch': 2.0948925481440135, 'step': 7506}\n",
      "06/30/2020 16:51:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5075821006605268e-05, 'epoch': 2.095450739603684, 'step': 7508}\n",
      "06/30/2020 16:51:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5066517815610756e-05, 'epoch': 2.0960089310633547, 'step': 7510}\n",
      "06/30/2020 16:51:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5057214624616245e-05, 'epoch': 2.0965671225230254, 'step': 7512}\n",
      "06/30/2020 16:51:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5047911433621733e-05, 'epoch': 2.097125313982696, 'step': 7514}\n",
      "06/30/2020 16:51:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5038608242627223e-05, 'epoch': 2.0976835054423666, 'step': 7516}\n",
      "06/30/2020 16:51:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5029305051632712e-05, 'epoch': 2.098241696902037, 'step': 7518}\n",
      "06/30/2020 16:51:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.50200018606382e-05, 'epoch': 2.0987998883617083, 'step': 7520}\n",
      "06/30/2020 16:51:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5010698669643689e-05, 'epoch': 2.099358079821379, 'step': 7522}\n",
      "06/30/2020 16:51:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5001395478649177e-05, 'epoch': 2.0999162712810495, 'step': 7524}\n",
      "06/30/2020 16:51:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4992092287654665e-05, 'epoch': 2.10047446274072, 'step': 7526}\n",
      "06/30/2020 16:51:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4982789096660154e-05, 'epoch': 2.1010326542003908, 'step': 7528}\n",
      "06/30/2020 16:51:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4973485905665644e-05, 'epoch': 2.1015908456600614, 'step': 7530}\n",
      "06/30/2020 16:51:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4964182714671133e-05, 'epoch': 2.102149037119732, 'step': 7532}\n",
      "06/30/2020 16:51:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4954879523676621e-05, 'epoch': 2.1027072285794026, 'step': 7534}\n",
      "06/30/2020 16:51:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.494557633268211e-05, 'epoch': 2.1032654200390732, 'step': 7536}\n",
      "06/30/2020 16:51:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4936273141687598e-05, 'epoch': 2.103823611498744, 'step': 7538}\n",
      "06/30/2020 16:51:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4926969950693086e-05, 'epoch': 2.104381802958415, 'step': 7540}\n",
      "06/30/2020 16:51:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4917666759698578e-05, 'epoch': 2.1049399944180855, 'step': 7542}\n",
      "06/30/2020 16:51:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4908363568704067e-05, 'epoch': 2.105498185877756, 'step': 7544}\n",
      "06/30/2020 16:51:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4899060377709557e-05, 'epoch': 2.106056377337427, 'step': 7546}\n",
      "06/30/2020 16:51:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4889757186715045e-05, 'epoch': 2.1066145687970974, 'step': 7548}\n",
      "06/30/2020 16:51:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4880453995720534e-05, 'epoch': 2.107172760256768, 'step': 7550}\n",
      "06/30/2020 16:51:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4871150804726022e-05, 'epoch': 2.1077309517164386, 'step': 7552}\n",
      "06/30/2020 16:51:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.486184761373151e-05, 'epoch': 2.1082891431761093, 'step': 7554}\n",
      "06/30/2020 16:51:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4852544422737e-05, 'epoch': 2.10884733463578, 'step': 7556}\n",
      "06/30/2020 16:51:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4843241231742488e-05, 'epoch': 2.1094055260954505, 'step': 7558}\n",
      "06/30/2020 16:51:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4833938040747978e-05, 'epoch': 2.1099637175551216, 'step': 7560}\n",
      "06/30/2020 16:51:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4824634849753466e-05, 'epoch': 2.110521909014792, 'step': 7562}\n",
      "06/30/2020 16:51:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4815331658758955e-05, 'epoch': 2.111080100474463, 'step': 7564}\n",
      "06/30/2020 16:51:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4806028467764443e-05, 'epoch': 2.1116382919341334, 'step': 7566}\n",
      "06/30/2020 16:51:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4796725276769932e-05, 'epoch': 2.112196483393804, 'step': 7568}\n",
      "06/30/2020 16:51:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.478742208577542e-05, 'epoch': 2.1127546748534747, 'step': 7570}\n",
      "06/30/2020 16:51:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.477811889478091e-05, 'epoch': 2.1133128663131453, 'step': 7572}\n",
      "06/30/2020 16:51:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4768815703786399e-05, 'epoch': 2.113871057772816, 'step': 7574}\n",
      "06/30/2020 16:51:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4759512512791887e-05, 'epoch': 2.1144292492324865, 'step': 7576}\n",
      "06/30/2020 16:51:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4750209321797379e-05, 'epoch': 2.1149874406921576, 'step': 7578}\n",
      "06/30/2020 16:51:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4740906130802868e-05, 'epoch': 2.1155456321518282, 'step': 7580}\n",
      "06/30/2020 16:51:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4731602939808356e-05, 'epoch': 2.116103823611499, 'step': 7582}\n",
      "06/30/2020 16:51:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4722299748813844e-05, 'epoch': 2.1166620150711695, 'step': 7584}\n",
      "06/30/2020 16:51:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4712996557819333e-05, 'epoch': 2.11722020653084, 'step': 7586}\n",
      "06/30/2020 16:51:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4703693366824821e-05, 'epoch': 2.1177783979905107, 'step': 7588}\n",
      "06/30/2020 16:51:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4694390175830312e-05, 'epoch': 2.1183365894501813, 'step': 7590}\n",
      "06/30/2020 16:51:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.46850869848358e-05, 'epoch': 2.118894780909852, 'step': 7592}\n",
      "06/30/2020 16:51:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4675783793841289e-05, 'epoch': 2.1194529723695226, 'step': 7594}\n",
      "06/30/2020 16:51:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4666480602846777e-05, 'epoch': 2.1200111638291936, 'step': 7596}\n",
      "06/30/2020 16:51:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4657177411852265e-05, 'epoch': 2.1205693552888643, 'step': 7598}\n",
      "06/30/2020 16:51:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4647874220857754e-05, 'epoch': 2.121127546748535, 'step': 7600}\n",
      "06/30/2020 16:51:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4638571029863244e-05, 'epoch': 2.1216857382082055, 'step': 7602}\n",
      "06/30/2020 16:51:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4629267838868733e-05, 'epoch': 2.122243929667876, 'step': 7604}\n",
      "06/30/2020 16:51:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4619964647874221e-05, 'epoch': 2.1228021211275467, 'step': 7606}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:51:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.461066145687971e-05, 'epoch': 2.1233603125872174, 'step': 7608}\n",
      "06/30/2020 16:51:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4601358265885198e-05, 'epoch': 2.123918504046888, 'step': 7610}\n",
      "06/30/2020 16:51:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4592055074890686e-05, 'epoch': 2.1244766955065586, 'step': 7612}\n",
      "06/30/2020 16:51:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4582751883896177e-05, 'epoch': 2.125034886966229, 'step': 7614}\n",
      "06/30/2020 16:51:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4573448692901667e-05, 'epoch': 2.1255930784259003, 'step': 7616}\n",
      "06/30/2020 16:51:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4564145501907155e-05, 'epoch': 2.126151269885571, 'step': 7618}\n",
      "06/30/2020 16:51:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4554842310912645e-05, 'epoch': 2.1267094613452415, 'step': 7620}\n",
      "06/30/2020 16:51:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4545539119918134e-05, 'epoch': 2.127267652804912, 'step': 7622}\n",
      "06/30/2020 16:51:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4536235928923622e-05, 'epoch': 2.1278258442645828, 'step': 7624}\n",
      "06/30/2020 16:51:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.452693273792911e-05, 'epoch': 2.1283840357242534, 'step': 7626}\n",
      "06/30/2020 16:51:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.45176295469346e-05, 'epoch': 2.128942227183924, 'step': 7628}\n",
      "06/30/2020 16:51:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4508326355940088e-05, 'epoch': 2.1295004186435946, 'step': 7630}\n",
      "06/30/2020 16:51:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4499023164945578e-05, 'epoch': 2.1300586101032652, 'step': 7632}\n",
      "06/30/2020 16:51:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4489719973951066e-05, 'epoch': 2.130616801562936, 'step': 7634}\n",
      "06/30/2020 16:51:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4480416782956555e-05, 'epoch': 2.131174993022607, 'step': 7636}\n",
      "06/30/2020 16:51:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4471113591962043e-05, 'epoch': 2.1317331844822776, 'step': 7638}\n",
      "06/30/2020 16:51:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4461810400967532e-05, 'epoch': 2.132291375941948, 'step': 7640}\n",
      "06/30/2020 16:51:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.445250720997302e-05, 'epoch': 2.132849567401619, 'step': 7642}\n",
      "06/30/2020 16:51:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.444320401897851e-05, 'epoch': 2.1334077588612894, 'step': 7644}\n",
      "06/30/2020 16:51:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4433900827983999e-05, 'epoch': 2.13396595032096, 'step': 7646}\n",
      "06/30/2020 16:51:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4424597636989487e-05, 'epoch': 2.1345241417806307, 'step': 7648}\n",
      "06/30/2020 16:51:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4415294445994976e-05, 'epoch': 2.1350823332403013, 'step': 7650}\n",
      "06/30/2020 16:51:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4405991255000468e-05, 'epoch': 2.135640524699972, 'step': 7652}\n",
      "06/30/2020 16:51:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4396688064005956e-05, 'epoch': 2.136198716159643, 'step': 7654}\n",
      "06/30/2020 16:51:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4387384873011444e-05, 'epoch': 2.1367569076193136, 'step': 7656}\n",
      "06/30/2020 16:51:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4378081682016933e-05, 'epoch': 2.137315099078984, 'step': 7658}\n",
      "06/30/2020 16:51:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4368778491022421e-05, 'epoch': 2.137873290538655, 'step': 7660}\n",
      "06/30/2020 16:51:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4359475300027912e-05, 'epoch': 2.1384314819983254, 'step': 7662}\n",
      "06/30/2020 16:51:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.43501721090334e-05, 'epoch': 2.138989673457996, 'step': 7664}\n",
      "06/30/2020 16:51:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4340868918038888e-05, 'epoch': 2.1395478649176667, 'step': 7666}\n",
      "06/30/2020 16:51:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4331565727044377e-05, 'epoch': 2.1401060563773373, 'step': 7668}\n",
      "06/30/2020 16:51:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4322262536049865e-05, 'epoch': 2.140664247837008, 'step': 7670}\n",
      "06/30/2020 16:51:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4312959345055354e-05, 'epoch': 2.141222439296679, 'step': 7672}\n",
      "06/30/2020 16:51:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4303656154060844e-05, 'epoch': 2.1417806307563496, 'step': 7674}\n",
      "06/30/2020 16:51:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4294352963066332e-05, 'epoch': 2.1423388222160202, 'step': 7676}\n",
      "06/30/2020 16:51:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4285049772071821e-05, 'epoch': 2.142897013675691, 'step': 7678}\n",
      "06/30/2020 16:51:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.427574658107731e-05, 'epoch': 2.1434552051353615, 'step': 7680}\n",
      "06/30/2020 16:51:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4266443390082798e-05, 'epoch': 2.144013396595032, 'step': 7682}\n",
      "06/30/2020 16:51:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4257140199088286e-05, 'epoch': 2.1445715880547027, 'step': 7684}\n",
      "06/30/2020 16:51:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4247837008093776e-05, 'epoch': 2.1451297795143733, 'step': 7686}\n",
      "06/30/2020 16:51:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4238533817099265e-05, 'epoch': 2.145687970974044, 'step': 7688}\n",
      "06/30/2020 16:51:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4229230626104755e-05, 'epoch': 2.1462461624337146, 'step': 7690}\n",
      "06/30/2020 16:51:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4219927435110245e-05, 'epoch': 2.146804353893385, 'step': 7692}\n",
      "06/30/2020 16:51:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4210624244115734e-05, 'epoch': 2.1473625453530563, 'step': 7694}\n",
      "06/30/2020 16:51:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4201321053121222e-05, 'epoch': 2.147920736812727, 'step': 7696}\n",
      "06/30/2020 16:51:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.419201786212671e-05, 'epoch': 2.1484789282723975, 'step': 7698}\n",
      "06/30/2020 16:51:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4182714671132199e-05, 'epoch': 2.149037119732068, 'step': 7700}\n",
      "06/30/2020 16:51:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4173411480137688e-05, 'epoch': 2.1495953111917387, 'step': 7702}\n",
      "06/30/2020 16:51:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4164108289143178e-05, 'epoch': 2.1501535026514094, 'step': 7704}\n",
      "06/30/2020 16:51:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4154805098148666e-05, 'epoch': 2.15071169411108, 'step': 7706}\n",
      "06/30/2020 16:51:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4145501907154155e-05, 'epoch': 2.1512698855707506, 'step': 7708}\n",
      "06/30/2020 16:51:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4136198716159643e-05, 'epoch': 2.1518280770304212, 'step': 7710}\n",
      "06/30/2020 16:51:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4126895525165132e-05, 'epoch': 2.1523862684900923, 'step': 7712}\n",
      "06/30/2020 16:51:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.411759233417062e-05, 'epoch': 2.152944459949763, 'step': 7714}\n",
      "06/30/2020 16:51:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.410828914317611e-05, 'epoch': 2.1535026514094335, 'step': 7716}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:51:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4098985952181599e-05, 'epoch': 2.154060842869104, 'step': 7718}\n",
      "06/30/2020 16:51:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4089682761187087e-05, 'epoch': 2.1546190343287748, 'step': 7720}\n",
      "06/30/2020 16:51:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4080379570192576e-05, 'epoch': 2.1551772257884454, 'step': 7722}\n",
      "06/30/2020 16:51:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4071076379198064e-05, 'epoch': 2.155735417248116, 'step': 7724}\n",
      "06/30/2020 16:51:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4061773188203556e-05, 'epoch': 2.1562936087077866, 'step': 7726}\n",
      "06/30/2020 16:51:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4052469997209044e-05, 'epoch': 2.1568518001674573, 'step': 7728}\n",
      "06/30/2020 16:51:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4043166806214533e-05, 'epoch': 2.1574099916271283, 'step': 7730}\n",
      "06/30/2020 16:51:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4033863615220021e-05, 'epoch': 2.157968183086799, 'step': 7732}\n",
      "06/30/2020 16:51:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4024560424225511e-05, 'epoch': 2.1585263745464696, 'step': 7734}\n",
      "06/30/2020 16:51:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4015257233231e-05, 'epoch': 2.15908456600614, 'step': 7736}\n",
      "06/30/2020 16:51:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4005954042236488e-05, 'epoch': 2.159642757465811, 'step': 7738}\n",
      "06/30/2020 16:51:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3996650851241977e-05, 'epoch': 2.1602009489254814, 'step': 7740}\n",
      "06/30/2020 16:51:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3987347660247465e-05, 'epoch': 2.160759140385152, 'step': 7742}\n",
      "06/30/2020 16:51:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3978044469252954e-05, 'epoch': 2.1613173318448227, 'step': 7744}\n",
      "06/30/2020 16:51:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3968741278258444e-05, 'epoch': 2.1618755233044933, 'step': 7746}\n",
      "06/30/2020 16:51:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3959438087263932e-05, 'epoch': 2.162433714764164, 'step': 7748}\n",
      "06/30/2020 16:51:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3950134896269421e-05, 'epoch': 2.162991906223835, 'step': 7750}\n",
      "06/30/2020 16:51:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.394083170527491e-05, 'epoch': 2.1635500976835056, 'step': 7752}\n",
      "06/30/2020 16:51:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3931528514280398e-05, 'epoch': 2.164108289143176, 'step': 7754}\n",
      "06/30/2020 16:51:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3922225323285886e-05, 'epoch': 2.164666480602847, 'step': 7756}\n",
      "06/30/2020 16:51:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3912922132291375e-05, 'epoch': 2.1652246720625175, 'step': 7758}\n",
      "06/30/2020 16:51:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3903618941296865e-05, 'epoch': 2.165782863522188, 'step': 7760}\n",
      "06/30/2020 16:51:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3894315750302353e-05, 'epoch': 2.1663410549818587, 'step': 7762}\n",
      "06/30/2020 16:51:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3885012559307845e-05, 'epoch': 2.1668992464415293, 'step': 7764}\n",
      "06/30/2020 16:51:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3875709368313334e-05, 'epoch': 2.1674574379012, 'step': 7766}\n",
      "06/30/2020 16:51:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3866406177318822e-05, 'epoch': 2.1680156293608706, 'step': 7768}\n",
      "06/30/2020 16:51:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.385710298632431e-05, 'epoch': 2.1685738208205416, 'step': 7770}\n",
      "06/30/2020 16:51:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3847799795329799e-05, 'epoch': 2.1691320122802122, 'step': 7772}\n",
      "06/30/2020 16:51:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3838496604335288e-05, 'epoch': 2.169690203739883, 'step': 7774}\n",
      "06/30/2020 16:51:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3829193413340778e-05, 'epoch': 2.1702483951995535, 'step': 7776}\n",
      "06/30/2020 16:51:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3819890222346266e-05, 'epoch': 2.170806586659224, 'step': 7778}\n",
      "06/30/2020 16:51:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3810587031351755e-05, 'epoch': 2.1713647781188947, 'step': 7780}\n",
      "06/30/2020 16:51:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3801283840357243e-05, 'epoch': 2.1719229695785653, 'step': 7782}\n",
      "06/30/2020 16:51:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3791980649362732e-05, 'epoch': 2.172481161038236, 'step': 7784}\n",
      "06/30/2020 16:51:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.378267745836822e-05, 'epoch': 2.1730393524979066, 'step': 7786}\n",
      "06/30/2020 16:51:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3773374267373708e-05, 'epoch': 2.1735975439575776, 'step': 7788}\n",
      "06/30/2020 16:51:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3764071076379199e-05, 'epoch': 2.1741557354172483, 'step': 7790}\n",
      "06/30/2020 16:51:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3754767885384687e-05, 'epoch': 2.174713926876919, 'step': 7792}\n",
      "06/30/2020 16:51:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3745464694390176e-05, 'epoch': 2.1752721183365895, 'step': 7794}\n",
      "06/30/2020 16:51:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3736161503395664e-05, 'epoch': 2.17583030979626, 'step': 7796}\n",
      "06/30/2020 16:51:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3726858312401152e-05, 'epoch': 2.1763885012559308, 'step': 7798}\n",
      "06/30/2020 16:51:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3717555121406644e-05, 'epoch': 2.1769466927156014, 'step': 7800}\n",
      "06/30/2020 16:51:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3708251930412133e-05, 'epoch': 2.177504884175272, 'step': 7802}\n",
      "06/30/2020 16:51:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3698948739417621e-05, 'epoch': 2.1780630756349426, 'step': 7804}\n",
      "06/30/2020 16:51:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3689645548423111e-05, 'epoch': 2.1786212670946137, 'step': 7806}\n",
      "06/30/2020 16:51:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.36803423574286e-05, 'epoch': 2.1791794585542843, 'step': 7808}\n",
      "06/30/2020 16:51:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3671039166434088e-05, 'epoch': 2.179737650013955, 'step': 7810}\n",
      "06/30/2020 16:51:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3661735975439577e-05, 'epoch': 2.1802958414736255, 'step': 7812}\n",
      "06/30/2020 16:51:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3652432784445065e-05, 'epoch': 2.180854032933296, 'step': 7814}\n",
      "06/30/2020 16:51:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3643129593450554e-05, 'epoch': 2.181412224392967, 'step': 7816}\n",
      "06/30/2020 16:51:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3633826402456042e-05, 'epoch': 2.1819704158526374, 'step': 7818}\n",
      "06/30/2020 16:51:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3624523211461532e-05, 'epoch': 2.182528607312308, 'step': 7820}\n",
      "06/30/2020 16:51:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.361522002046702e-05, 'epoch': 2.1830867987719786, 'step': 7822}\n",
      "06/30/2020 16:51:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.360591682947251e-05, 'epoch': 2.1836449902316493, 'step': 7824}\n",
      "06/30/2020 16:51:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3596613638477998e-05, 'epoch': 2.1842031816913203, 'step': 7826}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:51:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3587310447483486e-05, 'epoch': 2.184761373150991, 'step': 7828}\n",
      "06/30/2020 16:51:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3578007256488975e-05, 'epoch': 2.1853195646106616, 'step': 7830}\n",
      "06/30/2020 16:51:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3568704065494465e-05, 'epoch': 2.185877756070332, 'step': 7832}\n",
      "06/30/2020 16:51:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3559400874499953e-05, 'epoch': 2.186435947530003, 'step': 7834}\n",
      "06/30/2020 16:51:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3550097683505445e-05, 'epoch': 2.1869941389896734, 'step': 7836}\n",
      "06/30/2020 16:51:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3540794492510934e-05, 'epoch': 2.187552330449344, 'step': 7838}\n",
      "06/30/2020 16:51:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3531491301516422e-05, 'epoch': 2.1881105219090147, 'step': 7840}\n",
      "06/30/2020 16:51:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.352218811052191e-05, 'epoch': 2.1886687133686853, 'step': 7842}\n",
      "06/30/2020 16:51:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3512884919527399e-05, 'epoch': 2.189226904828356, 'step': 7844}\n",
      "06/30/2020 16:51:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3503581728532887e-05, 'epoch': 2.189785096288027, 'step': 7846}\n",
      "06/30/2020 16:51:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3494278537538378e-05, 'epoch': 2.1903432877476976, 'step': 7848}\n",
      "06/30/2020 16:51:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3484975346543866e-05, 'epoch': 2.190901479207368, 'step': 7850}\n",
      "06/30/2020 16:51:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3475672155549355e-05, 'epoch': 2.191459670667039, 'step': 7852}\n",
      "06/30/2020 16:51:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3466368964554843e-05, 'epoch': 2.1920178621267095, 'step': 7854}\n",
      "06/30/2020 16:51:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3457065773560331e-05, 'epoch': 2.19257605358638, 'step': 7856}\n",
      "06/30/2020 16:51:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.344776258256582e-05, 'epoch': 2.1931342450460507, 'step': 7858}\n",
      "06/30/2020 16:51:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3438459391571308e-05, 'epoch': 2.1936924365057213, 'step': 7860}\n",
      "06/30/2020 16:51:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3429156200576799e-05, 'epoch': 2.194250627965392, 'step': 7862}\n",
      "06/30/2020 16:51:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3419853009582287e-05, 'epoch': 2.194808819425063, 'step': 7864}\n",
      "06/30/2020 16:51:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3410549818587775e-05, 'epoch': 2.1953670108847336, 'step': 7866}\n",
      "06/30/2020 16:51:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3401246627593264e-05, 'epoch': 2.1959252023444042, 'step': 7868}\n",
      "06/30/2020 16:51:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3391943436598752e-05, 'epoch': 2.196483393804075, 'step': 7870}\n",
      "06/30/2020 16:51:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3382640245604241e-05, 'epoch': 2.1970415852637455, 'step': 7872}\n",
      "06/30/2020 16:51:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3373337054609733e-05, 'epoch': 2.197599776723416, 'step': 7874}\n",
      "06/30/2020 16:51:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3364033863615221e-05, 'epoch': 2.1981579681830867, 'step': 7876}\n",
      "06/30/2020 16:51:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3354730672620711e-05, 'epoch': 2.1987161596427574, 'step': 7878}\n",
      "06/30/2020 16:51:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.33454274816262e-05, 'epoch': 2.199274351102428, 'step': 7880}\n",
      "06/30/2020 16:51:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3336124290631688e-05, 'epoch': 2.1998325425620986, 'step': 7882}\n",
      "06/30/2020 16:51:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3326821099637177e-05, 'epoch': 2.2003907340217697, 'step': 7884}\n",
      "06/30/2020 16:51:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3317517908642665e-05, 'epoch': 2.2009489254814403, 'step': 7886}\n",
      "06/30/2020 16:51:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3308214717648154e-05, 'epoch': 2.201507116941111, 'step': 7888}\n",
      "06/30/2020 16:51:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3298911526653642e-05, 'epoch': 2.2020653084007815, 'step': 7890}\n",
      "06/30/2020 16:51:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3289608335659132e-05, 'epoch': 2.202623499860452, 'step': 7892}\n",
      "06/30/2020 16:51:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.328030514466462e-05, 'epoch': 2.2031816913201228, 'step': 7894}\n",
      "06/30/2020 16:51:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.327100195367011e-05, 'epoch': 2.2037398827797934, 'step': 7896}\n",
      "06/30/2020 16:51:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3261698762675598e-05, 'epoch': 2.204298074239464, 'step': 7898}\n",
      "06/30/2020 16:51:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3252395571681086e-05, 'epoch': 2.2048562656991346, 'step': 7900}\n",
      "06/30/2020 16:51:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3243092380686575e-05, 'epoch': 2.2054144571588052, 'step': 7902}\n",
      "06/30/2020 16:51:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3233789189692065e-05, 'epoch': 2.2059726486184763, 'step': 7904}\n",
      "06/30/2020 16:51:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3224485998697553e-05, 'epoch': 2.206530840078147, 'step': 7906}\n",
      "06/30/2020 16:51:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3215182807703042e-05, 'epoch': 2.2070890315378175, 'step': 7908}\n",
      "06/30/2020 16:51:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3205879616708534e-05, 'epoch': 2.207647222997488, 'step': 7910}\n",
      "06/30/2020 16:51:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3196576425714022e-05, 'epoch': 2.208205414457159, 'step': 7912}\n",
      "06/30/2020 16:51:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.318727323471951e-05, 'epoch': 2.2087636059168294, 'step': 7914}\n",
      "06/30/2020 16:51:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3177970043724999e-05, 'epoch': 2.2093217973765, 'step': 7916}\n",
      "06/30/2020 16:51:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3168666852730487e-05, 'epoch': 2.2098799888361707, 'step': 7918}\n",
      "06/30/2020 16:51:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3159363661735976e-05, 'epoch': 2.2104381802958413, 'step': 7920}\n",
      "06/30/2020 16:51:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3150060470741466e-05, 'epoch': 2.2109963717555123, 'step': 7922}\n",
      "06/30/2020 16:51:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3140757279746954e-05, 'epoch': 2.211554563215183, 'step': 7924}\n",
      "06/30/2020 16:51:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3131454088752443e-05, 'epoch': 2.2121127546748536, 'step': 7926}\n",
      "06/30/2020 16:51:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3122150897757931e-05, 'epoch': 2.212670946134524, 'step': 7928}\n",
      "06/30/2020 16:51:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.311284770676342e-05, 'epoch': 2.213229137594195, 'step': 7930}\n",
      "06/30/2020 16:51:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3103544515768908e-05, 'epoch': 2.2137873290538654, 'step': 7932}\n",
      "06/30/2020 16:51:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3094241324774399e-05, 'epoch': 2.214345520513536, 'step': 7934}\n",
      "06/30/2020 16:51:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3084938133779887e-05, 'epoch': 2.2149037119732067, 'step': 7936}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:51:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3075634942785375e-05, 'epoch': 2.2154619034328773, 'step': 7938}\n",
      "06/30/2020 16:51:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3066331751790864e-05, 'epoch': 2.2160200948925484, 'step': 7940}\n",
      "06/30/2020 16:51:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3057028560796352e-05, 'epoch': 2.216578286352219, 'step': 7942}\n",
      "06/30/2020 16:51:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.304772536980184e-05, 'epoch': 2.2171364778118896, 'step': 7944}\n",
      "06/30/2020 16:51:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3038422178807331e-05, 'epoch': 2.2176946692715602, 'step': 7946}\n",
      "06/30/2020 16:51:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3029118987812821e-05, 'epoch': 2.218252860731231, 'step': 7948}\n",
      "06/30/2020 16:51:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.301981579681831e-05, 'epoch': 2.2188110521909015, 'step': 7950}\n",
      "06/30/2020 16:51:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.30105126058238e-05, 'epoch': 2.219369243650572, 'step': 7952}\n",
      "06/30/2020 16:51:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3001209414829288e-05, 'epoch': 2.2199274351102427, 'step': 7954}\n",
      "06/30/2020 16:51:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2991906223834777e-05, 'epoch': 2.2204856265699133, 'step': 7956}\n",
      "06/30/2020 16:51:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2982603032840265e-05, 'epoch': 2.221043818029584, 'step': 7958}\n",
      "06/30/2020 16:51:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2973299841845754e-05, 'epoch': 2.221602009489255, 'step': 7960}\n",
      "06/30/2020 16:51:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2963996650851242e-05, 'epoch': 2.2221602009489256, 'step': 7962}\n",
      "06/30/2020 16:51:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2954693459856732e-05, 'epoch': 2.2227183924085963, 'step': 7964}\n",
      "06/30/2020 16:51:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.294539026886222e-05, 'epoch': 2.223276583868267, 'step': 7966}\n",
      "06/30/2020 16:51:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.293608707786771e-05, 'epoch': 2.2238347753279375, 'step': 7968}\n",
      "06/30/2020 16:51:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2926783886873198e-05, 'epoch': 2.224392966787608, 'step': 7970}\n",
      "06/30/2020 16:51:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2917480695878686e-05, 'epoch': 2.2249511582472787, 'step': 7972}\n",
      "06/30/2020 16:51:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2908177504884175e-05, 'epoch': 2.2255093497069494, 'step': 7974}\n",
      "06/30/2020 16:51:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2898874313889665e-05, 'epoch': 2.22606754116662, 'step': 7976}\n",
      "06/30/2020 16:51:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2889571122895153e-05, 'epoch': 2.2266257326262906, 'step': 7978}\n",
      "06/30/2020 16:51:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2880267931900642e-05, 'epoch': 2.2271839240859617, 'step': 7980}\n",
      "06/30/2020 16:51:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.287096474090613e-05, 'epoch': 2.2277421155456323, 'step': 7982}\n",
      "06/30/2020 16:51:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2861661549911622e-05, 'epoch': 2.228300307005303, 'step': 7984}\n",
      "06/30/2020 16:51:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.285235835891711e-05, 'epoch': 2.2288584984649735, 'step': 7986}\n",
      "06/30/2020 16:51:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2843055167922599e-05, 'epoch': 2.229416689924644, 'step': 7988}\n",
      "06/30/2020 16:51:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2833751976928087e-05, 'epoch': 2.2299748813843148, 'step': 7990}\n",
      "06/30/2020 16:51:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2824448785933576e-05, 'epoch': 2.2305330728439854, 'step': 7992}\n",
      "06/30/2020 16:51:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2815145594939066e-05, 'epoch': 2.231091264303656, 'step': 7994}\n",
      "06/30/2020 16:51:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2805842403944554e-05, 'epoch': 2.2316494557633266, 'step': 7996}\n",
      "06/30/2020 16:51:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2796539212950043e-05, 'epoch': 2.2322076472229977, 'step': 7998}\n",
      "06/30/2020 16:51:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2787236021955531e-05, 'epoch': 2.2327658386826683, 'step': 8000}\n",
      "06/30/2020 16:51:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.277793283096102e-05, 'epoch': 2.233324030142339, 'step': 8002}\n",
      "06/30/2020 16:51:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2768629639966508e-05, 'epoch': 2.2338822216020096, 'step': 8004}\n",
      "06/30/2020 16:51:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2759326448971998e-05, 'epoch': 2.23444041306168, 'step': 8006}\n",
      "06/30/2020 16:51:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2750023257977487e-05, 'epoch': 2.234998604521351, 'step': 8008}\n",
      "06/30/2020 16:51:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2740720066982975e-05, 'epoch': 2.2355567959810214, 'step': 8010}\n",
      "06/30/2020 16:51:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2731416875988464e-05, 'epoch': 2.236114987440692, 'step': 8012}\n",
      "06/30/2020 16:51:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2722113684993952e-05, 'epoch': 2.2366731789003627, 'step': 8014}\n",
      "06/30/2020 16:51:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.271281049399944e-05, 'epoch': 2.2372313703600337, 'step': 8016}\n",
      "06/30/2020 16:51:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2703507303004931e-05, 'epoch': 2.2377895618197043, 'step': 8018}\n",
      "06/30/2020 16:51:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.269420411201042e-05, 'epoch': 2.238347753279375, 'step': 8020}\n",
      "06/30/2020 16:51:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.268490092101591e-05, 'epoch': 2.2389059447390456, 'step': 8022}\n",
      "06/30/2020 16:51:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.26755977300214e-05, 'epoch': 2.239464136198716, 'step': 8024}\n",
      "06/30/2020 16:51:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2666294539026888e-05, 'epoch': 2.240022327658387, 'step': 8026}\n",
      "06/30/2020 16:51:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2656991348032377e-05, 'epoch': 2.2405805191180574, 'step': 8028}\n",
      "06/30/2020 16:51:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2647688157037865e-05, 'epoch': 2.241138710577728, 'step': 8030}\n",
      "06/30/2020 16:51:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2638384966043354e-05, 'epoch': 2.2416969020373987, 'step': 8032}\n",
      "06/30/2020 16:51:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2629081775048842e-05, 'epoch': 2.2422550934970693, 'step': 8034}\n",
      "06/30/2020 16:51:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2619778584054332e-05, 'epoch': 2.24281328495674, 'step': 8036}\n",
      "06/30/2020 16:51:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.261047539305982e-05, 'epoch': 2.243371476416411, 'step': 8038}\n",
      "06/30/2020 16:51:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2601172202065309e-05, 'epoch': 2.2439296678760816, 'step': 8040}\n",
      "06/30/2020 16:51:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2591869011070798e-05, 'epoch': 2.2444878593357522, 'step': 8042}\n",
      "06/30/2020 16:51:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2582565820076286e-05, 'epoch': 2.245046050795423, 'step': 8044}\n",
      "06/30/2020 16:51:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2573262629081774e-05, 'epoch': 2.2456042422550935, 'step': 8046}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:51:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2563959438087265e-05, 'epoch': 2.246162433714764, 'step': 8048}\n",
      "06/30/2020 16:51:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2554656247092753e-05, 'epoch': 2.2467206251744347, 'step': 8050}\n",
      "06/30/2020 16:51:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2545353056098242e-05, 'epoch': 2.2472788166341053, 'step': 8052}\n",
      "06/30/2020 16:51:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.253604986510373e-05, 'epoch': 2.247837008093776, 'step': 8054}\n",
      "06/30/2020 16:51:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2526746674109219e-05, 'epoch': 2.248395199553447, 'step': 8056}\n",
      "06/30/2020 16:52:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.251744348311471e-05, 'epoch': 2.2489533910131176, 'step': 8058}\n",
      "06/30/2020 16:52:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2508140292120199e-05, 'epoch': 2.2495115824727883, 'step': 8060}\n",
      "06/30/2020 16:52:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2498837101125686e-05, 'epoch': 2.250069773932459, 'step': 8062}\n",
      "06/30/2020 16:52:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2489533910131176e-05, 'epoch': 2.2506279653921295, 'step': 8064}\n",
      "06/30/2020 16:52:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2480230719136664e-05, 'epoch': 2.2511861568518, 'step': 8066}\n",
      "06/30/2020 16:52:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2470927528142154e-05, 'epoch': 2.2517443483114707, 'step': 8068}\n",
      "06/30/2020 16:52:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2461624337147643e-05, 'epoch': 2.2523025397711414, 'step': 8070}\n",
      "06/30/2020 16:52:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2452321146153131e-05, 'epoch': 2.252860731230812, 'step': 8072}\n",
      "06/30/2020 16:52:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.244301795515862e-05, 'epoch': 2.253418922690483, 'step': 8074}\n",
      "06/30/2020 16:52:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2433714764164108e-05, 'epoch': 2.2539771141501537, 'step': 8076}\n",
      "06/30/2020 16:52:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2424411573169598e-05, 'epoch': 2.2545353056098243, 'step': 8078}\n",
      "06/30/2020 16:52:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2415108382175087e-05, 'epoch': 2.255093497069495, 'step': 8080}\n",
      "06/30/2020 16:52:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2405805191180575e-05, 'epoch': 2.2556516885291655, 'step': 8082}\n",
      "06/30/2020 16:52:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2396502000186064e-05, 'epoch': 2.256209879988836, 'step': 8084}\n",
      "06/30/2020 16:52:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2387198809191554e-05, 'epoch': 2.2567680714485068, 'step': 8086}\n",
      "06/30/2020 16:52:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2377895618197042e-05, 'epoch': 2.2573262629081774, 'step': 8088}\n",
      "06/30/2020 16:52:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2368592427202531e-05, 'epoch': 2.257884454367848, 'step': 8090}\n",
      "06/30/2020 16:52:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.235928923620802e-05, 'epoch': 2.258442645827519, 'step': 8092}\n",
      "06/30/2020 16:52:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.234998604521351e-05, 'epoch': 2.2590008372871897, 'step': 8094}\n",
      "06/30/2020 16:52:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2340682854218998e-05, 'epoch': 2.2595590287468603, 'step': 8096}\n",
      "06/30/2020 16:52:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2331379663224486e-05, 'epoch': 2.260117220206531, 'step': 8098}\n",
      "06/30/2020 16:52:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2322076472229975e-05, 'epoch': 2.2606754116662016, 'step': 8100}\n",
      "06/30/2020 16:52:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2312773281235463e-05, 'epoch': 2.261233603125872, 'step': 8102}\n",
      "06/30/2020 16:52:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2303470090240954e-05, 'epoch': 2.261791794585543, 'step': 8104}\n",
      "06/30/2020 16:52:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2294166899246442e-05, 'epoch': 2.2623499860452134, 'step': 8106}\n",
      "06/30/2020 16:52:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2284863708251932e-05, 'epoch': 2.262908177504884, 'step': 8108}\n",
      "06/30/2020 16:52:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.227556051725742e-05, 'epoch': 2.2634663689645547, 'step': 8110}\n",
      "06/30/2020 16:52:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2266257326262909e-05, 'epoch': 2.2640245604242253, 'step': 8112}\n",
      "06/30/2020 16:52:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2256954135268398e-05, 'epoch': 2.2645827518838963, 'step': 8114}\n",
      "06/30/2020 16:52:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2247650944273886e-05, 'epoch': 2.265140943343567, 'step': 8116}\n",
      "06/30/2020 16:52:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2238347753279374e-05, 'epoch': 2.2656991348032376, 'step': 8118}\n",
      "06/30/2020 16:52:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2229044562284863e-05, 'epoch': 2.266257326262908, 'step': 8120}\n",
      "06/30/2020 16:52:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2219741371290353e-05, 'epoch': 2.266815517722579, 'step': 8122}\n",
      "06/30/2020 16:52:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2210438180295843e-05, 'epoch': 2.2673737091822495, 'step': 8124}\n",
      "06/30/2020 16:52:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2201134989301332e-05, 'epoch': 2.26793190064192, 'step': 8126}\n",
      "06/30/2020 16:52:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.219183179830682e-05, 'epoch': 2.2684900921015907, 'step': 8128}\n",
      "06/30/2020 16:52:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2182528607312309e-05, 'epoch': 2.2690482835612613, 'step': 8130}\n",
      "06/30/2020 16:52:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2173225416317797e-05, 'epoch': 2.2696064750209324, 'step': 8132}\n",
      "06/30/2020 16:52:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2163922225323286e-05, 'epoch': 2.270164666480603, 'step': 8134}\n",
      "06/30/2020 16:52:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2154619034328776e-05, 'epoch': 2.2707228579402736, 'step': 8136}\n",
      "06/30/2020 16:52:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2145315843334264e-05, 'epoch': 2.2712810493999442, 'step': 8138}\n",
      "06/30/2020 16:52:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2136012652339753e-05, 'epoch': 2.271839240859615, 'step': 8140}\n",
      "06/30/2020 16:52:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2126709461345243e-05, 'epoch': 2.2723974323192855, 'step': 8142}\n",
      "06/30/2020 16:52:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2117406270350731e-05, 'epoch': 2.272955623778956, 'step': 8144}\n",
      "06/30/2020 16:52:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.210810307935622e-05, 'epoch': 2.2735138152386267, 'step': 8146}\n",
      "06/30/2020 16:52:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2098799888361708e-05, 'epoch': 2.2740720066982973, 'step': 8148}\n",
      "06/30/2020 16:52:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2089496697367197e-05, 'epoch': 2.2746301981579684, 'step': 8150}\n",
      "06/30/2020 16:52:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2080193506372687e-05, 'epoch': 2.275188389617639, 'step': 8152}\n",
      "06/30/2020 16:52:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2070890315378175e-05, 'epoch': 2.2757465810773096, 'step': 8154}\n",
      "06/30/2020 16:52:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2061587124383664e-05, 'epoch': 2.2763047725369803, 'step': 8156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:52:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2052283933389152e-05, 'epoch': 2.276862963996651, 'step': 8158}\n",
      "06/30/2020 16:52:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2042980742394642e-05, 'epoch': 2.2774211554563215, 'step': 8160}\n",
      "06/30/2020 16:52:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.203367755140013e-05, 'epoch': 2.277979346915992, 'step': 8162}\n",
      "06/30/2020 16:52:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.202437436040562e-05, 'epoch': 2.2785375383756628, 'step': 8164}\n",
      "06/30/2020 16:52:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.201507116941111e-05, 'epoch': 2.2790957298353334, 'step': 8166}\n",
      "06/30/2020 16:52:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2005767978416598e-05, 'epoch': 2.279653921295004, 'step': 8168}\n",
      "06/30/2020 16:52:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1996464787422086e-05, 'epoch': 2.2802121127546746, 'step': 8170}\n",
      "06/30/2020 16:52:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1987161596427575e-05, 'epoch': 2.2807703042143457, 'step': 8172}\n",
      "06/30/2020 16:52:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1977858405433063e-05, 'epoch': 2.2813284956740163, 'step': 8174}\n",
      "06/30/2020 16:52:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1968555214438552e-05, 'epoch': 2.281886687133687, 'step': 8176}\n",
      "06/30/2020 16:52:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1959252023444042e-05, 'epoch': 2.2824448785933575, 'step': 8178}\n",
      "06/30/2020 16:52:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1949948832449532e-05, 'epoch': 2.283003070053028, 'step': 8180}\n",
      "06/30/2020 16:52:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.194064564145502e-05, 'epoch': 2.283561261512699, 'step': 8182}\n",
      "06/30/2020 16:52:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1931342450460509e-05, 'epoch': 2.2841194529723694, 'step': 8184}\n",
      "06/30/2020 16:52:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1922039259465997e-05, 'epoch': 2.28467764443204, 'step': 8186}\n",
      "06/30/2020 16:52:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1912736068471486e-05, 'epoch': 2.2852358358917106, 'step': 8188}\n",
      "06/30/2020 16:52:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1903432877476974e-05, 'epoch': 2.2857940273513817, 'step': 8190}\n",
      "06/30/2020 16:52:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1894129686482463e-05, 'epoch': 2.2863522188110523, 'step': 8192}\n",
      "06/30/2020 16:52:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1884826495487953e-05, 'epoch': 2.286910410270723, 'step': 8194}\n",
      "06/30/2020 16:52:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1875523304493443e-05, 'epoch': 2.2874686017303936, 'step': 8196}\n",
      "06/30/2020 16:52:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1866220113498932e-05, 'epoch': 2.288026793190064, 'step': 8198}\n",
      "06/30/2020 16:52:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.185691692250442e-05, 'epoch': 2.288584984649735, 'step': 8200}\n",
      "06/30/2020 16:52:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1847613731509909e-05, 'epoch': 2.2891431761094054, 'step': 8202}\n",
      "06/30/2020 16:52:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1838310540515397e-05, 'epoch': 2.289701367569076, 'step': 8204}\n",
      "06/30/2020 16:52:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1829007349520885e-05, 'epoch': 2.2902595590287467, 'step': 8206}\n",
      "06/30/2020 16:52:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1819704158526376e-05, 'epoch': 2.2908177504884177, 'step': 8208}\n",
      "06/30/2020 16:52:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1810400967531864e-05, 'epoch': 2.2913759419480884, 'step': 8210}\n",
      "06/30/2020 16:52:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1801097776537353e-05, 'epoch': 2.291934133407759, 'step': 8212}\n",
      "06/30/2020 16:52:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1791794585542843e-05, 'epoch': 2.2924923248674296, 'step': 8214}\n",
      "06/30/2020 16:52:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1782491394548331e-05, 'epoch': 2.2930505163271, 'step': 8216}\n",
      "06/30/2020 16:52:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.177318820355382e-05, 'epoch': 2.293608707786771, 'step': 8218}\n",
      "06/30/2020 16:52:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1763885012559308e-05, 'epoch': 2.2941668992464415, 'step': 8220}\n",
      "06/30/2020 16:52:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1754581821564797e-05, 'epoch': 2.294725090706112, 'step': 8222}\n",
      "06/30/2020 16:52:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1745278630570287e-05, 'epoch': 2.2952832821657827, 'step': 8224}\n",
      "06/30/2020 16:52:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1735975439575775e-05, 'epoch': 2.2958414736254538, 'step': 8226}\n",
      "06/30/2020 16:52:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1726672248581264e-05, 'epoch': 2.2963996650851244, 'step': 8228}\n",
      "06/30/2020 16:52:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1717369057586752e-05, 'epoch': 2.296957856544795, 'step': 8230}\n",
      "06/30/2020 16:52:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.170806586659224e-05, 'epoch': 2.2975160480044656, 'step': 8232}\n",
      "06/30/2020 16:52:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.169876267559773e-05, 'epoch': 2.2980742394641362, 'step': 8234}\n",
      "06/30/2020 16:52:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.168945948460322e-05, 'epoch': 2.298632430923807, 'step': 8236}\n",
      "06/30/2020 16:52:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.168015629360871e-05, 'epoch': 2.2991906223834775, 'step': 8238}\n",
      "06/30/2020 16:52:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1670853102614198e-05, 'epoch': 2.299748813843148, 'step': 8240}\n",
      "06/30/2020 16:52:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1661549911619686e-05, 'epoch': 2.3003070053028187, 'step': 8242}\n",
      "06/30/2020 16:52:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1652246720625175e-05, 'epoch': 2.3008651967624894, 'step': 8244}\n",
      "06/30/2020 16:52:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1642943529630663e-05, 'epoch': 2.30142338822216, 'step': 8246}\n",
      "06/30/2020 16:52:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1633640338636152e-05, 'epoch': 2.301981579681831, 'step': 8248}\n",
      "06/30/2020 16:52:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.162433714764164e-05, 'epoch': 2.3025397711415017, 'step': 8250}\n",
      "06/30/2020 16:52:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.161503395664713e-05, 'epoch': 2.3030979626011723, 'step': 8252}\n",
      "06/30/2020 16:52:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.160573076565262e-05, 'epoch': 2.303656154060843, 'step': 8254}\n",
      "06/30/2020 16:52:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1596427574658109e-05, 'epoch': 2.3042143455205135, 'step': 8256}\n",
      "06/30/2020 16:52:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1587124383663597e-05, 'epoch': 2.304772536980184, 'step': 8258}\n",
      "06/30/2020 16:52:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1577821192669086e-05, 'epoch': 2.3053307284398548, 'step': 8260}\n",
      "06/30/2020 16:52:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1568518001674574e-05, 'epoch': 2.3058889198995254, 'step': 8262}\n",
      "06/30/2020 16:52:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1559214810680063e-05, 'epoch': 2.306447111359196, 'step': 8264}\n",
      "06/30/2020 16:52:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1549911619685553e-05, 'epoch': 2.307005302818867, 'step': 8266}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:52:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1540608428691041e-05, 'epoch': 2.3075634942785377, 'step': 8268}\n",
      "06/30/2020 16:52:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1531305237696532e-05, 'epoch': 2.3081216857382083, 'step': 8270}\n",
      "06/30/2020 16:52:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.152200204670202e-05, 'epoch': 2.308679877197879, 'step': 8272}\n",
      "06/30/2020 16:52:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1512698855707509e-05, 'epoch': 2.3092380686575495, 'step': 8274}\n",
      "06/30/2020 16:52:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1503395664712997e-05, 'epoch': 2.30979626011722, 'step': 8276}\n",
      "06/30/2020 16:52:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1494092473718485e-05, 'epoch': 2.310354451576891, 'step': 8278}\n",
      "06/30/2020 16:52:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1484789282723976e-05, 'epoch': 2.3109126430365614, 'step': 8280}\n",
      "06/30/2020 16:52:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1475486091729464e-05, 'epoch': 2.311470834496232, 'step': 8282}\n",
      "06/30/2020 16:52:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1466182900734953e-05, 'epoch': 2.312029025955903, 'step': 8284}\n",
      "06/30/2020 16:52:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1456879709740441e-05, 'epoch': 2.3125872174155737, 'step': 8286}\n",
      "06/30/2020 16:52:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1447576518745931e-05, 'epoch': 2.3131454088752443, 'step': 8288}\n",
      "06/30/2020 16:52:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.143827332775142e-05, 'epoch': 2.313703600334915, 'step': 8290}\n",
      "06/30/2020 16:52:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1428970136756908e-05, 'epoch': 2.3142617917945856, 'step': 8292}\n",
      "06/30/2020 16:52:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1419666945762397e-05, 'epoch': 2.314819983254256, 'step': 8294}\n",
      "06/30/2020 16:52:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1410363754767887e-05, 'epoch': 2.315378174713927, 'step': 8296}\n",
      "06/30/2020 16:52:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1401060563773375e-05, 'epoch': 2.3159363661735974, 'step': 8298}\n",
      "06/30/2020 16:52:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1391757372778864e-05, 'epoch': 2.316494557633268, 'step': 8300}\n",
      "06/30/2020 16:52:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1382454181784352e-05, 'epoch': 2.317052749092939, 'step': 8302}\n",
      "06/30/2020 16:52:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.137315099078984e-05, 'epoch': 2.3176109405526093, 'step': 8304}\n",
      "06/30/2020 16:52:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1363847799795329e-05, 'epoch': 2.3181691320122804, 'step': 8306}\n",
      "06/30/2020 16:52:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.135454460880082e-05, 'epoch': 2.318727323471951, 'step': 8308}\n",
      "06/30/2020 16:52:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.134524141780631e-05, 'epoch': 2.3192855149316216, 'step': 8310}\n",
      "06/30/2020 16:52:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1335938226811798e-05, 'epoch': 2.3198437063912922, 'step': 8312}\n",
      "06/30/2020 16:52:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1326635035817286e-05, 'epoch': 2.320401897850963, 'step': 8314}\n",
      "06/30/2020 16:52:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1317331844822775e-05, 'epoch': 2.3209600893106335, 'step': 8316}\n",
      "06/30/2020 16:52:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1308028653828263e-05, 'epoch': 2.321518280770304, 'step': 8318}\n",
      "06/30/2020 16:52:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1298725462833752e-05, 'epoch': 2.3220764722299747, 'step': 8320}\n",
      "06/30/2020 16:52:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.128942227183924e-05, 'epoch': 2.3226346636896453, 'step': 8322}\n",
      "06/30/2020 16:52:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.128011908084473e-05, 'epoch': 2.3231928551493164, 'step': 8324}\n",
      "06/30/2020 16:52:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.127081588985022e-05, 'epoch': 2.323751046608987, 'step': 8326}\n",
      "06/30/2020 16:52:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1261512698855709e-05, 'epoch': 2.3243092380686576, 'step': 8328}\n",
      "06/30/2020 16:52:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1252209507861197e-05, 'epoch': 2.3248674295283283, 'step': 8330}\n",
      "06/30/2020 16:52:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1242906316866686e-05, 'epoch': 2.325425620987999, 'step': 8332}\n",
      "06/30/2020 16:52:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1233603125872174e-05, 'epoch': 2.3259838124476695, 'step': 8334}\n",
      "06/30/2020 16:52:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1224299934877663e-05, 'epoch': 2.32654200390734, 'step': 8336}\n",
      "06/30/2020 16:52:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1214996743883153e-05, 'epoch': 2.3271001953670107, 'step': 8338}\n",
      "06/30/2020 16:52:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1205693552888641e-05, 'epoch': 2.3276583868266814, 'step': 8340}\n",
      "06/30/2020 16:52:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.119639036189413e-05, 'epoch': 2.3282165782863524, 'step': 8342}\n",
      "06/30/2020 16:52:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.118708717089962e-05, 'epoch': 2.328774769746023, 'step': 8344}\n",
      "06/30/2020 16:52:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1177783979905108e-05, 'epoch': 2.3293329612056937, 'step': 8346}\n",
      "06/30/2020 16:52:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1168480788910597e-05, 'epoch': 2.3298911526653643, 'step': 8348}\n",
      "06/30/2020 16:52:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1159177597916085e-05, 'epoch': 2.330449344125035, 'step': 8350}\n",
      "06/30/2020 16:52:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1149874406921574e-05, 'epoch': 2.3310075355847055, 'step': 8352}\n",
      "06/30/2020 16:52:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1140571215927064e-05, 'epoch': 2.331565727044376, 'step': 8354}\n",
      "06/30/2020 16:52:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1131268024932552e-05, 'epoch': 2.3321239185040468, 'step': 8356}\n",
      "06/30/2020 16:52:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1121964833938041e-05, 'epoch': 2.3326821099637174, 'step': 8358}\n",
      "06/30/2020 16:52:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.111266164294353e-05, 'epoch': 2.3332403014233885, 'step': 8360}\n",
      "06/30/2020 16:52:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.110335845194902e-05, 'epoch': 2.333798492883059, 'step': 8362}\n",
      "06/30/2020 16:52:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1094055260954508e-05, 'epoch': 2.3343566843427297, 'step': 8364}\n",
      "06/30/2020 16:52:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1084752069959996e-05, 'epoch': 2.3349148758024003, 'step': 8366}\n",
      "06/30/2020 16:52:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1075448878965487e-05, 'epoch': 2.335473067262071, 'step': 8368}\n",
      "06/30/2020 16:52:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1066145687970975e-05, 'epoch': 2.3360312587217416, 'step': 8370}\n",
      "06/30/2020 16:52:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1056842496976464e-05, 'epoch': 2.336589450181412, 'step': 8372}\n",
      "06/30/2020 16:52:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1047539305981952e-05, 'epoch': 2.337147641641083, 'step': 8374}\n",
      "06/30/2020 16:52:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.103823611498744e-05, 'epoch': 2.3377058331007534, 'step': 8376}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:52:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1028932923992929e-05, 'epoch': 2.338264024560424, 'step': 8378}\n",
      "06/30/2020 16:52:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1019629732998419e-05, 'epoch': 2.3388222160200947, 'step': 8380}\n",
      "06/30/2020 16:52:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1010326542003908e-05, 'epoch': 2.3393804074797657, 'step': 8382}\n",
      "06/30/2020 16:52:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1001023351009398e-05, 'epoch': 2.3399385989394363, 'step': 8384}\n",
      "06/30/2020 16:52:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0991720160014886e-05, 'epoch': 2.340496790399107, 'step': 8386}\n",
      "06/30/2020 16:52:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0982416969020375e-05, 'epoch': 2.3410549818587776, 'step': 8388}\n",
      "06/30/2020 16:52:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0973113778025863e-05, 'epoch': 2.341613173318448, 'step': 8390}\n",
      "06/30/2020 16:52:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0963810587031352e-05, 'epoch': 2.342171364778119, 'step': 8392}\n",
      "06/30/2020 16:52:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.095450739603684e-05, 'epoch': 2.3427295562377894, 'step': 8394}\n",
      "06/30/2020 16:52:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.094520420504233e-05, 'epoch': 2.34328774769746, 'step': 8396}\n",
      "06/30/2020 16:52:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0935901014047819e-05, 'epoch': 2.3438459391571307, 'step': 8398}\n",
      "06/30/2020 16:52:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0926597823053309e-05, 'epoch': 2.3444041306168018, 'step': 8400}\n",
      "06/30/2020 16:52:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0917294632058797e-05, 'epoch': 2.3449623220764724, 'step': 8402}\n",
      "06/30/2020 16:52:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0907991441064286e-05, 'epoch': 2.345520513536143, 'step': 8404}\n",
      "06/30/2020 16:52:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0898688250069774e-05, 'epoch': 2.3460787049958136, 'step': 8406}\n",
      "06/30/2020 16:52:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0889385059075263e-05, 'epoch': 2.3466368964554842, 'step': 8408}\n",
      "06/30/2020 16:52:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0880081868080753e-05, 'epoch': 2.347195087915155, 'step': 8410}\n",
      "06/30/2020 16:52:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0870778677086241e-05, 'epoch': 2.3477532793748255, 'step': 8412}\n",
      "06/30/2020 16:52:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.086147548609173e-05, 'epoch': 2.348311470834496, 'step': 8414}\n",
      "06/30/2020 16:52:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0852172295097218e-05, 'epoch': 2.3488696622941667, 'step': 8416}\n",
      "06/30/2020 16:52:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0842869104102708e-05, 'epoch': 2.349427853753838, 'step': 8418}\n",
      "06/30/2020 16:52:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0833565913108197e-05, 'epoch': 2.3499860452135084, 'step': 8420}\n",
      "06/30/2020 16:52:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0824262722113685e-05, 'epoch': 2.350544236673179, 'step': 8422}\n",
      "06/30/2020 16:52:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0814959531119174e-05, 'epoch': 2.3511024281328496, 'step': 8424}\n",
      "06/30/2020 16:52:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0805656340124664e-05, 'epoch': 2.3516606195925203, 'step': 8426}\n",
      "06/30/2020 16:52:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0796353149130152e-05, 'epoch': 2.352218811052191, 'step': 8428}\n",
      "06/30/2020 16:52:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0787049958135641e-05, 'epoch': 2.3527770025118615, 'step': 8430}\n",
      "06/30/2020 16:52:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.077774676714113e-05, 'epoch': 2.353335193971532, 'step': 8432}\n",
      "06/30/2020 16:52:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0768443576146618e-05, 'epoch': 2.3538933854312027, 'step': 8434}\n",
      "06/30/2020 16:52:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0759140385152108e-05, 'epoch': 2.354451576890874, 'step': 8436}\n",
      "06/30/2020 16:52:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0749837194157596e-05, 'epoch': 2.3550097683505444, 'step': 8438}\n",
      "06/30/2020 16:52:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0740534003163087e-05, 'epoch': 2.355567959810215, 'step': 8440}\n",
      "06/30/2020 16:52:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0731230812168575e-05, 'epoch': 2.3561261512698857, 'step': 8442}\n",
      "06/30/2020 16:52:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0721927621174064e-05, 'epoch': 2.3566843427295563, 'step': 8444}\n",
      "06/30/2020 16:52:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0712624430179552e-05, 'epoch': 2.357242534189227, 'step': 8446}\n",
      "06/30/2020 16:52:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.070332123918504e-05, 'epoch': 2.3578007256488975, 'step': 8448}\n",
      "06/30/2020 16:52:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0694018048190529e-05, 'epoch': 2.358358917108568, 'step': 8450}\n",
      "06/30/2020 16:52:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0684714857196017e-05, 'epoch': 2.3589171085682388, 'step': 8452}\n",
      "06/30/2020 16:52:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0675411666201508e-05, 'epoch': 2.3594753000279094, 'step': 8454}\n",
      "06/30/2020 16:52:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0666108475206998e-05, 'epoch': 2.36003349148758, 'step': 8456}\n",
      "06/30/2020 16:52:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0656805284212486e-05, 'epoch': 2.360591682947251, 'step': 8458}\n",
      "06/30/2020 16:52:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0647502093217975e-05, 'epoch': 2.3611498744069217, 'step': 8460}\n",
      "06/30/2020 16:52:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0638198902223463e-05, 'epoch': 2.3617080658665923, 'step': 8462}\n",
      "06/30/2020 16:52:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0628895711228952e-05, 'epoch': 2.362266257326263, 'step': 8464}\n",
      "06/30/2020 16:52:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.061959252023444e-05, 'epoch': 2.3628244487859336, 'step': 8466}\n",
      "06/30/2020 16:52:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.061028932923993e-05, 'epoch': 2.363382640245604, 'step': 8468}\n",
      "06/30/2020 16:52:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0600986138245419e-05, 'epoch': 2.363940831705275, 'step': 8470}\n",
      "06/30/2020 16:52:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0591682947250909e-05, 'epoch': 2.3644990231649454, 'step': 8472}\n",
      "06/30/2020 16:52:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0582379756256397e-05, 'epoch': 2.365057214624616, 'step': 8474}\n",
      "06/30/2020 16:52:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0573076565261886e-05, 'epoch': 2.365615406084287, 'step': 8476}\n",
      "06/30/2020 16:52:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0563773374267374e-05, 'epoch': 2.3661735975439577, 'step': 8478}\n",
      "06/30/2020 16:52:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0554470183272863e-05, 'epoch': 2.3667317890036284, 'step': 8480}\n",
      "06/30/2020 16:52:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0545166992278351e-05, 'epoch': 2.367289980463299, 'step': 8482}\n",
      "06/30/2020 16:52:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0535863801283841e-05, 'epoch': 2.3678481719229696, 'step': 8484}\n",
      "06/30/2020 16:52:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.052656061028933e-05, 'epoch': 2.36840636338264, 'step': 8486}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:52:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0517257419294818e-05, 'epoch': 2.368964554842311, 'step': 8488}\n",
      "06/30/2020 16:52:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0507954228300307e-05, 'epoch': 2.3695227463019815, 'step': 8490}\n",
      "06/30/2020 16:52:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0498651037305797e-05, 'epoch': 2.370080937761652, 'step': 8492}\n",
      "06/30/2020 16:52:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0489347846311285e-05, 'epoch': 2.370639129221323, 'step': 8494}\n",
      "06/30/2020 16:52:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0480044655316774e-05, 'epoch': 2.3711973206809938, 'step': 8496}\n",
      "06/30/2020 16:52:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0470741464322264e-05, 'epoch': 2.3717555121406644, 'step': 8498}\n",
      "06/30/2020 16:52:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0461438273327752e-05, 'epoch': 2.372313703600335, 'step': 8500}\n",
      "06/30/2020 16:52:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.045213508233324e-05, 'epoch': 2.3728718950600056, 'step': 8502}\n",
      "06/30/2020 16:52:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.044283189133873e-05, 'epoch': 2.3734300865196762, 'step': 8504}\n",
      "06/30/2020 16:52:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0433528700344218e-05, 'epoch': 2.373988277979347, 'step': 8506}\n",
      "06/30/2020 16:52:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0424225509349706e-05, 'epoch': 2.3745464694390175, 'step': 8508}\n",
      "06/30/2020 16:52:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0414922318355196e-05, 'epoch': 2.375104660898688, 'step': 8510}\n",
      "06/30/2020 16:52:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0405619127360687e-05, 'epoch': 2.3756628523583587, 'step': 8512}\n",
      "06/30/2020 16:52:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0396315936366175e-05, 'epoch': 2.3762210438180293, 'step': 8514}\n",
      "06/30/2020 16:52:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0387012745371663e-05, 'epoch': 2.3767792352777004, 'step': 8516}\n",
      "06/30/2020 16:52:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0377709554377152e-05, 'epoch': 2.377337426737371, 'step': 8518}\n",
      "06/30/2020 16:52:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.036840636338264e-05, 'epoch': 2.3778956181970416, 'step': 8520}\n",
      "06/30/2020 16:52:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0359103172388129e-05, 'epoch': 2.3784538096567123, 'step': 8522}\n",
      "06/30/2020 16:52:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0349799981393617e-05, 'epoch': 2.379012001116383, 'step': 8524}\n",
      "06/30/2020 16:52:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0340496790399107e-05, 'epoch': 2.3795701925760535, 'step': 8526}\n",
      "06/30/2020 16:52:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0331193599404598e-05, 'epoch': 2.380128384035724, 'step': 8528}\n",
      "06/30/2020 16:52:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0321890408410086e-05, 'epoch': 2.3806865754953948, 'step': 8530}\n",
      "06/30/2020 16:52:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0312587217415575e-05, 'epoch': 2.3812447669550654, 'step': 8532}\n",
      "06/30/2020 16:52:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0303284026421063e-05, 'epoch': 2.3818029584147364, 'step': 8534}\n",
      "06/30/2020 16:52:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0293980835426551e-05, 'epoch': 2.382361149874407, 'step': 8536}\n",
      "06/30/2020 16:52:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.028467764443204e-05, 'epoch': 2.3829193413340777, 'step': 8538}\n",
      "06/30/2020 16:52:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.027537445343753e-05, 'epoch': 2.3834775327937483, 'step': 8540}\n",
      "06/30/2020 16:52:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0266071262443019e-05, 'epoch': 2.384035724253419, 'step': 8542}\n",
      "06/30/2020 16:52:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0256768071448507e-05, 'epoch': 2.3845939157130895, 'step': 8544}\n",
      "06/30/2020 16:52:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0247464880453997e-05, 'epoch': 2.38515210717276, 'step': 8546}\n",
      "06/30/2020 16:52:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0238161689459486e-05, 'epoch': 2.385710298632431, 'step': 8548}\n",
      "06/30/2020 16:52:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0228858498464974e-05, 'epoch': 2.3862684900921014, 'step': 8550}\n",
      "06/30/2020 16:52:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0219555307470463e-05, 'epoch': 2.3868266815517725, 'step': 8552}\n",
      "06/30/2020 16:52:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0210252116475951e-05, 'epoch': 2.387384873011443, 'step': 8554}\n",
      "06/30/2020 16:52:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0200948925481441e-05, 'epoch': 2.3879430644711137, 'step': 8556}\n",
      "06/30/2020 16:52:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.019164573448693e-05, 'epoch': 2.3885012559307843, 'step': 8558}\n",
      "06/30/2020 16:52:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0182342543492418e-05, 'epoch': 2.389059447390455, 'step': 8560}\n",
      "06/30/2020 16:52:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0173039352497907e-05, 'epoch': 2.3896176388501256, 'step': 8562}\n",
      "06/30/2020 16:52:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0163736161503395e-05, 'epoch': 2.390175830309796, 'step': 8564}\n",
      "06/30/2020 16:52:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0154432970508885e-05, 'epoch': 2.390734021769467, 'step': 8566}\n",
      "06/30/2020 16:52:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0145129779514374e-05, 'epoch': 2.3912922132291374, 'step': 8568}\n",
      "06/30/2020 16:52:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0135826588519864e-05, 'epoch': 2.3918504046888085, 'step': 8570}\n",
      "06/30/2020 16:52:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0126523397525352e-05, 'epoch': 2.392408596148479, 'step': 8572}\n",
      "06/30/2020 16:52:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.011722020653084e-05, 'epoch': 2.3929667876081497, 'step': 8574}\n",
      "06/30/2020 16:52:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.010791701553633e-05, 'epoch': 2.3935249790678204, 'step': 8576}\n",
      "06/30/2020 16:52:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0098613824541818e-05, 'epoch': 2.394083170527491, 'step': 8578}\n",
      "06/30/2020 16:52:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0089310633547306e-05, 'epoch': 2.3946413619871616, 'step': 8580}\n",
      "06/30/2020 16:52:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0080007442552795e-05, 'epoch': 2.395199553446832, 'step': 8582}\n",
      "06/30/2020 16:52:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0070704251558285e-05, 'epoch': 2.395757744906503, 'step': 8584}\n",
      "06/30/2020 16:52:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0061401060563775e-05, 'epoch': 2.3963159363661735, 'step': 8586}\n",
      "06/30/2020 16:52:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0052097869569263e-05, 'epoch': 2.396874127825844, 'step': 8588}\n",
      "06/30/2020 16:52:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0042794678574752e-05, 'epoch': 2.3974323192855147, 'step': 8590}\n",
      "06/30/2020 16:52:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.003349148758024e-05, 'epoch': 2.3979905107451858, 'step': 8592}\n",
      "06/30/2020 16:52:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0024188296585729e-05, 'epoch': 2.3985487022048564, 'step': 8594}\n",
      "06/30/2020 16:52:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0014885105591217e-05, 'epoch': 2.399106893664527, 'step': 8596}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:52:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0005581914596707e-05, 'epoch': 2.3996650851241976, 'step': 8598}\n",
      "06/30/2020 16:52:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.996278723602196e-06, 'epoch': 2.4002232765838682, 'step': 8600}\n",
      "06/30/2020 16:52:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.986975532607686e-06, 'epoch': 2.400781468043539, 'step': 8602}\n",
      "06/30/2020 16:52:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.977672341613174e-06, 'epoch': 2.4013396595032095, 'step': 8604}\n",
      "06/30/2020 16:52:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.968369150618663e-06, 'epoch': 2.40189785096288, 'step': 8606}\n",
      "06/30/2020 16:52:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.959065959624151e-06, 'epoch': 2.4024560424225507, 'step': 8608}\n",
      "06/30/2020 16:52:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.94976276862964e-06, 'epoch': 2.403014233882222, 'step': 8610}\n",
      "06/30/2020 16:52:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.94045957763513e-06, 'epoch': 2.4035724253418924, 'step': 8612}\n",
      "06/30/2020 16:52:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.931156386640618e-06, 'epoch': 2.404130616801563, 'step': 8614}\n",
      "06/30/2020 16:52:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.921853195646107e-06, 'epoch': 2.4046888082612337, 'step': 8616}\n",
      "06/30/2020 16:52:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.912550004651595e-06, 'epoch': 2.4052469997209043, 'step': 8618}\n",
      "06/30/2020 16:52:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.903246813657086e-06, 'epoch': 2.405805191180575, 'step': 8620}\n",
      "06/30/2020 16:52:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.893943622662574e-06, 'epoch': 2.4063633826402455, 'step': 8622}\n",
      "06/30/2020 16:52:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.884640431668063e-06, 'epoch': 2.406921574099916, 'step': 8624}\n",
      "06/30/2020 16:52:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.875337240673551e-06, 'epoch': 2.4074797655595868, 'step': 8626}\n",
      "06/30/2020 16:52:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.866034049679041e-06, 'epoch': 2.408037957019258, 'step': 8628}\n",
      "06/30/2020 16:52:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.85673085868453e-06, 'epoch': 2.4085961484789284, 'step': 8630}\n",
      "06/30/2020 16:52:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.847427667690018e-06, 'epoch': 2.409154339938599, 'step': 8632}\n",
      "06/30/2020 16:52:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.838124476695507e-06, 'epoch': 2.4097125313982697, 'step': 8634}\n",
      "06/30/2020 16:52:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.828821285700995e-06, 'epoch': 2.4102707228579403, 'step': 8636}\n",
      "06/30/2020 16:52:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.819518094706485e-06, 'epoch': 2.410828914317611, 'step': 8638}\n",
      "06/30/2020 16:52:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.810214903711974e-06, 'epoch': 2.4113871057772815, 'step': 8640}\n",
      "06/30/2020 16:52:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.800911712717464e-06, 'epoch': 2.411945297236952, 'step': 8642}\n",
      "06/30/2020 16:52:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.791608521722952e-06, 'epoch': 2.412503488696623, 'step': 8644}\n",
      "06/30/2020 16:52:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.78230533072844e-06, 'epoch': 2.413061680156294, 'step': 8646}\n",
      "06/30/2020 16:52:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.77300213973393e-06, 'epoch': 2.413619871615964, 'step': 8648}\n",
      "06/30/2020 16:52:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.763698948739418e-06, 'epoch': 2.414178063075635, 'step': 8650}\n",
      "06/30/2020 16:52:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.754395757744906e-06, 'epoch': 2.4147362545353057, 'step': 8652}\n",
      "06/30/2020 16:52:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.745092566750395e-06, 'epoch': 2.4152944459949763, 'step': 8654}\n",
      "06/30/2020 16:52:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.735789375755885e-06, 'epoch': 2.415852637454647, 'step': 8656}\n",
      "06/30/2020 16:52:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.726486184761375e-06, 'epoch': 2.4164108289143176, 'step': 8658}\n",
      "06/30/2020 16:52:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.717182993766863e-06, 'epoch': 2.416969020373988, 'step': 8660}\n",
      "06/30/2020 16:52:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.707879802772352e-06, 'epoch': 2.417527211833659, 'step': 8662}\n",
      "06/30/2020 16:52:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.69857661177784e-06, 'epoch': 2.4180854032933294, 'step': 8664}\n",
      "06/30/2020 16:52:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.689273420783329e-06, 'epoch': 2.418643594753, 'step': 8666}\n",
      "06/30/2020 16:52:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.679970229788817e-06, 'epoch': 2.419201786212671, 'step': 8668}\n",
      "06/30/2020 16:52:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.670667038794307e-06, 'epoch': 2.4197599776723417, 'step': 8670}\n",
      "06/30/2020 16:52:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.661363847799796e-06, 'epoch': 2.4203181691320124, 'step': 8672}\n",
      "06/30/2020 16:52:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.652060656805284e-06, 'epoch': 2.420876360591683, 'step': 8674}\n",
      "06/30/2020 16:52:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.642757465810774e-06, 'epoch': 2.4214345520513536, 'step': 8676}\n",
      "06/30/2020 16:52:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.633454274816263e-06, 'epoch': 2.4219927435110242, 'step': 8678}\n",
      "06/30/2020 16:52:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.624151083821751e-06, 'epoch': 2.422550934970695, 'step': 8680}\n",
      "06/30/2020 16:52:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.61484789282724e-06, 'epoch': 2.4231091264303655, 'step': 8682}\n",
      "06/30/2020 16:52:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.605544701832728e-06, 'epoch': 2.423667317890036, 'step': 8684}\n",
      "06/30/2020 16:52:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.596241510838218e-06, 'epoch': 2.424225509349707, 'step': 8686}\n",
      "06/30/2020 16:52:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.586938319843707e-06, 'epoch': 2.4247837008093778, 'step': 8688}\n",
      "06/30/2020 16:52:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.577635128849195e-06, 'epoch': 2.4253418922690484, 'step': 8690}\n",
      "06/30/2020 16:52:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.568331937854684e-06, 'epoch': 2.425900083728719, 'step': 8692}\n",
      "06/30/2020 16:52:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.559028746860174e-06, 'epoch': 2.4264582751883896, 'step': 8694}\n",
      "06/30/2020 16:52:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.549725555865662e-06, 'epoch': 2.4270164666480603, 'step': 8696}\n",
      "06/30/2020 16:52:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.540422364871151e-06, 'epoch': 2.427574658107731, 'step': 8698}\n",
      "06/30/2020 16:52:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.531119173876641e-06, 'epoch': 2.4281328495674015, 'step': 8700}\n",
      "06/30/2020 16:52:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.52181598288213e-06, 'epoch': 2.428691041027072, 'step': 8702}\n",
      "06/30/2020 16:52:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.512512791887618e-06, 'epoch': 2.429249232486743, 'step': 8704}\n",
      "06/30/2020 16:52:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.503209600893106e-06, 'epoch': 2.429807423946414, 'step': 8706}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:52:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.493906409898595e-06, 'epoch': 2.4303656154060844, 'step': 8708}\n",
      "06/30/2020 16:52:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.484603218904083e-06, 'epoch': 2.430923806865755, 'step': 8710}\n",
      "06/30/2020 16:52:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.475300027909574e-06, 'epoch': 2.4314819983254257, 'step': 8712}\n",
      "06/30/2020 16:52:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.465996836915062e-06, 'epoch': 2.4320401897850963, 'step': 8714}\n",
      "06/30/2020 16:52:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.456693645920552e-06, 'epoch': 2.432598381244767, 'step': 8716}\n",
      "06/30/2020 16:52:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.44739045492604e-06, 'epoch': 2.4331565727044375, 'step': 8718}\n",
      "06/30/2020 16:52:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.438087263931529e-06, 'epoch': 2.433714764164108, 'step': 8720}\n",
      "06/30/2020 16:52:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.428784072937018e-06, 'epoch': 2.4342729556237788, 'step': 8722}\n",
      "06/30/2020 16:52:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.419480881942506e-06, 'epoch': 2.4348311470834494, 'step': 8724}\n",
      "06/30/2020 16:52:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.410177690947994e-06, 'epoch': 2.4353893385431205, 'step': 8726}\n",
      "06/30/2020 16:52:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.400874499953485e-06, 'epoch': 2.435947530002791, 'step': 8728}\n",
      "06/30/2020 16:52:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.391571308958973e-06, 'epoch': 2.4365057214624617, 'step': 8730}\n",
      "06/30/2020 16:52:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.382268117964463e-06, 'epoch': 2.4370639129221323, 'step': 8732}\n",
      "06/30/2020 16:52:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.372964926969952e-06, 'epoch': 2.437622104381803, 'step': 8734}\n",
      "06/30/2020 16:52:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.36366173597544e-06, 'epoch': 2.4381802958414736, 'step': 8736}\n",
      "06/30/2020 16:52:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.354358544980929e-06, 'epoch': 2.438738487301144, 'step': 8738}\n",
      "06/30/2020 16:52:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.345055353986417e-06, 'epoch': 2.439296678760815, 'step': 8740}\n",
      "06/30/2020 16:52:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.335752162991907e-06, 'epoch': 2.4398548702204854, 'step': 8742}\n",
      "06/30/2020 16:52:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.326448971997396e-06, 'epoch': 2.4404130616801565, 'step': 8744}\n",
      "06/30/2020 16:52:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.317145781002884e-06, 'epoch': 2.440971253139827, 'step': 8746}\n",
      "06/30/2020 16:52:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.307842590008373e-06, 'epoch': 2.4415294445994977, 'step': 8748}\n",
      "06/30/2020 16:52:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.298539399013863e-06, 'epoch': 2.4420876360591683, 'step': 8750}\n",
      "06/30/2020 16:52:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.289236208019351e-06, 'epoch': 2.442645827518839, 'step': 8752}\n",
      "06/30/2020 16:52:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.27993301702484e-06, 'epoch': 2.4432040189785096, 'step': 8754}\n",
      "06/30/2020 16:52:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.270629826030328e-06, 'epoch': 2.44376221043818, 'step': 8756}\n",
      "06/30/2020 16:52:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.261326635035818e-06, 'epoch': 2.444320401897851, 'step': 8758}\n",
      "06/30/2020 16:52:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.252023444041307e-06, 'epoch': 2.4448785933575214, 'step': 8760}\n",
      "06/30/2020 16:52:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.242720253046795e-06, 'epoch': 2.4454367848171925, 'step': 8762}\n",
      "06/30/2020 16:52:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.233417062052284e-06, 'epoch': 2.445994976276863, 'step': 8764}\n",
      "06/30/2020 16:52:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.224113871057772e-06, 'epoch': 2.4465531677365338, 'step': 8766}\n",
      "06/30/2020 16:52:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.214810680063262e-06, 'epoch': 2.4471113591962044, 'step': 8768}\n",
      "06/30/2020 16:52:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.205507489068751e-06, 'epoch': 2.447669550655875, 'step': 8770}\n",
      "06/30/2020 16:52:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.196204298074241e-06, 'epoch': 2.4482277421155456, 'step': 8772}\n",
      "06/30/2020 16:52:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.18690110707973e-06, 'epoch': 2.4487859335752162, 'step': 8774}\n",
      "06/30/2020 16:52:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.177597916085218e-06, 'epoch': 2.449344125034887, 'step': 8776}\n",
      "06/30/2020 16:52:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.168294725090706e-06, 'epoch': 2.4499023164945575, 'step': 8778}\n",
      "06/30/2020 16:52:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.158991534096195e-06, 'epoch': 2.4504605079542285, 'step': 8780}\n",
      "06/30/2020 16:52:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.149688343101683e-06, 'epoch': 2.451018699413899, 'step': 8782}\n",
      "06/30/2020 16:52:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.140385152107172e-06, 'epoch': 2.45157689087357, 'step': 8784}\n",
      "06/30/2020 16:52:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.131081961112662e-06, 'epoch': 2.4521350823332404, 'step': 8786}\n",
      "06/30/2020 16:52:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.121778770118152e-06, 'epoch': 2.452693273792911, 'step': 8788}\n",
      "06/30/2020 16:52:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.11247557912364e-06, 'epoch': 2.4532514652525816, 'step': 8790}\n",
      "06/30/2020 16:52:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.103172388129129e-06, 'epoch': 2.4538096567122523, 'step': 8792}\n",
      "06/30/2020 16:52:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.093869197134618e-06, 'epoch': 2.454367848171923, 'step': 8794}\n",
      "06/30/2020 16:52:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.084566006140106e-06, 'epoch': 2.4549260396315935, 'step': 8796}\n",
      "06/30/2020 16:52:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.075262815145594e-06, 'epoch': 2.455484231091264, 'step': 8798}\n",
      "06/30/2020 16:52:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.065959624151085e-06, 'epoch': 2.4560424225509347, 'step': 8800}\n",
      "06/30/2020 16:52:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.056656433156573e-06, 'epoch': 2.456600614010606, 'step': 8802}\n",
      "06/30/2020 16:52:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.047353242162063e-06, 'epoch': 2.4571588054702764, 'step': 8804}\n",
      "06/30/2020 16:52:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.038050051167552e-06, 'epoch': 2.457716996929947, 'step': 8806}\n",
      "06/30/2020 16:52:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.02874686017304e-06, 'epoch': 2.4582751883896177, 'step': 8808}\n",
      "06/30/2020 16:52:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.019443669178529e-06, 'epoch': 2.4588333798492883, 'step': 8810}\n",
      "06/30/2020 16:52:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.010140478184017e-06, 'epoch': 2.459391571308959, 'step': 8812}\n",
      "06/30/2020 16:52:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.000837287189506e-06, 'epoch': 2.4599497627686295, 'step': 8814}\n",
      "06/30/2020 16:52:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.991534096194996e-06, 'epoch': 2.4605079542283, 'step': 8816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:52:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.982230905200484e-06, 'epoch': 2.4610661456879708, 'step': 8818}\n",
      "06/30/2020 16:52:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.972927714205973e-06, 'epoch': 2.461624337147642, 'step': 8820}\n",
      "06/30/2020 16:52:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.963624523211461e-06, 'epoch': 2.4621825286073125, 'step': 8822}\n",
      "06/30/2020 16:52:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.954321332216951e-06, 'epoch': 2.462740720066983, 'step': 8824}\n",
      "06/30/2020 16:52:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.94501814122244e-06, 'epoch': 2.4632989115266537, 'step': 8826}\n",
      "06/30/2020 16:52:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.935714950227928e-06, 'epoch': 2.4638571029863243, 'step': 8828}\n",
      "06/30/2020 16:52:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.926411759233418e-06, 'epoch': 2.464415294445995, 'step': 8830}\n",
      "06/30/2020 16:52:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.917108568238907e-06, 'epoch': 2.4649734859056656, 'step': 8832}\n",
      "06/30/2020 16:52:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.907805377244395e-06, 'epoch': 2.465531677365336, 'step': 8834}\n",
      "06/30/2020 16:52:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.898502186249884e-06, 'epoch': 2.466089868825007, 'step': 8836}\n",
      "06/30/2020 16:52:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.889198995255372e-06, 'epoch': 2.466648060284678, 'step': 8838}\n",
      "06/30/2020 16:52:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.87989580426086e-06, 'epoch': 2.4672062517443485, 'step': 8840}\n",
      "06/30/2020 16:52:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.87059261326635e-06, 'epoch': 2.467764443204019, 'step': 8842}\n",
      "06/30/2020 16:52:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.86128942227184e-06, 'epoch': 2.4683226346636897, 'step': 8844}\n",
      "06/30/2020 16:52:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.85198623127733e-06, 'epoch': 2.4688808261233604, 'step': 8846}\n",
      "06/30/2020 16:52:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.842683040282818e-06, 'epoch': 2.469439017583031, 'step': 8848}\n",
      "06/30/2020 16:52:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.833379849288306e-06, 'epoch': 2.4699972090427016, 'step': 8850}\n",
      "06/30/2020 16:52:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.824076658293795e-06, 'epoch': 2.470555400502372, 'step': 8852}\n",
      "06/30/2020 16:52:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.814773467299283e-06, 'epoch': 2.471113591962043, 'step': 8854}\n",
      "06/30/2020 16:52:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.805470276304772e-06, 'epoch': 2.471671783421714, 'step': 8856}\n",
      "06/30/2020 16:52:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.796167085310262e-06, 'epoch': 2.472229974881384, 'step': 8858}\n",
      "06/30/2020 16:52:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.786863894315752e-06, 'epoch': 2.472788166341055, 'step': 8860}\n",
      "06/30/2020 16:52:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.77756070332124e-06, 'epoch': 2.4733463578007258, 'step': 8862}\n",
      "06/30/2020 16:52:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.768257512326729e-06, 'epoch': 2.4739045492603964, 'step': 8864}\n",
      "06/30/2020 16:52:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.758954321332217e-06, 'epoch': 2.474462740720067, 'step': 8866}\n",
      "06/30/2020 16:52:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.749651130337706e-06, 'epoch': 2.4750209321797376, 'step': 8868}\n",
      "06/30/2020 16:52:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.740347939343194e-06, 'epoch': 2.4755791236394082, 'step': 8870}\n",
      "06/30/2020 16:52:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.731044748348685e-06, 'epoch': 2.476137315099079, 'step': 8872}\n",
      "06/30/2020 16:52:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.721741557354173e-06, 'epoch': 2.4766955065587495, 'step': 8874}\n",
      "06/30/2020 16:52:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.712438366359661e-06, 'epoch': 2.47725369801842, 'step': 8876}\n",
      "06/30/2020 16:52:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.703135175365152e-06, 'epoch': 2.477811889478091, 'step': 8878}\n",
      "06/30/2020 16:53:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.69383198437064e-06, 'epoch': 2.478370080937762, 'step': 8880}\n",
      "06/30/2020 16:53:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.684528793376129e-06, 'epoch': 2.4789282723974324, 'step': 8882}\n",
      "06/30/2020 16:53:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.675225602381617e-06, 'epoch': 2.479486463857103, 'step': 8884}\n",
      "06/30/2020 16:53:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.665922411387105e-06, 'epoch': 2.4800446553167736, 'step': 8886}\n",
      "06/30/2020 16:53:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.656619220392596e-06, 'epoch': 2.4806028467764443, 'step': 8888}\n",
      "06/30/2020 16:53:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.647316029398084e-06, 'epoch': 2.481161038236115, 'step': 8890}\n",
      "06/30/2020 16:53:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.638012838403573e-06, 'epoch': 2.4817192296957855, 'step': 8892}\n",
      "06/30/2020 16:53:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.628709647409061e-06, 'epoch': 2.482277421155456, 'step': 8894}\n",
      "06/30/2020 16:53:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.61940645641455e-06, 'epoch': 2.482835612615127, 'step': 8896}\n",
      "06/30/2020 16:53:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.61010326542004e-06, 'epoch': 2.483393804074798, 'step': 8898}\n",
      "06/30/2020 16:53:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.600800074425528e-06, 'epoch': 2.4839519955344684, 'step': 8900}\n",
      "06/30/2020 16:53:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.591496883431018e-06, 'epoch': 2.484510186994139, 'step': 8902}\n",
      "06/30/2020 16:53:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.582193692436507e-06, 'epoch': 2.4850683784538097, 'step': 8904}\n",
      "06/30/2020 16:53:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.572890501441995e-06, 'epoch': 2.4856265699134803, 'step': 8906}\n",
      "06/30/2020 16:53:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.563587310447484e-06, 'epoch': 2.486184761373151, 'step': 8908}\n",
      "06/30/2020 16:53:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.554284119452972e-06, 'epoch': 2.4867429528328215, 'step': 8910}\n",
      "06/30/2020 16:53:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.54498092845846e-06, 'epoch': 2.487301144292492, 'step': 8912}\n",
      "06/30/2020 16:53:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.535677737463949e-06, 'epoch': 2.4878593357521632, 'step': 8914}\n",
      "06/30/2020 16:53:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.52637454646944e-06, 'epoch': 2.488417527211834, 'step': 8916}\n",
      "06/30/2020 16:53:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.51707135547493e-06, 'epoch': 2.4889757186715045, 'step': 8918}\n",
      "06/30/2020 16:53:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.507768164480418e-06, 'epoch': 2.489533910131175, 'step': 8920}\n",
      "06/30/2020 16:53:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.498464973485906e-06, 'epoch': 2.4900921015908457, 'step': 8922}\n",
      "06/30/2020 16:53:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.489161782491395e-06, 'epoch': 2.4906502930505163, 'step': 8924}\n",
      "06/30/2020 16:53:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.479858591496883e-06, 'epoch': 2.491208484510187, 'step': 8926}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:53:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.470555400502372e-06, 'epoch': 2.4917666759698576, 'step': 8928}\n",
      "06/30/2020 16:53:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.461252209507862e-06, 'epoch': 2.492324867429528, 'step': 8930}\n",
      "06/30/2020 16:53:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.45194901851335e-06, 'epoch': 2.492883058889199, 'step': 8932}\n",
      "06/30/2020 16:53:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.44264582751884e-06, 'epoch': 2.4934412503488694, 'step': 8934}\n",
      "06/30/2020 16:53:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.433342636524329e-06, 'epoch': 2.4939994418085405, 'step': 8936}\n",
      "06/30/2020 16:53:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.424039445529817e-06, 'epoch': 2.494557633268211, 'step': 8938}\n",
      "06/30/2020 16:53:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.414736254535306e-06, 'epoch': 2.4951158247278817, 'step': 8940}\n",
      "06/30/2020 16:53:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.405433063540794e-06, 'epoch': 2.4956740161875524, 'step': 8942}\n",
      "06/30/2020 16:53:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.396129872546283e-06, 'epoch': 2.496232207647223, 'step': 8944}\n",
      "06/30/2020 16:53:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.386826681551773e-06, 'epoch': 2.4967903991068936, 'step': 8946}\n",
      "06/30/2020 16:53:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.377523490557261e-06, 'epoch': 2.497348590566564, 'step': 8948}\n",
      "06/30/2020 16:53:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.36822029956275e-06, 'epoch': 2.497906782026235, 'step': 8950}\n",
      "06/30/2020 16:53:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.35891710856824e-06, 'epoch': 2.4984649734859055, 'step': 8952}\n",
      "06/30/2020 16:53:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.349613917573728e-06, 'epoch': 2.4990231649455765, 'step': 8954}\n",
      "06/30/2020 16:53:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.340310726579217e-06, 'epoch': 2.499581356405247, 'step': 8956}\n",
      "06/30/2020 16:53:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.331007535584705e-06, 'epoch': 2.5001395478649178, 'step': 8958}\n",
      "06/30/2020 16:53:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.321704344590196e-06, 'epoch': 2.5006977393245884, 'step': 8960}\n",
      "06/30/2020 16:53:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.312401153595684e-06, 'epoch': 2.501255930784259, 'step': 8962}\n",
      "06/30/2020 16:53:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.303097962601173e-06, 'epoch': 2.5018141222439296, 'step': 8964}\n",
      "06/30/2020 16:53:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.293794771606661e-06, 'epoch': 2.5023723137036002, 'step': 8966}\n",
      "06/30/2020 16:53:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.28449158061215e-06, 'epoch': 2.502930505163271, 'step': 8968}\n",
      "06/30/2020 16:53:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.27518838961764e-06, 'epoch': 2.5034886966229415, 'step': 8970}\n",
      "06/30/2020 16:53:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.265885198623128e-06, 'epoch': 2.5040468880826126, 'step': 8972}\n",
      "06/30/2020 16:53:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.256582007628618e-06, 'epoch': 2.5046050795422827, 'step': 8974}\n",
      "06/30/2020 16:53:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.247278816634107e-06, 'epoch': 2.505163271001954, 'step': 8976}\n",
      "06/30/2020 16:53:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.237975625639595e-06, 'epoch': 2.5057214624616244, 'step': 8978}\n",
      "06/30/2020 16:53:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.228672434645084e-06, 'epoch': 2.506279653921295, 'step': 8980}\n",
      "06/30/2020 16:53:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.219369243650572e-06, 'epoch': 2.5068378453809657, 'step': 8982}\n",
      "06/30/2020 16:53:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.21006605265606e-06, 'epoch': 2.5073960368406363, 'step': 8984}\n",
      "06/30/2020 16:53:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.200762861661549e-06, 'epoch': 2.507954228300307, 'step': 8986}\n",
      "06/30/2020 16:53:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.19145967066704e-06, 'epoch': 2.5085124197599775, 'step': 8988}\n",
      "06/30/2020 16:53:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.18215647967253e-06, 'epoch': 2.5090706112196486, 'step': 8990}\n",
      "06/30/2020 16:53:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.172853288678018e-06, 'epoch': 2.5096288026793188, 'step': 8992}\n",
      "06/30/2020 16:53:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.163550097683506e-06, 'epoch': 2.51018699413899, 'step': 8994}\n",
      "06/30/2020 16:53:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.154246906688995e-06, 'epoch': 2.5107451855986604, 'step': 8996}\n",
      "06/30/2020 16:53:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.144943715694483e-06, 'epoch': 2.511303377058331, 'step': 8998}\n",
      "06/30/2020 16:53:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.135640524699972e-06, 'epoch': 2.5118615685180017, 'step': 9000}\n",
      "06/30/2020 16:53:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.126337333705462e-06, 'epoch': 2.5124197599776723, 'step': 9002}\n",
      "06/30/2020 16:53:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.11703414271095e-06, 'epoch': 2.512977951437343, 'step': 9004}\n",
      "06/30/2020 16:53:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.107730951716439e-06, 'epoch': 2.5135361428970135, 'step': 9006}\n",
      "06/30/2020 16:53:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.098427760721929e-06, 'epoch': 2.5140943343566846, 'step': 9008}\n",
      "06/30/2020 16:53:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.089124569727417e-06, 'epoch': 2.514652525816355, 'step': 9010}\n",
      "06/30/2020 16:53:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.079821378732906e-06, 'epoch': 2.515210717276026, 'step': 9012}\n",
      "06/30/2020 16:53:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.070518187738394e-06, 'epoch': 2.5157689087356965, 'step': 9014}\n",
      "06/30/2020 16:53:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.061214996743883e-06, 'epoch': 2.516327100195367, 'step': 9016}\n",
      "06/30/2020 16:53:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.051911805749373e-06, 'epoch': 2.5168852916550377, 'step': 9018}\n",
      "06/30/2020 16:53:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.042608614754861e-06, 'epoch': 2.5174434831147083, 'step': 9020}\n",
      "06/30/2020 16:53:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.03330542376035e-06, 'epoch': 2.518001674574379, 'step': 9022}\n",
      "06/30/2020 16:53:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.024002232765838e-06, 'epoch': 2.5185598660340496, 'step': 9024}\n",
      "06/30/2020 16:53:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.014699041771328e-06, 'epoch': 2.51911805749372, 'step': 9026}\n",
      "06/30/2020 16:53:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.005395850776817e-06, 'epoch': 2.519676248953391, 'step': 9028}\n",
      "06/30/2020 16:53:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.996092659782305e-06, 'epoch': 2.520234440413062, 'step': 9030}\n",
      "06/30/2020 16:53:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.986789468787796e-06, 'epoch': 2.5207926318727325, 'step': 9032}\n",
      "06/30/2020 16:53:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.977486277793284e-06, 'epoch': 2.521350823332403, 'step': 9034}\n",
      "06/30/2020 16:53:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.968183086798772e-06, 'epoch': 2.5219090147920737, 'step': 9036}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:53:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.958879895804261e-06, 'epoch': 2.5224672062517444, 'step': 9038}\n",
      "06/30/2020 16:53:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.94957670480975e-06, 'epoch': 2.523025397711415, 'step': 9040}\n",
      "06/30/2020 16:53:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.940273513815238e-06, 'epoch': 2.5235835891710856, 'step': 9042}\n",
      "06/30/2020 16:53:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.930970322820728e-06, 'epoch': 2.5241417806307562, 'step': 9044}\n",
      "06/30/2020 16:53:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.921667131826216e-06, 'epoch': 2.524699972090427, 'step': 9046}\n",
      "06/30/2020 16:53:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.912363940831707e-06, 'epoch': 2.525258163550098, 'step': 9048}\n",
      "06/30/2020 16:53:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.903060749837195e-06, 'epoch': 2.525816355009768, 'step': 9050}\n",
      "06/30/2020 16:53:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.893757558842684e-06, 'epoch': 2.526374546469439, 'step': 9052}\n",
      "06/30/2020 16:53:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.884454367848172e-06, 'epoch': 2.5269327379291098, 'step': 9054}\n",
      "06/30/2020 16:53:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.87515117685366e-06, 'epoch': 2.5274909293887804, 'step': 9056}\n",
      "06/30/2020 16:53:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.865847985859149e-06, 'epoch': 2.528049120848451, 'step': 9058}\n",
      "06/30/2020 16:53:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.856544794864639e-06, 'epoch': 2.5286073123081216, 'step': 9060}\n",
      "06/30/2020 16:53:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.84724160387013e-06, 'epoch': 2.5291655037677923, 'step': 9062}\n",
      "06/30/2020 16:53:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.837938412875618e-06, 'epoch': 2.529723695227463, 'step': 9064}\n",
      "06/30/2020 16:53:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.828635221881106e-06, 'epoch': 2.530281886687134, 'step': 9066}\n",
      "06/30/2020 16:53:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.819332030886595e-06, 'epoch': 2.530840078146804, 'step': 9068}\n",
      "06/30/2020 16:53:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.810028839892083e-06, 'epoch': 2.531398269606475, 'step': 9070}\n",
      "06/30/2020 16:53:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.800725648897572e-06, 'epoch': 2.531956461066146, 'step': 9072}\n",
      "06/30/2020 16:53:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.791422457903062e-06, 'epoch': 2.5325146525258164, 'step': 9074}\n",
      "06/30/2020 16:53:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.78211926690855e-06, 'epoch': 2.533072843985487, 'step': 9076}\n",
      "06/30/2020 16:53:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.772816075914039e-06, 'epoch': 2.5336310354451577, 'step': 9078}\n",
      "06/30/2020 16:53:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.763512884919527e-06, 'epoch': 2.5341892269048283, 'step': 9080}\n",
      "06/30/2020 16:53:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.754209693925017e-06, 'epoch': 2.534747418364499, 'step': 9082}\n",
      "06/30/2020 16:53:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.744906502930506e-06, 'epoch': 2.5353056098241695, 'step': 9084}\n",
      "06/30/2020 16:53:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.735603311935994e-06, 'epoch': 2.53586380128384, 'step': 9086}\n",
      "06/30/2020 16:53:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.726300120941483e-06, 'epoch': 2.536421992743511, 'step': 9088}\n",
      "06/30/2020 16:53:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.716996929946973e-06, 'epoch': 2.536980184203182, 'step': 9090}\n",
      "06/30/2020 16:53:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.707693738952461e-06, 'epoch': 2.5375383756628525, 'step': 9092}\n",
      "06/30/2020 16:53:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.69839054795795e-06, 'epoch': 2.538096567122523, 'step': 9094}\n",
      "06/30/2020 16:53:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.689087356963438e-06, 'epoch': 2.5386547585821937, 'step': 9096}\n",
      "06/30/2020 16:53:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.679784165968927e-06, 'epoch': 2.5392129500418643, 'step': 9098}\n",
      "06/30/2020 16:53:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.670480974974417e-06, 'epoch': 2.539771141501535, 'step': 9100}\n",
      "06/30/2020 16:53:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.661177783979905e-06, 'epoch': 2.5403293329612056, 'step': 9102}\n",
      "06/30/2020 16:53:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.651874592985395e-06, 'epoch': 2.540887524420876, 'step': 9104}\n",
      "06/30/2020 16:53:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.642571401990884e-06, 'epoch': 2.5414457158805472, 'step': 9106}\n",
      "06/30/2020 16:53:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.633268210996372e-06, 'epoch': 2.542003907340218, 'step': 9108}\n",
      "06/30/2020 16:53:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.623965020001861e-06, 'epoch': 2.5425620987998885, 'step': 9110}\n",
      "06/30/2020 16:53:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.614661829007349e-06, 'epoch': 2.543120290259559, 'step': 9112}\n",
      "06/30/2020 16:53:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.605358638012839e-06, 'epoch': 2.5436784817192297, 'step': 9114}\n",
      "06/30/2020 16:53:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.596055447018327e-06, 'epoch': 2.5442366731789003, 'step': 9116}\n",
      "06/30/2020 16:53:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.586752256023817e-06, 'epoch': 2.544794864638571, 'step': 9118}\n",
      "06/30/2020 16:53:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.577449065029306e-06, 'epoch': 2.5453530560982416, 'step': 9120}\n",
      "06/30/2020 16:53:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.568145874034795e-06, 'epoch': 2.545911247557912, 'step': 9122}\n",
      "06/30/2020 16:53:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.5588426830402835e-06, 'epoch': 2.5464694390175833, 'step': 9124}\n",
      "06/30/2020 16:53:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.549539492045772e-06, 'epoch': 2.5470276304772534, 'step': 9126}\n",
      "06/30/2020 16:53:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.5402363010512604e-06, 'epoch': 2.5475858219369245, 'step': 9128}\n",
      "06/30/2020 16:53:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.53093311005675e-06, 'epoch': 2.548144013396595, 'step': 9130}\n",
      "06/30/2020 16:53:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.521629919062238e-06, 'epoch': 2.5487022048562658, 'step': 9132}\n",
      "06/30/2020 16:53:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.512326728067727e-06, 'epoch': 2.5492603963159364, 'step': 9134}\n",
      "06/30/2020 16:53:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.503023537073217e-06, 'epoch': 2.549818587775607, 'step': 9136}\n",
      "06/30/2020 16:53:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.493720346078706e-06, 'epoch': 2.5503767792352776, 'step': 9138}\n",
      "06/30/2020 16:53:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.484417155084195e-06, 'epoch': 2.5509349706949482, 'step': 9140}\n",
      "06/30/2020 16:53:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.475113964089683e-06, 'epoch': 2.5514931621546193, 'step': 9142}\n",
      "06/30/2020 16:53:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.465810773095172e-06, 'epoch': 2.5520513536142895, 'step': 9144}\n",
      "06/30/2020 16:53:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.456507582100661e-06, 'epoch': 2.5526095450739605, 'step': 9146}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:53:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.447204391106149e-06, 'epoch': 2.553167736533631, 'step': 9148}\n",
      "06/30/2020 16:53:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.437901200111639e-06, 'epoch': 2.553725927993302, 'step': 9150}\n",
      "06/30/2020 16:53:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.428598009117127e-06, 'epoch': 2.5542841194529724, 'step': 9152}\n",
      "06/30/2020 16:53:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.4192948181226155e-06, 'epoch': 2.554842310912643, 'step': 9154}\n",
      "06/30/2020 16:53:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.409991627128106e-06, 'epoch': 2.5554005023723136, 'step': 9156}\n",
      "06/30/2020 16:53:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.400688436133595e-06, 'epoch': 2.5559586938319843, 'step': 9158}\n",
      "06/30/2020 16:53:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.3913852451390835e-06, 'epoch': 2.556516885291655, 'step': 9160}\n",
      "06/30/2020 16:53:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.382082054144572e-06, 'epoch': 2.5570750767513255, 'step': 9162}\n",
      "06/30/2020 16:53:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.37277886315006e-06, 'epoch': 2.5576332682109966, 'step': 9164}\n",
      "06/30/2020 16:53:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.36347567215555e-06, 'epoch': 2.558191459670667, 'step': 9166}\n",
      "06/30/2020 16:53:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.354172481161038e-06, 'epoch': 2.558749651130338, 'step': 9168}\n",
      "06/30/2020 16:53:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.344869290166527e-06, 'epoch': 2.5593078425900084, 'step': 9170}\n",
      "06/30/2020 16:53:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.335566099172016e-06, 'epoch': 2.559866034049679, 'step': 9172}\n",
      "06/30/2020 16:53:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.326262908177506e-06, 'epoch': 2.5604242255093497, 'step': 9174}\n",
      "06/30/2020 16:53:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.3169597171829946e-06, 'epoch': 2.5609824169690203, 'step': 9176}\n",
      "06/30/2020 16:53:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.307656526188483e-06, 'epoch': 2.561540608428691, 'step': 9178}\n",
      "06/30/2020 16:53:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.298353335193972e-06, 'epoch': 2.5620987998883615, 'step': 9180}\n",
      "06/30/2020 16:53:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.289050144199461e-06, 'epoch': 2.5626569913480326, 'step': 9182}\n",
      "06/30/2020 16:53:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.279746953204949e-06, 'epoch': 2.5632151828077028, 'step': 9184}\n",
      "06/30/2020 16:53:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.270443762210439e-06, 'epoch': 2.563773374267374, 'step': 9186}\n",
      "06/30/2020 16:53:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.261140571215927e-06, 'epoch': 2.5643315657270445, 'step': 9188}\n",
      "06/30/2020 16:53:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.2518373802214155e-06, 'epoch': 2.564889757186715, 'step': 9190}\n",
      "06/30/2020 16:53:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.242534189226906e-06, 'epoch': 2.5654479486463857, 'step': 9192}\n",
      "06/30/2020 16:53:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.233230998232394e-06, 'epoch': 2.5660061401060563, 'step': 9194}\n",
      "06/30/2020 16:53:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.2239278072378834e-06, 'epoch': 2.566564331565727, 'step': 9196}\n",
      "06/30/2020 16:53:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.214624616243372e-06, 'epoch': 2.5671225230253976, 'step': 9198}\n",
      "06/30/2020 16:53:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.20532142524886e-06, 'epoch': 2.5676807144850686, 'step': 9200}\n",
      "06/30/2020 16:53:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.19601823425435e-06, 'epoch': 2.568238905944739, 'step': 9202}\n",
      "06/30/2020 16:53:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.186715043259838e-06, 'epoch': 2.56879709740441, 'step': 9204}\n",
      "06/30/2020 16:53:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.177411852265327e-06, 'epoch': 2.5693552888640805, 'step': 9206}\n",
      "06/30/2020 16:53:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.168108661270816e-06, 'epoch': 2.569913480323751, 'step': 9208}\n",
      "06/30/2020 16:53:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.158805470276306e-06, 'epoch': 2.5704716717834217, 'step': 9210}\n",
      "06/30/2020 16:53:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.1495022792817945e-06, 'epoch': 2.5710298632430924, 'step': 9212}\n",
      "06/30/2020 16:53:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.140199088287283e-06, 'epoch': 2.571588054702763, 'step': 9214}\n",
      "06/30/2020 16:53:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.130895897292772e-06, 'epoch': 2.5721462461624336, 'step': 9216}\n",
      "06/30/2020 16:53:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.121592706298261e-06, 'epoch': 2.5727044376221047, 'step': 9218}\n",
      "06/30/2020 16:53:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.112289515303749e-06, 'epoch': 2.573262629081775, 'step': 9220}\n",
      "06/30/2020 16:53:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.1029863243092386e-06, 'epoch': 2.573820820541446, 'step': 9222}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:53:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.093683133314727e-06, 'epoch': 2.5743790120011165, 'step': 9224}\n",
      "06/30/2020 16:53:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.0843799423202155e-06, 'epoch': 2.574937203460787, 'step': 9226}\n",
      "06/30/2020 16:53:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.075076751325706e-06, 'epoch': 2.5754953949204578, 'step': 9228}\n",
      "06/30/2020 16:53:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.065773560331194e-06, 'epoch': 2.5760535863801284, 'step': 9230}\n",
      "06/30/2020 16:53:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.056470369336683e-06, 'epoch': 2.576611777839799, 'step': 9232}\n",
      "06/30/2020 16:53:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.047167178342172e-06, 'epoch': 2.5771699692994696, 'step': 9234}\n",
      "06/30/2020 16:53:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.03786398734766e-06, 'epoch': 2.5777281607591402, 'step': 9236}\n",
      "06/30/2020 16:53:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.02856079635315e-06, 'epoch': 2.578286352218811, 'step': 9238}\n",
      "06/30/2020 16:53:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.019257605358638e-06, 'epoch': 2.578844543678482, 'step': 9240}\n",
      "06/30/2020 16:53:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.009954414364127e-06, 'epoch': 2.5794027351381525, 'step': 9242}\n",
      "06/30/2020 16:53:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.000651223369616e-06, 'epoch': 2.579960926597823, 'step': 9244}\n",
      "06/30/2020 16:53:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.991348032375104e-06, 'epoch': 2.580519118057494, 'step': 9246}\n",
      "06/30/2020 16:53:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.9820448413805945e-06, 'epoch': 2.5810773095171644, 'step': 9248}\n",
      "06/30/2020 16:53:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.972741650386083e-06, 'epoch': 2.581635500976835, 'step': 9250}\n",
      "06/30/2020 16:53:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.963438459391572e-06, 'epoch': 2.5821936924365056, 'step': 9252}\n",
      "06/30/2020 16:53:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.954135268397061e-06, 'epoch': 2.5827518838961763, 'step': 9254}\n",
      "06/30/2020 16:53:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.944832077402549e-06, 'epoch': 2.583310075355847, 'step': 9256}\n",
      "06/30/2020 16:53:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.9355288864080385e-06, 'epoch': 2.583868266815518, 'step': 9258}\n",
      "06/30/2020 16:53:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.926225695413527e-06, 'epoch': 2.584426458275188, 'step': 9260}\n",
      "06/30/2020 16:53:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.9169225044190155e-06, 'epoch': 2.584984649734859, 'step': 9262}\n",
      "06/30/2020 16:53:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.907619313424504e-06, 'epoch': 2.58554284119453, 'step': 9264}\n",
      "06/30/2020 16:53:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.898316122429994e-06, 'epoch': 2.5861010326542004, 'step': 9266}\n",
      "06/30/2020 16:53:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.889012931435483e-06, 'epoch': 2.586659224113871, 'step': 9268}\n",
      "06/30/2020 16:53:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.879709740440972e-06, 'epoch': 2.5872174155735417, 'step': 9270}\n",
      "06/30/2020 16:53:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.87040654944646e-06, 'epoch': 2.5877756070332123, 'step': 9272}\n",
      "06/30/2020 16:53:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.86110335845195e-06, 'epoch': 2.588333798492883, 'step': 9274}\n",
      "06/30/2020 16:53:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.851800167457438e-06, 'epoch': 2.588891989952554, 'step': 9276}\n",
      "06/30/2020 16:53:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.8424969764629265e-06, 'epoch': 2.589450181412224, 'step': 9278}\n",
      "06/30/2020 16:53:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.833193785468416e-06, 'epoch': 2.5900083728718952, 'step': 9280}\n",
      "06/30/2020 16:53:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.823890594473904e-06, 'epoch': 2.590566564331566, 'step': 9282}\n",
      "06/30/2020 16:53:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.8145874034793945e-06, 'epoch': 2.5911247557912365, 'step': 9284}\n",
      "06/30/2020 16:53:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.805284212484883e-06, 'epoch': 2.591682947250907, 'step': 9286}\n",
      "06/30/2020 16:53:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.795981021490372e-06, 'epoch': 2.5922411387105777, 'step': 9288}\n",
      "06/30/2020 16:53:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.786677830495861e-06, 'epoch': 2.5927993301702483, 'step': 9290}\n",
      "06/30/2020 16:53:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.777374639501349e-06, 'epoch': 2.593357521629919, 'step': 9292}\n",
      "06/30/2020 16:53:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.768071448506838e-06, 'epoch': 2.5939157130895896, 'step': 9294}\n",
      "06/30/2020 16:53:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.758768257512327e-06, 'epoch': 2.59447390454926, 'step': 9296}\n",
      "06/30/2020 16:53:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.749465066517815e-06, 'epoch': 2.5950320960089313, 'step': 9298}\n",
      "06/30/2020 16:53:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.740161875523304e-06, 'epoch': 2.595590287468602, 'step': 9300}\n",
      "06/30/2020 16:53:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.730858684528794e-06, 'epoch': 2.5961484789282725, 'step': 9302}\n",
      "06/30/2020 16:53:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.721555493534283e-06, 'epoch': 2.596706670387943, 'step': 9304}\n",
      "06/30/2020 16:53:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.712252302539772e-06, 'epoch': 2.5972648618476137, 'step': 9306}\n",
      "06/30/2020 16:53:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.70294911154526e-06, 'epoch': 2.5978230533072844, 'step': 9308}\n",
      "06/30/2020 16:53:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.69364592055075e-06, 'epoch': 2.598381244766955, 'step': 9310}\n",
      "06/30/2020 16:53:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.684342729556238e-06, 'epoch': 2.5989394362266256, 'step': 9312}\n",
      "06/30/2020 16:53:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.6750395385617265e-06, 'epoch': 2.599497627686296, 'step': 9314}\n",
      "06/30/2020 16:53:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.665736347567216e-06, 'epoch': 2.6000558191459673, 'step': 9316}\n",
      "06/30/2020 16:53:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.656433156572704e-06, 'epoch': 2.6006140106056375, 'step': 9318}\n",
      "06/30/2020 16:53:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.647129965578193e-06, 'epoch': 2.6011722020653085, 'step': 9320}\n",
      "06/30/2020 16:53:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.637826774583683e-06, 'epoch': 2.601730393524979, 'step': 9322}\n",
      "06/30/2020 16:53:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.628523583589171e-06, 'epoch': 2.6022885849846498, 'step': 9324}\n",
      "06/30/2020 16:53:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.619220392594661e-06, 'epoch': 2.6028467764443204, 'step': 9326}\n",
      "06/30/2020 16:53:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.609917201600149e-06, 'epoch': 2.603404967903991, 'step': 9328}\n",
      "06/30/2020 16:53:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.600614010605638e-06, 'epoch': 2.6039631593636616, 'step': 9330}\n",
      "06/30/2020 16:53:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.591310819611127e-06, 'epoch': 2.6045213508233322, 'step': 9332}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:53:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.582007628616615e-06, 'epoch': 2.6050795422830033, 'step': 9334}\n",
      "06/30/2020 16:53:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.572704437622104e-06, 'epoch': 2.6056377337426735, 'step': 9336}\n",
      "06/30/2020 16:53:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.563401246627593e-06, 'epoch': 2.6061959252023446, 'step': 9338}\n",
      "06/30/2020 16:53:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.554098055633083e-06, 'epoch': 2.606754116662015, 'step': 9340}\n",
      "06/30/2020 16:53:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.544794864638572e-06, 'epoch': 2.607312308121686, 'step': 9342}\n",
      "06/30/2020 16:53:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.53549167364406e-06, 'epoch': 2.6078704995813564, 'step': 9344}\n",
      "06/30/2020 16:53:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.5261884826495496e-06, 'epoch': 2.608428691041027, 'step': 9346}\n",
      "06/30/2020 16:53:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.516885291655038e-06, 'epoch': 2.6089868825006977, 'step': 9348}\n",
      "06/30/2020 16:53:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.5075821006605265e-06, 'epoch': 2.6095450739603683, 'step': 9350}\n",
      "06/30/2020 16:53:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.498278909666016e-06, 'epoch': 2.6101032654200393, 'step': 9352}\n",
      "06/30/2020 16:53:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.488975718671504e-06, 'epoch': 2.6106614568797095, 'step': 9354}\n",
      "06/30/2020 16:53:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.479672527676993e-06, 'epoch': 2.6112196483393806, 'step': 9356}\n",
      "06/30/2020 16:53:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.470369336682483e-06, 'epoch': 2.611777839799051, 'step': 9358}\n",
      "06/30/2020 16:53:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.461066145687971e-06, 'epoch': 2.612336031258722, 'step': 9360}\n",
      "06/30/2020 16:53:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.451762954693461e-06, 'epoch': 2.6128942227183924, 'step': 9362}\n",
      "06/30/2020 16:53:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.442459763698949e-06, 'epoch': 2.613452414178063, 'step': 9364}\n",
      "06/30/2020 16:53:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.433156572704438e-06, 'epoch': 2.6140106056377337, 'step': 9366}\n",
      "06/30/2020 16:53:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.423853381709927e-06, 'epoch': 2.6145687970974043, 'step': 9368}\n",
      "06/30/2020 16:53:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.414550190715415e-06, 'epoch': 2.615126988557075, 'step': 9370}\n",
      "06/30/2020 16:53:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.405246999720904e-06, 'epoch': 2.6156851800167455, 'step': 9372}\n",
      "06/30/2020 16:53:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.395943808726393e-06, 'epoch': 2.6162433714764166, 'step': 9374}\n",
      "06/30/2020 16:53:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.386640617731883e-06, 'epoch': 2.6168015629360872, 'step': 9376}\n",
      "06/30/2020 16:53:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.377337426737372e-06, 'epoch': 2.617359754395758, 'step': 9378}\n",
      "06/30/2020 16:53:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.36803423574286e-06, 'epoch': 2.6179179458554285, 'step': 9380}\n",
      "06/30/2020 16:53:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.3587310447483495e-06, 'epoch': 2.618476137315099, 'step': 9382}\n",
      "06/30/2020 16:53:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.349427853753838e-06, 'epoch': 2.6190343287747697, 'step': 9384}\n",
      "06/30/2020 16:53:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.3401246627593265e-06, 'epoch': 2.6195925202344403, 'step': 9386}\n",
      "06/30/2020 16:53:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.330821471764816e-06, 'epoch': 2.620150711694111, 'step': 9388}\n",
      "06/30/2020 16:53:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.321518280770304e-06, 'epoch': 2.6207089031537816, 'step': 9390}\n",
      "06/30/2020 16:53:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.312215089775793e-06, 'epoch': 2.6212670946134526, 'step': 9392}\n",
      "06/30/2020 16:53:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.302911898781283e-06, 'epoch': 2.621825286073123, 'step': 9394}\n",
      "06/30/2020 16:53:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.293608707786771e-06, 'epoch': 2.622383477532794, 'step': 9396}\n",
      "06/30/2020 16:53:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.284305516792261e-06, 'epoch': 2.6229416689924645, 'step': 9398}\n",
      "06/30/2020 16:53:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.275002325797749e-06, 'epoch': 2.623499860452135, 'step': 9400}\n",
      "06/30/2020 16:53:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.2656991348032376e-06, 'epoch': 2.6240580519118057, 'step': 9402}\n",
      "06/30/2020 16:53:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.256395943808727e-06, 'epoch': 2.6246162433714764, 'step': 9404}\n",
      "06/30/2020 16:53:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.247092752814215e-06, 'epoch': 2.625174434831147, 'step': 9406}\n",
      "06/30/2020 16:53:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.237789561819705e-06, 'epoch': 2.6257326262908176, 'step': 9408}\n",
      "06/30/2020 16:53:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.228486370825193e-06, 'epoch': 2.6262908177504887, 'step': 9410}\n",
      "06/30/2020 16:53:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.2191831798306824e-06, 'epoch': 2.626849009210159, 'step': 9412}\n",
      "06/30/2020 16:53:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.209879988836171e-06, 'epoch': 2.62740720066983, 'step': 9414}\n",
      "06/30/2020 16:53:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.200576797841659e-06, 'epoch': 2.6279653921295005, 'step': 9416}\n",
      "06/30/2020 16:53:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.1912736068471495e-06, 'epoch': 2.628523583589171, 'step': 9418}\n",
      "06/30/2020 16:53:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.181970415852638e-06, 'epoch': 2.6290817750488418, 'step': 9420}\n",
      "06/30/2020 16:53:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.1726672248581264e-06, 'epoch': 2.6296399665085124, 'step': 9422}\n",
      "06/30/2020 16:53:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.163364033863616e-06, 'epoch': 2.630198157968183, 'step': 9424}\n",
      "06/30/2020 16:53:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.154060842869104e-06, 'epoch': 2.6307563494278536, 'step': 9426}\n",
      "06/30/2020 16:53:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.1447576518745935e-06, 'epoch': 2.6313145408875243, 'step': 9428}\n",
      "06/30/2020 16:53:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.135454460880082e-06, 'epoch': 2.631872732347195, 'step': 9430}\n",
      "06/30/2020 16:53:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.126151269885571e-06, 'epoch': 2.632430923806866, 'step': 9432}\n",
      "06/30/2020 16:53:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.11684807889106e-06, 'epoch': 2.6329891152665366, 'step': 9434}\n",
      "06/30/2020 16:53:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.107544887896549e-06, 'epoch': 2.633547306726207, 'step': 9436}\n",
      "06/30/2020 16:53:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.0982416969020375e-06, 'epoch': 2.634105498185878, 'step': 9438}\n",
      "06/30/2020 16:53:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.088938505907527e-06, 'epoch': 2.6346636896455484, 'step': 9440}\n",
      "06/30/2020 16:53:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.079635314913015e-06, 'epoch': 2.635221881105219, 'step': 9442}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:53:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.070332123918504e-06, 'epoch': 2.6357800725648897, 'step': 9444}\n",
      "06/30/2020 16:53:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.061028932923993e-06, 'epoch': 2.6363382640245603, 'step': 9446}\n",
      "06/30/2020 16:53:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.051725741929482e-06, 'epoch': 2.636896455484231, 'step': 9448}\n",
      "06/30/2020 16:53:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.042422550934971e-06, 'epoch': 2.637454646943902, 'step': 9450}\n",
      "06/30/2020 16:53:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.033119359940459e-06, 'epoch': 2.6380128384035726, 'step': 9452}\n",
      "06/30/2020 16:53:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.0238161689459495e-06, 'epoch': 2.638571029863243, 'step': 9454}\n",
      "06/30/2020 16:53:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.014512977951438e-06, 'epoch': 2.639129221322914, 'step': 9456}\n",
      "06/30/2020 16:53:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.005209786956926e-06, 'epoch': 2.6396874127825845, 'step': 9458}\n",
      "06/30/2020 16:53:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.995906595962415e-06, 'epoch': 2.640245604242255, 'step': 9460}\n",
      "06/30/2020 16:53:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.986603404967904e-06, 'epoch': 2.6408037957019257, 'step': 9462}\n",
      "06/30/2020 16:53:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.9773002139733935e-06, 'epoch': 2.6413619871615963, 'step': 9464}\n",
      "06/30/2020 16:53:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.967997022978882e-06, 'epoch': 2.641920178621267, 'step': 9466}\n",
      "06/30/2020 16:53:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.958693831984371e-06, 'epoch': 2.642478370080938, 'step': 9468}\n",
      "06/30/2020 16:53:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.94939064098986e-06, 'epoch': 2.643036561540608, 'step': 9470}\n",
      "06/30/2020 16:53:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.940087449995348e-06, 'epoch': 2.6435947530002792, 'step': 9472}\n",
      "06/30/2020 16:53:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.9307842590008375e-06, 'epoch': 2.64415294445995, 'step': 9474}\n",
      "06/30/2020 16:53:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.921481068006327e-06, 'epoch': 2.6447111359196205, 'step': 9476}\n",
      "06/30/2020 16:53:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.912177877011815e-06, 'epoch': 2.645269327379291, 'step': 9478}\n",
      "06/30/2020 16:53:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.902874686017304e-06, 'epoch': 2.6458275188389617, 'step': 9480}\n",
      "06/30/2020 16:53:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.893571495022793e-06, 'epoch': 2.6463857102986323, 'step': 9482}\n",
      "06/30/2020 16:53:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.884268304028282e-06, 'epoch': 2.646943901758303, 'step': 9484}\n",
      "06/30/2020 16:53:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.874965113033771e-06, 'epoch': 2.647502093217974, 'step': 9486}\n",
      "06/30/2020 16:53:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.865661922039259e-06, 'epoch': 2.648060284677644, 'step': 9488}\n",
      "06/30/2020 16:53:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.856358731044749e-06, 'epoch': 2.6486184761373153, 'step': 9490}\n",
      "06/30/2020 16:53:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.847055540050238e-06, 'epoch': 2.649176667596986, 'step': 9492}\n",
      "06/30/2020 16:53:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.837752349055726e-06, 'epoch': 2.6497348590566565, 'step': 9494}\n",
      "06/30/2020 16:53:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.828449158061215e-06, 'epoch': 2.650293050516327, 'step': 9496}\n",
      "06/30/2020 16:53:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.819145967066704e-06, 'epoch': 2.6508512419759978, 'step': 9498}\n",
      "06/30/2020 16:53:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.8098427760721935e-06, 'epoch': 2.6514094334356684, 'step': 9500}\n",
      "06/30/2020 16:53:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.800539585077682e-06, 'epoch': 2.651967624895339, 'step': 9502}\n",
      "06/30/2020 16:53:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.791236394083171e-06, 'epoch': 2.6525258163550096, 'step': 9504}\n",
      "06/30/2020 16:53:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.78193320308866e-06, 'epoch': 2.6530840078146802, 'step': 9506}\n",
      "06/30/2020 16:53:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.772630012094148e-06, 'epoch': 2.6536421992743513, 'step': 9508}\n",
      "06/30/2020 16:53:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.7633268210996375e-06, 'epoch': 2.654200390734022, 'step': 9510}\n",
      "06/30/2020 16:53:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.754023630105127e-06, 'epoch': 2.6547585821936925, 'step': 9512}\n",
      "06/30/2020 16:53:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.744720439110615e-06, 'epoch': 2.655316773653363, 'step': 9514}\n",
      "06/30/2020 16:53:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.735417248116104e-06, 'epoch': 2.655874965113034, 'step': 9516}\n",
      "06/30/2020 16:53:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.726114057121593e-06, 'epoch': 2.6564331565727044, 'step': 9518}\n",
      "06/30/2020 16:53:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.716810866127082e-06, 'epoch': 2.656991348032375, 'step': 9520}\n",
      "06/30/2020 16:53:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.707507675132571e-06, 'epoch': 2.6575495394920456, 'step': 9522}\n",
      "06/30/2020 16:53:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.698204484138059e-06, 'epoch': 2.6581077309517163, 'step': 9524}\n",
      "06/30/2020 16:53:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.688901293143549e-06, 'epoch': 2.6586659224113873, 'step': 9526}\n",
      "06/30/2020 16:53:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.679598102149038e-06, 'epoch': 2.6592241138710575, 'step': 9528}\n",
      "06/30/2020 16:53:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.670294911154526e-06, 'epoch': 2.6597823053307286, 'step': 9530}\n",
      "06/30/2020 16:53:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.660991720160015e-06, 'epoch': 2.660340496790399, 'step': 9532}\n",
      "06/30/2020 16:53:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.651688529165504e-06, 'epoch': 2.66089868825007, 'step': 9534}\n",
      "06/30/2020 16:53:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.642385338170993e-06, 'epoch': 2.6614568797097404, 'step': 9536}\n",
      "06/30/2020 16:53:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.633082147176482e-06, 'epoch': 2.662015071169411, 'step': 9538}\n",
      "06/30/2020 16:53:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.62377895618197e-06, 'epoch': 2.6625732626290817, 'step': 9540}\n",
      "06/30/2020 16:53:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.61447576518746e-06, 'epoch': 2.6631314540887523, 'step': 9542}\n",
      "06/30/2020 16:53:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.605172574192948e-06, 'epoch': 2.6636896455484234, 'step': 9544}\n",
      "06/30/2020 16:53:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.5958693831984375e-06, 'epoch': 2.6642478370080935, 'step': 9546}\n",
      "06/30/2020 16:53:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.586566192203927e-06, 'epoch': 2.6648060284677646, 'step': 9548}\n",
      "06/30/2020 16:53:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.577263001209415e-06, 'epoch': 2.665364219927435, 'step': 9550}\n",
      "06/30/2020 16:53:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.567959810214904e-06, 'epoch': 2.665922411387106, 'step': 9552}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:53:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.558656619220393e-06, 'epoch': 2.6664806028467765, 'step': 9554}\n",
      "06/30/2020 16:53:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.549353428225882e-06, 'epoch': 2.667038794306447, 'step': 9556}\n",
      "06/30/2020 16:53:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.540050237231371e-06, 'epoch': 2.6675969857661177, 'step': 9558}\n",
      "06/30/2020 16:53:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.530747046236859e-06, 'epoch': 2.6681551772257883, 'step': 9560}\n",
      "06/30/2020 16:53:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.5214438552423485e-06, 'epoch': 2.6687133686854594, 'step': 9562}\n",
      "06/30/2020 16:53:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.512140664247837e-06, 'epoch': 2.6692715601451296, 'step': 9564}\n",
      "06/30/2020 16:53:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.502837473253326e-06, 'epoch': 2.6698297516048006, 'step': 9566}\n",
      "06/30/2020 16:53:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.493534282258815e-06, 'epoch': 2.6703879430644712, 'step': 9568}\n",
      "06/30/2020 16:53:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.484231091264304e-06, 'epoch': 2.670946134524142, 'step': 9570}\n",
      "06/30/2020 16:53:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.4749279002697926e-06, 'epoch': 2.6715043259838125, 'step': 9572}\n",
      "06/30/2020 16:53:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.465624709275282e-06, 'epoch': 2.672062517443483, 'step': 9574}\n",
      "06/30/2020 16:53:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.45632151828077e-06, 'epoch': 2.6726207089031537, 'step': 9576}\n",
      "06/30/2020 16:53:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.44701832728626e-06, 'epoch': 2.6731789003628244, 'step': 9578}\n",
      "06/30/2020 16:53:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.437715136291748e-06, 'epoch': 2.673737091822495, 'step': 9580}\n",
      "06/30/2020 16:53:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.4284119452972366e-06, 'epoch': 2.6742952832821656, 'step': 9582}\n",
      "06/30/2020 16:53:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.419108754302727e-06, 'epoch': 2.6748534747418367, 'step': 9584}\n",
      "06/30/2020 16:53:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.409805563308215e-06, 'epoch': 2.6754116662015073, 'step': 9586}\n",
      "06/30/2020 16:53:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.400502372313704e-06, 'epoch': 2.675969857661178, 'step': 9588}\n",
      "06/30/2020 16:53:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.391199181319193e-06, 'epoch': 2.6765280491208485, 'step': 9590}\n",
      "06/30/2020 16:53:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.3818959903246814e-06, 'epoch': 2.677086240580519, 'step': 9592}\n",
      "06/30/2020 16:53:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.372592799330171e-06, 'epoch': 2.6776444320401898, 'step': 9594}\n",
      "06/30/2020 16:53:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.363289608335659e-06, 'epoch': 2.6782026234998604, 'step': 9596}\n",
      "06/30/2020 16:53:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.3539864173411485e-06, 'epoch': 2.678760814959531, 'step': 9598}\n",
      "06/30/2020 16:53:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.344683226346637e-06, 'epoch': 2.6793190064192016, 'step': 9600}\n",
      "06/30/2020 16:53:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.335380035352126e-06, 'epoch': 2.6798771978788727, 'step': 9602}\n",
      "06/30/2020 16:53:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.326076844357615e-06, 'epoch': 2.680435389338543, 'step': 9604}\n",
      "06/30/2020 16:53:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.316773653363104e-06, 'epoch': 2.680993580798214, 'step': 9606}\n",
      "06/30/2020 16:53:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.3074704623685925e-06, 'epoch': 2.6815517722578845, 'step': 9608}\n",
      "06/30/2020 16:53:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.298167271374081e-06, 'epoch': 2.682109963717555, 'step': 9610}\n",
      "06/30/2020 16:53:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.28886408037957e-06, 'epoch': 2.682668155177226, 'step': 9612}\n",
      "06/30/2020 16:53:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.27956088938506e-06, 'epoch': 2.6832263466368964, 'step': 9614}\n",
      "06/30/2020 16:53:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.270257698390548e-06, 'epoch': 2.683784538096567, 'step': 9616}\n",
      "06/30/2020 16:53:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.2609545073960365e-06, 'epoch': 2.6843427295562377, 'step': 9618}\n",
      "06/30/2020 16:53:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.251651316401527e-06, 'epoch': 2.6849009210159087, 'step': 9620}\n",
      "06/30/2020 16:53:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.242348125407015e-06, 'epoch': 2.685459112475579, 'step': 9622}\n",
      "06/30/2020 16:53:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.233044934412504e-06, 'epoch': 2.68601730393525, 'step': 9624}\n",
      "06/30/2020 16:53:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.223741743417992e-06, 'epoch': 2.6865754953949206, 'step': 9626}\n",
      "06/30/2020 16:53:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.214438552423481e-06, 'epoch': 2.687133686854591, 'step': 9628}\n",
      "06/30/2020 16:53:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.205135361428971e-06, 'epoch': 2.687691878314262, 'step': 9630}\n",
      "06/30/2020 16:53:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.195832170434459e-06, 'epoch': 2.6882500697739324, 'step': 9632}\n",
      "06/30/2020 16:53:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.1865289794399485e-06, 'epoch': 2.688808261233603, 'step': 9634}\n",
      "06/30/2020 16:53:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.177225788445437e-06, 'epoch': 2.6893664526932737, 'step': 9636}\n",
      "06/30/2020 16:53:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.167922597450925e-06, 'epoch': 2.6899246441529443, 'step': 9638}\n",
      "06/30/2020 16:53:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.158619406456415e-06, 'epoch': 2.690482835612615, 'step': 9640}\n",
      "06/30/2020 16:53:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.149316215461904e-06, 'epoch': 2.691041027072286, 'step': 9642}\n",
      "06/30/2020 16:53:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.1400130244673925e-06, 'epoch': 2.6915992185319566, 'step': 9644}\n",
      "06/30/2020 16:53:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.130709833472881e-06, 'epoch': 2.6921574099916272, 'step': 9646}\n",
      "06/30/2020 16:53:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.12140664247837e-06, 'epoch': 2.692715601451298, 'step': 9648}\n",
      "06/30/2020 16:53:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.11210345148386e-06, 'epoch': 2.6932737929109685, 'step': 9650}\n",
      "06/30/2020 16:53:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.102800260489348e-06, 'epoch': 2.693831984370639, 'step': 9652}\n",
      "06/30/2020 16:53:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.0934970694948365e-06, 'epoch': 2.6943901758303097, 'step': 9654}\n",
      "06/30/2020 16:53:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.084193878500326e-06, 'epoch': 2.6949483672899803, 'step': 9656}\n",
      "06/30/2020 16:53:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.074890687505815e-06, 'epoch': 2.695506558749651, 'step': 9658}\n",
      "06/30/2020 16:53:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.065587496511304e-06, 'epoch': 2.696064750209322, 'step': 9660}\n",
      "06/30/2020 16:53:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.056284305516792e-06, 'epoch': 2.696622941668992, 'step': 9662}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:53:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.046981114522281e-06, 'epoch': 2.6971811331286633, 'step': 9664}\n",
      "06/30/2020 16:53:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.037677923527771e-06, 'epoch': 2.697739324588334, 'step': 9666}\n",
      "06/30/2020 16:53:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.028374732533259e-06, 'epoch': 2.6982975160480045, 'step': 9668}\n",
      "06/30/2020 16:53:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.0190715415387485e-06, 'epoch': 2.698855707507675, 'step': 9670}\n",
      "06/30/2020 16:53:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.009768350544237e-06, 'epoch': 2.6994138989673457, 'step': 9672}\n",
      "06/30/2020 16:53:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.000465159549725e-06, 'epoch': 2.6999720904270164, 'step': 9674}\n",
      "06/30/2020 16:53:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.991161968555215e-06, 'epoch': 2.700530281886687, 'step': 9676}\n",
      "06/30/2020 16:53:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.981858777560704e-06, 'epoch': 2.701088473346358, 'step': 9678}\n",
      "06/30/2020 16:53:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.9725555865661925e-06, 'epoch': 2.701646664806028, 'step': 9680}\n",
      "06/30/2020 16:53:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.963252395571681e-06, 'epoch': 2.7022048562656993, 'step': 9682}\n",
      "06/30/2020 16:53:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.95394920457717e-06, 'epoch': 2.70276304772537, 'step': 9684}\n",
      "06/30/2020 16:53:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.9446460135826596e-06, 'epoch': 2.7033212391850405, 'step': 9686}\n",
      "06/30/2020 16:53:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.935342822588148e-06, 'epoch': 2.703879430644711, 'step': 9688}\n",
      "06/30/2020 16:53:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.9260396315936365e-06, 'epoch': 2.7044376221043818, 'step': 9690}\n",
      "06/30/2020 16:53:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.916736440599126e-06, 'epoch': 2.7049958135640524, 'step': 9692}\n",
      "06/30/2020 16:53:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.907433249604615e-06, 'epoch': 2.705554005023723, 'step': 9694}\n",
      "06/30/2020 16:53:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.898130058610104e-06, 'epoch': 2.706112196483394, 'step': 9696}\n",
      "06/30/2020 16:53:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.888826867615592e-06, 'epoch': 2.7066703879430642, 'step': 9698}\n",
      "06/30/2020 16:53:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.879523676621081e-06, 'epoch': 2.7072285794027353, 'step': 9700}\n",
      "06/30/2020 16:53:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.87022048562657e-06, 'epoch': 2.707786770862406, 'step': 9702}\n",
      "06/30/2020 16:53:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.860917294632059e-06, 'epoch': 2.7083449623220766, 'step': 9704}\n",
      "06/30/2020 16:53:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.851614103637548e-06, 'epoch': 2.708903153781747, 'step': 9706}\n",
      "06/30/2020 16:53:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.842310912643037e-06, 'epoch': 2.709461345241418, 'step': 9708}\n",
      "06/30/2020 16:53:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.833007721648525e-06, 'epoch': 2.7100195367010884, 'step': 9710}\n",
      "06/30/2020 16:53:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.823704530654015e-06, 'epoch': 2.710577728160759, 'step': 9712}\n",
      "06/30/2020 16:53:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.814401339659504e-06, 'epoch': 2.7111359196204297, 'step': 9714}\n",
      "06/30/2020 16:54:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.8050981486649925e-06, 'epoch': 2.7116941110801003, 'step': 9716}\n",
      "06/30/2020 16:54:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.795794957670481e-06, 'epoch': 2.7122523025397713, 'step': 9718}\n",
      "06/30/2020 16:54:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.78649176667597e-06, 'epoch': 2.712810493999442, 'step': 9720}\n",
      "06/30/2020 16:54:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7771885756814595e-06, 'epoch': 2.7133686854591126, 'step': 9722}\n",
      "06/30/2020 16:54:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.767885384686948e-06, 'epoch': 2.713926876918783, 'step': 9724}\n",
      "06/30/2020 16:54:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7585821936924365e-06, 'epoch': 2.714485068378454, 'step': 9726}\n",
      "06/30/2020 16:54:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.749279002697926e-06, 'epoch': 2.7150432598381244, 'step': 9728}\n",
      "06/30/2020 16:54:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.739975811703414e-06, 'epoch': 2.715601451297795, 'step': 9730}\n",
      "06/30/2020 16:54:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.7306726207089035e-06, 'epoch': 2.7161596427574657, 'step': 9732}\n",
      "06/30/2020 16:54:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.721369429714392e-06, 'epoch': 2.7167178342171363, 'step': 9734}\n",
      "06/30/2020 16:54:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.712066238719881e-06, 'epoch': 2.7172760256768074, 'step': 9736}\n",
      "06/30/2020 16:54:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.70276304772537e-06, 'epoch': 2.7178342171364775, 'step': 9738}\n",
      "06/30/2020 16:54:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.693459856730859e-06, 'epoch': 2.7183924085961486, 'step': 9740}\n",
      "06/30/2020 16:54:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6841566657363476e-06, 'epoch': 2.7189506000558192, 'step': 9742}\n",
      "06/30/2020 16:54:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.674853474741837e-06, 'epoch': 2.71950879151549, 'step': 9744}\n",
      "06/30/2020 16:54:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.665550283747325e-06, 'epoch': 2.7200669829751605, 'step': 9746}\n",
      "06/30/2020 16:54:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.656247092752814e-06, 'epoch': 2.720625174434831, 'step': 9748}\n",
      "06/30/2020 16:54:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.646943901758304e-06, 'epoch': 2.7211833658945017, 'step': 9750}\n",
      "06/30/2020 16:54:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.637640710763792e-06, 'epoch': 2.7217415573541723, 'step': 9752}\n",
      "06/30/2020 16:54:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.628337519769281e-06, 'epoch': 2.7222997488138434, 'step': 9754}\n",
      "06/30/2020 16:54:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.619034328774769e-06, 'epoch': 2.7228579402735136, 'step': 9756}\n",
      "06/30/2020 16:54:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6097311377802595e-06, 'epoch': 2.7234161317331846, 'step': 9758}\n",
      "06/30/2020 16:54:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.600427946785748e-06, 'epoch': 2.7239743231928553, 'step': 9760}\n",
      "06/30/2020 16:54:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5911247557912364e-06, 'epoch': 2.724532514652526, 'step': 9762}\n",
      "06/30/2020 16:54:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.581821564796726e-06, 'epoch': 2.7250907061121965, 'step': 9764}\n",
      "06/30/2020 16:54:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.572518373802214e-06, 'epoch': 2.725648897571867, 'step': 9766}\n",
      "06/30/2020 16:54:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5632151828077035e-06, 'epoch': 2.7262070890315377, 'step': 9768}\n",
      "06/30/2020 16:54:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.553911991813192e-06, 'epoch': 2.7267652804912084, 'step': 9770}\n",
      "06/30/2020 16:54:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.544608800818681e-06, 'epoch': 2.727323471950879, 'step': 9772}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:54:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.53530560982417e-06, 'epoch': 2.7278816634105496, 'step': 9774}\n",
      "06/30/2020 16:54:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.526002418829658e-06, 'epoch': 2.7284398548702207, 'step': 9776}\n",
      "06/30/2020 16:54:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5166992278351475e-06, 'epoch': 2.7289980463298913, 'step': 9778}\n",
      "06/30/2020 16:54:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.507396036840637e-06, 'epoch': 2.729556237789562, 'step': 9780}\n",
      "06/30/2020 16:54:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.498092845846125e-06, 'epoch': 2.7301144292492325, 'step': 9782}\n",
      "06/30/2020 16:54:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.488789654851614e-06, 'epoch': 2.730672620708903, 'step': 9784}\n",
      "06/30/2020 16:54:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.479486463857104e-06, 'epoch': 2.7312308121685738, 'step': 9786}\n",
      "06/30/2020 16:54:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.470183272862592e-06, 'epoch': 2.7317890036282444, 'step': 9788}\n",
      "06/30/2020 16:54:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.460880081868081e-06, 'epoch': 2.732347195087915, 'step': 9790}\n",
      "06/30/2020 16:54:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.451576890873569e-06, 'epoch': 2.7329053865475856, 'step': 9792}\n",
      "06/30/2020 16:54:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.442273699879059e-06, 'epoch': 2.7334635780072567, 'step': 9794}\n",
      "06/30/2020 16:54:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.432970508884548e-06, 'epoch': 2.7340217694669273, 'step': 9796}\n",
      "06/30/2020 16:54:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.423667317890036e-06, 'epoch': 2.734579960926598, 'step': 9798}\n",
      "06/30/2020 16:54:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.414364126895526e-06, 'epoch': 2.7351381523862686, 'step': 9800}\n",
      "06/30/2020 16:54:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.405060935901014e-06, 'epoch': 2.735696343845939, 'step': 9802}\n",
      "06/30/2020 16:54:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.395757744906503e-06, 'epoch': 2.73625453530561, 'step': 9804}\n",
      "06/30/2020 16:54:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.386454553911992e-06, 'epoch': 2.7368127267652804, 'step': 9806}\n",
      "06/30/2020 16:54:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.377151362917481e-06, 'epoch': 2.737370918224951, 'step': 9808}\n",
      "06/30/2020 16:54:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.36784817192297e-06, 'epoch': 2.7379291096846217, 'step': 9810}\n",
      "06/30/2020 16:54:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.358544980928458e-06, 'epoch': 2.7384873011442927, 'step': 9812}\n",
      "06/30/2020 16:54:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3492417899339475e-06, 'epoch': 2.739045492603963, 'step': 9814}\n",
      "06/30/2020 16:54:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.339938598939437e-06, 'epoch': 2.739603684063634, 'step': 9816}\n",
      "06/30/2020 16:54:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.330635407944925e-06, 'epoch': 2.7401618755233046, 'step': 9818}\n",
      "06/30/2020 16:54:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.321332216950414e-06, 'epoch': 2.740720066982975, 'step': 9820}\n",
      "06/30/2020 16:54:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.312029025955903e-06, 'epoch': 2.741278258442646, 'step': 9822}\n",
      "06/30/2020 16:54:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.302725834961392e-06, 'epoch': 2.7418364499023165, 'step': 9824}\n",
      "06/30/2020 16:54:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.293422643966881e-06, 'epoch': 2.742394641361987, 'step': 9826}\n",
      "06/30/2020 16:54:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.284119452972369e-06, 'epoch': 2.7429528328216577, 'step': 9828}\n",
      "06/30/2020 16:54:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.274816261977859e-06, 'epoch': 2.7435110242813288, 'step': 9830}\n",
      "06/30/2020 16:54:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.265513070983348e-06, 'epoch': 2.744069215740999, 'step': 9832}\n",
      "06/30/2020 16:54:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.256209879988836e-06, 'epoch': 2.74462740720067, 'step': 9834}\n",
      "06/30/2020 16:54:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.246906688994326e-06, 'epoch': 2.7451855986603406, 'step': 9836}\n",
      "06/30/2020 16:54:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.237603497999814e-06, 'epoch': 2.7457437901200112, 'step': 9838}\n",
      "06/30/2020 16:54:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.228300307005303e-06, 'epoch': 2.746301981579682, 'step': 9840}\n",
      "06/30/2020 16:54:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.218997116010792e-06, 'epoch': 2.7468601730393525, 'step': 9842}\n",
      "06/30/2020 16:54:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.209693925016281e-06, 'epoch': 2.747418364499023, 'step': 9844}\n",
      "06/30/2020 16:54:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.20039073402177e-06, 'epoch': 2.7479765559586937, 'step': 9846}\n",
      "06/30/2020 16:54:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.191087543027258e-06, 'epoch': 2.7485347474183643, 'step': 9848}\n",
      "06/30/2020 16:54:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1817843520327475e-06, 'epoch': 2.749092938878035, 'step': 9850}\n",
      "06/30/2020 16:54:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.172481161038237e-06, 'epoch': 2.749651130337706, 'step': 9852}\n",
      "06/30/2020 16:54:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.163177970043725e-06, 'epoch': 2.7502093217973766, 'step': 9854}\n",
      "06/30/2020 16:54:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.153874779049214e-06, 'epoch': 2.7507675132570473, 'step': 9856}\n",
      "06/30/2020 16:54:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.144571588054703e-06, 'epoch': 2.751325704716718, 'step': 9858}\n",
      "06/30/2020 16:54:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.135268397060192e-06, 'epoch': 2.7518838961763885, 'step': 9860}\n",
      "06/30/2020 16:54:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.125965206065681e-06, 'epoch': 2.752442087636059, 'step': 9862}\n",
      "06/30/2020 16:54:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.116662015071169e-06, 'epoch': 2.7530002790957298, 'step': 9864}\n",
      "06/30/2020 16:54:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.1073588240766586e-06, 'epoch': 2.7535584705554004, 'step': 9866}\n",
      "06/30/2020 16:54:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.098055633082147e-06, 'epoch': 2.754116662015071, 'step': 9868}\n",
      "06/30/2020 16:54:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.088752442087636e-06, 'epoch': 2.754674853474742, 'step': 9870}\n",
      "06/30/2020 16:54:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.079449251093125e-06, 'epoch': 2.7552330449344122, 'step': 9872}\n",
      "06/30/2020 16:54:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.070146060098614e-06, 'epoch': 2.7557912363940833, 'step': 9874}\n",
      "06/30/2020 16:54:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.060842869104103e-06, 'epoch': 2.756349427853754, 'step': 9876}\n",
      "06/30/2020 16:54:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.051539678109592e-06, 'epoch': 2.7569076193134245, 'step': 9878}\n",
      "06/30/2020 16:54:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.042236487115081e-06, 'epoch': 2.757465810773095, 'step': 9880}\n",
      "06/30/2020 16:54:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.03293329612057e-06, 'epoch': 2.758024002232766, 'step': 9882}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:54:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.023630105126058e-06, 'epoch': 2.7585821936924364, 'step': 9884}\n",
      "06/30/2020 16:54:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0143269141315474e-06, 'epoch': 2.759140385152107, 'step': 9886}\n",
      "06/30/2020 16:54:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.005023723137037e-06, 'epoch': 2.759698576611778, 'step': 9888}\n",
      "06/30/2020 16:54:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.995720532142525e-06, 'epoch': 2.7602567680714483, 'step': 9890}\n",
      "06/30/2020 16:54:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.986417341148014e-06, 'epoch': 2.7608149595311193, 'step': 9892}\n",
      "06/30/2020 16:54:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.977114150153503e-06, 'epoch': 2.76137315099079, 'step': 9894}\n",
      "06/30/2020 16:54:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9678109591589915e-06, 'epoch': 2.7619313424504606, 'step': 9896}\n",
      "06/30/2020 16:54:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.958507768164481e-06, 'epoch': 2.762489533910131, 'step': 9898}\n",
      "06/30/2020 16:54:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.949204577169969e-06, 'epoch': 2.763047725369802, 'step': 9900}\n",
      "06/30/2020 16:54:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.9399013861754585e-06, 'epoch': 2.7636059168294724, 'step': 9902}\n",
      "06/30/2020 16:54:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.930598195180947e-06, 'epoch': 2.764164108289143, 'step': 9904}\n",
      "06/30/2020 16:54:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.921295004186436e-06, 'epoch': 2.764722299748814, 'step': 9906}\n",
      "06/30/2020 16:54:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.911991813191925e-06, 'epoch': 2.7652804912084843, 'step': 9908}\n",
      "06/30/2020 16:54:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.902688622197414e-06, 'epoch': 2.7658386826681554, 'step': 9910}\n",
      "06/30/2020 16:54:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8933854312029026e-06, 'epoch': 2.766396874127826, 'step': 9912}\n",
      "06/30/2020 16:54:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.884082240208391e-06, 'epoch': 2.7669550655874966, 'step': 9914}\n",
      "06/30/2020 16:54:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.874779049213881e-06, 'epoch': 2.767513257047167, 'step': 9916}\n",
      "06/30/2020 16:54:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.86547585821937e-06, 'epoch': 2.768071448506838, 'step': 9918}\n",
      "06/30/2020 16:54:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.856172667224858e-06, 'epoch': 2.7686296399665085, 'step': 9920}\n",
      "06/30/2020 16:54:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8468694762303466e-06, 'epoch': 2.769187831426179, 'step': 9922}\n",
      "06/30/2020 16:54:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.837566285235837e-06, 'epoch': 2.7697460228858497, 'step': 9924}\n",
      "06/30/2020 16:54:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.828263094241325e-06, 'epoch': 2.7703042143455203, 'step': 9926}\n",
      "06/30/2020 16:54:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.818959903246814e-06, 'epoch': 2.7708624058051914, 'step': 9928}\n",
      "06/30/2020 16:54:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8096567122523025e-06, 'epoch': 2.771420597264862, 'step': 9930}\n",
      "06/30/2020 16:54:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.8003535212577914e-06, 'epoch': 2.7719787887245326, 'step': 9932}\n",
      "06/30/2020 16:54:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7910503302632807e-06, 'epoch': 2.7725369801842032, 'step': 9934}\n",
      "06/30/2020 16:54:15 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7817471392687696e-06, 'epoch': 2.773095171643874, 'step': 9936}\n",
      "06/30/2020 16:54:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.772443948274258e-06, 'epoch': 2.7736533631035445, 'step': 9938}\n",
      "06/30/2020 16:54:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.763140757279747e-06, 'epoch': 2.774211554563215, 'step': 9940}\n",
      "06/30/2020 16:54:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.753837566285236e-06, 'epoch': 2.7747697460228857, 'step': 9942}\n",
      "06/30/2020 16:54:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.744534375290725e-06, 'epoch': 2.7753279374825564, 'step': 9944}\n",
      "06/30/2020 16:54:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7352311842962136e-06, 'epoch': 2.7758861289422274, 'step': 9946}\n",
      "06/30/2020 16:54:16 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7259279933017025e-06, 'epoch': 2.7764443204018976, 'step': 9948}\n",
      "06/30/2020 16:54:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7166248023071914e-06, 'epoch': 2.7770025118615687, 'step': 9950}\n",
      "06/30/2020 16:54:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.7073216113126807e-06, 'epoch': 2.7775607033212393, 'step': 9952}\n",
      "06/30/2020 16:54:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6980184203181696e-06, 'epoch': 2.77811889478091, 'step': 9954}\n",
      "06/30/2020 16:54:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.688715229323658e-06, 'epoch': 2.7786770862405805, 'step': 9956}\n",
      "06/30/2020 16:54:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.679412038329147e-06, 'epoch': 2.779235277700251, 'step': 9958}\n",
      "06/30/2020 16:54:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.670108847334636e-06, 'epoch': 2.7797934691599218, 'step': 9960}\n",
      "06/30/2020 16:54:17 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.660805656340125e-06, 'epoch': 2.7803516606195924, 'step': 9962}\n",
      "06/30/2020 16:54:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6515024653456136e-06, 'epoch': 2.7809098520792634, 'step': 9964}\n",
      "06/30/2020 16:54:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6421992743511025e-06, 'epoch': 2.7814680435389336, 'step': 9966}\n",
      "06/30/2020 16:54:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6328960833565914e-06, 'epoch': 2.7820262349986047, 'step': 9968}\n",
      "06/30/2020 16:54:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.62359289236208e-06, 'epoch': 2.7825844264582753, 'step': 9970}\n",
      "06/30/2020 16:54:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6142897013675696e-06, 'epoch': 2.783142617917946, 'step': 9972}\n",
      "06/30/2020 16:54:18 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.604986510373058e-06, 'epoch': 2.7837008093776165, 'step': 9974}\n",
      "06/30/2020 16:54:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.595683319378547e-06, 'epoch': 2.784259000837287, 'step': 9976}\n",
      "06/30/2020 16:54:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.586380128384036e-06, 'epoch': 2.784817192296958, 'step': 9978}\n",
      "06/30/2020 16:54:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.577076937389525e-06, 'epoch': 2.7853753837566284, 'step': 9980}\n",
      "06/30/2020 16:54:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5677737463950136e-06, 'epoch': 2.785933575216299, 'step': 9982}\n",
      "06/30/2020 16:54:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5584705554005025e-06, 'epoch': 2.7864917666759697, 'step': 9984}\n",
      "06/30/2020 16:54:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5491673644059914e-06, 'epoch': 2.7870499581356407, 'step': 9986}\n",
      "06/30/2020 16:54:19 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.53986417341148e-06, 'epoch': 2.7876081495953113, 'step': 9988}\n",
      "06/30/2020 16:54:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5305609824169696e-06, 'epoch': 2.788166341054982, 'step': 9990}\n",
      "06/30/2020 16:54:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.521257791422458e-06, 'epoch': 2.7887245325146526, 'step': 9992}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:54:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.511954600427947e-06, 'epoch': 2.789282723974323, 'step': 9994}\n",
      "06/30/2020 16:54:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.5026514094334354e-06, 'epoch': 2.789840915433994, 'step': 9996}\n",
      "06/30/2020 16:54:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.493348218438925e-06, 'epoch': 2.7903991068936644, 'step': 9998}\n",
      "06/30/2020 16:54:20 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4840450274444136e-06, 'epoch': 2.790957298353335, 'step': 10000}\n",
      "06/30/2020 16:54:20 - INFO - transformers.trainer -   Saving model checkpoint to ../../weights/gpt2/papers_milan/checkpoint-10000\n",
      "06/30/2020 16:54:20 - INFO - transformers.configuration_utils -   Configuration saved in ../../weights/gpt2/papers_milan/checkpoint-10000/config.json\n",
      "06/30/2020 16:54:21 - INFO - transformers.modeling_utils -   Model weights saved in ../../weights/gpt2/papers_milan/checkpoint-10000/pytorch_model.bin\n",
      "06/30/2020 16:54:21 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4747418364499025e-06, 'epoch': 2.7915154898130057, 'step': 10002}\n",
      "06/30/2020 16:54:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4654386454553914e-06, 'epoch': 2.7920736812726767, 'step': 10004}\n",
      "06/30/2020 16:54:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.45613545446088e-06, 'epoch': 2.792631872732347, 'step': 10006}\n",
      "06/30/2020 16:54:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4468322634663696e-06, 'epoch': 2.793190064192018, 'step': 10008}\n",
      "06/30/2020 16:54:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.437529072471858e-06, 'epoch': 2.7937482556516886, 'step': 10010}\n",
      "06/30/2020 16:54:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.428225881477347e-06, 'epoch': 2.7943064471113592, 'step': 10012}\n",
      "06/30/2020 16:54:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4189226904828354e-06, 'epoch': 2.79486463857103, 'step': 10014}\n",
      "06/30/2020 16:54:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4096194994883243e-06, 'epoch': 2.7954228300307005, 'step': 10016}\n",
      "06/30/2020 16:54:22 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4003163084938136e-06, 'epoch': 2.795981021490371, 'step': 10018}\n",
      "06/30/2020 16:54:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3910131174993025e-06, 'epoch': 2.7965392129500417, 'step': 10020}\n",
      "06/30/2020 16:54:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3817099265047914e-06, 'epoch': 2.7970974044097128, 'step': 10022}\n",
      "06/30/2020 16:54:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.37240673551028e-06, 'epoch': 2.797655595869383, 'step': 10024}\n",
      "06/30/2020 16:54:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3631035445157696e-06, 'epoch': 2.798213787329054, 'step': 10026}\n",
      "06/30/2020 16:54:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.353800353521258e-06, 'epoch': 2.7987719787887246, 'step': 10028}\n",
      "06/30/2020 16:54:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.344497162526747e-06, 'epoch': 2.7993301702483953, 'step': 10030}\n",
      "06/30/2020 16:54:23 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3351939715322354e-06, 'epoch': 2.799888361708066, 'step': 10032}\n",
      "06/30/2020 16:54:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3258907805377243e-06, 'epoch': 2.8004465531677365, 'step': 10034}\n",
      "06/30/2020 16:54:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3165875895432136e-06, 'epoch': 2.801004744627407, 'step': 10036}\n",
      "06/30/2020 16:54:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3072843985487025e-06, 'epoch': 2.8015629360870777, 'step': 10038}\n",
      "06/30/2020 16:54:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2979812075541913e-06, 'epoch': 2.802121127546749, 'step': 10040}\n",
      "06/30/2020 16:54:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.28867801655968e-06, 'epoch': 2.802679319006419, 'step': 10042}\n",
      "06/30/2020 16:54:24 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2793748255651695e-06, 'epoch': 2.80323751046609, 'step': 10044}\n",
      "06/30/2020 16:54:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.270071634570658e-06, 'epoch': 2.8037957019257607, 'step': 10046}\n",
      "06/30/2020 16:54:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.260768443576147e-06, 'epoch': 2.8043538933854313, 'step': 10048}\n",
      "06/30/2020 16:54:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2514652525816354e-06, 'epoch': 2.804912084845102, 'step': 10050}\n",
      "06/30/2020 16:54:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2421620615871243e-06, 'epoch': 2.8054702763047725, 'step': 10052}\n",
      "06/30/2020 16:54:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2328588705926136e-06, 'epoch': 2.806028467764443, 'step': 10054}\n",
      "06/30/2020 16:54:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2235556795981024e-06, 'epoch': 2.8065866592241138, 'step': 10056}\n",
      "06/30/2020 16:54:25 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2142524886035913e-06, 'epoch': 2.8071448506837844, 'step': 10058}\n",
      "06/30/2020 16:54:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.20494929760908e-06, 'epoch': 2.807703042143455, 'step': 10060}\n",
      "06/30/2020 16:54:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1956461066145687e-06, 'epoch': 2.808261233603126, 'step': 10062}\n",
      "06/30/2020 16:54:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.186342915620058e-06, 'epoch': 2.8088194250627967, 'step': 10064}\n",
      "06/30/2020 16:54:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.177039724625547e-06, 'epoch': 2.8093776165224673, 'step': 10066}\n",
      "06/30/2020 16:54:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1677365336310353e-06, 'epoch': 2.809935807982138, 'step': 10068}\n",
      "06/30/2020 16:54:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1584333426365242e-06, 'epoch': 2.8104939994418086, 'step': 10070}\n",
      "06/30/2020 16:54:26 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1491301516420135e-06, 'epoch': 2.811052190901479, 'step': 10072}\n",
      "06/30/2020 16:54:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1398269606475024e-06, 'epoch': 2.81161038236115, 'step': 10074}\n",
      "06/30/2020 16:54:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1305237696529913e-06, 'epoch': 2.8121685738208204, 'step': 10076}\n",
      "06/30/2020 16:54:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1212205786584798e-06, 'epoch': 2.812726765280491, 'step': 10078}\n",
      "06/30/2020 16:54:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.111917387663969e-06, 'epoch': 2.813284956740162, 'step': 10080}\n",
      "06/30/2020 16:54:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1026141966694576e-06, 'epoch': 2.8138431481998323, 'step': 10082}\n",
      "06/30/2020 16:54:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.093311005674947e-06, 'epoch': 2.8144013396595033, 'step': 10084}\n",
      "06/30/2020 16:54:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0840078146804353e-06, 'epoch': 2.814959531119174, 'step': 10086}\n",
      "06/30/2020 16:54:27 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0747046236859246e-06, 'epoch': 2.8155177225788446, 'step': 10088}\n",
      "06/30/2020 16:54:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.065401432691413e-06, 'epoch': 2.816075914038515, 'step': 10090}\n",
      "06/30/2020 16:54:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.056098241696902e-06, 'epoch': 2.816634105498186, 'step': 10092}\n",
      "06/30/2020 16:54:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0467950507023913e-06, 'epoch': 2.8171922969578564, 'step': 10094}\n",
      "06/30/2020 16:54:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0374918597078798e-06, 'epoch': 2.817750488417527, 'step': 10096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:54:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.028188668713369e-06, 'epoch': 2.818308679877198, 'step': 10098}\n",
      "06/30/2020 16:54:28 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0188854777188575e-06, 'epoch': 2.8188668713368683, 'step': 10100}\n",
      "06/30/2020 16:54:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.009582286724347e-06, 'epoch': 2.8194250627965394, 'step': 10102}\n",
      "06/30/2020 16:54:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.0002790957298353e-06, 'epoch': 2.81998325425621, 'step': 10104}\n",
      "06/30/2020 16:54:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9909759047353246e-06, 'epoch': 2.8205414457158806, 'step': 10106}\n",
      "06/30/2020 16:54:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.981672713740813e-06, 'epoch': 2.8210996371755512, 'step': 10108}\n",
      "06/30/2020 16:54:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.972369522746302e-06, 'epoch': 2.821657828635222, 'step': 10110}\n",
      "06/30/2020 16:54:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.963066331751791e-06, 'epoch': 2.8222160200948925, 'step': 10112}\n",
      "06/30/2020 16:54:29 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9537631407572798e-06, 'epoch': 2.822774211554563, 'step': 10114}\n",
      "06/30/2020 16:54:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.944459949762769e-06, 'epoch': 2.8233324030142337, 'step': 10116}\n",
      "06/30/2020 16:54:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9351567587682575e-06, 'epoch': 2.8238905944739043, 'step': 10118}\n",
      "06/30/2020 16:54:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.925853567773747e-06, 'epoch': 2.8244487859335754, 'step': 10120}\n",
      "06/30/2020 16:54:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.9165503767792353e-06, 'epoch': 2.825006977393246, 'step': 10122}\n",
      "06/30/2020 16:54:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.907247185784724e-06, 'epoch': 2.8255651688529166, 'step': 10124}\n",
      "06/30/2020 16:54:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.897943994790213e-06, 'epoch': 2.8261233603125873, 'step': 10126}\n",
      "06/30/2020 16:54:30 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.888640803795702e-06, 'epoch': 2.826681551772258, 'step': 10128}\n",
      "06/30/2020 16:54:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.879337612801191e-06, 'epoch': 2.8272397432319285, 'step': 10130}\n",
      "06/30/2020 16:54:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8700344218066797e-06, 'epoch': 2.827797934691599, 'step': 10132}\n",
      "06/30/2020 16:54:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.860731230812169e-06, 'epoch': 2.8283561261512697, 'step': 10134}\n",
      "06/30/2020 16:54:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8514280398176575e-06, 'epoch': 2.8289143176109404, 'step': 10136}\n",
      "06/30/2020 16:54:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8421248488231464e-06, 'epoch': 2.8294725090706114, 'step': 10138}\n",
      "06/30/2020 16:54:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.8328216578286353e-06, 'epoch': 2.830030700530282, 'step': 10140}\n",
      "06/30/2020 16:54:31 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.823518466834124e-06, 'epoch': 2.8305888919899527, 'step': 10142}\n",
      "06/30/2020 16:54:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.814215275839613e-06, 'epoch': 2.8311470834496233, 'step': 10144}\n",
      "06/30/2020 16:54:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.804912084845102e-06, 'epoch': 2.831705274909294, 'step': 10146}\n",
      "06/30/2020 16:54:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.795608893850591e-06, 'epoch': 2.8322634663689645, 'step': 10148}\n",
      "06/30/2020 16:54:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7863057028560797e-06, 'epoch': 2.832821657828635, 'step': 10150}\n",
      "06/30/2020 16:54:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7770025118615686e-06, 'epoch': 2.8333798492883058, 'step': 10152}\n",
      "06/30/2020 16:54:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7676993208670575e-06, 'epoch': 2.8339380407479764, 'step': 10154}\n",
      "06/30/2020 16:54:32 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7583961298725464e-06, 'epoch': 2.8344962322076475, 'step': 10156}\n",
      "06/30/2020 16:54:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7490929388780353e-06, 'epoch': 2.8350544236673176, 'step': 10158}\n",
      "06/30/2020 16:54:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.739789747883524e-06, 'epoch': 2.8356126151269887, 'step': 10160}\n",
      "06/30/2020 16:54:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.730486556889013e-06, 'epoch': 2.8361708065866593, 'step': 10162}\n",
      "06/30/2020 16:54:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.721183365894502e-06, 'epoch': 2.83672899804633, 'step': 10164}\n",
      "06/30/2020 16:54:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.711880174899991e-06, 'epoch': 2.8372871895060006, 'step': 10166}\n",
      "06/30/2020 16:54:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.7025769839054797e-06, 'epoch': 2.837845380965671, 'step': 10168}\n",
      "06/30/2020 16:54:33 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6932737929109686e-06, 'epoch': 2.838403572425342, 'step': 10170}\n",
      "06/30/2020 16:54:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6839706019164575e-06, 'epoch': 2.8389617638850124, 'step': 10172}\n",
      "06/30/2020 16:54:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6746674109219464e-06, 'epoch': 2.8395199553446835, 'step': 10174}\n",
      "06/30/2020 16:54:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6653642199274353e-06, 'epoch': 2.8400781468043537, 'step': 10176}\n",
      "06/30/2020 16:54:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.656061028932924e-06, 'epoch': 2.8406363382640247, 'step': 10178}\n",
      "06/30/2020 16:54:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.646757837938413e-06, 'epoch': 2.8411945297236954, 'step': 10180}\n",
      "06/30/2020 16:54:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.637454646943902e-06, 'epoch': 2.841752721183366, 'step': 10182}\n",
      "06/30/2020 16:54:34 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.628151455949391e-06, 'epoch': 2.8423109126430366, 'step': 10184}\n",
      "06/30/2020 16:54:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6188482649548797e-06, 'epoch': 2.842869104102707, 'step': 10186}\n",
      "06/30/2020 16:54:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6095450739603686e-06, 'epoch': 2.843427295562378, 'step': 10188}\n",
      "06/30/2020 16:54:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6002418829658575e-06, 'epoch': 2.8439854870220485, 'step': 10190}\n",
      "06/30/2020 16:54:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5909386919713464e-06, 'epoch': 2.844543678481719, 'step': 10192}\n",
      "06/30/2020 16:54:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5816355009768353e-06, 'epoch': 2.8451018699413897, 'step': 10194}\n",
      "06/30/2020 16:54:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.572332309982324e-06, 'epoch': 2.8456600614010608, 'step': 10196}\n",
      "06/30/2020 16:54:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5630291189878126e-06, 'epoch': 2.8462182528607314, 'step': 10198}\n",
      "06/30/2020 16:54:35 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.553725927993302e-06, 'epoch': 2.846776444320402, 'step': 10200}\n",
      "06/30/2020 16:54:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.544422736998791e-06, 'epoch': 2.8473346357800726, 'step': 10202}\n",
      "06/30/2020 16:54:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5351195460042797e-06, 'epoch': 2.8478928272397432, 'step': 10204}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:54:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5258163550097686e-06, 'epoch': 2.848451018699414, 'step': 10206}\n",
      "06/30/2020 16:54:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5165131640152575e-06, 'epoch': 2.8490092101590845, 'step': 10208}\n",
      "06/30/2020 16:54:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5072099730207463e-06, 'epoch': 2.849567401618755, 'step': 10210}\n",
      "06/30/2020 16:54:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.497906782026235e-06, 'epoch': 2.8501255930784257, 'step': 10212}\n",
      "06/30/2020 16:54:36 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.488603591031724e-06, 'epoch': 2.850683784538097, 'step': 10214}\n",
      "06/30/2020 16:54:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4793004000372126e-06, 'epoch': 2.851241975997767, 'step': 10216}\n",
      "06/30/2020 16:54:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.469997209042702e-06, 'epoch': 2.851800167457438, 'step': 10218}\n",
      "06/30/2020 16:54:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4606940180481904e-06, 'epoch': 2.8523583589171086, 'step': 10220}\n",
      "06/30/2020 16:54:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4513908270536797e-06, 'epoch': 2.8529165503767793, 'step': 10222}\n",
      "06/30/2020 16:54:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4420876360591686e-06, 'epoch': 2.85347474183645, 'step': 10224}\n",
      "06/30/2020 16:54:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4327844450646574e-06, 'epoch': 2.8540329332961205, 'step': 10226}\n",
      "06/30/2020 16:54:37 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4234812540701463e-06, 'epoch': 2.854591124755791, 'step': 10228}\n",
      "06/30/2020 16:54:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.414178063075635e-06, 'epoch': 2.8551493162154618, 'step': 10230}\n",
      "06/30/2020 16:54:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.404874872081124e-06, 'epoch': 2.855707507675133, 'step': 10232}\n",
      "06/30/2020 16:54:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3955716810866126e-06, 'epoch': 2.856265699134803, 'step': 10234}\n",
      "06/30/2020 16:54:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.386268490092102e-06, 'epoch': 2.856823890594474, 'step': 10236}\n",
      "06/30/2020 16:54:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3769652990975903e-06, 'epoch': 2.8573820820541447, 'step': 10238}\n",
      "06/30/2020 16:54:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3676621081030797e-06, 'epoch': 2.8579402735138153, 'step': 10240}\n",
      "06/30/2020 16:54:38 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3583589171085685e-06, 'epoch': 2.858498464973486, 'step': 10242}\n",
      "06/30/2020 16:54:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.349055726114057e-06, 'epoch': 2.8590566564331565, 'step': 10244}\n",
      "06/30/2020 16:54:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3397525351195463e-06, 'epoch': 2.859614847892827, 'step': 10246}\n",
      "06/30/2020 16:54:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3304493441250348e-06, 'epoch': 2.860173039352498, 'step': 10248}\n",
      "06/30/2020 16:54:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.321146153130524e-06, 'epoch': 2.860731230812169, 'step': 10250}\n",
      "06/30/2020 16:54:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3118429621360126e-06, 'epoch': 2.861289422271839, 'step': 10252}\n",
      "06/30/2020 16:54:39 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.302539771141502e-06, 'epoch': 2.86184761373151, 'step': 10254}\n",
      "06/30/2020 16:54:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2932365801469903e-06, 'epoch': 2.8624058051911807, 'step': 10256}\n",
      "06/30/2020 16:54:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2839333891524792e-06, 'epoch': 2.8629639966508513, 'step': 10258}\n",
      "06/30/2020 16:54:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2746301981579685e-06, 'epoch': 2.863522188110522, 'step': 10260}\n",
      "06/30/2020 16:54:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.265327007163457e-06, 'epoch': 2.8640803795701926, 'step': 10262}\n",
      "06/30/2020 16:54:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2560238161689463e-06, 'epoch': 2.864638571029863, 'step': 10264}\n",
      "06/30/2020 16:54:40 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2467206251744348e-06, 'epoch': 2.865196762489534, 'step': 10266}\n",
      "06/30/2020 16:54:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.237417434179924e-06, 'epoch': 2.8657549539492044, 'step': 10268}\n",
      "06/30/2020 16:54:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2281142431854125e-06, 'epoch': 2.866313145408875, 'step': 10270}\n",
      "06/30/2020 16:54:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.218811052190902e-06, 'epoch': 2.866871336868546, 'step': 10272}\n",
      "06/30/2020 16:54:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.2095078611963903e-06, 'epoch': 2.8674295283282167, 'step': 10274}\n",
      "06/30/2020 16:54:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.200204670201879e-06, 'epoch': 2.8679877197878874, 'step': 10276}\n",
      "06/30/2020 16:54:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.190901479207368e-06, 'epoch': 2.868545911247558, 'step': 10278}\n",
      "06/30/2020 16:54:41 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.181598288212857e-06, 'epoch': 2.8691041027072286, 'step': 10280}\n",
      "06/30/2020 16:54:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1722950972183463e-06, 'epoch': 2.869662294166899, 'step': 10282}\n",
      "06/30/2020 16:54:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1629919062238348e-06, 'epoch': 2.87022048562657, 'step': 10284}\n",
      "06/30/2020 16:54:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.153688715229324e-06, 'epoch': 2.8707786770862405, 'step': 10286}\n",
      "06/30/2020 16:54:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1443855242348125e-06, 'epoch': 2.871336868545911, 'step': 10288}\n",
      "06/30/2020 16:54:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1350823332403014e-06, 'epoch': 2.871895060005582, 'step': 10290}\n",
      "06/30/2020 16:54:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1257791422457903e-06, 'epoch': 2.8724532514652523, 'step': 10292}\n",
      "06/30/2020 16:54:42 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.116475951251279e-06, 'epoch': 2.8730114429249234, 'step': 10294}\n",
      "06/30/2020 16:54:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.107172760256768e-06, 'epoch': 2.873569634384594, 'step': 10296}\n",
      "06/30/2020 16:54:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.097869569262257e-06, 'epoch': 2.8741278258442646, 'step': 10298}\n",
      "06/30/2020 16:54:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0885663782677463e-06, 'epoch': 2.8746860173039352, 'step': 10300}\n",
      "06/30/2020 16:54:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0792631872732347e-06, 'epoch': 2.875244208763606, 'step': 10302}\n",
      "06/30/2020 16:54:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0699599962787236e-06, 'epoch': 2.8758024002232765, 'step': 10304}\n",
      "06/30/2020 16:54:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0606568052842125e-06, 'epoch': 2.876360591682947, 'step': 10306}\n",
      "06/30/2020 16:54:43 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0513536142897014e-06, 'epoch': 2.876918783142618, 'step': 10308}\n",
      "06/30/2020 16:54:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0420504232951903e-06, 'epoch': 2.8774769746022884, 'step': 10310}\n",
      "06/30/2020 16:54:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.032747232300679e-06, 'epoch': 2.8780351660619594, 'step': 10312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:54:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.023444041306168e-06, 'epoch': 2.87859335752163, 'step': 10314}\n",
      "06/30/2020 16:54:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.014140850311657e-06, 'epoch': 2.8791515489813007, 'step': 10316}\n",
      "06/30/2020 16:54:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.004837659317146e-06, 'epoch': 2.8797097404409713, 'step': 10318}\n",
      "06/30/2020 16:54:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9955344683226347e-06, 'epoch': 2.880267931900642, 'step': 10320}\n",
      "06/30/2020 16:54:44 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9862312773281236e-06, 'epoch': 2.8808261233603125, 'step': 10322}\n",
      "06/30/2020 16:54:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9769280863336125e-06, 'epoch': 2.881384314819983, 'step': 10324}\n",
      "06/30/2020 16:54:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9676248953391014e-06, 'epoch': 2.8819425062796538, 'step': 10326}\n",
      "06/30/2020 16:54:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9583217043445903e-06, 'epoch': 2.8825006977393244, 'step': 10328}\n",
      "06/30/2020 16:54:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.949018513350079e-06, 'epoch': 2.8830588891989954, 'step': 10330}\n",
      "06/30/2020 16:54:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.939715322355568e-06, 'epoch': 2.883617080658666, 'step': 10332}\n",
      "06/30/2020 16:54:45 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.930412131361057e-06, 'epoch': 2.8841752721183367, 'step': 10334}\n",
      "06/30/2020 16:54:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.921108940366546e-06, 'epoch': 2.8847334635780073, 'step': 10336}\n",
      "06/30/2020 16:54:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9118057493720347e-06, 'epoch': 2.885291655037678, 'step': 10338}\n",
      "06/30/2020 16:54:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9025025583775234e-06, 'epoch': 2.8858498464973485, 'step': 10340}\n",
      "06/30/2020 16:54:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8931993673830125e-06, 'epoch': 2.886408037957019, 'step': 10342}\n",
      "06/30/2020 16:54:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8838961763885014e-06, 'epoch': 2.88696622941669, 'step': 10344}\n",
      "06/30/2020 16:54:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8745929853939905e-06, 'epoch': 2.8875244208763604, 'step': 10346}\n",
      "06/30/2020 16:54:46 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8652897943994792e-06, 'epoch': 2.8880826123360315, 'step': 10348}\n",
      "06/30/2020 16:54:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8559866034049678e-06, 'epoch': 2.8886408037957017, 'step': 10350}\n",
      "06/30/2020 16:54:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.846683412410457e-06, 'epoch': 2.8891989952553727, 'step': 10352}\n",
      "06/30/2020 16:54:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8373802214159456e-06, 'epoch': 2.8897571867150433, 'step': 10354}\n",
      "06/30/2020 16:54:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8280770304214347e-06, 'epoch': 2.890315378174714, 'step': 10356}\n",
      "06/30/2020 16:54:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8187738394269234e-06, 'epoch': 2.8908735696343846, 'step': 10358}\n",
      "06/30/2020 16:54:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8094706484324125e-06, 'epoch': 2.891431761094055, 'step': 10360}\n",
      "06/30/2020 16:54:47 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.8001674574379014e-06, 'epoch': 2.891989952553726, 'step': 10362}\n",
      "06/30/2020 16:54:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.79086426644339e-06, 'epoch': 2.8925481440133964, 'step': 10364}\n",
      "06/30/2020 16:54:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7815610754488791e-06, 'epoch': 2.8931063354730675, 'step': 10366}\n",
      "06/30/2020 16:54:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7722578844543678e-06, 'epoch': 2.8936645269327377, 'step': 10368}\n",
      "06/30/2020 16:54:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.762954693459857e-06, 'epoch': 2.8942227183924087, 'step': 10370}\n",
      "06/30/2020 16:54:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7536515024653456e-06, 'epoch': 2.8947809098520794, 'step': 10372}\n",
      "06/30/2020 16:54:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7443483114708347e-06, 'epoch': 2.89533910131175, 'step': 10374}\n",
      "06/30/2020 16:54:48 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7350451204763234e-06, 'epoch': 2.8958972927714206, 'step': 10376}\n",
      "06/30/2020 16:54:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7257419294818125e-06, 'epoch': 2.8964554842310912, 'step': 10378}\n",
      "06/30/2020 16:54:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.7164387384873013e-06, 'epoch': 2.897013675690762, 'step': 10380}\n",
      "06/30/2020 16:54:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.70713554749279e-06, 'epoch': 2.8975718671504325, 'step': 10382}\n",
      "06/30/2020 16:54:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6978323564982791e-06, 'epoch': 2.8981300586101035, 'step': 10384}\n",
      "06/30/2020 16:54:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6885291655037678e-06, 'epoch': 2.8986882500697737, 'step': 10386}\n",
      "06/30/2020 16:54:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.679225974509257e-06, 'epoch': 2.8992464415294448, 'step': 10388}\n",
      "06/30/2020 16:54:49 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6699227835147456e-06, 'epoch': 2.8998046329891154, 'step': 10390}\n",
      "06/30/2020 16:54:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6606195925202347e-06, 'epoch': 2.900362824448786, 'step': 10392}\n",
      "06/30/2020 16:54:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6513164015257233e-06, 'epoch': 2.9009210159084566, 'step': 10394}\n",
      "06/30/2020 16:54:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6420132105312122e-06, 'epoch': 2.9014792073681273, 'step': 10396}\n",
      "06/30/2020 16:54:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6327100195367011e-06, 'epoch': 2.902037398827798, 'step': 10398}\n",
      "06/30/2020 16:54:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.62340682854219e-06, 'epoch': 2.9025955902874685, 'step': 10400}\n",
      "06/30/2020 16:54:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6141036375476791e-06, 'epoch': 2.903153781747139, 'step': 10402}\n",
      "06/30/2020 16:54:50 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6048004465531678e-06, 'epoch': 2.9037119732068097, 'step': 10404}\n",
      "06/30/2020 16:54:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5954972555586569e-06, 'epoch': 2.904270164666481, 'step': 10406}\n",
      "06/30/2020 16:54:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5861940645641456e-06, 'epoch': 2.9048283561261514, 'step': 10408}\n",
      "06/30/2020 16:54:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5768908735696342e-06, 'epoch': 2.905386547585822, 'step': 10410}\n",
      "06/30/2020 16:54:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5675876825751233e-06, 'epoch': 2.9059447390454927, 'step': 10412}\n",
      "06/30/2020 16:54:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5582844915806122e-06, 'epoch': 2.9065029305051633, 'step': 10414}\n",
      "06/30/2020 16:54:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5489813005861011e-06, 'epoch': 2.907061121964834, 'step': 10416}\n",
      "06/30/2020 16:54:51 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.53967810959159e-06, 'epoch': 2.9076193134245045, 'step': 10418}\n",
      "06/30/2020 16:54:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5303749185970789e-06, 'epoch': 2.908177504884175, 'step': 10420}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:54:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5210717276025678e-06, 'epoch': 2.9087356963438458, 'step': 10422}\n",
      "06/30/2020 16:54:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5117685366080567e-06, 'epoch': 2.909293887803517, 'step': 10424}\n",
      "06/30/2020 16:54:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5024653456135455e-06, 'epoch': 2.909852079263187, 'step': 10426}\n",
      "06/30/2020 16:54:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4931621546190344e-06, 'epoch': 2.910410270722858, 'step': 10428}\n",
      "06/30/2020 16:54:52 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4838589636245233e-06, 'epoch': 2.9109684621825287, 'step': 10430}\n",
      "06/30/2020 16:54:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.474555772630012e-06, 'epoch': 2.9115266536421993, 'step': 10432}\n",
      "06/30/2020 16:54:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.465252581635501e-06, 'epoch': 2.91208484510187, 'step': 10434}\n",
      "06/30/2020 16:54:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.45594939064099e-06, 'epoch': 2.9126430365615406, 'step': 10436}\n",
      "06/30/2020 16:54:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4466461996464789e-06, 'epoch': 2.913201228021211, 'step': 10438}\n",
      "06/30/2020 16:54:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4373430086519678e-06, 'epoch': 2.913759419480882, 'step': 10440}\n",
      "06/30/2020 16:54:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4280398176574566e-06, 'epoch': 2.914317610940553, 'step': 10442}\n",
      "06/30/2020 16:54:53 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4187366266629455e-06, 'epoch': 2.914875802400223, 'step': 10444}\n",
      "06/30/2020 16:54:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4094334356684344e-06, 'epoch': 2.915433993859894, 'step': 10446}\n",
      "06/30/2020 16:54:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.400130244673923e-06, 'epoch': 2.9159921853195647, 'step': 10448}\n",
      "06/30/2020 16:54:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.390827053679412e-06, 'epoch': 2.9165503767792353, 'step': 10450}\n",
      "06/30/2020 16:54:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3815238626849009e-06, 'epoch': 2.917108568238906, 'step': 10452}\n",
      "06/30/2020 16:54:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.37222067169039e-06, 'epoch': 2.9176667596985766, 'step': 10454}\n",
      "06/30/2020 16:54:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3629174806958789e-06, 'epoch': 2.918224951158247, 'step': 10456}\n",
      "06/30/2020 16:54:54 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3536142897013677e-06, 'epoch': 2.918783142617918, 'step': 10458}\n",
      "06/30/2020 16:54:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3443110987068566e-06, 'epoch': 2.919341334077589, 'step': 10460}\n",
      "06/30/2020 16:54:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3350079077123453e-06, 'epoch': 2.919899525537259, 'step': 10462}\n",
      "06/30/2020 16:54:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3257047167178342e-06, 'epoch': 2.92045771699693, 'step': 10464}\n",
      "06/30/2020 16:54:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.316401525723323e-06, 'epoch': 2.9210159084566008, 'step': 10466}\n",
      "06/30/2020 16:54:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.307098334728812e-06, 'epoch': 2.9215740999162714, 'step': 10468}\n",
      "06/30/2020 16:54:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2977951437343009e-06, 'epoch': 2.922132291375942, 'step': 10470}\n",
      "06/30/2020 16:54:55 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2884919527397897e-06, 'epoch': 2.9226904828356126, 'step': 10472}\n",
      "06/30/2020 16:54:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2791887617452788e-06, 'epoch': 2.9232486742952832, 'step': 10474}\n",
      "06/30/2020 16:54:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2698855707507677e-06, 'epoch': 2.923806865754954, 'step': 10476}\n",
      "06/30/2020 16:54:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2605823797562564e-06, 'epoch': 2.9243650572146245, 'step': 10478}\n",
      "06/30/2020 16:54:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2512791887617453e-06, 'epoch': 2.924923248674295, 'step': 10480}\n",
      "06/30/2020 16:54:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2419759977672342e-06, 'epoch': 2.925481440133966, 'step': 10482}\n",
      "06/30/2020 16:54:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.232672806772723e-06, 'epoch': 2.926039631593637, 'step': 10484}\n",
      "06/30/2020 16:54:56 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.223369615778212e-06, 'epoch': 2.9265978230533074, 'step': 10486}\n",
      "06/30/2020 16:54:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2140664247837008e-06, 'epoch': 2.927156014512978, 'step': 10488}\n",
      "06/30/2020 16:54:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2047632337891897e-06, 'epoch': 2.9277142059726486, 'step': 10490}\n",
      "06/30/2020 16:54:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1954600427946786e-06, 'epoch': 2.9282723974323193, 'step': 10492}\n",
      "06/30/2020 16:54:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1861568518001675e-06, 'epoch': 2.92883058889199, 'step': 10494}\n",
      "06/30/2020 16:54:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1768536608056564e-06, 'epoch': 2.9293887803516605, 'step': 10496}\n",
      "06/30/2020 16:54:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1675504698111453e-06, 'epoch': 2.929946971811331, 'step': 10498}\n",
      "06/30/2020 16:54:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1582472788166342e-06, 'epoch': 2.930505163271002, 'step': 10500}\n",
      "06/30/2020 16:54:57 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.148944087822123e-06, 'epoch': 2.9310633547306724, 'step': 10502}\n",
      "06/30/2020 16:54:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.139640896827612e-06, 'epoch': 2.9316215461903434, 'step': 10504}\n",
      "06/30/2020 16:54:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1303377058331008e-06, 'epoch': 2.932179737650014, 'step': 10506}\n",
      "06/30/2020 16:54:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1210345148385897e-06, 'epoch': 2.9327379291096847, 'step': 10508}\n",
      "06/30/2020 16:54:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1117313238440786e-06, 'epoch': 2.9332961205693553, 'step': 10510}\n",
      "06/30/2020 16:54:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1024281328495675e-06, 'epoch': 2.933854312029026, 'step': 10512}\n",
      "06/30/2020 16:54:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0931249418550564e-06, 'epoch': 2.9344125034886965, 'step': 10514}\n",
      "06/30/2020 16:54:58 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0838217508605453e-06, 'epoch': 2.934970694948367, 'step': 10516}\n",
      "06/30/2020 16:54:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0745185598660341e-06, 'epoch': 2.935528886408038, 'step': 10518}\n",
      "06/30/2020 16:54:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.065215368871523e-06, 'epoch': 2.9360870778677084, 'step': 10520}\n",
      "06/30/2020 16:54:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.055912177877012e-06, 'epoch': 2.9366452693273795, 'step': 10522}\n",
      "06/30/2020 16:54:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0466089868825006e-06, 'epoch': 2.93720346078705, 'step': 10524}\n",
      "06/30/2020 16:54:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0373057958879895e-06, 'epoch': 2.9377616522467207, 'step': 10526}\n",
      "06/30/2020 16:54:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0280026048934786e-06, 'epoch': 2.9383198437063913, 'step': 10528}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:54:59 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0186994138989675e-06, 'epoch': 2.938878035166062, 'step': 10530}\n",
      "06/30/2020 16:55:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0093962229044564e-06, 'epoch': 2.9394362266257326, 'step': 10532}\n",
      "06/30/2020 16:55:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0000930319099452e-06, 'epoch': 2.939994418085403, 'step': 10534}\n",
      "06/30/2020 16:55:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.907898409154341e-07, 'epoch': 2.940552609545074, 'step': 10536}\n",
      "06/30/2020 16:55:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.814866499209228e-07, 'epoch': 2.9411108010047444, 'step': 10538}\n",
      "06/30/2020 16:55:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.721834589264117e-07, 'epoch': 2.9416689924644155, 'step': 10540}\n",
      "06/30/2020 16:55:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.628802679319006e-07, 'epoch': 2.942227183924086, 'step': 10542}\n",
      "06/30/2020 16:55:00 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.535770769373896e-07, 'epoch': 2.9427853753837567, 'step': 10544}\n",
      "06/30/2020 16:55:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.442738859428785e-07, 'epoch': 2.9433435668434274, 'step': 10546}\n",
      "06/30/2020 16:55:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.349706949483674e-07, 'epoch': 2.943901758303098, 'step': 10548}\n",
      "06/30/2020 16:55:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.256675039538562e-07, 'epoch': 2.9444599497627686, 'step': 10550}\n",
      "06/30/2020 16:55:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.163643129593452e-07, 'epoch': 2.945018141222439, 'step': 10552}\n",
      "06/30/2020 16:55:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.070611219648339e-07, 'epoch': 2.94557633268211, 'step': 10554}\n",
      "06/30/2020 16:55:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.977579309703228e-07, 'epoch': 2.9461345241417805, 'step': 10556}\n",
      "06/30/2020 16:55:01 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.884547399758117e-07, 'epoch': 2.9466927156014515, 'step': 10558}\n",
      "06/30/2020 16:55:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.791515489813007e-07, 'epoch': 2.9472509070611217, 'step': 10560}\n",
      "06/30/2020 16:55:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.698483579867896e-07, 'epoch': 2.9478090985207928, 'step': 10562}\n",
      "06/30/2020 16:55:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.605451669922785e-07, 'epoch': 2.9483672899804634, 'step': 10564}\n",
      "06/30/2020 16:55:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.512419759977673e-07, 'epoch': 2.948925481440134, 'step': 10566}\n",
      "06/30/2020 16:55:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.419387850032561e-07, 'epoch': 2.9494836728998046, 'step': 10568}\n",
      "06/30/2020 16:55:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.32635594008745e-07, 'epoch': 2.9500418643594752, 'step': 10570}\n",
      "06/30/2020 16:55:02 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.233324030142339e-07, 'epoch': 2.950600055819146, 'step': 10572}\n",
      "06/30/2020 16:55:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.140292120197228e-07, 'epoch': 2.9511582472788165, 'step': 10574}\n",
      "06/30/2020 16:55:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.047260210252117e-07, 'epoch': 2.9517164387384875, 'step': 10576}\n",
      "06/30/2020 16:55:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.954228300307006e-07, 'epoch': 2.9522746301981577, 'step': 10578}\n",
      "06/30/2020 16:55:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.861196390361896e-07, 'epoch': 2.952832821657829, 'step': 10580}\n",
      "06/30/2020 16:55:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.768164480416783e-07, 'epoch': 2.9533910131174994, 'step': 10582}\n",
      "06/30/2020 16:55:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.675132570471672e-07, 'epoch': 2.95394920457717, 'step': 10584}\n",
      "06/30/2020 16:55:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.582100660526561e-07, 'epoch': 2.9545073960368406, 'step': 10586}\n",
      "06/30/2020 16:55:03 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.48906875058145e-07, 'epoch': 2.9550655874965113, 'step': 10588}\n",
      "06/30/2020 16:55:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.396036840636339e-07, 'epoch': 2.955623778956182, 'step': 10590}\n",
      "06/30/2020 16:55:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.303004930691228e-07, 'epoch': 2.9561819704158525, 'step': 10592}\n",
      "06/30/2020 16:55:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.209973020746116e-07, 'epoch': 2.9567401618755236, 'step': 10594}\n",
      "06/30/2020 16:55:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.116941110801004e-07, 'epoch': 2.9572983533351938, 'step': 10596}\n",
      "06/30/2020 16:55:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.023909200855894e-07, 'epoch': 2.957856544794865, 'step': 10598}\n",
      "06/30/2020 16:55:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.930877290910783e-07, 'epoch': 2.9584147362545354, 'step': 10600}\n",
      "06/30/2020 16:55:04 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.837845380965671e-07, 'epoch': 2.958972927714206, 'step': 10602}\n",
      "06/30/2020 16:55:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.74481347102056e-07, 'epoch': 2.9595311191738767, 'step': 10604}\n",
      "06/30/2020 16:55:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.65178156107545e-07, 'epoch': 2.9600893106335473, 'step': 10606}\n",
      "06/30/2020 16:55:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.558749651130339e-07, 'epoch': 2.960647502093218, 'step': 10608}\n",
      "06/30/2020 16:55:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.465717741185226e-07, 'epoch': 2.9612056935528885, 'step': 10610}\n",
      "06/30/2020 16:55:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.372685831240115e-07, 'epoch': 2.961763885012559, 'step': 10612}\n",
      "06/30/2020 16:55:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.279653921295004e-07, 'epoch': 2.96232207647223, 'step': 10614}\n",
      "06/30/2020 16:55:05 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.186622011349894e-07, 'epoch': 2.962880267931901, 'step': 10616}\n",
      "06/30/2020 16:55:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.093590101404782e-07, 'epoch': 2.9634384593915715, 'step': 10618}\n",
      "06/30/2020 16:55:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.000558191459671e-07, 'epoch': 2.963996650851242, 'step': 10620}\n",
      "06/30/2020 16:55:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.90752628151456e-07, 'epoch': 2.9645548423109127, 'step': 10622}\n",
      "06/30/2020 16:55:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.814494371569449e-07, 'epoch': 2.9651130337705833, 'step': 10624}\n",
      "06/30/2020 16:55:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.721462461624337e-07, 'epoch': 2.965671225230254, 'step': 10626}\n",
      "06/30/2020 16:55:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.628430551679226e-07, 'epoch': 2.9662294166899246, 'step': 10628}\n",
      "06/30/2020 16:55:06 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.535398641734115e-07, 'epoch': 2.966787608149595, 'step': 10630}\n",
      "06/30/2020 16:55:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.442366731789003e-07, 'epoch': 2.967345799609266, 'step': 10632}\n",
      "06/30/2020 16:55:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.349334821843893e-07, 'epoch': 2.967903991068937, 'step': 10634}\n",
      "06/30/2020 16:55:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.256302911898782e-07, 'epoch': 2.968462182528607, 'step': 10636}\n",
      "06/30/2020 16:55:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.163271001953671e-07, 'epoch': 2.969020373988278, 'step': 10638}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:55:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.070239092008559e-07, 'epoch': 2.9695785654479487, 'step': 10640}\n",
      "06/30/2020 16:55:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.977207182063447e-07, 'epoch': 2.9701367569076194, 'step': 10642}\n",
      "06/30/2020 16:55:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.884175272118337e-07, 'epoch': 2.97069494836729, 'step': 10644}\n",
      "06/30/2020 16:55:07 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.791143362173226e-07, 'epoch': 2.9712531398269606, 'step': 10646}\n",
      "06/30/2020 16:55:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.698111452228114e-07, 'epoch': 2.971811331286631, 'step': 10648}\n",
      "06/30/2020 16:55:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.6050795422830034e-07, 'epoch': 2.972369522746302, 'step': 10650}\n",
      "06/30/2020 16:55:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.5120476323378923e-07, 'epoch': 2.972927714205973, 'step': 10652}\n",
      "06/30/2020 16:55:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.419015722392781e-07, 'epoch': 2.973485905665643, 'step': 10654}\n",
      "06/30/2020 16:55:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.3259838124476695e-07, 'epoch': 2.974044097125314, 'step': 10656}\n",
      "06/30/2020 16:55:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.2329519025025584e-07, 'epoch': 2.9746022885849848, 'step': 10658}\n",
      "06/30/2020 16:55:08 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.139919992557448e-07, 'epoch': 2.9751604800446554, 'step': 10660}\n",
      "06/30/2020 16:55:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.0468880826123367e-07, 'epoch': 2.975718671504326, 'step': 10662}\n",
      "06/30/2020 16:55:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.953856172667225e-07, 'epoch': 2.9762768629639966, 'step': 10664}\n",
      "06/30/2020 16:55:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.860824262722114e-07, 'epoch': 2.9768350544236672, 'step': 10666}\n",
      "06/30/2020 16:55:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.767792352777003e-07, 'epoch': 2.977393245883338, 'step': 10668}\n",
      "06/30/2020 16:55:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.6747604428318916e-07, 'epoch': 2.9779514373430085, 'step': 10670}\n",
      "06/30/2020 16:55:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.58172853288678e-07, 'epoch': 2.978509628802679, 'step': 10672}\n",
      "06/30/2020 16:55:09 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.4886966229416694e-07, 'epoch': 2.97906782026235, 'step': 10674}\n",
      "06/30/2020 16:55:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.3956647129965577e-07, 'epoch': 2.979626011722021, 'step': 10676}\n",
      "06/30/2020 16:55:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.302632803051447e-07, 'epoch': 2.9801842031816914, 'step': 10678}\n",
      "06/30/2020 16:55:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2096008931063355e-07, 'epoch': 2.980742394641362, 'step': 10680}\n",
      "06/30/2020 16:55:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.1165689831612243e-07, 'epoch': 2.9813005861010327, 'step': 10682}\n",
      "06/30/2020 16:55:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.023537073216113e-07, 'epoch': 2.9818587775607033, 'step': 10684}\n",
      "06/30/2020 16:55:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.930505163271002e-07, 'epoch': 2.982416969020374, 'step': 10686}\n",
      "06/30/2020 16:55:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.837473253325891e-07, 'epoch': 2.9829751604800445, 'step': 10688}\n",
      "06/30/2020 16:55:10 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.74444134338078e-07, 'epoch': 2.983533351939715, 'step': 10690}\n",
      "06/30/2020 16:55:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.6514094334356687e-07, 'epoch': 2.984091543399386, 'step': 10692}\n",
      "06/30/2020 16:55:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.5583775234905576e-07, 'epoch': 2.9846497348590564, 'step': 10694}\n",
      "06/30/2020 16:55:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.4653456135454464e-07, 'epoch': 2.9852079263187274, 'step': 10696}\n",
      "06/30/2020 16:55:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3723137036003348e-07, 'epoch': 2.985766117778398, 'step': 10698}\n",
      "06/30/2020 16:55:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.279281793655224e-07, 'epoch': 2.9863243092380687, 'step': 10700}\n",
      "06/30/2020 16:55:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.1862498837101125e-07, 'epoch': 2.9868825006977393, 'step': 10702}\n",
      "06/30/2020 16:55:11 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0932179737650014e-07, 'epoch': 2.98744069215741, 'step': 10704}\n",
      "06/30/2020 16:55:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.0001860638198903e-07, 'epoch': 2.9879988836170805, 'step': 10706}\n",
      "06/30/2020 16:55:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.9071541538747792e-07, 'epoch': 2.988557075076751, 'step': 10708}\n",
      "06/30/2020 16:55:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.814122243929668e-07, 'epoch': 2.9891152665364222, 'step': 10710}\n",
      "06/30/2020 16:55:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.721090333984557e-07, 'epoch': 2.9896734579960924, 'step': 10712}\n",
      "06/30/2020 16:55:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.6280584240394458e-07, 'epoch': 2.9902316494557635, 'step': 10714}\n",
      "06/30/2020 16:55:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.5350265140943344e-07, 'epoch': 2.990789840915434, 'step': 10716}\n",
      "06/30/2020 16:55:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.4419946041492233e-07, 'epoch': 2.9913480323751047, 'step': 10718}\n",
      "06/30/2020 16:55:12 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.348962694204112e-07, 'epoch': 2.9919062238347753, 'step': 10720}\n",
      "06/30/2020 16:55:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.2559307842590007e-07, 'epoch': 2.992464415294446, 'step': 10722}\n",
      "06/30/2020 16:55:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.1628988743138896e-07, 'epoch': 2.9930226067541166, 'step': 10724}\n",
      "06/30/2020 16:55:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.0698669643687785e-07, 'epoch': 2.993580798213787, 'step': 10726}\n",
      "06/30/2020 16:55:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 9.768350544236674e-08, 'epoch': 2.9941389896734583, 'step': 10728}\n",
      "06/30/2020 16:55:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 8.838031444785562e-08, 'epoch': 2.9946971811331284, 'step': 10730}\n",
      "06/30/2020 16:55:13 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 7.90771234533445e-08, 'epoch': 2.9952553725927995, 'step': 10732}\n",
      "06/30/2020 16:55:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.977393245883338e-08, 'epoch': 2.99581356405247, 'step': 10734}\n",
      "06/30/2020 16:55:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 6.047074146432227e-08, 'epoch': 2.9963717555121407, 'step': 10736}\n",
      "06/30/2020 16:55:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 5.116755046981115e-08, 'epoch': 2.9969299469718114, 'step': 10738}\n",
      "06/30/2020 16:55:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.186435947530003e-08, 'epoch': 2.997488138431482, 'step': 10740}\n",
      "06/30/2020 16:55:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 3.2561168480788914e-08, 'epoch': 2.9980463298911526, 'step': 10742}\n",
      "06/30/2020 16:55:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 2.3257977486277795e-08, 'epoch': 2.9986045213508232, 'step': 10744}\n",
      "06/30/2020 16:55:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 1.3954786491766677e-08, 'epoch': 2.999162712810494, 'step': 10746}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:55:14 - INFO - transformers.trainer -   {'loss': nan, 'learning_rate': 4.651595497255559e-09, 'epoch': 2.9997209042701645, 'step': 10748}\n",
      "06/30/2020 16:55:15 - INFO - transformers.trainer -   \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "06/30/2020 16:55:15 - INFO - transformers.trainer -   Saving model checkpoint to ../../weights/gpt2/papers_milan/\n",
      "06/30/2020 16:55:15 - INFO - transformers.configuration_utils -   Configuration saved in ../../weights/gpt2/papers_milan/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:55:15 - INFO - transformers.modeling_utils -   Model weights saved in ../../weights/gpt2/papers_milan/pytorch_model.bin\n",
      "06/30/2020 16:55:15 - INFO - __main__ -   *** Evaluate ***\n",
      "06/30/2020 16:55:15 - INFO - transformers.trainer -   ***** Running Evaluation *****\n",
      "06/30/2020 16:55:15 - INFO - transformers.trainer -     Num examples = 448\n",
      "06/30/2020 16:55:15 - INFO - transformers.trainer -     Batch size = 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd752e666d64a389166954ceb1f204e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=448.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:55:22 - INFO - transformers.trainer -   {'eval_loss': 3.6394232530146837, 'epoch': 3.0, 'step': 10749}\n",
      "06/30/2020 16:55:22 - INFO - __main__ -   ***** Eval results *****\n",
      "06/30/2020 16:55:22 - INFO - __main__ -     perplexity = 38.06987370756345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run {cmd_finetuning.format(**train_params)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:55:50 - INFO - transformers.training_args -   PyTorch: setting up devices\n",
      "06/30/2020 16:55:50 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "06/30/2020 16:55:50 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='../../weights/gpt2/papers_milan/', overwrite_output_dir=True, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jun30_16-55-50_Camilo-UbuntuPC', logging_first_step=False, logging_steps=2, save_steps=5000, save_total_limit=5, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, dataloader_drop_last=False)\n",
      "06/30/2020 16:55:50 - INFO - transformers.configuration_utils -   loading configuration file ../../weights/gpt2/papers_milan/config.json\n",
      "06/30/2020 16:55:50 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "06/30/2020 16:55:50 - INFO - transformers.configuration_utils -   loading configuration file ../../weights/gpt2/papers_milan/config.json\n",
      "06/30/2020 16:55:50 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "06/30/2020 16:55:50 - INFO - transformers.tokenization_utils_base -   Model name '../../weights/gpt2/papers_milan/' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '../../weights/gpt2/papers_milan/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "06/30/2020 16:55:50 - INFO - transformers.tokenization_utils_base -   Didn't find file ../../weights/gpt2/papers_milan/added_tokens.json. We won't load it.\n",
      "06/30/2020 16:55:50 - INFO - transformers.tokenization_utils_base -   loading file ../../weights/gpt2/papers_milan/vocab.json\n",
      "06/30/2020 16:55:50 - INFO - transformers.tokenization_utils_base -   loading file ../../weights/gpt2/papers_milan/merges.txt\n",
      "06/30/2020 16:55:50 - INFO - transformers.tokenization_utils_base -   loading file None\n",
      "06/30/2020 16:55:50 - INFO - transformers.tokenization_utils_base -   loading file ../../weights/gpt2/papers_milan/special_tokens_map.json\n",
      "06/30/2020 16:55:50 - INFO - transformers.tokenization_utils_base -   loading file ../../weights/gpt2/papers_milan/tokenizer_config.json\n",
      "06/30/2020 16:55:51 - INFO - transformers.modeling_utils -   loading weights file ../../weights/gpt2/papers_milan/pytorch_model.bin\n",
      "06/30/2020 16:55:54 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "06/30/2020 16:55:54 - INFO - transformers.modeling_utils -   All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ../../weights/gpt2/papers_milan/.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "06/30/2020 16:55:54 - INFO - transformers.data.datasets.language_modeling -   Creating features from dataset file at ../../data/papers_milan/val_papers.txt\n",
      "06/30/2020 16:55:54 - WARNING - transformers.tokenization_utils_base -   Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'only_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you may want to check this is the right behavior.\n",
      "06/30/2020 16:55:54 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n",
      "06/30/2020 16:55:54 - INFO - __main__ -   *** Evaluate ***\n",
      "06/30/2020 16:55:54 - INFO - transformers.trainer -   ***** Running Evaluation *****\n",
      "06/30/2020 16:55:54 - INFO - transformers.trainer -     Num examples = 447\n",
      "06/30/2020 16:55:54 - INFO - transformers.trainer -     Batch size = 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744604a3bc0946a28d887057c97ae27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=447.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:56:02 - INFO - transformers.trainer -   {'eval_loss': 3.582757234840052, 'step': 0}\n",
      "06/30/2020 16:56:02 - INFO - __main__ -   ***** Eval results *****\n",
      "06/30/2020 16:56:02 - INFO - __main__ -     perplexity = 35.972589110633976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run {cmd_finetuning.format(**val_finetuning_params)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:56:02 - INFO - transformers.training_args -   PyTorch: setting up devices\n",
      "06/30/2020 16:56:02 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "06/30/2020 16:56:02 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='../../weights/gpt2/papers_milan/', overwrite_output_dir=True, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jun30_16-56-02_Camilo-UbuntuPC', logging_first_step=False, logging_steps=2, save_steps=5000, save_total_limit=5, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, dataloader_drop_last=False)\n",
      "06/30/2020 16:56:02 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/camilojd/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "06/30/2020 16:56:02 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "06/30/2020 16:56:03 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/camilojd/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "06/30/2020 16:56:03 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "06/30/2020 16:56:04 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/camilojd/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "06/30/2020 16:56:04 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/camilojd/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "06/30/2020 16:56:14 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/camilojd/.cache/torch/transformers/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "06/30/2020 16:56:18 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "06/30/2020 16:56:18 - WARNING - transformers.modeling_utils -   Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "06/30/2020 16:56:18 - INFO - transformers.data.datasets.language_modeling -   Creating features from dataset file at ../../data/papers_milan/val_papers.txt\n",
      "06/30/2020 16:56:18 - WARNING - transformers.tokenization_utils_base -   Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'only_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you may want to check this is the right behavior.\n",
      "06/30/2020 16:56:18 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n",
      "06/30/2020 16:56:18 - INFO - __main__ -   *** Evaluate ***\n",
      "06/30/2020 16:56:18 - INFO - transformers.trainer -   ***** Running Evaluation *****\n",
      "06/30/2020 16:56:18 - INFO - transformers.trainer -     Num examples = 447\n",
      "06/30/2020 16:56:18 - INFO - transformers.trainer -     Batch size = 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cad9887ed040d6b57c0976ff5c01aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=447.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:56:25 - INFO - transformers.trainer -   {'eval_loss': 5.189669396786615, 'step': 0}\n",
      "06/30/2020 16:56:25 - INFO - __main__ -   ***** Eval results *****\n",
      "06/30/2020 16:56:25 - INFO - __main__ -     perplexity = 179.40922985827137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run {cmd_finetuning.format(**val_params)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params_generation(MODEL_TYPE, MODEL_NAME_OR_PATH, NUM_RETURN_SEQUENCES=1, LENGTH=20):\n",
    "    return {\n",
    "        \"model_type\": MODEL_TYPE,\n",
    "        \"model_name_or_path\": MODEL_NAME_OR_PATH,\n",
    "        \"num_return_sequences\": NUM_RETURN_SEQUENCES,\n",
    "        \"length\": LENGTH\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_generation = \"\"\"../../transformers/examples/text-generation/run_generation.py \\\n",
    "    --model_type={model_type} \\\n",
    "    --model_name_or_path={model_name_or_path} \\\n",
    "    --num_return_sequences={num_return_sequences} \\\n",
    "    --length={length}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_finetuning_params = create_params_generation(MODEL_TYPE, OUTPUT_DIR, NUM_RETURN_SEQUENCES=5, LENGTH=100)\n",
    "generation_params = create_params_generation(MODEL_TYPE, MODEL_TYPE, NUM_RETURN_SEQUENCES=5, LENGTH=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:56:50 - INFO - transformers.tokenization_utils_base -   Model name '../../weights/gpt2/papers_milan/' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '../../weights/gpt2/papers_milan/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "06/30/2020 16:56:50 - INFO - transformers.tokenization_utils_base -   Didn't find file ../../weights/gpt2/papers_milan/added_tokens.json. We won't load it.\n",
      "06/30/2020 16:56:50 - INFO - transformers.tokenization_utils_base -   loading file ../../weights/gpt2/papers_milan/vocab.json\n",
      "06/30/2020 16:56:50 - INFO - transformers.tokenization_utils_base -   loading file ../../weights/gpt2/papers_milan/merges.txt\n",
      "06/30/2020 16:56:50 - INFO - transformers.tokenization_utils_base -   loading file None\n",
      "06/30/2020 16:56:50 - INFO - transformers.tokenization_utils_base -   loading file ../../weights/gpt2/papers_milan/special_tokens_map.json\n",
      "06/30/2020 16:56:50 - INFO - transformers.tokenization_utils_base -   loading file ../../weights/gpt2/papers_milan/tokenizer_config.json\n",
      "06/30/2020 16:56:50 - INFO - transformers.configuration_utils -   loading configuration file ../../weights/gpt2/papers_milan/config.json\n",
      "06/30/2020 16:56:50 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "06/30/2020 16:56:50 - INFO - transformers.modeling_utils -   loading weights file ../../weights/gpt2/papers_milan/pytorch_model.bin\n",
      "06/30/2020 16:56:53 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "06/30/2020 16:56:53 - INFO - transformers.modeling_utils -   All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ../../weights/gpt2/papers_milan/.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "06/30/2020 16:56:53 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=100, model_name_or_path='../../weights/gpt2/papers_milan/', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prompt >>> It was already stated in Lemma that the reconstruction vector which mutual information between a source vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:58:38 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATED SEQUENCE 1 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector and its corresponding reconstruction error is if and only if is such that the previous definition. The latter definition is well understood and is consistent with what was in, Lemma..,. The latter definition is to be extended for in the, Lemma.,. and see Section.. More so, we argue that, equivalently, for any real valued random process, if,,, is said to be random a, then needs to satisfy the same condition for any other real valued random process\n",
      "=== GENERATED SEQUENCE 2 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector a and a, jointly with that source vector a would be defined in a matrix of x, y, z, where the first element of the matrix is the letter of the alphabet of the vector, the last element is the second element of the vector, and the last element is the number of the vector. This fact is equivalent to saying that the quadratic form of a random vector the differential of a source vector the differential of the source vector the differential of the source vector the differential of the\n",
      "=== GENERATED SEQUENCE 3 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector and a reconstruction u in is given by the following : A definition of the in can be found in Appendix A. Such a definition a best term approximation error vector, that is, one that with, by substituting into and, the following : Finally, we note that the th sample of is given by : and the variance of is given by :. Hence, Theorem. to where, if, it can be seen from that the variance of is a function of and, in general, does\n",
      "=== GENERATED SEQUENCE 4 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector in the class of. In order to prove this, we observe that the have two such that. Let us define, such that. Then we define the following ; from of, the following expression can be written : : see Definition. By the definition of, we have the following for the class of ; namely : :,,, L, L, d, d, d, d, x, x ; see Definition. The, is an arbitrary sequence of which is always positive. By the\n",
      "=== GENERATED SEQUENCE 5 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector and an output. For the first time in this work we used a key and of Lemma, which stated that one to obtain and represent the information between the source vector and the corresponding realization. As already in Section, this result the solution to a problem which the output is in some sense related to, for example, the order distortion redundancy in and the estimation error variance of a sequence of non binary. A key result of this work is that the mutual information of and, for the case when an\n"
     ]
    }
   ],
   "source": [
    "run {cmd_generation.format(**generation_finetuning_params)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:58:45 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /home/camilojd/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "06/30/2020 16:58:45 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /home/camilojd/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "06/30/2020 16:58:45 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/camilojd/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "06/30/2020 16:58:45 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "06/30/2020 16:58:48 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /home/camilojd/.cache/torch/transformers/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "06/30/2020 16:58:51 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "06/30/2020 16:58:51 - WARNING - transformers.modeling_utils -   Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "06/30/2020 16:58:52 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=100, model_name_or_path='gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prompt >>> It was already stated in Lemma that the reconstruction vector which mutual information between a source vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2020 16:58:54 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATED SEQUENCE 1 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector and itself must exist is not an independent unit. If an approach to this problem takes a solution of an independent vector, for example, two independent factors are required to exist in the base of the source vector, and if one of them is undefined, then other factors of our description must also exist. This includes natural systems or biologically meaningful parameters of nature. These laws of nature then permit the modification of the basic matter of a system or organism. Obviously, the known specialties of any high-speed\n",
      "=== GENERATED SEQUENCE 2 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector and a value is reciprocal is called the coincopious vector and the haggaristic vector is called the abrupt vector.\n",
      "\n",
      "The combination is also known as the matter variable (now known as the haggaristic condition).\n",
      "\n",
      "I must now discuss the excursion of the factor class into the energy division. When we directly produce an electron as an excursion, we never go beyond a point at which the excursion along the excursion path is exhausted.\n",
      "\n",
      "As soon as\n",
      "=== GENERATED SEQUENCE 3 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector and an archive in a library was used in the form of reference vectors.\n",
      "\n",
      "In the default initialization of a bundle in C#, each source and archive array is simply represented by a constant value of variable type for the bundle. This means that the components of a localized collections in C# are trivial:\n",
      "\n",
      "C-asm is compiled by wrapping the specified assembly into a virtual vector (either at runtime or asynchronously) under all available c_memory conditions.\n",
      "\n",
      "or as\n",
      "=== GENERATED SEQUENCE 4 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector and an operation vector is all between the source vector and the operation vector, and could be used for doubly nested loops at the high level. Note, as always, that this is not exactly what the description says: you cannot claim that the source vector has been built to work. This should not surprise anybody. However, from what I understand, the \"gen-col-work\" notation essentially holds because since you already know the system for both source and operand, you can just turn the\n",
      "=== GENERATED SEQUENCE 5 ===\n",
      "It was already stated in Lemma that the reconstruction vector which mutual information between a source vector and its cousin is expected to be faster to generate the result is:\n",
      "\n",
      "1 vector_minus 2 vector_third_zero 5 vector_radians 1\n",
      "\n",
      "Second, let's consider an arbitrary list of numerical variants of the positive bit. In order to detect this, we use the negative scalar of the type of vector in the method. Therefore we define:\n",
      "\n",
      "1 vector_minus1 2 vector_third_zero 5 vector_radians 1\n",
      "\n",
      "\n",
      "The argument makes this\n"
     ]
    }
   ],
   "source": [
    "run {cmd_generation.format(**generation_params)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
